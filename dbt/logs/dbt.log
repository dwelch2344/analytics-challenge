2020-10-17 00:14:42.088651 (MainThread): Running with dbt=0.18.0
2020-10-17 00:14:42.509980 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:14:42.515384 (MainThread): Tracking: tracking
2020-10-17 00:14:42.518047 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a6a26df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a5cf3ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a5cf3eb0>]}
2020-10-17 00:14:42.558478 (MainThread): Partial parsing not enabled
2020-10-17 00:14:42.561426 (MainThread): Parsing macros/etc.sql
2020-10-17 00:14:42.568422 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:14:42.582525 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:14:42.618598 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:14:42.624328 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:14:42.641776 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:14:42.662723 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:14:42.667335 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:14:42.675240 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:14:42.687938 (MainThread): Parsing macros/core.sql
2020-10-17 00:14:42.695548 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:14:42.711850 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:14:42.721799 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:14:42.734628 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:14:42.760936 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:14:42.788810 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:14:42.793826 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:14:42.846847 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:14:42.858840 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:14:42.863867 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:14:42.876853 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:14:42.916382 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:14:42.998308 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:14:43.001568 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:14:43.005482 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:14:43.008894 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:14:43.024725 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:14:43.029954 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:14:43.032816 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:14:43.036859 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:14:43.040381 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:14:43.045700 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:14:43.055576 (MainThread): * Deprecation Warning: dbt v0.17.0 introduces a new config format for the
dbt_project.yml file. Support for the existing version 1 format will be removed
in a future release of dbt. The following packages are currently configured with
config version 1:
 - dwelo

For upgrading instructions, consult the documentation:
  https://docs.getdbt.com/docs/guides/migration-guide/upgrading-to-0-17-0

2020-10-17 00:14:43.057148 (MainThread): Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '13ac52fe-d423-4470-89d3-660958ea18ec', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a82ced90>]}
2020-10-17 00:14:43.067336 (MainThread): Partial parsing not enabled
2020-10-17 00:14:43.184460 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:14:43.214643 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:14:43.230746 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:14:43.245857 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:14:43.261417 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:14:43.366685 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_thermostat_setpoint' (tests/staging/commands/stg_commands_thermostat_setpoint.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:14:43.367802 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_locked_state' (tests/staging/commands/stg_commands_locked_state.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:14:43.369318 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_switch_state' (tests/staging/commands/stg_commands_switch_state.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:14:43.370780 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_pin_assignment' (tests/staging/commands/stg_commands_pin_assignment.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:14:43.372128 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_thermostat_mode' (tests/staging/commands/stg_commands_thermostat_mode.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:14:43.424151 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dwelo

2020-10-17 00:14:43.491546 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-10-17 00:14:43.493226 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-10-17 00:14:43.494350 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a5ab2700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a5b088b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1a5b082b0>]}
2020-10-17 00:14:43.495614 (MainThread): Flushing usage events
2020-10-17 00:14:43.910076 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 00:36:45.398912 (MainThread): Running with dbt=0.18.0
2020-10-17 00:36:45.657079 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:36:45.663341 (MainThread): Tracking: tracking
2020-10-17 00:36:45.666184 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45ce685b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45c153eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45c153e80>]}
2020-10-17 00:36:45.711467 (MainThread): Partial parsing not enabled
2020-10-17 00:36:45.714255 (MainThread): Parsing macros/etc.sql
2020-10-17 00:36:45.719622 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:36:45.732555 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:36:45.766669 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:36:45.772605 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:36:45.790112 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:36:45.811275 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:36:45.815476 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:36:45.823309 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:36:45.829113 (MainThread): Parsing macros/core.sql
2020-10-17 00:36:45.835397 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:36:45.850996 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:36:45.860184 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:36:45.871374 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:36:45.897596 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:36:45.924679 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:36:45.929008 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:36:45.981287 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:36:45.991440 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:36:45.995109 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:36:46.006983 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:36:46.046189 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:36:46.126582 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:36:46.129445 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:36:46.133104 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:36:46.136384 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:36:46.151619 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:36:46.156016 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:36:46.159762 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:36:46.163454 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:36:46.166579 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:36:46.171390 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:36:46.180984 (MainThread): * Deprecation Warning: dbt v0.17.0 introduces a new config format for the
dbt_project.yml file. Support for the existing version 1 format will be removed
in a future release of dbt. The following packages are currently configured with
config version 1:
 - dwelo

For upgrading instructions, consult the documentation:
  https://docs.getdbt.com/docs/guides/migration-guide/upgrading-to-0-17-0

2020-10-17 00:36:46.182337 (MainThread): Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9a5a68ef-a48b-4e39-88f1-066aa95d525b', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45e72dd60>]}
2020-10-17 00:36:46.191735 (MainThread): Partial parsing not enabled
2020-10-17 00:36:46.301537 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:36:46.331085 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:36:46.349679 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:36:46.365336 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:36:46.380710 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:36:46.483773 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_thermostat_setpoint' (tests/staging/commands/stg_commands_thermostat_setpoint.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:36:46.484856 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_locked_state' (tests/staging/commands/stg_commands_locked_state.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:36:46.486130 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_switch_state' (tests/staging/commands/stg_commands_switch_state.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:36:46.487384 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_pin_assignment' (tests/staging/commands/stg_commands_pin_assignment.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:36:46.488620 (MainThread): [WARNING]: Test 'test.dwelo.stg_commands_thermostat_mode' (tests/staging/commands/stg_commands_thermostat_mode.sql) depends on a node named 'stg_commands' which was not found
2020-10-17 00:36:46.537152 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dwelo

2020-10-17 00:36:46.600455 (MainThread): Found 0 models, 0 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 0 sources
2020-10-17 00:36:46.602466 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-10-17 00:36:46.603478 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45bf11a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45bf67b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45bf67280>]}
2020-10-17 00:36:46.604571 (MainThread): Flushing usage events
2020-10-17 00:36:47.081110 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 00:45:05.230244 (MainThread): Running with dbt=0.18.0
2020-10-17 00:45:05.489685 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:45:05.496007 (MainThread): Tracking: tracking
2020-10-17 00:45:05.498680 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf8216d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf7561fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf7561f70>]}
2020-10-17 00:45:05.543531 (MainThread): Partial parsing not enabled
2020-10-17 00:45:05.545865 (MainThread): Parsing macros/etc.sql
2020-10-17 00:45:05.552868 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:45:05.566018 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:45:05.600533 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:45:05.606049 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:45:05.624399 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:45:05.644569 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:45:05.648619 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:45:05.656379 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:45:05.662467 (MainThread): Parsing macros/core.sql
2020-10-17 00:45:05.668713 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:45:05.683903 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:45:05.693391 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:45:05.704419 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:45:05.729500 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:45:05.756170 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:45:05.761058 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:45:05.813136 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:45:05.824176 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:45:05.828178 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:45:05.841051 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:45:05.876640 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:45:05.955931 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:45:05.959121 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:45:05.962899 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:45:05.966036 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:45:05.981557 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:45:05.985676 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:45:05.988006 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:45:05.991397 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:45:05.994551 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:45:05.999689 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:45:06.012168 (MainThread): * Deprecation Warning: dbt v0.17.0 introduces a new config format for the
dbt_project.yml file. Support for the existing version 1 format will be removed
in a future release of dbt. The following packages are currently configured with
config version 1:
 - dwelo

For upgrading instructions, consult the documentation:
  https://docs.getdbt.com/docs/guides/migration-guide/upgrading-to-0-17-0

2020-10-17 00:45:06.013416 (MainThread): Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '02e8dc96-0474-4847-af71-43d51e879899', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf9abfe50>]}
2020-10-17 00:45:06.023326 (MainThread): Partial parsing not enabled
2020-10-17 00:45:06.135049 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 00:45:06.178351 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 00:45:06.201057 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 00:45:06.242283 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:45:06.258859 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:45:06.273984 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:45:06.289457 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:45:06.304535 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:45:06.624740 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf73928e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf736aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bf73cbd90>]}
2020-10-17 00:45:06.625815 (MainThread): Flushing usage events
2020-10-17 00:45:07.018882 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 00:45:07.021443 (MainThread): Encountered an error:
2020-10-17 00:45:07.023293 (MainThread): Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Model 'model.dwelo.stg_commands' (models/staging/commands/stg_commands.sql) depends on a node named 'base_sync_map_updates' which was not found
2020-10-17 00:45:07.030879 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 678, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 350, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 326, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 298, in process_manifest
    process_refs(manifest, project_name)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 602, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 584, in _process_refs_for_node
    invalid_ref_fail_unless_test(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 382, in invalid_ref_fail_unless_test
    ref_target_not_found(
  File "/usr/local/lib/python3.8/site-packages/dbt/exceptions.py", line 538, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Model 'model.dwelo.stg_commands' (models/staging/commands/stg_commands.sql) depends on a node named 'base_sync_map_updates' which was not found

2020-10-17 00:45:44.887809 (MainThread): Running with dbt=0.18.0
2020-10-17 00:45:45.130569 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:45:45.138461 (MainThread): Tracking: tracking
2020-10-17 00:45:45.141272 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e018a3d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e00b73970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e00b73940>]}
2020-10-17 00:45:45.182458 (MainThread): Partial parsing not enabled
2020-10-17 00:45:45.185257 (MainThread): Parsing macros/etc.sql
2020-10-17 00:45:45.189552 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:45:45.202277 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:45:45.245936 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:45:45.253012 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:45:45.270068 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:45:45.291416 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:45:45.294841 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:45:45.301917 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:45:45.307626 (MainThread): Parsing macros/core.sql
2020-10-17 00:45:45.315190 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:45:45.333552 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:45:45.342305 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:45:45.354704 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:45:45.380388 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:45:45.408600 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:45:45.412389 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:45:45.464558 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:45:45.475354 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:45:45.478893 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:45:45.489917 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:45:45.528123 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:45:45.608868 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:45:45.611248 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:45:45.614489 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:45:45.617587 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:45:45.632270 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:45:45.636000 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:45:45.638473 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:45:45.642278 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:45:45.645481 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:45:45.650357 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:45:45.667188 (MainThread): Partial parsing not enabled
2020-10-17 00:45:45.765490 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 00:45:45.811894 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 00:45:45.840164 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 00:45:45.884194 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:45:45.905869 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:45:45.927535 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:45:45.947954 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:45:45.966590 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:45:46.341818 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e00a14f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0096f5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e00a58880>]}
2020-10-17 00:45:46.342521 (MainThread): Flushing usage events
2020-10-17 00:45:46.709340 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 00:45:46.711396 (MainThread): Encountered an error:
2020-10-17 00:45:46.712872 (MainThread): Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Model 'model.dwelo.stg_commands' (models/staging/commands/stg_commands.sql) depends on a node named 'base_sync_map_updates' which was not found
2020-10-17 00:45:46.716366 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 678, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 350, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 326, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 298, in process_manifest
    process_refs(manifest, project_name)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 602, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 584, in _process_refs_for_node
    invalid_ref_fail_unless_test(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 382, in invalid_ref_fail_unless_test
    ref_target_not_found(
  File "/usr/local/lib/python3.8/site-packages/dbt/exceptions.py", line 538, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Model 'model.dwelo.stg_commands' (models/staging/commands/stg_commands.sql) depends on a node named 'base_sync_map_updates' which was not found

2020-10-17 00:52:28.340753 (MainThread): Running with dbt=0.18.0
2020-10-17 00:52:28.630219 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:52:28.639109 (MainThread): Tracking: tracking
2020-10-17 00:52:28.641983 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd76965d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd75c359a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd75c35970>]}
2020-10-17 00:52:28.690481 (MainThread): Partial parsing not enabled
2020-10-17 00:52:28.692889 (MainThread): Parsing macros/etc.sql
2020-10-17 00:52:28.697290 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:52:28.710546 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:52:28.744953 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:52:28.751323 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:52:28.768839 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:52:28.792839 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:52:28.796862 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:52:28.805622 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:52:28.812173 (MainThread): Parsing macros/core.sql
2020-10-17 00:52:28.819489 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:52:28.839298 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:52:28.851937 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:52:28.865176 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:52:28.892879 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:52:28.922735 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:52:28.927572 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:52:28.981655 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:52:28.992319 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:52:28.995891 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:52:29.008292 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:52:29.043839 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:52:29.125506 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:52:29.128151 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:52:29.131449 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:52:29.134670 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:52:29.149562 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:52:29.153361 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:52:29.155918 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:52:29.160219 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:52:29.165003 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:52:29.170264 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:52:29.187546 (MainThread): Partial parsing not enabled
2020-10-17 00:52:29.295354 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 00:52:29.307919 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd75bb6670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd75b19c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efd75ab7220>]}
2020-10-17 00:52:29.309593 (MainThread): Flushing usage events
2020-10-17 00:52:29.722482 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-17 00:52:29.725728 (MainThread): Encountered an error:
2020-10-17 00:52:29.728210 (MainThread): Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  expected token ',', got 'analytics'
    line 61
      from {{ source(''analytics-interview'', ''interview_source'') }}
2020-10-17 00:52:29.741987 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 61, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'analytics'
  line 61
    from {{ source(''analytics-interview'', ''interview_source'') }}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 678, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 348, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 204, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 177, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 133, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/base.py", line 429, in parse_file
    self.parse_node(file_block)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/base.py", line 402, in parse_node
    self.render_update(node, config)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/base.py", line 377, in render_update
    self.render_with_context(node, config)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/base.py", line 288, in render_with_context
    get_rendered(
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 570, in get_rendered
    template = get_template(
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 499, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model stg_commands (models/staging/commands/stg_commands.sql)
  expected token ',', got 'analytics'
    line 61
      from {{ source(''analytics-interview'', ''interview_source'') }}

2020-10-17 00:52:56.155581 (MainThread): Running with dbt=0.18.0
2020-10-17 00:52:56.403770 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:52:56.412398 (MainThread): Tracking: tracking
2020-10-17 00:52:56.414912 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf3ba0670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf2e8d880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf2e8d850>]}
2020-10-17 00:52:56.453617 (MainThread): Partial parsing not enabled
2020-10-17 00:52:56.455676 (MainThread): Parsing macros/etc.sql
2020-10-17 00:52:56.460017 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:52:56.472510 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:52:56.507635 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:52:56.512954 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:52:56.528655 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:52:56.549146 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:52:56.553019 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:52:56.560839 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:52:56.566819 (MainThread): Parsing macros/core.sql
2020-10-17 00:52:56.573136 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:52:56.587989 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:52:56.596502 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:52:56.607759 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:52:56.634114 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:52:56.660140 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:52:56.664427 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:52:56.715616 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:52:56.726382 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:52:56.730232 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:52:56.741498 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:52:56.776289 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:52:56.854858 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:52:56.857887 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:52:56.861432 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:52:56.864789 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:52:56.879823 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:52:56.883930 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:52:56.886418 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:52:56.890521 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:52:56.893948 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:52:56.898759 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:52:56.916284 (MainThread): Partial parsing not enabled
2020-10-17 00:52:57.013551 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 00:52:57.049439 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 00:52:57.071697 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 00:52:57.110792 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:52:57.133008 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:52:57.155271 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:52:57.176951 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:52:57.198145 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:52:57.257502 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf2e77730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf2cfc640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fabf2cfc670>]}
2020-10-17 00:52:57.259298 (MainThread): Flushing usage events
2020-10-17 00:52:57.644743 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 00:52:57.648150 (MainThread): Encountered an error:
2020-10-17 00:52:57.650132 (MainThread): Compilation Error
  Failed to render models/staging/commands/schema.yml from project dwelo: Compilation Error
    Could not render {{var('base_source_schema')}}: Required var 'base_source_schema' not found in config:
    Vars supplied to <Configuration> = {}
2020-10-17 00:52:57.661462 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/config/renderer.py", line 41, in render_value
    return get_rendered(value, self.context, native=True)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 187, in render
    return self.environment.handle_exception()
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 138, in quoted_native_concat
    head = list(islice(nodes, 2))
  File "<template>", line 1, in top-level template code
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/context/configured.py", line 64, in __call__
    return self.get_missing_var(var_name)
  File "/usr/local/lib/python3.8/site-packages/dbt/context/base.py", line 129, in get_missing_var
    raise_compiler_error(msg, self._node)
  File "/usr/local/lib/python3.8/site-packages/dbt/exceptions.py", line 407, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  Required var 'base_source_schema' not found in config:
  Vars supplied to <Configuration> = {}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/schemas.py", line 514, in parse_file
    dct = self.raw_renderer.render_data(dct)
  File "/usr/local/lib/python3.8/site-packages/dbt/config/renderer.py", line 50, in render_data
    return deep_map(self.render_entry, data)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 217, in deep_map
    return _deep_map(func, value, ())
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 180, in _deep_map
    ret = {
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 181, in <dictcomp>
    k: _deep_map(func, v, (keypath + (str(k),)))
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 175, in _deep_map
    ret = [
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 176, in <listcomp>
    _deep_map(func, v, (keypath + (idx,)))
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 180, in _deep_map
    ret = {
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 181, in <dictcomp>
    k: _deep_map(func, v, (keypath + (str(k),)))
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 185, in _deep_map
    ret = func(value, keypath)
  File "/usr/local/lib/python3.8/site-packages/dbt/config/renderer.py", line 30, in render_entry
    return self.render_value(value, keypath)
  File "/usr/local/lib/python3.8/site-packages/dbt/config/renderer.py", line 44, in render_value
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Could not render {{var('base_source_schema')}}: Required var 'base_source_schema' not found in config:
  Vars supplied to <Configuration> = {}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 399, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 118, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 78, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 65, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 678, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 348, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 204, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 177, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/manifest.py", line 133, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/lib/python3.8/site-packages/dbt/parser/schemas.py", line 516, in parse_file
    raise CompilationException(
dbt.exceptions.CompilationException: Compilation Error
  Failed to render models/staging/commands/schema.yml from project dwelo: Compilation Error
    Could not render {{var('base_source_schema')}}: Required var 'base_source_schema' not found in config:
    Vars supplied to <Configuration> = {}

2020-10-17 00:54:03.094749 (MainThread): Running with dbt=0.18.0
2020-10-17 00:54:03.339287 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 00:54:03.345445 (MainThread): Tracking: tracking
2020-10-17 00:54:03.348172 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfd378d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfc648940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfc648910>]}
2020-10-17 00:54:03.391694 (MainThread): Partial parsing not enabled
2020-10-17 00:54:03.394032 (MainThread): Parsing macros/etc.sql
2020-10-17 00:54:03.398153 (MainThread): Parsing macros/catalog.sql
2020-10-17 00:54:03.410553 (MainThread): Parsing macros/adapters.sql
2020-10-17 00:54:03.444047 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 00:54:03.449977 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 00:54:03.467003 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 00:54:03.487842 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 00:54:03.492093 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 00:54:03.499925 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 00:54:03.505649 (MainThread): Parsing macros/core.sql
2020-10-17 00:54:03.511933 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 00:54:03.527825 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 00:54:03.536320 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 00:54:03.547139 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 00:54:03.572890 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 00:54:03.599043 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 00:54:03.603345 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 00:54:03.654548 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 00:54:03.664993 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 00:54:03.668912 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 00:54:03.680444 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 00:54:03.715583 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 00:54:03.794856 (MainThread): Parsing macros/etc/query.sql
2020-10-17 00:54:03.797376 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 00:54:03.800550 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 00:54:03.803785 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 00:54:03.818672 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 00:54:03.823263 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 00:54:03.825830 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 00:54:03.829326 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 00:54:03.832646 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 00:54:03.837549 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 00:54:03.855095 (MainThread): Partial parsing not enabled
2020-10-17 00:54:03.958419 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 00:54:03.993522 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 00:54:04.014116 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 00:54:04.050938 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 00:54:04.073151 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 00:54:04.093117 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 00:54:04.113366 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 00:54:04.132848 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 00:54:04.721372 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 00:54:04.724672 (MainThread): 
2020-10-17 00:54:04.726292 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 00:54:04.770235 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 00:54:04.771343 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 00:54:10.790127 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 00:54:10.792159 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 00:54:10.802097 (MainThread): Connection 'master' was properly closed.
2020-10-17 00:54:10.803440 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 00:54:10.804861 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfc532880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfc372c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dfc2fcd60>]}
2020-10-17 00:54:10.806256 (MainThread): Flushing usage events
2020-10-17 00:54:11.205588 (MainThread): Encountered an error:
2020-10-17 00:54:11.207877 (MainThread): Could not find command, ensure it is in the user's PATH: "gcloud"
2020-10-17 00:54:11.222037 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 206, in open
    handle = cls.get_bigquery_client(connection.credentials)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 187, in get_bigquery_client
    creds = cls.get_bigquery_credentials(profile_credentials)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in get_bigquery_credentials
    credentials, project_id = google.auth.default(scopes=cls.SCOPE)
  File "/usr/local/lib/python3.8/site-packages/google/auth/_default.py", line 354, in default
    raise exceptions.DefaultCredentialsError(_HELP_MESSAGE)
google.auth.exceptions.DefaultCredentialsError: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 419, in run_cmd
    proc = subprocess.Popen(
  File "/usr/local/lib/python3.8/subprocess.py", line 854, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1702, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'gcloud'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 395, in before_run
    self.populate_adapter_cache(adapter)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 359, in populate_adapter_cache
    adapter.set_relations_cache(self.manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 368, in set_relations_cache
    self._relations_cache_for_schemas(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 345, in _relations_cache_for_schemas
    for relation in future.result():
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 256, in list_relations_without_caching
    client = connection.handle
  File "/usr/local/lib/python3.8/site-packages/dbt/contracts/connection.py", line 71, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/site-packages/dbt/contracts/connection.py", line 96, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 210, in open
    gcloud.setup_default_credentials()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/gcloud.py", line 23, in setup_default_credentials
    if gcloud_installed():
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/gcloud.py", line 15, in gcloud_installed
    run_cmd('.', ['gcloud', '--version'])
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 428, in run_cmd
    _interpret_oserror(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 396, in _interpret_oserror
    _handle_posix_error(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 362, in _handle_posix_error
    _handle_posix_cmd_error(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 335, in _handle_posix_cmd_error
    raise dbt.exceptions.ExecutableError(cwd, cmd, message)
dbt.exceptions.ExecutableError: Could not find command, ensure it is in the user's PATH: "gcloud"

2020-10-17 01:03:41.024959 (MainThread): Running with dbt=0.18.0
2020-10-17 01:03:41.267705 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 01:03:41.277505 (MainThread): Tracking: tracking
2020-10-17 01:03:41.280191 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca808bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca735a8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca735a8b0>]}
2020-10-17 01:03:41.317816 (MainThread): Partial parsing not enabled
2020-10-17 01:03:41.320324 (MainThread): Parsing macros/etc.sql
2020-10-17 01:03:41.324059 (MainThread): Parsing macros/catalog.sql
2020-10-17 01:03:41.336608 (MainThread): Parsing macros/adapters.sql
2020-10-17 01:03:41.369583 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 01:03:41.375109 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 01:03:41.391439 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 01:03:41.411463 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 01:03:41.415648 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 01:03:41.422754 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 01:03:41.428480 (MainThread): Parsing macros/core.sql
2020-10-17 01:03:41.434655 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 01:03:41.449812 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 01:03:41.458182 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 01:03:41.468932 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 01:03:41.494429 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 01:03:41.520554 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 01:03:41.524328 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 01:03:41.574774 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 01:03:41.585924 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 01:03:41.589963 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 01:03:41.601506 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 01:03:41.639456 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 01:03:41.717661 (MainThread): Parsing macros/etc/query.sql
2020-10-17 01:03:41.720050 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 01:03:41.723208 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 01:03:41.726397 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 01:03:41.741176 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 01:03:41.744884 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 01:03:41.746956 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 01:03:41.750455 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 01:03:41.753484 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 01:03:41.758205 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 01:03:41.773811 (MainThread): Partial parsing not enabled
2020-10-17 01:03:41.871242 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 01:03:41.904144 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 01:03:41.923147 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 01:03:41.956587 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 01:03:41.976532 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 01:03:41.994770 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 01:03:42.013309 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 01:03:42.031133 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 01:03:42.591486 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 01:03:42.594495 (MainThread): 
2020-10-17 01:03:42.595895 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 01:03:42.630641 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 01:03:42.632463 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 01:03:42.633521 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 01:03:42.634396 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 01:03:42.646121 (MainThread): Connection 'master' was properly closed.
2020-10-17 01:03:42.647708 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 01:03:42.649014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca7245820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca72cff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbca70114c0>]}
2020-10-17 01:03:42.650359 (MainThread): Flushing usage events
2020-10-17 01:03:43.046625 (MainThread): Encountered an error:
2020-10-17 01:03:43.049125 (MainThread): Could not find command, ensure it is in the user's PATH: "gcloud"
2020-10-17 01:03:43.055586 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 206, in open
    handle = cls.get_bigquery_client(connection.credentials)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 187, in get_bigquery_client
    creds = cls.get_bigquery_credentials(profile_credentials)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 157, in get_bigquery_credentials
    credentials, project_id = google.auth.default(scopes=cls.SCOPE)
  File "/usr/local/lib/python3.8/site-packages/google/auth/_default.py", line 338, in default
    credentials, project_id = checker()
  File "/usr/local/lib/python3.8/site-packages/google/auth/_default.py", line 185, in _get_explicit_environ_credentials
    credentials, project_id = load_credentials_from_file(
  File "/usr/local/lib/python3.8/site-packages/google/auth/_default.py", line 96, in load_credentials_from_file
    raise exceptions.DefaultCredentialsError(
google.auth.exceptions.DefaultCredentialsError: File /Users/speck/gcp_laptop_key.json was not found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 419, in run_cmd
    proc = subprocess.Popen(
  File "/usr/local/lib/python3.8/subprocess.py", line 854, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File "/usr/local/lib/python3.8/subprocess.py", line 1702, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
FileNotFoundError: [Errno 2] No such file or directory: 'gcloud'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 395, in before_run
    self.populate_adapter_cache(adapter)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 359, in populate_adapter_cache
    adapter.set_relations_cache(self.manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 368, in set_relations_cache
    self._relations_cache_for_schemas(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 345, in _relations_cache_for_schemas
    for relation in future.result():
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 256, in list_relations_without_caching
    client = connection.handle
  File "/usr/local/lib/python3.8/site-packages/dbt/contracts/connection.py", line 71, in handle
    self._handle.resolve(self)
  File "/usr/local/lib/python3.8/site-packages/dbt/contracts/connection.py", line 96, in resolve
    return self.opener(connection)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 210, in open
    gcloud.setup_default_credentials()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/gcloud.py", line 23, in setup_default_credentials
    if gcloud_installed():
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/gcloud.py", line 15, in gcloud_installed
    run_cmd('.', ['gcloud', '--version'])
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 428, in run_cmd
    _interpret_oserror(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 396, in _interpret_oserror
    _handle_posix_error(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 362, in _handle_posix_error
    _handle_posix_cmd_error(exc, cwd, cmd)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/system.py", line 335, in _handle_posix_cmd_error
    raise dbt.exceptions.ExecutableError(cwd, cmd, message)
dbt.exceptions.ExecutableError: Could not find command, ensure it is in the user's PATH: "gcloud"

2020-10-17 01:22:10.493573 (MainThread): Running with dbt=0.18.0
2020-10-17 01:22:10.741076 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 01:22:10.746881 (MainThread): Tracking: tracking
2020-10-17 01:22:10.749688 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1055a10ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1054cdf8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1054cdf8b0>]}
2020-10-17 01:22:10.790959 (MainThread): Partial parsing not enabled
2020-10-17 01:22:10.793335 (MainThread): Parsing macros/etc.sql
2020-10-17 01:22:10.797389 (MainThread): Parsing macros/catalog.sql
2020-10-17 01:22:10.810660 (MainThread): Parsing macros/adapters.sql
2020-10-17 01:22:10.844178 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 01:22:10.850003 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 01:22:10.867219 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 01:22:10.888321 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 01:22:10.892176 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 01:22:10.899791 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 01:22:10.905704 (MainThread): Parsing macros/core.sql
2020-10-17 01:22:10.912381 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 01:22:10.928001 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 01:22:10.936431 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 01:22:10.947391 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 01:22:10.972627 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 01:22:10.999132 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 01:22:11.003373 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 01:22:11.056123 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 01:22:11.066435 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 01:22:11.070088 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 01:22:11.081478 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 01:22:11.117701 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 01:22:11.196690 (MainThread): Parsing macros/etc/query.sql
2020-10-17 01:22:11.199396 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 01:22:11.203120 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 01:22:11.206319 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 01:22:11.221491 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 01:22:11.225505 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 01:22:11.227733 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 01:22:11.232952 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 01:22:11.236250 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 01:22:11.241391 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 01:22:11.258869 (MainThread): Partial parsing not enabled
2020-10-17 01:22:11.360328 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 01:22:11.393759 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 01:22:11.413180 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 01:22:11.449712 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 01:22:11.470136 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 01:22:11.489663 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 01:22:11.509517 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 01:22:11.528068 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 01:22:12.101945 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 01:22:12.104684 (MainThread): 
2020-10-17 01:22:12.105987 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 01:22:12.139402 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 01:22:12.141465 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 01:22:12.143131 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 01:22:12.145365 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 01:22:13.563094 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 01:22:13.564285 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 01:22:13.565169 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 01:22:29.010880 (ThreadPoolExecutor-1_0): STDOUT: "b'Enter verification code: '"
2020-10-17 01:22:29.012394 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \nGo to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=ataoUp-iNb-UOgbeJ8H9KVnHtkM679VYux6eTQwWbpk&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n\n\n\n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 01:22:29.013680 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 01:22:29.015884 (MainThread): Connection 'master' was properly closed.
2020-10-17 01:22:29.016967 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 01:22:29.018055 (MainThread): Flushing usage events
2020-10-17 01:22:29.425092 (MainThread): ctrl-c
2020-10-17 04:31:16.245422 (MainThread): Running with dbt=0.18.0
2020-10-17 04:31:16.490513 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:31:16.503732 (MainThread): Tracking: tracking
2020-10-17 04:31:16.506776 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f430d83ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f430cb0f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f430cb0f9a0>]}
2020-10-17 04:31:16.553465 (MainThread): Partial parsing not enabled
2020-10-17 04:31:16.555981 (MainThread): Parsing macros/etc.sql
2020-10-17 04:31:16.559850 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:31:16.572550 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:31:16.607088 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:31:16.612308 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:31:16.628754 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:31:16.651466 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:31:16.655502 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:31:16.663118 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:31:16.669162 (MainThread): Parsing macros/core.sql
2020-10-17 04:31:16.675386 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:31:16.693785 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:31:16.702597 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:31:16.713767 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:31:16.739122 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:31:16.765619 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:31:16.770275 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:31:16.828103 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:31:16.838523 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:31:16.842072 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:31:16.853282 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:31:16.890552 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:31:16.968943 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:31:16.971812 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:31:16.975287 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:31:16.978257 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:31:16.993402 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:31:16.997383 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:31:16.999978 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:31:17.003848 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:31:17.006905 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:31:17.011708 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:31:17.027327 (MainThread): Partial parsing not enabled
2020-10-17 04:31:17.126330 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:31:17.169015 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:31:17.189816 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:31:17.239963 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:31:17.262158 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:31:17.283700 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:31:17.305372 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:31:17.325401 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:31:17.907509 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:31:17.910702 (MainThread): 
2020-10-17 04:31:17.912247 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:31:17.948814 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:31:17.950905 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:31:17.952273 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:31:17.953677 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:31:19.327623 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:31:19.329383 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:31:19.330696 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:31:24.677602 (ThreadPoolExecutor-1_0): STDOUT: "b'Enter verification code: '"
2020-10-17 04:31:24.679352 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \nGo to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=T_QY0EUk1FmASbXuMOfGDf7YV-Gmr1shOZxVNBl-6oQ&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n\n\n\n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:31:24.680895 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:31:24.683529 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:31:24.684864 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:31:24.685848 (MainThread): Flushing usage events
2020-10-17 04:31:25.054213 (MainThread): ctrl-c
2020-10-17 04:38:26.761929 (MainThread): Running with dbt=0.18.0
2020-10-17 04:38:27.004546 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:38:27.010619 (MainThread): Tracking: tracking
2020-10-17 04:38:27.013461 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40a709dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4099d9a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4099d9a30>]}
2020-10-17 04:38:27.056192 (MainThread): Partial parsing not enabled
2020-10-17 04:38:27.058529 (MainThread): Parsing macros/etc.sql
2020-10-17 04:38:27.061845 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:38:27.074700 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:38:27.108993 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:38:27.114634 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:38:27.130915 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:38:27.153341 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:38:27.157379 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:38:27.165717 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:38:27.171844 (MainThread): Parsing macros/core.sql
2020-10-17 04:38:27.178270 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:38:27.193350 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:38:27.202430 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:38:27.213570 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:38:27.239009 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:38:27.265785 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:38:27.269699 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:38:27.320740 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:38:27.331847 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:38:27.335644 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:38:27.346960 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:38:27.382693 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:38:27.461888 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:38:27.464758 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:38:27.468383 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:38:27.472179 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:38:27.487637 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:38:27.491468 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:38:27.494751 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:38:27.500142 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:38:27.503320 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:38:27.508474 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:38:27.525699 (MainThread): Partial parsing not enabled
2020-10-17 04:38:27.626227 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:38:27.661315 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:38:27.681743 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:38:27.717948 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:38:27.739864 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:38:27.769317 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:38:27.790198 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:38:27.810148 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:38:28.416629 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:38:28.420550 (MainThread): 
2020-10-17 04:38:28.421986 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:38:28.454768 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:38:28.457072 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:38:28.459782 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:38:28.461637 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:38:29.037495 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:38:29.039068 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:38:29.040157 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:38:37.351093 (ThreadPoolExecutor-1_0): STDOUT: "b''"
2020-10-17 04:38:37.352513 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:38:37.353407 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:38:37.355518 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:38:37.356489 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:38:37.357364 (MainThread): Flushing usage events
2020-10-17 04:38:37.751495 (MainThread): ctrl-c
2020-10-17 04:39:38.881888 (MainThread): Running with dbt=0.18.0
2020-10-17 04:39:39.122170 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:39:39.127876 (MainThread): Tracking: tracking
2020-10-17 04:39:39.130542 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55f18f1ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55f0bc08e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55f0bc08b0>]}
2020-10-17 04:39:39.172526 (MainThread): Partial parsing not enabled
2020-10-17 04:39:39.174707 (MainThread): Parsing macros/etc.sql
2020-10-17 04:39:39.177718 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:39:39.190113 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:39:39.223581 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:39:39.228858 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:39:39.244386 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:39:39.264873 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:39:39.268517 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:39:39.276097 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:39:39.281658 (MainThread): Parsing macros/core.sql
2020-10-17 04:39:39.287820 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:39:39.302794 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:39:39.310855 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:39:39.321573 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:39:39.346834 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:39:39.372643 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:39:39.376411 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:39:39.426555 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:39:39.436836 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:39:39.440286 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:39:39.451343 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:39:39.486494 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:39:39.565931 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:39:39.568577 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:39:39.572060 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:39:39.575537 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:39:39.590850 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:39:39.615681 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:39:39.619555 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:39:39.624593 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:39:39.628801 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:39:39.634195 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:39:39.649365 (MainThread): Partial parsing not enabled
2020-10-17 04:39:39.747803 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:39:39.780381 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:39:39.799708 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:39:39.832908 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:39:39.853592 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:39:39.870890 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:39:39.889846 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:39:39.907912 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:39:40.468395 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:39:40.471191 (MainThread): 
2020-10-17 04:39:40.472505 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:39:40.505621 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:39:40.507188 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:39:40.508216 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:39:40.508933 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:39:41.065988 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:39:41.067538 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:39:41.068413 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:39:44.572026 (ThreadPoolExecutor-1_0): STDOUT: "b''"
2020-10-17 04:39:44.573481 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:39:44.574248 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:39:44.576223 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:39:44.577435 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:39:44.578332 (MainThread): Flushing usage events
2020-10-17 04:39:44.936921 (MainThread): ctrl-c
2020-10-17 04:40:45.561548 (MainThread): Running with dbt=0.18.0
2020-10-17 04:40:45.760728 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:40:45.768536 (MainThread): Tracking: tracking
2020-10-17 04:40:45.771174 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e9eb948e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e9de87c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e9de87c10>]}
2020-10-17 04:40:45.812900 (MainThread): Partial parsing not enabled
2020-10-17 04:40:45.814872 (MainThread): Parsing macros/etc.sql
2020-10-17 04:40:45.818037 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:40:45.830261 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:40:45.863550 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:40:45.869083 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:40:45.885543 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:40:45.906024 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:40:45.909722 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:40:45.917105 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:40:45.922826 (MainThread): Parsing macros/core.sql
2020-10-17 04:40:45.929148 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:40:45.944679 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:40:45.953128 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:40:45.963922 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:40:45.989534 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:40:46.016439 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:40:46.020601 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:40:46.073515 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:40:46.084261 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:40:46.087928 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:40:46.099009 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:40:46.135402 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:40:46.214728 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:40:46.217591 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:40:46.221198 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:40:46.224530 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:40:46.239572 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:40:46.244004 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:40:46.247020 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:40:46.250499 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:40:46.253446 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:40:46.258162 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:40:46.274824 (MainThread): Partial parsing not enabled
2020-10-17 04:40:46.373419 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:40:46.407806 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:40:46.428385 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:40:46.463887 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:40:46.484642 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:40:46.503781 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:40:46.525022 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:40:46.544689 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:40:47.111155 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:40:47.113975 (MainThread): 
2020-10-17 04:40:47.115323 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:40:47.149110 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:40:47.151035 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:40:47.152533 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:40:47.153791 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:40:47.731090 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:40:47.732377 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:40:47.733269 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:40:49.637589 (ThreadPoolExecutor-1_0): STDOUT: "b''"
2020-10-17 04:40:49.639256 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:40:49.640301 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:40:49.642567 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:40:49.643683 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:40:49.644676 (MainThread): Flushing usage events
2020-10-17 04:40:50.046183 (MainThread): ctrl-c
2020-10-17 04:42:01.028835 (MainThread): Running with dbt=0.18.0
2020-10-17 04:42:01.262181 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:42:01.269396 (MainThread): Tracking: tracking
2020-10-17 04:42:01.272089 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a47de2f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4712fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a4712fca0>]}
2020-10-17 04:42:01.314978 (MainThread): Partial parsing not enabled
2020-10-17 04:42:01.317715 (MainThread): Parsing macros/etc.sql
2020-10-17 04:42:01.321523 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:42:01.334277 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:42:01.369267 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:42:01.375037 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:42:01.391664 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:42:01.413390 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:42:01.417781 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:42:01.425506 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:42:01.431478 (MainThread): Parsing macros/core.sql
2020-10-17 04:42:01.437650 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:42:01.453361 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:42:01.462826 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:42:01.474121 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:42:01.499389 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:42:01.526530 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:42:01.530955 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:42:01.581497 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:42:01.592239 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:42:01.595967 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:42:01.607296 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:42:01.643340 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:42:01.721859 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:42:01.724890 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:42:01.728597 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:42:01.731783 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:42:01.747238 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:42:01.751141 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:42:01.753396 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:42:01.757032 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:42:01.760148 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:42:01.764954 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:42:01.782917 (MainThread): Partial parsing not enabled
2020-10-17 04:42:01.883069 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:42:01.918406 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:42:01.939327 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:42:01.974539 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:42:01.995002 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:42:02.013638 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:42:02.032898 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:42:02.051549 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:42:02.611871 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:42:02.614640 (MainThread): 
2020-10-17 04:42:02.615776 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:42:02.648603 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:42:02.649697 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:42:02.650780 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:42:02.651624 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:42:03.199432 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:42:03.200884 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:42:03.201981 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:42:08.490255 (ThreadPoolExecutor-1_0): STDOUT: "b''"
2020-10-17 04:42:08.491993 (ThreadPoolExecutor-1_0): STDERR: "b'\nThe environment variable [GOOGLE_APPLICATION_CREDENTIALS] is set to:\n  [/Users/speck/gcp_laptop_key.json]\nCredentials will still be generated to the default location:\n  [/root/.config/gcloud/application_default_credentials.json]\nTo use these credentials, unset this environment variable before\nrunning your application.\n\nDo you want to continue (Y/n)?  \n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:42:08.493076 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:42:08.495455 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:42:08.496624 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:42:08.497536 (MainThread): Flushing usage events
2020-10-17 04:42:08.900034 (MainThread): ctrl-c
2020-10-17 04:43:32.855742 (MainThread): Running with dbt=0.18.0
2020-10-17 04:43:33.090698 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:43:33.097963 (MainThread): Tracking: tracking
2020-10-17 04:43:33.100832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f446f8e4eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f446ec31ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f446ec31c70>]}
2020-10-17 04:43:33.146220 (MainThread): Partial parsing not enabled
2020-10-17 04:43:33.148927 (MainThread): Parsing macros/etc.sql
2020-10-17 04:43:33.152630 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:43:33.165489 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:43:33.199366 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:43:33.204916 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:43:33.220876 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:43:33.242448 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:43:33.246852 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:43:33.254670 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:43:33.260343 (MainThread): Parsing macros/core.sql
2020-10-17 04:43:33.266552 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:43:33.282326 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:43:33.290878 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:43:33.301846 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:43:33.327655 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:43:33.354022 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:43:33.358252 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:43:33.409642 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:43:33.420325 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:43:33.423923 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:43:33.435108 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:43:33.470812 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:43:33.550258 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:43:33.553272 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:43:33.557243 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:43:33.561059 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:43:33.576295 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:43:33.580073 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:43:33.582377 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:43:33.586075 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:43:33.589359 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:43:33.594348 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:43:33.612319 (MainThread): Partial parsing not enabled
2020-10-17 04:43:33.709510 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:43:33.744643 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:43:33.765471 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:43:33.802714 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:43:33.824708 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:43:33.843979 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:43:33.864931 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:43:33.884455 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:43:34.459058 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:43:34.462491 (MainThread): 
2020-10-17 04:43:34.464135 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:43:34.498518 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:43:34.500380 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:43:34.501769 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:43:34.502889 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:43:35.052470 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:43:35.054123 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:43:35.055554 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:43:42.256745 (ThreadPoolExecutor-1_0): STDOUT: "b'Enter verification code: '"
2020-10-17 04:43:42.258086 (ThreadPoolExecutor-1_0): STDERR: "b'Go to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=Su_awZ-iFc90cbsQwYXedhT0_Qo_106NKJs8sYpGMx4&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n\n\n\n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:43:42.259024 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:43:42.261116 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:43:42.262063 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:43:42.262906 (MainThread): Flushing usage events
2020-10-17 04:43:42.654714 (MainThread): ctrl-c
2020-10-17 04:45:35.157750 (MainThread): Running with dbt=0.18.0
2020-10-17 04:45:35.403261 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:45:35.409728 (MainThread): Tracking: tracking
2020-10-17 04:45:35.412437 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f192528f760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1924582c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1924582c40>]}
2020-10-17 04:45:35.458347 (MainThread): Partial parsing not enabled
2020-10-17 04:45:35.460964 (MainThread): Parsing macros/etc.sql
2020-10-17 04:45:35.464156 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:45:35.476492 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:45:35.509978 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:45:35.515812 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:45:35.532455 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:45:35.553134 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:45:35.557199 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:45:35.564681 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:45:35.570376 (MainThread): Parsing macros/core.sql
2020-10-17 04:45:35.576736 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:45:35.592052 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:45:35.600700 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:45:35.611854 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:45:35.637188 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:45:35.663825 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:45:35.667957 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:45:35.719000 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:45:35.729168 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:45:35.732830 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:45:35.744233 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:45:35.781057 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:45:35.859278 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:45:35.862199 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:45:35.865765 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:45:35.869044 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:45:35.884170 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:45:35.887986 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:45:35.890434 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:45:35.894001 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:45:35.898146 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:45:35.903014 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:45:35.920655 (MainThread): Partial parsing not enabled
2020-10-17 04:45:36.019619 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:45:36.053715 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:45:36.073745 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:45:36.111291 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:45:36.132767 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:45:36.151906 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:45:36.171629 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:45:36.191008 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:45:36.774574 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:45:36.778686 (MainThread): 
2020-10-17 04:45:36.780449 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:45:36.813708 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:45:36.815851 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:45:36.819854 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:37.365810 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-17 04:45:37.995905 (MainThread): 04:45:37 | Concurrency: 4 threads (target='dev')
2020-10-17 04:45:37.997609 (MainThread): 04:45:37 | 
2020-10-17 04:45:38.023136 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:45:38.023609 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:45:38.024028 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:45:38.024464 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:45:38.025457 (Thread-1): 04:45:38 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-17 04:45:38.026658 (Thread-2): 04:45:38 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-17 04:45:38.027836 (Thread-3): 04:45:38 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-17 04:45:38.029521 (Thread-4): 04:45:38 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-17 04:45:38.031236 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-17 04:45:38.034276 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-17 04:45:38.036106 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-17 04:45:38.037609 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-17 04:45:38.038948 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:45:38.040192 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:45:38.041541 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:45:38.042598 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:45:38.080845 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-17 04:45:38.086435 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-17 04:45:38.097983 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-17 04:45:38.109700 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-17 04:45:38.120153 (Thread-1): finished collecting timing info
2020-10-17 04:45:38.121710 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:45:38.121921 (Thread-2): finished collecting timing info
2020-10-17 04:45:38.123914 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:38.124099 (Thread-4): finished collecting timing info
2020-10-17 04:45:38.124773 (Thread-2): Opening a new connection, currently in state init
2020-10-17 04:45:38.125267 (Thread-3): finished collecting timing info
2020-10-17 04:45:38.129344 (Thread-4): Opening a new connection, currently in state init
2020-10-17 04:45:38.130971 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:38.131844 (Thread-3): Opening a new connection, currently in state init
2020-10-17 04:45:38.133151 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:38.137803 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:38.737809 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 04:45:38.744338 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 04:45:38.746315 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 04:45:38.751308 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 04:45:39.377778 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 04:45:39.379894 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: 66cd5ac2-98e1-459c-8ca1-6fdda945ff56)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:39.381767 (Thread-2): finished collecting timing info
2020-10-17 04:45:39.387602 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 04:45:39.388988 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: c3b45580-cbc8-4e23-81f9-479e49cec994)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:39.391073 (Thread-3): finished collecting timing info
2020-10-17 04:45:39.383784 (Thread-2): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: 66cd5ac2-98e1-459c-8ca1-6fdda945ff56)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: 66cd5ac2-98e1-459c-8ca1-6fdda945ff56)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: 66cd5ac2-98e1-459c-8ca1-6fdda945ff56)
2020-10-17 04:45:39.392743 (Thread-3): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: c3b45580-cbc8-4e23-81f9-479e49cec994)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: c3b45580-cbc8-4e23-81f9-479e49cec994)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: c3b45580-cbc8-4e23-81f9-479e49cec994)
2020-10-17 04:45:39.394012 (Thread-2): 04:45:39 | 2 of 17 ERROR not_null_stg_command_actives_update_timestamp.......... [ERROR in 1.36s]
2020-10-17 04:45:39.395378 (Thread-3): 04:45:39 | 3 of 17 ERROR not_null_stg_command_results_command_uuid.............. [ERROR in 1.36s]
2020-10-17 04:45:39.396875 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:45:39.398866 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:45:39.399615 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:45:39.401399 (Thread-3): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:45:39.402553 (Thread-2): 04:45:39 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-17 04:45:39.403772 (Thread-3): 04:45:39 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-17 04:45:39.405456 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-17 04:45:39.406671 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-17 04:45:39.407178 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:45:39.408324 (Thread-3): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:45:39.419876 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 04:45:39.426310 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-17 04:45:39.441104 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-17 04:45:39.441445 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1e33b5d1-f1de-4480-9683-880baa1da84f)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:39.444646 (Thread-4): finished collecting timing info
2020-10-17 04:45:39.446252 (Thread-4): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1e33b5d1-f1de-4480-9683-880baa1da84f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1e33b5d1-f1de-4480-9683-880baa1da84f)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1e33b5d1-f1de-4480-9683-880baa1da84f)
2020-10-17 04:45:39.447966 (Thread-4): 04:45:39 | 4 of 17 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 1.41s]
2020-10-17 04:45:39.448941 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:45:39.450322 (Thread-2): finished collecting timing info
2020-10-17 04:45:39.451051 (Thread-4): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:45:39.451657 (Thread-3): finished collecting timing info
2020-10-17 04:45:39.452427 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:45:39.453216 (Thread-4): 04:45:39 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-17 04:45:39.453978 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:45:39.455146 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:39.456133 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-17 04:45:39.458177 (Thread-3): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42924), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:39.463180 (Thread-4): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:45:39.465557 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42930), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:39.484116 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-17 04:45:39.484850 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58800), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:39.486569 (Thread-3): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58802), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:39.488611 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:39.493902 (Thread-4): finished collecting timing info
2020-10-17 04:45:39.495356 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:45:39.498085 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:39.592498 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 04:45:39.594061 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: c1bb6928-12b0-41da-afa1-c3068e28cea9)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:39.594967 (Thread-1): finished collecting timing info
2020-10-17 04:45:39.596508 (Thread-1): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: c1bb6928-12b0-41da-afa1-c3068e28cea9)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: c1bb6928-12b0-41da-afa1-c3068e28cea9)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: c1bb6928-12b0-41da-afa1-c3068e28cea9)
2020-10-17 04:45:39.597927 (Thread-1): 04:45:39 | 1 of 17 ERROR not_null_stg_command_actives_command_uuid.............. [ERROR in 1.57s]
2020-10-17 04:45:39.599065 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:45:39.600812 (Thread-1): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:45:39.602161 (Thread-1): 04:45:39 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-17 04:45:39.603683 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-17 04:45:39.604690 (Thread-1): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:45:39.619657 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-17 04:45:39.628472 (Thread-1): finished collecting timing info
2020-10-17 04:45:39.629479 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:45:39.630742 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:40.110695 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 04:45:40.126935 (Thread-4): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 04:45:40.137137 (Thread-3): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 04:45:40.276178 (Thread-1): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 04:45:40.677161 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 04:45:40.678194 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 04:45:40.680594 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 04:45:40.680879 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 8a2666d6-ae99-4ecf-bb08-bfc855db25d7)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:40.682104 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 7c3c2f9e-2330-4b4c-a5ce-c2b32f157790)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:40.683293 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 84b0ca9f-667e-4912-a9b9-bbe3f4fb815f)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:40.684627 (Thread-3): finished collecting timing info
2020-10-17 04:45:40.686457 (Thread-4): finished collecting timing info
2020-10-17 04:45:40.687692 (Thread-2): finished collecting timing info
2020-10-17 04:45:40.689223 (Thread-3): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 8a2666d6-ae99-4ecf-bb08-bfc855db25d7)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 8a2666d6-ae99-4ecf-bb08-bfc855db25d7)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 8a2666d6-ae99-4ecf-bb08-bfc855db25d7)
2020-10-17 04:45:40.691019 (Thread-4): Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 7c3c2f9e-2330-4b4c-a5ce-c2b32f157790)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 7c3c2f9e-2330-4b4c-a5ce-c2b32f157790)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 7c3c2f9e-2330-4b4c-a5ce-c2b32f157790)
2020-10-17 04:45:40.692139 (Thread-2): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 84b0ca9f-667e-4912-a9b9-bbe3f4fb815f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 84b0ca9f-667e-4912-a9b9-bbe3f4fb815f)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 84b0ca9f-667e-4912-a9b9-bbe3f4fb815f)
2020-10-17 04:45:40.693676 (Thread-3): 04:45:40 | 6 of 17 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 1.29s]
2020-10-17 04:45:40.694677 (Thread-4): 04:45:40 | 7 of 17 ERROR not_null_stg_commands_command_uuid..................... [ERROR in 1.24s]
2020-10-17 04:45:40.695543 (Thread-2): 04:45:40 | 5 of 17 ERROR not_null_stg_command_results_update_timestamp.......... [ERROR in 1.29s]
2020-10-17 04:45:40.696990 (Thread-3): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:45:40.698251 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:45:40.700281 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:45:40.700733 (Thread-3): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:45:40.702250 (Thread-4): Began running node test.dwelo.stg_commands_locked_state
2020-10-17 04:45:40.703525 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-17 04:45:40.704334 (Thread-3): 04:45:40 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-17 04:45:40.705197 (Thread-4): 04:45:40 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-17 04:45:40.705929 (Thread-2): 04:45:40 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-17 04:45:40.707038 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-17 04:45:40.707888 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:45:40.709445 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:45:40.709940 (Thread-3): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:45:40.710778 (Thread-4): Compiling test.dwelo.stg_commands_locked_state
2020-10-17 04:45:40.711540 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-17 04:45:40.726748 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-17 04:45:40.753975 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-17 04:45:40.758560 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-17 04:45:40.765638 (Thread-3): finished collecting timing info
2020-10-17 04:45:40.766831 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:45:40.767503 (Thread-4): finished collecting timing info
2020-10-17 04:45:40.768564 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:40.769073 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:45:40.769246 (Thread-2): finished collecting timing info
2020-10-17 04:45:40.774803 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:40.776234 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:45:40.781493 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:40.801356 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 04:45:40.802722 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 090b731b-11c1-4675-a986-5905104a8875)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:40.803637 (Thread-1): finished collecting timing info
2020-10-17 04:45:40.805668 (Thread-1): Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 090b731b-11c1-4675-a986-5905104a8875)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 090b731b-11c1-4675-a986-5905104a8875)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 090b731b-11c1-4675-a986-5905104a8875)
2020-10-17 04:45:40.807182 (Thread-1): 04:45:40 | 8 of 17 ERROR not_null_stg_commands_update_timestamp................. [ERROR in 1.20s]
2020-10-17 04:45:40.808462 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:45:40.809659 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-17 04:45:40.811009 (Thread-1): 04:45:40 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-17 04:45:40.812266 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:45:40.813656 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-17 04:45:40.830630 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-17 04:45:40.838830 (Thread-1): finished collecting timing info
2020-10-17 04:45:40.840493 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:45:40.842063 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:41.475135 (Thread-3): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 04:45:41.500878 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:41.506921 (Thread-4): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:41.589193 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.036387 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.038503 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 62f38c4c-bb93-4530-904a-52253d4b7f4e)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:42.040075 (Thread-2): finished collecting timing info
2020-10-17 04:45:42.042567 (Thread-2): Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 62f38c4c-bb93-4530-904a-52253d4b7f4e)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 62f38c4c-bb93-4530-904a-52253d4b7f4e)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 62f38c4c-bb93-4530-904a-52253d4b7f4e)
2020-10-17 04:45:42.044254 (Thread-2): 04:45:42 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 1.33s]
2020-10-17 04:45:42.045831 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-17 04:45:42.047621 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:45:42.050095 (Thread-2): 04:45:42 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-17 04:45:42.050777 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.051834 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:45:42.053285 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: e7d0b5fc-a075-4f49-8097-890c9d4c5fbd)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:42.054222 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:45:42.055193 (Thread-4): finished collecting timing info
2020-10-17 04:45:42.068000 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 04:45:42.073079 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-17 04:45:42.074095 (Thread-4): Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: e7d0b5fc-a075-4f49-8097-890c9d4c5fbd)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: e7d0b5fc-a075-4f49-8097-890c9d4c5fbd)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: e7d0b5fc-a075-4f49-8097-890c9d4c5fbd)
2020-10-17 04:45:42.075694 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 99ae05fc-872e-4afc-ab8e-42019f97e7bf)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:42.077794 (Thread-4): 04:45:42 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 1.37s]
2020-10-17 04:45:42.078806 (Thread-3): finished collecting timing info
2020-10-17 04:45:42.080584 (Thread-4): Finished running node test.dwelo.stg_commands_locked_state
2020-10-17 04:45:42.081921 (Thread-3): Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 99ae05fc-872e-4afc-ab8e-42019f97e7bf)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 99ae05fc-872e-4afc-ab8e-42019f97e7bf)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 99ae05fc-872e-4afc-ab8e-42019f97e7bf)
2020-10-17 04:45:42.083650 (Thread-2): finished collecting timing info
2020-10-17 04:45:42.084220 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:45:42.085239 (Thread-3): 04:45:42 | 9 of 17 ERROR not_null_stg_commands_user_id.......................... [ERROR in 1.38s]
2020-10-17 04:45:42.086174 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:45:42.087265 (Thread-4): 04:45:42 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-17 04:45:42.088688 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:45:42.089787 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:42.091463 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:45:42.092121 (Thread-3): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:45:42.099740 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:45:42.101762 (Thread-3): 04:45:42 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-17 04:45:42.110232 (Thread-4): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42942), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:42.111873 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-17 04:45:42.112629 (Thread-4): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58818), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:42.113269 (Thread-3): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:45:42.114577 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42952), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:42.125590 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.136296 (Thread-4): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58822), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:42.140523 (Thread-4): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42958), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:42.138882 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: e1ad0031-321f-420b-bc6e-f0b479e0b587)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:42.138120 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-17 04:45:42.141965 (Thread-4): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42960), raddr=('172.217.5.202', 443)>
2020-10-17 04:45:42.143037 (Thread-1): finished collecting timing info
2020-10-17 04:45:42.145190 (Thread-4): unclosed <socket.socket fd=26, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58834), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:42.146201 (Thread-1): Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: e1ad0031-321f-420b-bc6e-f0b479e0b587)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: e1ad0031-321f-420b-bc6e-f0b479e0b587)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: e1ad0031-321f-420b-bc6e-f0b479e0b587)
2020-10-17 04:45:42.147962 (Thread-4): unclosed <socket.socket fd=27, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58836), raddr=('172.217.14.74', 443)>
2020-10-17 04:45:42.148709 (Thread-1): 04:45:42 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 1.34s]
2020-10-17 04:45:42.159081 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-17 04:45:42.159695 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-17 04:45:42.161887 (Thread-3): finished collecting timing info
2020-10-17 04:45:42.162824 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:45:42.164298 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:45:42.166000 (Thread-1): 04:45:42 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-17 04:45:42.167907 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:42.170515 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-17 04:45:42.175814 (Thread-4): finished collecting timing info
2020-10-17 04:45:42.178218 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:45:42.179579 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:45:42.197834 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-17 04:45:42.199190 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:42.209527 (Thread-1): finished collecting timing info
2020-10-17 04:45:42.211432 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:45:42.212687 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:42.730789 (Thread-2): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.801446 (Thread-3): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:42.829755 (Thread-4): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:42.841368 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:43.203461 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:43.206015 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 6b0d1f7d-e006-4ad2-b871-5fbe795871aa)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:43.207833 (Thread-2): finished collecting timing info
2020-10-17 04:45:43.210275 (Thread-2): Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 6b0d1f7d-e006-4ad2-b871-5fbe795871aa)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 6b0d1f7d-e006-4ad2-b871-5fbe795871aa)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 6b0d1f7d-e006-4ad2-b871-5fbe795871aa)
2020-10-17 04:45:43.212322 (Thread-2): 04:45:43 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 1.16s]
2020-10-17 04:45:43.213666 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:45:43.215369 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:45:43.216853 (Thread-2): 04:45:43 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-17 04:45:43.218656 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-17 04:45:43.219939 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:45:43.235057 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-17 04:45:43.242616 (Thread-2): finished collecting timing info
2020-10-17 04:45:43.243754 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:45:43.244681 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:45:43.347780 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:45:43.349736 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9d907c77-4d65-44b6-8981-7f024ab657cd)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:43.351238 (Thread-4): finished collecting timing info
2020-10-17 04:45:43.353197 (Thread-4): Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9d907c77-4d65-44b6-8981-7f024ab657cd)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9d907c77-4d65-44b6-8981-7f024ab657cd)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9d907c77-4d65-44b6-8981-7f024ab657cd)
2020-10-17 04:45:43.354861 (Thread-4): 04:45:43 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.26s]
2020-10-17 04:45:43.356314 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:45:43.358939 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:43.360780 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: a450900d-38ea-42ca-9549-c84b4592e1b1)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_results`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:43.361674 (Thread-1): finished collecting timing info
2020-10-17 04:45:43.362838 (Thread-1): Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: a450900d-38ea-42ca-9549-c84b4592e1b1)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: a450900d-38ea-42ca-9549-c84b4592e1b1)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_results`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: a450900d-38ea-42ca-9549-c84b4592e1b1)
2020-10-17 04:45:43.363939 (Thread-1): 04:45:43 | 16 of 17 ERROR unique_stg_command_results_command_uuid............... [ERROR in 1.19s]
2020-10-17 04:45:43.364589 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:45:43.360663 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:43.366307 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: cc6f08c8-f4da-4267-b6f7-5da7cc6a488b)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_actives`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:43.367683 (Thread-3): finished collecting timing info
2020-10-17 04:45:43.369114 (Thread-3): Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: cc6f08c8-f4da-4267-b6f7-5da7cc6a488b)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: cc6f08c8-f4da-4267-b6f7-5da7cc6a488b)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_actives`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: cc6f08c8-f4da-4267-b6f7-5da7cc6a488b)
2020-10-17 04:45:43.370600 (Thread-3): 04:45:43 | 15 of 17 ERROR unique_stg_command_actives_command_uuid............... [ERROR in 1.26s]
2020-10-17 04:45:43.371796 (Thread-3): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:45:43.812914 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:44.355053 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:45:44.357622 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 139b79e1-19bb-4af9-a312-314bc2dd90ad)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_commands`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:45:44.359278 (Thread-2): finished collecting timing info
2020-10-17 04:45:44.361678 (Thread-2): Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 139b79e1-19bb-4af9-a312-314bc2dd90ad)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 139b79e1-19bb-4af9-a312-314bc2dd90ad)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_commands`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 139b79e1-19bb-4af9-a312-314bc2dd90ad)
2020-10-17 04:45:44.363257 (Thread-2): 04:45:44 | 17 of 17 ERROR unique_stg_commands_command_uuid...................... [ERROR in 1.14s]
2020-10-17 04:45:44.364465 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:45:44.369086 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:45:44.370501 (MainThread): 04:45:44 | 
2020-10-17 04:45:44.371577 (MainThread): 04:45:44 | Finished running 17 tests in 7.59s.
2020-10-17 04:45:44.372601 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:45:44.373998 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-17 04:45:44.375042 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-17 04:45:44.376021 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-17 04:45:44.377028 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-17 04:45:44.445716 (MainThread): 
2020-10-17 04:45:44.446618 (MainThread): Completed with 17 errors and 0 warnings:
2020-10-17 04:45:44.447626 (MainThread): 
2020-10-17 04:45:44.448721 (MainThread): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:45:44.449719 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:45:44.450952 (MainThread):   
2020-10-17 04:45:44.453608 (MainThread):   (job ID: 66cd5ac2-98e1-459c-8ca1-6fdda945ff56)
2020-10-17 04:45:44.455636 (MainThread): 
2020-10-17 04:45:44.458059 (MainThread): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.460277 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:45:44.462756 (MainThread):   
2020-10-17 04:45:44.464545 (MainThread):   (job ID: c3b45580-cbc8-4e23-81f9-479e49cec994)
2020-10-17 04:45:44.466514 (MainThread): 
2020-10-17 04:45:44.467833 (MainThread): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-17 04:45:44.469062 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:45:44.470541 (MainThread):   
2020-10-17 04:45:44.472573 (MainThread):   (job ID: 1e33b5d1-f1de-4480-9683-880baa1da84f)
2020-10-17 04:45:44.475029 (MainThread): 
2020-10-17 04:45:44.477272 (MainThread): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.479308 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:45:44.481748 (MainThread):   
2020-10-17 04:45:44.483656 (MainThread):   (job ID: c1bb6928-12b0-41da-afa1-c3068e28cea9)
2020-10-17 04:45:44.485271 (MainThread): 
2020-10-17 04:45:44.486787 (MainThread): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
2020-10-17 04:45:44.488129 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.489928 (MainThread):   
2020-10-17 04:45:44.491146 (MainThread):   (job ID: 8a2666d6-ae99-4ecf-bb08-bfc855db25d7)
2020-10-17 04:45:44.492666 (MainThread): 
2020-10-17 04:45:44.493916 (MainThread): Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.495308 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.496683 (MainThread):   
2020-10-17 04:45:44.497970 (MainThread):   (job ID: 7c3c2f9e-2330-4b4c-a5ce-c2b32f157790)
2020-10-17 04:45:44.499323 (MainThread): 
2020-10-17 04:45:44.500679 (MainThread): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:45:44.502061 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:45:44.503693 (MainThread):   
2020-10-17 04:45:44.504995 (MainThread):   (job ID: 84b0ca9f-667e-4912-a9b9-bbe3f4fb815f)
2020-10-17 04:45:44.506204 (MainThread): 
2020-10-17 04:45:44.507639 (MainThread): Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:45:44.509290 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.511331 (MainThread):   
2020-10-17 04:45:44.512911 (MainThread):   (job ID: 090b731b-11c1-4675-a986-5905104a8875)
2020-10-17 04:45:44.514361 (MainThread): 
2020-10-17 04:45:44.515709 (MainThread): Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-17 04:45:44.517055 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.518361 (MainThread):   
2020-10-17 04:45:44.520261 (MainThread):   (job ID: 62f38c4c-bb93-4530-904a-52253d4b7f4e)
2020-10-17 04:45:44.521609 (MainThread): 
2020-10-17 04:45:44.523273 (MainThread): Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-17 04:45:44.524701 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.525895 (MainThread):   
2020-10-17 04:45:44.527529 (MainThread):   (job ID: e7d0b5fc-a075-4f49-8097-890c9d4c5fbd)
2020-10-17 04:45:44.529299 (MainThread): 
2020-10-17 04:45:44.530681 (MainThread): Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
2020-10-17 04:45:44.531894 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.533120 (MainThread):   
2020-10-17 04:45:44.534494 (MainThread):   (job ID: 99ae05fc-872e-4afc-ab8e-42019f97e7bf)
2020-10-17 04:45:44.535714 (MainThread): 
2020-10-17 04:45:44.536966 (MainThread): Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-17 04:45:44.538206 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.539490 (MainThread):   
2020-10-17 04:45:44.541129 (MainThread):   (job ID: e1ad0031-321f-420b-bc6e-f0b479e0b587)
2020-10-17 04:45:44.551974 (MainThread): 
2020-10-17 04:45:44.561272 (MainThread): Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-17 04:45:44.563440 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.565076 (MainThread):   
2020-10-17 04:45:44.566688 (MainThread):   (job ID: 6b0d1f7d-e006-4ad2-b871-5fbe795871aa)
2020-10-17 04:45:44.568321 (MainThread): 
2020-10-17 04:45:44.569874 (MainThread): Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-17 04:45:44.571466 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.573015 (MainThread):   
2020-10-17 04:45:44.574572 (MainThread):   (job ID: 9d907c77-4d65-44b6-8981-7f024ab657cd)
2020-10-17 04:45:44.575981 (MainThread): 
2020-10-17 04:45:44.577463 (MainThread): Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.578730 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:45:44.580173 (MainThread):   
2020-10-17 04:45:44.581495 (MainThread):   (job ID: a450900d-38ea-42ca-9549-c84b4592e1b1)
2020-10-17 04:45:44.582722 (MainThread): 
2020-10-17 04:45:44.584685 (MainThread): Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.585903 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:45:44.587716 (MainThread):   
2020-10-17 04:45:44.589066 (MainThread):   (job ID: cc6f08c8-f4da-4267-b6f7-5da7cc6a488b)
2020-10-17 04:45:44.590629 (MainThread): 
2020-10-17 04:45:44.591997 (MainThread): Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:45:44.593840 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:45:44.595573 (MainThread):   
2020-10-17 04:45:44.596883 (MainThread):   (job ID: 139b79e1-19bb-4af9-a312-314bc2dd90ad)
2020-10-17 04:45:44.598237 (MainThread): 
Done. PASS=0 WARN=0 ERROR=17 SKIP=0 TOTAL=17
2020-10-17 04:45:44.599737 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19244fa520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19242d98b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19207a4f10>]}
2020-10-17 04:45:44.601174 (MainThread): Flushing usage events
2020-10-17 04:46:31.599854 (MainThread): Running with dbt=0.18.0
2020-10-17 04:46:31.847101 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:46:31.854167 (MainThread): Tracking: tracking
2020-10-17 04:46:31.857013 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b037a0d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b02a6e940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b02a6e910>]}
2020-10-17 04:46:31.903951 (MainThread): Partial parsing not enabled
2020-10-17 04:46:31.906699 (MainThread): Parsing macros/etc.sql
2020-10-17 04:46:31.910595 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:46:31.923074 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:46:31.956402 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:46:31.962175 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:46:31.978356 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:46:31.999620 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:46:32.003840 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:46:32.011655 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:46:32.017973 (MainThread): Parsing macros/core.sql
2020-10-17 04:46:32.024680 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:46:32.040504 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:46:32.049247 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:46:32.060963 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:46:32.087794 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:46:32.114489 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:46:32.118564 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:46:32.171241 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:46:32.181659 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:46:32.185480 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:46:32.196622 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:46:32.232317 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:46:32.312279 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:46:32.315479 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:46:32.318823 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:46:32.321951 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:46:32.337155 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:46:32.341376 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:46:32.343618 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:46:32.347628 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:46:32.350993 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:46:32.356098 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:46:32.375256 (MainThread): Partial parsing not enabled
2020-10-17 04:46:32.471957 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:46:32.506217 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:46:32.526256 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:46:32.563407 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:46:32.583466 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:46:32.603871 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:46:32.633490 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:46:32.654120 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:46:33.231878 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:46:33.234714 (MainThread): 
2020-10-17 04:46:33.236091 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:46:33.269212 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:46:33.271576 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:46:36.283634 (ThreadPoolExecutor-1_0): Please log into GCP to continue
2020-10-17 04:46:36.287364 (ThreadPoolExecutor-1_0): Executing "gcloud --version"
2020-10-17 04:46:36.842632 (ThreadPoolExecutor-1_0): STDOUT: "b'Google Cloud SDK 314.0.0\nalpha 2020.10.09\nbeta 2020.10.09\nbq 2.0.62\ncore 2020.10.09\ngsutil 4.53\nkubectl 1.15.11\n'"
2020-10-17 04:46:36.844475 (ThreadPoolExecutor-1_0): STDERR: "b''"
2020-10-17 04:46:36.845834 (ThreadPoolExecutor-1_0): Executing "gcloud auth application-default login"
2020-10-17 04:46:38.769427 (ThreadPoolExecutor-1_0): STDOUT: "b'Enter verification code: '"
2020-10-17 04:46:38.770921 (ThreadPoolExecutor-1_0): STDERR: "b'Go to the following link in your browser:\n\n    https://accounts.google.com/o/oauth2/auth?client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&code_challenge=J96XMtHbPFDKtTJIBpT9cDAlsjsQdXQHLrrsVu7pKDM&code_challenge_method=S256&access_type=offline&response_type=code&prompt=select_account\n\n\n\n\nCommand killed by keyboard interrupt\n\n'"
2020-10-17 04:46:38.771590 (ThreadPoolExecutor-1_0): command return code=-2
2020-10-17 04:46:38.773747 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:46:38.774671 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-17 04:46:38.775632 (MainThread): Flushing usage events
2020-10-17 04:46:39.140759 (MainThread): ctrl-c
2020-10-17 04:47:15.916802 (MainThread): Running with dbt=0.18.0
2020-10-17 04:47:16.170905 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 04:47:16.176070 (MainThread): Tracking: tracking
2020-10-17 04:47:16.178751 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e1672f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e0941910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e09418e0>]}
2020-10-17 04:47:16.221827 (MainThread): Partial parsing not enabled
2020-10-17 04:47:16.224369 (MainThread): Parsing macros/etc.sql
2020-10-17 04:47:16.228088 (MainThread): Parsing macros/catalog.sql
2020-10-17 04:47:16.240634 (MainThread): Parsing macros/adapters.sql
2020-10-17 04:47:16.275777 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 04:47:16.281146 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 04:47:16.297122 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 04:47:16.318240 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 04:47:16.322254 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 04:47:16.329740 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 04:47:16.336514 (MainThread): Parsing macros/core.sql
2020-10-17 04:47:16.342658 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 04:47:16.358443 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 04:47:16.367173 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 04:47:16.378712 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 04:47:16.405005 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 04:47:16.431119 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 04:47:16.435479 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 04:47:16.487274 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 04:47:16.498228 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 04:47:16.501789 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 04:47:16.513358 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 04:47:16.548976 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 04:47:16.629013 (MainThread): Parsing macros/etc/query.sql
2020-10-17 04:47:16.632501 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 04:47:16.635638 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 04:47:16.638727 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 04:47:16.653671 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 04:47:16.657751 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 04:47:16.660580 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 04:47:16.664683 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 04:47:16.668129 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 04:47:16.673086 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 04:47:16.691147 (MainThread): Partial parsing not enabled
2020-10-17 04:47:16.791412 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 04:47:16.826187 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 04:47:16.846636 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 04:47:16.882235 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:47:16.902771 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:47:16.921149 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:47:16.940937 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:47:16.959596 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:47:17.528115 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 04:47:17.530870 (MainThread): 
2020-10-17 04:47:17.531993 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:47:17.563148 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 04:47:17.564568 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 04:47:17.567094 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:18.144858 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-17 04:47:18.530359 (MainThread): 04:47:18 | Concurrency: 4 threads (target='dev')
2020-10-17 04:47:18.532100 (MainThread): 04:47:18 | 
2020-10-17 04:47:18.555619 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:47:18.556113 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:47:18.556553 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:47:18.557133 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:47:18.557514 (Thread-1): 04:47:18 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-17 04:47:18.559078 (Thread-2): 04:47:18 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-17 04:47:18.560124 (Thread-3): 04:47:18 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-17 04:47:18.561044 (Thread-4): 04:47:18 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-17 04:47:18.562046 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-17 04:47:18.563384 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-17 04:47:18.565923 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-17 04:47:18.567218 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-17 04:47:18.569139 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:47:18.570738 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:47:18.572087 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:47:18.573114 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:47:18.620248 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-17 04:47:18.621747 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-17 04:47:18.639509 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-17 04:47:18.641928 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-17 04:47:18.649687 (Thread-4): finished collecting timing info
2020-10-17 04:47:18.650686 (Thread-1): finished collecting timing info
2020-10-17 04:47:18.653102 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:47:18.652072 (Thread-3): finished collecting timing info
2020-10-17 04:47:18.652417 (Thread-2): finished collecting timing info
2020-10-17 04:47:18.651670 (Thread-4): Opening a new connection, currently in state init
2020-10-17 04:47:18.656831 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:18.655169 (Thread-3): Opening a new connection, currently in state init
2020-10-17 04:47:18.656000 (Thread-2): Opening a new connection, currently in state init
2020-10-17 04:47:18.654240 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:18.662815 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:18.664663 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:19.272979 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 04:47:19.306685 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 04:47:19.329358 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 04:47:19.342066 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 04:47:19.740611 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 04:47:19.742580 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: 21344991-512b-43aa-bc86-be40da9370ea)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:19.744325 (Thread-2): finished collecting timing info
2020-10-17 04:47:19.746642 (Thread-2): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: 21344991-512b-43aa-bc86-be40da9370ea)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: 21344991-512b-43aa-bc86-be40da9370ea)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: 21344991-512b-43aa-bc86-be40da9370ea)
2020-10-17 04:47:19.750759 (Thread-2): 04:47:19 | 2 of 17 ERROR not_null_stg_command_actives_update_timestamp.......... [ERROR in 1.19s]
2020-10-17 04:47:19.752114 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 04:47:19.753898 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:47:19.755287 (Thread-2): 04:47:19 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-17 04:47:19.756520 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-17 04:47:19.757656 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:47:19.771140 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-17 04:47:19.778629 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 04:47:19.779764 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: ae40cfd5-ebbb-4d7a-bc94-f0eb78c686d4)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:19.780942 (Thread-2): finished collecting timing info
2020-10-17 04:47:19.781435 (Thread-1): finished collecting timing info
2020-10-17 04:47:19.782588 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:47:19.783731 (Thread-1): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: ae40cfd5-ebbb-4d7a-bc94-f0eb78c686d4)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: ae40cfd5-ebbb-4d7a-bc94-f0eb78c686d4)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: ae40cfd5-ebbb-4d7a-bc94-f0eb78c686d4)
2020-10-17 04:47:19.785258 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:19.786511 (Thread-1): 04:47:19 | 1 of 17 ERROR not_null_stg_command_actives_command_uuid.............. [ERROR in 1.22s]
2020-10-17 04:47:19.793443 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 04:47:19.796331 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:47:19.798083 (Thread-1): 04:47:19 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-17 04:47:19.800249 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-17 04:47:19.801245 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:47:19.825824 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-17 04:47:19.837009 (Thread-1): finished collecting timing info
2020-10-17 04:47:19.838532 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:47:19.840071 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:19.867758 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 04:47:19.868956 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 7a440e93-660a-441d-b392-fa1970156594)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:19.870150 (Thread-4): finished collecting timing info
2020-10-17 04:47:19.872058 (Thread-4): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 7a440e93-660a-441d-b392-fa1970156594)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 7a440e93-660a-441d-b392-fa1970156594)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 7a440e93-660a-441d-b392-fa1970156594)
2020-10-17 04:47:19.873748 (Thread-4): 04:47:19 | 4 of 17 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 1.31s]
2020-10-17 04:47:19.875687 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 04:47:19.876678 (Thread-4): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:47:19.878140 (Thread-4): 04:47:19 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-17 04:47:19.880195 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-17 04:47:19.881228 (Thread-4): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:47:19.895581 (Thread-4): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42756), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:19.898145 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42758), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:19.900361 (Thread-4): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42762), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:19.901662 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58886), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:19.903151 (Thread-4): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58892), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:19.904606 (Thread-4): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58888), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:19.922790 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-17 04:47:19.923540 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 04:47:19.925678 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1b628ed0-f8f6-44dd-802b-636b297d2276)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:19.926771 (Thread-3): finished collecting timing info
2020-10-17 04:47:19.928760 (Thread-3): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1b628ed0-f8f6-44dd-802b-636b297d2276)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1b628ed0-f8f6-44dd-802b-636b297d2276)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1b628ed0-f8f6-44dd-802b-636b297d2276)
2020-10-17 04:47:19.930245 (Thread-3): 04:47:19 | 3 of 17 ERROR not_null_stg_command_results_command_uuid.............. [ERROR in 1.37s]
2020-10-17 04:47:19.931191 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 04:47:19.932283 (Thread-4): finished collecting timing info
2020-10-17 04:47:19.932813 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:47:19.934486 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:47:19.935641 (Thread-3): 04:47:19 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-17 04:47:19.937220 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:19.939140 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-17 04:47:19.945398 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:47:19.971493 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-17 04:47:19.979425 (Thread-3): finished collecting timing info
2020-10-17 04:47:19.981202 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:47:19.983073 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:20.439022 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 04:47:20.486364 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 04:47:20.589734 (Thread-4): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 04:47:20.608206 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 04:47:20.876304 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 04:47:20.878347 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: a0a304b4-d573-47ac-bc8e-5facb2f6bf59)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:20.880165 (Thread-2): finished collecting timing info
2020-10-17 04:47:20.882889 (Thread-2): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: a0a304b4-d573-47ac-bc8e-5facb2f6bf59)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: a0a304b4-d573-47ac-bc8e-5facb2f6bf59)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: a0a304b4-d573-47ac-bc8e-5facb2f6bf59)
2020-10-17 04:47:20.885141 (Thread-2): 04:47:20 | 5 of 17 ERROR not_null_stg_command_results_update_timestamp.......... [ERROR in 1.13s]
2020-10-17 04:47:20.886368 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 04:47:20.888085 (Thread-2): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:47:20.889309 (Thread-2): 04:47:20 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-17 04:47:20.890673 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-17 04:47:20.892054 (Thread-2): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:47:20.906858 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-17 04:47:20.916370 (Thread-2): finished collecting timing info
2020-10-17 04:47:20.917643 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:47:20.918724 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:21.035076 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 04:47:21.037139 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: a8c9980a-5fb1-41e7-a2a3-d08de94405e8)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:21.039080 (Thread-1): finished collecting timing info
2020-10-17 04:47:21.041476 (Thread-1): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: a8c9980a-5fb1-41e7-a2a3-d08de94405e8)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: a8c9980a-5fb1-41e7-a2a3-d08de94405e8)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: a8c9980a-5fb1-41e7-a2a3-d08de94405e8)
2020-10-17 04:47:21.043345 (Thread-1): 04:47:21 | 6 of 17 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 1.24s]
2020-10-17 04:47:21.044496 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 04:47:21.045635 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-17 04:47:21.046756 (Thread-1): 04:47:21 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-17 04:47:21.047967 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 04:47:21.049145 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-17 04:47:21.068780 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 04:47:21.075781 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 5086491d-9ec4-4eec-b73d-fcbf7a7a3bdb)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:21.077166 (Thread-3): finished collecting timing info
2020-10-17 04:47:21.078708 (Thread-3): Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 5086491d-9ec4-4eec-b73d-fcbf7a7a3bdb)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 5086491d-9ec4-4eec-b73d-fcbf7a7a3bdb)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 5086491d-9ec4-4eec-b73d-fcbf7a7a3bdb)
2020-10-17 04:47:21.080251 (Thread-3): 04:47:21 | 8 of 17 ERROR not_null_stg_commands_update_timestamp................. [ERROR in 1.14s]
2020-10-17 04:47:21.081319 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 04:47:21.082345 (Thread-3): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-17 04:47:21.083644 (Thread-3): 04:47:21 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-17 04:47:21.084905 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 04:47:21.085993 (Thread-3): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-17 04:47:21.075482 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-17 04:47:21.101684 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-17 04:47:21.110431 (Thread-1): finished collecting timing info
2020-10-17 04:47:21.112081 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:47:21.113201 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:21.111277 (Thread-3): finished collecting timing info
2020-10-17 04:47:21.118310 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:47:21.120437 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:21.128555 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 04:47:21.129933 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9c63b85d-af66-4ea9-b352-6f348c634b5a)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:21.130995 (Thread-4): finished collecting timing info
2020-10-17 04:47:21.132969 (Thread-4): Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9c63b85d-af66-4ea9-b352-6f348c634b5a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9c63b85d-af66-4ea9-b352-6f348c634b5a)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9c63b85d-af66-4ea9-b352-6f348c634b5a)
2020-10-17 04:47:21.134551 (Thread-4): 04:47:21 | 7 of 17 ERROR not_null_stg_commands_command_uuid..................... [ERROR in 1.25s]
2020-10-17 04:47:21.136174 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 04:47:21.137336 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-17 04:47:21.138606 (Thread-4): 04:47:21 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-17 04:47:21.140636 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 04:47:21.141812 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-17 04:47:21.164565 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-17 04:47:21.178135 (Thread-4): finished collecting timing info
2020-10-17 04:47:21.179872 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:47:21.181404 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:21.580002 (Thread-2): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 04:47:21.776327 (Thread-3): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:21.791388 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:21.844389 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:22.026254 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 04:47:22.027269 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: b3ddf4a9-1f10-4bce-8f1c-95895be056da)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:22.028281 (Thread-2): finished collecting timing info
2020-10-17 04:47:22.030054 (Thread-2): Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: b3ddf4a9-1f10-4bce-8f1c-95895be056da)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: b3ddf4a9-1f10-4bce-8f1c-95895be056da)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: b3ddf4a9-1f10-4bce-8f1c-95895be056da)
2020-10-17 04:47:22.031182 (Thread-2): 04:47:22 | 9 of 17 ERROR not_null_stg_commands_user_id.......................... [ERROR in 1.14s]
2020-10-17 04:47:22.032035 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 04:47:22.033075 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:47:22.034336 (Thread-2): 04:47:22 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-17 04:47:22.035460 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 04:47:22.036691 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:47:22.042948 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42778), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:22.044108 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42780), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:22.045138 (Thread-2): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58906), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:22.046096 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58908), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:22.047000 (Thread-2): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 58912), raddr=('172.217.14.74', 443)>
2020-10-17 04:47:22.047767 (Thread-2): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 42788), raddr=('172.217.11.170', 443)>
2020-10-17 04:47:22.057775 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-17 04:47:22.065400 (Thread-2): finished collecting timing info
2020-10-17 04:47:22.066601 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:47:22.067603 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:22.287742 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:22.289020 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 2fbf2322-a19d-4706-8a4d-fb41634b072c)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:22.290525 (Thread-1): finished collecting timing info
2020-10-17 04:47:22.292516 (Thread-1): Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 2fbf2322-a19d-4706-8a4d-fb41634b072c)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 2fbf2322-a19d-4706-8a4d-fb41634b072c)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 2fbf2322-a19d-4706-8a4d-fb41634b072c)
2020-10-17 04:47:22.294207 (Thread-1): 04:47:22 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 1.25s]
2020-10-17 04:47:22.295201 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-17 04:47:22.296646 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:47:22.298073 (Thread-1): 04:47:22 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-17 04:47:22.299675 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 04:47:22.300683 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:47:22.315223 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-17 04:47:22.324834 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:22.326268 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 05b5c694-54b7-404c-87d6-b244a04d7553)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:22.327517 (Thread-3): finished collecting timing info
2020-10-17 04:47:22.329254 (Thread-3): Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 05b5c694-54b7-404c-87d6-b244a04d7553)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 05b5c694-54b7-404c-87d6-b244a04d7553)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 05b5c694-54b7-404c-87d6-b244a04d7553)
2020-10-17 04:47:22.330083 (Thread-1): finished collecting timing info
2020-10-17 04:47:22.331527 (Thread-3): 04:47:22 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 1.25s]
2020-10-17 04:47:22.332588 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 04:47:22.333978 (Thread-3): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-17 04:47:22.336340 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:22.337801 (Thread-3): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:47:22.344281 (Thread-3): 04:47:22 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-17 04:47:22.346871 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-17 04:47:22.348320 (Thread-3): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:47:22.370929 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-17 04:47:22.381190 (Thread-3): finished collecting timing info
2020-10-17 04:47:22.382639 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 04:47:22.384095 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:22.413822 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:22.415438 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 71da4d71-482b-4c15-bace-560d2a45858e)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:22.416656 (Thread-4): finished collecting timing info
2020-10-17 04:47:22.418812 (Thread-4): Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 71da4d71-482b-4c15-bace-560d2a45858e)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 71da4d71-482b-4c15-bace-560d2a45858e)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 71da4d71-482b-4c15-bace-560d2a45858e)
2020-10-17 04:47:22.420849 (Thread-4): 04:47:22 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 1.28s]
2020-10-17 04:47:22.422058 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-17 04:47:22.423004 (Thread-4): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:47:22.424648 (Thread-4): 04:47:22 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-17 04:47:22.426104 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-17 04:47:22.427090 (Thread-4): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:47:22.445668 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-17 04:47:22.455207 (Thread-4): finished collecting timing info
2020-10-17 04:47:22.456826 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 04:47:22.458205 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:22.720222 (Thread-2): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:23.054865 (Thread-1): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:23.063556 (Thread-3): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:23.132171 (Thread-4): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:23.229713 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:23.231523 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 8feec09e-2552-4d83-a007-847997c31355)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:23.233261 (Thread-2): finished collecting timing info
2020-10-17 04:47:23.236052 (Thread-2): Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 8feec09e-2552-4d83-a007-847997c31355)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 8feec09e-2552-4d83-a007-847997c31355)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 8feec09e-2552-4d83-a007-847997c31355)
2020-10-17 04:47:23.237946 (Thread-2): 04:47:23 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 1.20s]
2020-10-17 04:47:23.240374 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 04:47:23.242811 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:47:23.244428 (Thread-2): 04:47:23 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-17 04:47:23.247236 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-17 04:47:23.249791 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:47:23.267258 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-17 04:47:23.279586 (Thread-2): finished collecting timing info
2020-10-17 04:47:23.280584 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 04:47:23.281535 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 04:47:23.590384 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:23.599183 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: df582ef6-e784-4afd-a139-6857cc0e8f84)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_actives`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:23.600722 (Thread-3): finished collecting timing info
2020-10-17 04:47:23.602455 (Thread-3): Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: df582ef6-e784-4afd-a139-6857cc0e8f84)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: df582ef6-e784-4afd-a139-6857cc0e8f84)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_actives`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: df582ef6-e784-4afd-a139-6857cc0e8f84)
2020-10-17 04:47:23.606759 (Thread-3): 04:47:23 | 15 of 17 ERROR unique_stg_command_actives_command_uuid............... [ERROR in 1.26s]
2020-10-17 04:47:23.593164 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 04:47:23.608513 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9e0e6497-2bfe-4dd2-923e-0ee76b1fcea0)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:23.609960 (Thread-1): finished collecting timing info
2020-10-17 04:47:23.611680 (Thread-1): Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9e0e6497-2bfe-4dd2-923e-0ee76b1fcea0)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 9e0e6497-2bfe-4dd2-923e-0ee76b1fcea0)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 9e0e6497-2bfe-4dd2-923e-0ee76b1fcea0)
2020-10-17 04:47:23.613085 (Thread-1): 04:47:23 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.31s]
2020-10-17 04:47:23.613939 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 04:47:23.607738 (Thread-3): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 04:47:23.661622 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:23.662785 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 190458ea-81e6-4543-86a9-1817904c85ea)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_results`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:23.663684 (Thread-4): finished collecting timing info
2020-10-17 04:47:23.665260 (Thread-4): Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 190458ea-81e6-4543-86a9-1817904c85ea)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 190458ea-81e6-4543-86a9-1817904c85ea)

                                                                  -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_command_results`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 190458ea-81e6-4543-86a9-1817904c85ea)
2020-10-17 04:47:23.666643 (Thread-4): 04:47:23 | 16 of 17 ERROR unique_stg_command_results_command_uuid............... [ERROR in 1.24s]
2020-10-17 04:47:23.667666 (Thread-4): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 04:47:23.883558 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:24.323855 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 04:47:24.326778 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 68f44077-f93b-4e7c-86cf-75985a3e19fd)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_commands`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 04:47:24.329079 (Thread-2): finished collecting timing info
2020-10-17 04:47:24.331273 (Thread-2): Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 68f44077-f93b-4e7c-86cf-75985a3e19fd)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 68f44077-f93b-4e7c-86cf-75985a3e19fd)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_commands`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 68f44077-f93b-4e7c-86cf-75985a3e19fd)
2020-10-17 04:47:24.333095 (Thread-2): 04:47:24 | 17 of 17 ERROR unique_stg_commands_command_uuid...................... [ERROR in 1.09s]
2020-10-17 04:47:24.334558 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 04:47:24.339759 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 04:47:24.341196 (MainThread): 04:47:24 | 
2020-10-17 04:47:24.342245 (MainThread): 04:47:24 | Finished running 17 tests in 6.81s.
2020-10-17 04:47:24.344203 (MainThread): Connection 'master' was properly closed.
2020-10-17 04:47:24.345180 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-17 04:47:24.346077 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-17 04:47:24.347124 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-17 04:47:24.347990 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-17 04:47:24.413931 (MainThread): 
2020-10-17 04:47:24.414692 (MainThread): Completed with 17 errors and 0 warnings:
2020-10-17 04:47:24.415664 (MainThread): 
2020-10-17 04:47:24.416647 (MainThread): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:47:24.417394 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:47:24.418413 (MainThread):   
2020-10-17 04:47:24.419459 (MainThread):   (job ID: 21344991-512b-43aa-bc86-be40da9370ea)
2020-10-17 04:47:24.420635 (MainThread): 
2020-10-17 04:47:24.421804 (MainThread): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.423060 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:47:24.424211 (MainThread):   
2020-10-17 04:47:24.425245 (MainThread):   (job ID: ae40cfd5-ebbb-4d7a-bc94-f0eb78c686d4)
2020-10-17 04:47:24.426572 (MainThread): 
2020-10-17 04:47:24.428001 (MainThread): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-17 04:47:24.428914 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:47:24.429809 (MainThread):   
2020-10-17 04:47:24.430832 (MainThread):   (job ID: 7a440e93-660a-441d-b392-fa1970156594)
2020-10-17 04:47:24.431944 (MainThread): 
2020-10-17 04:47:24.432836 (MainThread): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.433796 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:47:24.435007 (MainThread):   
2020-10-17 04:47:24.436025 (MainThread):   (job ID: 1b628ed0-f8f6-44dd-802b-636b297d2276)
2020-10-17 04:47:24.437029 (MainThread): 
2020-10-17 04:47:24.438316 (MainThread): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:47:24.439416 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:47:24.441116 (MainThread):   
2020-10-17 04:47:24.442807 (MainThread):   (job ID: a0a304b4-d573-47ac-bc8e-5facb2f6bf59)
2020-10-17 04:47:24.444115 (MainThread): 
2020-10-17 04:47:24.445316 (MainThread): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
2020-10-17 04:47:24.446357 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.447583 (MainThread):   
2020-10-17 04:47:24.449473 (MainThread):   (job ID: a8c9980a-5fb1-41e7-a2a3-d08de94405e8)
2020-10-17 04:47:24.450543 (MainThread): 
2020-10-17 04:47:24.451665 (MainThread): Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 04:47:24.452693 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.453642 (MainThread):   
2020-10-17 04:47:24.454605 (MainThread):   (job ID: 5086491d-9ec4-4eec-b73d-fcbf7a7a3bdb)
2020-10-17 04:47:24.455439 (MainThread): 
2020-10-17 04:47:24.456376 (MainThread): Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.457370 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.458364 (MainThread):   
2020-10-17 04:47:24.459282 (MainThread):   (job ID: 9c63b85d-af66-4ea9-b352-6f348c634b5a)
2020-10-17 04:47:24.460421 (MainThread): 
2020-10-17 04:47:24.461593 (MainThread): Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
2020-10-17 04:47:24.462988 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.464089 (MainThread):   
2020-10-17 04:47:24.465299 (MainThread):   (job ID: b3ddf4a9-1f10-4bce-8f1c-95895be056da)
2020-10-17 04:47:24.466364 (MainThread): 
2020-10-17 04:47:24.467336 (MainThread): Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-17 04:47:24.468474 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.469652 (MainThread):   
2020-10-17 04:47:24.470959 (MainThread):   (job ID: 2fbf2322-a19d-4706-8a4d-fb41634b072c)
2020-10-17 04:47:24.472286 (MainThread): 
2020-10-17 04:47:24.473524 (MainThread): Runtime Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-17 04:47:24.474526 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.475640 (MainThread):   
2020-10-17 04:47:24.476569 (MainThread):   (job ID: 05b5c694-54b7-404c-87d6-b244a04d7553)
2020-10-17 04:47:24.477618 (MainThread): 
2020-10-17 04:47:24.478820 (MainThread): Runtime Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-17 04:47:24.480387 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.481654 (MainThread):   
2020-10-17 04:47:24.483018 (MainThread):   (job ID: 71da4d71-482b-4c15-bace-560d2a45858e)
2020-10-17 04:47:24.484030 (MainThread): 
2020-10-17 04:47:24.485318 (MainThread): Runtime Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-17 04:47:24.486398 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.487772 (MainThread):   
2020-10-17 04:47:24.489143 (MainThread):   (job ID: 8feec09e-2552-4d83-a007-847997c31355)
2020-10-17 04:47:24.490104 (MainThread): 
2020-10-17 04:47:24.491347 (MainThread): Runtime Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-17 04:47:24.492403 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.493370 (MainThread):   
2020-10-17 04:47:24.494712 (MainThread):   (job ID: 9e0e6497-2bfe-4dd2-923e-0ee76b1fcea0)
2020-10-17 04:47:24.495759 (MainThread): 
2020-10-17 04:47:24.497038 (MainThread): Runtime Error in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.498099 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 04:47:24.499124 (MainThread):   
2020-10-17 04:47:24.500352 (MainThread):   (job ID: df582ef6-e784-4afd-a139-6857cc0e8f84)
2020-10-17 04:47:24.501398 (MainThread): 
2020-10-17 04:47:24.502786 (MainThread): Runtime Error in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.504252 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 04:47:24.505441 (MainThread):   
2020-10-17 04:47:24.506498 (MainThread):   (job ID: 190458ea-81e6-4543-86a9-1817904c85ea)
2020-10-17 04:47:24.507461 (MainThread): 
2020-10-17 04:47:24.508520 (MainThread): Runtime Error in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-17 04:47:24.509961 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 04:47:24.511553 (MainThread):   
2020-10-17 04:47:24.512990 (MainThread):   (job ID: 68f44077-f93b-4e7c-86cf-75985a3e19fd)
2020-10-17 04:47:24.514787 (MainThread): 
Done. PASS=0 WARN=0 ERROR=17 SKIP=0 TOTAL=17
2020-10-17 04:47:24.516568 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e08b80d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e0635970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28e0635f10>]}
2020-10-17 04:47:24.517815 (MainThread): Flushing usage events
2020-10-17 05:11:59.498426 (MainThread): Running with dbt=0.18.0
2020-10-17 05:11:59.738996 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='.', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 05:11:59.745415 (MainThread): Tracking: tracking
2020-10-17 05:11:59.748128 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63ee8559a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63edb47940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63edb47910>]}
2020-10-17 05:11:59.790683 (MainThread): Partial parsing not enabled
2020-10-17 05:11:59.793280 (MainThread): Parsing macros/etc.sql
2020-10-17 05:11:59.796478 (MainThread): Parsing macros/catalog.sql
2020-10-17 05:11:59.810227 (MainThread): Parsing macros/adapters.sql
2020-10-17 05:11:59.844050 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 05:11:59.849856 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 05:11:59.866623 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 05:11:59.888261 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 05:11:59.892243 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 05:11:59.899718 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 05:11:59.905802 (MainThread): Parsing macros/core.sql
2020-10-17 05:11:59.912079 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 05:11:59.927468 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 05:11:59.936998 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 05:11:59.948128 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 05:11:59.973869 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 05:12:00.000379 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 05:12:00.004538 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 05:12:00.057108 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 05:12:00.067478 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 05:12:00.071423 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 05:12:00.083392 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 05:12:00.118307 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 05:12:00.196967 (MainThread): Parsing macros/etc/query.sql
2020-10-17 05:12:00.200207 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 05:12:00.203741 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 05:12:00.206983 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 05:12:00.222022 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 05:12:00.226259 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 05:12:00.228911 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 05:12:00.232773 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 05:12:00.236046 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 05:12:00.240941 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 05:12:00.258385 (MainThread): Partial parsing not enabled
2020-10-17 05:12:00.358751 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 05:12:00.392641 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 05:12:00.413186 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 05:12:00.449830 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 05:12:00.470797 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 05:12:00.490589 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 05:12:00.511627 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 05:12:00.531489 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 05:12:01.101098 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 05:12:01.104298 (MainThread): 
2020-10-17 05:12:01.105904 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 05:12:01.137676 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 05:12:01.139842 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 05:12:01.143372 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:01.717461 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-17 05:12:02.378010 (MainThread): 05:12:02 | Concurrency: 4 threads (target='dev')
2020-10-17 05:12:02.380296 (MainThread): 05:12:02 | 
2020-10-17 05:12:02.403172 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:02.403664 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:02.404017 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:02.404302 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:02.404781 (Thread-1): 05:12:02 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-17 05:12:02.405888 (Thread-2): 05:12:02 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-17 05:12:02.407048 (Thread-3): 05:12:02 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-17 05:12:02.408123 (Thread-4): 05:12:02 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-17 05:12:02.409342 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-17 05:12:02.411611 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-17 05:12:02.412932 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-17 05:12:02.414086 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-17 05:12:02.414746 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:02.416150 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:02.417641 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:02.418934 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:02.470277 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-17 05:12:02.471425 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-17 05:12:02.476613 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-17 05:12:02.490801 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-17 05:12:02.498995 (Thread-2): finished collecting timing info
2020-10-17 05:12:02.499572 (Thread-4): finished collecting timing info
2020-10-17 05:12:02.500213 (Thread-3): finished collecting timing info
2020-10-17 05:12:02.500820 (Thread-2): Opening a new connection, currently in state init
2020-10-17 05:12:02.503378 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:02.501812 (Thread-4): Opening a new connection, currently in state init
2020-10-17 05:12:02.502500 (Thread-3): Opening a new connection, currently in state init
2020-10-17 05:12:02.500929 (Thread-1): finished collecting timing info
2020-10-17 05:12:02.508356 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:02.509648 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:02.510396 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:02.518791 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:03.099001 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 05:12:03.108100 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 05:12:03.112635 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 05:12:03.119109 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 05:12:03.809764 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 05:12:03.811218 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 05:12:03.812842 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: d2385690-9770-4c3f-a08f-abfb7bf9345e)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:03.814381 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: ddd695cc-d49d-47bf-b303-e4222d467b0f)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:03.816377 (Thread-2): finished collecting timing info
2020-10-17 05:12:03.818429 (Thread-1): finished collecting timing info
2020-10-17 05:12:03.820442 (Thread-2): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: d2385690-9770-4c3f-a08f-abfb7bf9345e)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: d2385690-9770-4c3f-a08f-abfb7bf9345e)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: d2385690-9770-4c3f-a08f-abfb7bf9345e)
2020-10-17 05:12:03.823149 (Thread-1): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: ddd695cc-d49d-47bf-b303-e4222d467b0f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US

(job ID: ddd695cc-d49d-47bf-b303-e4222d467b0f)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_actives`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
  
  (job ID: ddd695cc-d49d-47bf-b303-e4222d467b0f)
2020-10-17 05:12:03.827105 (Thread-2): 05:12:03 | 2 of 17 ERROR not_null_stg_command_actives_update_timestamp.......... [ERROR in 1.42s]
2020-10-17 05:12:03.828133 (Thread-1): 05:12:03 | 1 of 17 ERROR not_null_stg_command_actives_command_uuid.............. [ERROR in 1.42s]
2020-10-17 05:12:03.829670 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:03.830890 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:03.831996 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:03.833013 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:03.833871 (Thread-2): 05:12:03 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-17 05:12:03.834478 (Thread-1): 05:12:03 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-17 05:12:03.836276 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-17 05:12:03.837202 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-17 05:12:03.838704 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:03.837854 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:03.852948 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-17 05:12:03.867557 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-17 05:12:03.876617 (Thread-1): finished collecting timing info
2020-10-17 05:12:03.877109 (Thread-2): finished collecting timing info
2020-10-17 05:12:03.877747 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:03.878459 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:03.879511 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:03.880553 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:04.457964 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 05:12:04.462002 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46874), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:04.463295 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46878), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:04.464514 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33026), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:04.465826 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33024), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:04.471870 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 05:12:04.866009 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 05:12:04.868633 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1c8d91b2-e9c9-4dd3-bd42-c285fbddc36a)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:04.870430 (Thread-3): finished collecting timing info
2020-10-17 05:12:04.873301 (Thread-3): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1c8d91b2-e9c9-4dd3-bd42-c285fbddc36a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 1c8d91b2-e9c9-4dd3-bd42-c285fbddc36a)

                                                                   -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 1c8d91b2-e9c9-4dd3-bd42-c285fbddc36a)
2020-10-17 05:12:04.875698 (Thread-3): 05:12:04 | 3 of 17 ERROR not_null_stg_command_results_command_uuid.............. [ERROR in 2.46s]
2020-10-17 05:12:04.877719 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 05:12:04.878691 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:04.879882 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 904049b3-2f40-4b45-acb5-5179805b2efb)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:04.881100 (Thread-3): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:04.882403 (Thread-4): finished collecting timing info
2020-10-17 05:12:04.883902 (Thread-3): 05:12:04 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-17 05:12:04.885242 (Thread-4): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 904049b3-2f40-4b45-acb5-5179805b2efb)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 904049b3-2f40-4b45-acb5-5179805b2efb)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 904049b3-2f40-4b45-acb5-5179805b2efb)
2020-10-17 05:12:04.887067 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-17 05:12:04.888312 (Thread-4): 05:12:04 | 4 of 17 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 2.47s]
2020-10-17 05:12:04.889385 (Thread-3): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:04.890839 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:04.907244 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-17 05:12:04.907800 (Thread-4): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:04.910603 (Thread-4): 05:12:04 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-17 05:12:04.912622 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-17 05:12:04.914104 (Thread-4): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:04.929926 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-17 05:12:04.931633 (Thread-3): finished collecting timing info
2020-10-17 05:12:04.933213 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 05:12:04.934938 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:04.941775 (Thread-4): finished collecting timing info
2020-10-17 05:12:04.943839 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 05:12:04.945458 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:04.994780 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 05:12:04.995997 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 6d23aae7-a77e-4bbd-a434-33f8f283cc6f)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:04.997294 (Thread-2): finished collecting timing info
2020-10-17 05:12:04.999078 (Thread-2): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 6d23aae7-a77e-4bbd-a434-33f8f283cc6f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US

(job ID: 6d23aae7-a77e-4bbd-a434-33f8f283cc6f)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
  
  (job ID: 6d23aae7-a77e-4bbd-a434-33f8f283cc6f)
2020-10-17 05:12:05.000465 (Thread-2): 05:12:04 | 5 of 17 ERROR not_null_stg_command_results_update_timestamp.......... [ERROR in 1.16s]
2020-10-17 05:12:05.001773 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:05.002832 (Thread-2): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:05.003736 (Thread-2): 05:12:05 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-17 05:12:05.005103 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-17 05:12:05.006044 (Thread-2): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:05.020309 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-17 05:12:05.025162 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 05:12:05.026394 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 864e20db-47db-459b-b380-ce9c60638418)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:05.027705 (Thread-1): finished collecting timing info
2020-10-17 05:12:05.029442 (Thread-1): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 864e20db-47db-459b-b380-ce9c60638418)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 864e20db-47db-459b-b380-ce9c60638418)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 864e20db-47db-459b-b380-ce9c60638418)
2020-10-17 05:12:05.030790 (Thread-2): finished collecting timing info
2020-10-17 05:12:05.032011 (Thread-1): 05:12:05 | 6 of 17 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 1.20s]
2020-10-17 05:12:05.033346 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:05.034935 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:05.039186 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:05.040239 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-17 05:12:05.048460 (Thread-1): 05:12:05 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-17 05:12:05.051647 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 05:12:05.053348 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-17 05:12:05.082459 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-17 05:12:05.091759 (Thread-1): finished collecting timing info
2020-10-17 05:12:05.093366 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:05.094489 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:05.288977 (MainThread): 05:12:05 | The bigquery adapter does not support query cancellation. Some queries may still be running!
2020-10-17 05:12:05.319099 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:05.331314 (Thread-2): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 05:12:05.339740 (Thread-4): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 05:12:05.344497 (Thread-3): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 05:12:05.751203 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 05:12:05.753845 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 62cc5f16-c864-4977-8b56-8271a302c850)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:05.755841 (Thread-3): finished collecting timing info
2020-10-17 05:12:05.758415 (Thread-3): Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 62cc5f16-c864-4977-8b56-8271a302c850)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 62cc5f16-c864-4977-8b56-8271a302c850)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_command_uuid (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 62cc5f16-c864-4977-8b56-8271a302c850)
2020-10-17 05:12:05.760805 (Thread-3): 05:12:05 | 7 of 17 ERROR not_null_stg_commands_command_uuid..................... [ERROR in 0.87s]
2020-10-17 05:12:05.762249 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:05.774053 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 05:12:05.775693 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 6b1f5d06-8e09-46ab-b8a2-b734148be261)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:05.776956 (Thread-4): finished collecting timing info
2020-10-17 05:12:05.778751 (Thread-4): Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 6b1f5d06-8e09-46ab-b8a2-b734148be261)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 6b1f5d06-8e09-46ab-b8a2-b734148be261)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where update_timestamp is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_update_timestamp (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 6b1f5d06-8e09-46ab-b8a2-b734148be261)
2020-10-17 05:12:05.780184 (Thread-4): 05:12:05 | 8 of 17 ERROR not_null_stg_commands_update_timestamp................. [ERROR in 0.87s]
2020-10-17 05:12:05.781237 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:05.862627 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 05:12:05.865476 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 943c9308-e788-4365-a95d-db4f4bc298ed)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:05.868066 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:05.869203 (Thread-2): finished collecting timing info
2020-10-17 05:12:05.871089 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: cf5072f4-5c30-44fb-ac5e-58b891fcfd06)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-17 05:12:05.872648 (Thread-2): Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 943c9308-e788-4365-a95d-db4f4bc298ed)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: 943c9308-e788-4365-a95d-db4f4bc298ed)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: 943c9308-e788-4365-a95d-db4f4bc298ed)
2020-10-17 05:12:05.874279 (Thread-1): finished collecting timing info
2020-10-17 05:12:05.875717 (Thread-2): 05:12:05 | 9 of 17 ERROR not_null_stg_commands_user_id.......................... [ERROR in 0.87s]
2020-10-17 05:12:05.877013 (Thread-1): Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: cf5072f4-5c30-44fb-ac5e-58b891fcfd06)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US

(job ID: cf5072f4-5c30-44fb-ac5e-58b891fcfd06)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
  
  (job ID: cf5072f4-5c30-44fb-ac5e-58b891fcfd06)
2020-10-17 05:12:05.878470 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:05.879817 (Thread-1): 05:12:05 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 0.83s]
2020-10-17 05:12:05.882095 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-17 05:12:05.883997 (MainThread): 
2020-10-17 05:12:05.885128 (MainThread): Exited because of keyboard interrupt.
2020-10-17 05:12:05.886179 (MainThread): 
2020-10-17 05:12:05.887473 (MainThread): Runtime Error in test not_null_stg_command_actives_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 05:12:05.888834 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 05:12:05.890079 (MainThread):   
2020-10-17 05:12:05.891157 (MainThread):   (job ID: d2385690-9770-4c3f-a08f-abfb7bf9345e)
2020-10-17 05:12:05.892160 (MainThread): 
2020-10-17 05:12:05.892991 (MainThread): Runtime Error in test not_null_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 05:12:05.893859 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_actives was not found in location US
2020-10-17 05:12:05.894960 (MainThread):   
2020-10-17 05:12:05.895718 (MainThread):   (job ID: ddd695cc-d49d-47bf-b303-e4222d467b0f)
2020-10-17 05:12:05.896488 (MainThread): 
2020-10-17 05:12:05.897283 (MainThread): Runtime Error in test not_null_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 05:12:05.898300 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 05:12:05.899470 (MainThread):   
2020-10-17 05:12:05.900365 (MainThread):   (job ID: 1c8d91b2-e9c9-4dd3-bd42-c285fbddc36a)
2020-10-17 05:12:05.901315 (MainThread): 
2020-10-17 05:12:05.902239 (MainThread): Runtime Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-17 05:12:05.903145 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 05:12:05.904016 (MainThread):   
2020-10-17 05:12:05.904851 (MainThread):   (job ID: 904049b3-2f40-4b45-acb5-5179805b2efb)
2020-10-17 05:12:05.905727 (MainThread): 
2020-10-17 05:12:05.906748 (MainThread): Runtime Error in test not_null_stg_command_results_update_timestamp (models/staging/commands/schema.yml)
2020-10-17 05:12:05.907562 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_command_results was not found in location US
2020-10-17 05:12:05.908706 (MainThread):   
2020-10-17 05:12:05.909848 (MainThread):   (job ID: 6d23aae7-a77e-4bbd-a434-33f8f283cc6f)
2020-10-17 05:12:05.910791 (MainThread): 
2020-10-17 05:12:05.911637 (MainThread): Runtime Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
2020-10-17 05:12:05.912542 (MainThread):   404 Not found: Table analytics-interview:dev_sam.stg_commands was not found in location US
2020-10-17 05:12:05.913673 (MainThread):   
2020-10-17 05:12:05.914699 (MainThread):   (job ID: 864e20db-47db-459b-b380-ce9c60638418)
2020-10-17 05:12:05.915679 (MainThread): 
Done. PASS=0 WARN=0 ERROR=6 SKIP=0 TOTAL=6
2020-10-17 05:12:05.916593 (MainThread): Connection 'master' was properly closed.
2020-10-17 05:12:05.917437 (MainThread): Connection 'test.dwelo.stg_commands_locked_state' was properly closed.
2020-10-17 05:12:05.918228 (MainThread): Connection 'test.dwelo.not_null_stg_commands_user_id' was properly closed.
2020-10-17 05:12:05.918895 (MainThread): Connection 'test.dwelo.not_null_stg_commands_command_uuid' was properly closed.
2020-10-17 05:12:05.919565 (MainThread): Connection 'test.dwelo.not_null_stg_commands_update_timestamp' was properly closed.
2020-10-17 05:12:05.920261 (MainThread): Flushing usage events
2020-10-17 05:12:06.294147 (MainThread): ctrl-c
2020-10-17 05:12:10.930714 (MainThread): Running with dbt=0.18.0
2020-10-17 05:12:11.161455 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='.', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-17 05:12:11.166377 (MainThread): Tracking: tracking
2020-10-17 05:12:11.169063 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8833a92b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd88269bbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd88269bbb0>]}
2020-10-17 05:12:11.209637 (MainThread): Partial parsing not enabled
2020-10-17 05:12:11.211787 (MainThread): Parsing macros/etc.sql
2020-10-17 05:12:11.214973 (MainThread): Parsing macros/catalog.sql
2020-10-17 05:12:11.227806 (MainThread): Parsing macros/adapters.sql
2020-10-17 05:12:11.261016 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 05:12:11.266631 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 05:12:11.282959 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 05:12:11.303321 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 05:12:11.307241 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 05:12:11.315015 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 05:12:11.320751 (MainThread): Parsing macros/core.sql
2020-10-17 05:12:11.327033 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 05:12:11.342163 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 05:12:11.350390 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 05:12:11.361170 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 05:12:11.386640 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 05:12:11.412485 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 05:12:11.416253 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 05:12:11.467319 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 05:12:11.477315 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 05:12:11.481233 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 05:12:11.493099 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 05:12:11.528747 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 05:12:11.606436 (MainThread): Parsing macros/etc/query.sql
2020-10-17 05:12:11.609212 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 05:12:11.612746 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 05:12:11.616184 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 05:12:11.631431 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 05:12:11.635539 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 05:12:11.637643 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 05:12:11.641222 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 05:12:11.644445 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 05:12:11.649401 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 05:12:11.665838 (MainThread): Partial parsing not enabled
2020-10-17 05:12:11.763150 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 05:12:11.797350 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 05:12:11.816429 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 05:12:11.849316 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 05:12:11.868305 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 05:12:11.885713 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 05:12:11.903845 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 05:12:11.922184 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 05:12:12.481048 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 05:12:12.483858 (MainThread): 
2020-10-17 05:12:12.485234 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 05:12:12.490831 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-17 05:12:12.492041 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-17 05:12:12.494066 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:13.456314 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 05:12:13.457919 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-17 05:12:13.459509 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:13.975376 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-17 05:12:14.483311 (MainThread): 05:12:14 | Concurrency: 4 threads (target='dev')
2020-10-17 05:12:14.485220 (MainThread): 05:12:14 | 
2020-10-17 05:12:14.493915 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-17 05:12:14.494388 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-17 05:12:14.494715 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-17 05:12:14.496747 (Thread-1): 05:12:14 | 1 of 3 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-17 05:12:14.498896 (Thread-2): 05:12:14 | 2 of 3 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-17 05:12:14.500872 (Thread-3): 05:12:14 | 3 of 3 START view model dev_sam.stg_commands......................... [RUN]
2020-10-17 05:12:14.502078 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 05:12:14.503150 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 05:12:14.504433 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 05:12:14.505770 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-17 05:12:14.507062 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-17 05:12:14.508266 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-17 05:12:14.562451 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-17 05:12:14.574219 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-17 05:12:14.579096 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-17 05:12:14.586007 (Thread-1): finished collecting timing info
2020-10-17 05:12:14.598671 (Thread-3): finished collecting timing info
2020-10-17 05:12:14.605242 (Thread-2): finished collecting timing info
2020-10-17 05:12:14.649058 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46918), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:14.653816 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-17 05:12:14.656477 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-17 05:12:14.657534 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33064), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:14.663315 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-17 05:12:14.667887 (Thread-2): Opening a new connection, currently in state init
2020-10-17 05:12:14.668897 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:14.673116 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:14.674927 (Thread-3): Opening a new connection, currently in state init
2020-10-17 05:12:14.676696 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:14.677243 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:15.254862 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-17 05:12:15.255421 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-17 05:12:15.261142 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-17 05:12:16.195529 (Thread-2): finished collecting timing info
2020-10-17 05:12:16.197476 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa7d0aa2-1510-40c1-93fb-30f93c0d16be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8824ffeb0>]}
2020-10-17 05:12:16.199789 (Thread-2): 05:12:16 | 2 of 3 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.69s]
2020-10-17 05:12:16.200700 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-17 05:12:16.228275 (Thread-1): finished collecting timing info
2020-10-17 05:12:16.231365 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa7d0aa2-1510-40c1-93fb-30f93c0d16be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd88240a490>]}
2020-10-17 05:12:16.235222 (Thread-1): 05:12:16 | 1 of 3 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.73s]
2020-10-17 05:12:16.236649 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-17 05:12:16.260574 (Thread-3): finished collecting timing info
2020-10-17 05:12:16.262546 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fa7d0aa2-1510-40c1-93fb-30f93c0d16be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd882472790>]}
2020-10-17 05:12:16.264912 (Thread-3): 05:12:16 | 3 of 3 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.76s]
2020-10-17 05:12:16.266017 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-17 05:12:16.269381 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 05:12:16.270643 (MainThread): 05:12:16 | 
2020-10-17 05:12:16.271519 (MainThread): 05:12:16 | Finished running 3 view models in 3.79s.
2020-10-17 05:12:16.272470 (MainThread): Connection 'master' was properly closed.
2020-10-17 05:12:16.273428 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-17 05:12:16.274224 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-17 05:12:16.275074 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-17 05:12:16.294524 (MainThread): 
2020-10-17 05:12:16.295313 (MainThread): Completed successfully
2020-10-17 05:12:16.296239 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-10-17 05:12:16.297869 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd882532fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8823ba2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8823ba4c0>]}
2020-10-17 05:12:16.298977 (MainThread): Flushing usage events
2020-10-17 05:12:21.116890 (MainThread): Running with dbt=0.18.0
2020-10-17 05:12:21.350882 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='.', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-17 05:12:21.355329 (MainThread): Tracking: tracking
2020-10-17 05:12:21.358080 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e33c78e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e32fc5c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e32fc5c40>]}
2020-10-17 05:12:21.398849 (MainThread): Partial parsing not enabled
2020-10-17 05:12:21.401001 (MainThread): Parsing macros/etc.sql
2020-10-17 05:12:21.404480 (MainThread): Parsing macros/catalog.sql
2020-10-17 05:12:21.417327 (MainThread): Parsing macros/adapters.sql
2020-10-17 05:12:21.453424 (MainThread): Parsing macros/materializations/view.sql
2020-10-17 05:12:21.458886 (MainThread): Parsing macros/materializations/table.sql
2020-10-17 05:12:21.475745 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-17 05:12:21.496944 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-17 05:12:21.502021 (MainThread): Parsing macros/materializations/copy.sql
2020-10-17 05:12:21.509562 (MainThread): Parsing macros/materializations/seed.sql
2020-10-17 05:12:21.515282 (MainThread): Parsing macros/core.sql
2020-10-17 05:12:21.521832 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-17 05:12:21.537232 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-17 05:12:21.545779 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-17 05:12:21.556760 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-17 05:12:21.582398 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-17 05:12:21.609041 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-17 05:12:21.613228 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-17 05:12:21.664001 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-17 05:12:21.674889 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-17 05:12:21.678644 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-17 05:12:21.689978 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-17 05:12:21.725128 (MainThread): Parsing macros/adapters/common.sql
2020-10-17 05:12:21.806743 (MainThread): Parsing macros/etc/query.sql
2020-10-17 05:12:21.809888 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-17 05:12:21.813941 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-17 05:12:21.817481 (MainThread): Parsing macros/etc/datetime.sql
2020-10-17 05:12:21.832758 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-17 05:12:21.836867 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-17 05:12:21.839841 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-17 05:12:21.843677 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-17 05:12:21.846701 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-17 05:12:21.851493 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-17 05:12:21.865559 (MainThread): Partial parsing not enabled
2020-10-17 05:12:21.961016 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-17 05:12:21.992682 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-17 05:12:22.010632 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-17 05:12:22.042757 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 05:12:22.060031 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 05:12:22.077444 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 05:12:22.095663 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 05:12:22.113127 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 05:12:22.697676 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-17 05:12:22.701137 (MainThread): 
2020-10-17 05:12:22.702713 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 05:12:22.740588 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-17 05:12:22.742238 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-17 05:12:22.744577 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:23.325774 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-17 05:12:23.976839 (MainThread): 05:12:23 | Concurrency: 4 threads (target='dev')
2020-10-17 05:12:23.978336 (MainThread): 05:12:23 | 
2020-10-17 05:12:23.986039 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:23.986468 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:23.986740 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:23.987009 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:23.987779 (Thread-1): 05:12:23 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-17 05:12:23.988601 (Thread-2): 05:12:23 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-17 05:12:23.989291 (Thread-3): 05:12:23 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-17 05:12:23.990180 (Thread-4): 05:12:23 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-17 05:12:23.991776 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-17 05:12:23.992617 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-17 05:12:23.993571 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-17 05:12:23.994848 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-17 05:12:23.995858 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:23.996611 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:23.997517 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:23.998758 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:24.042968 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-17 05:12:24.048806 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-17 05:12:24.055005 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-17 05:12:24.068211 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-17 05:12:24.075658 (Thread-1): finished collecting timing info
2020-10-17 05:12:24.076599 (Thread-2): finished collecting timing info
2020-10-17 05:12:24.078912 (Thread-2): Opening a new connection, currently in state init
2020-10-17 05:12:24.077205 (Thread-4): finished collecting timing info
2020-10-17 05:12:24.078128 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:24.076947 (Thread-3): finished collecting timing info
2020-10-17 05:12:24.082491 (Thread-3): Opening a new connection, currently in state init
2020-10-17 05:12:24.080891 (Thread-4): Opening a new connection, currently in state init
2020-10-17 05:12:24.081865 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:24.080128 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:24.083266 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:24.084137 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:24.736928 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-17 05:12:24.742445 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-17 05:12:24.769737 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-17 05:12:24.781487 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-17 05:12:25.221089 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: is_hub_success at [10:7]')
2020-10-17 05:12:25.851352 (Thread-4): finished collecting timing info
2020-10-17 05:12:25.855210 (Thread-4): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: is_hub_success at [10:7]

(job ID: 3f545113-66ee-4646-87f7-1d3b166c04a1)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-17 05:12:25.859896 (Thread-4): 05:12:25 | 4 of 17 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 1.87s]
2020-10-17 05:12:25.861639 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-17 05:12:25.863720 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:25.865117 (Thread-4): 05:12:25 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-17 05:12:25.867207 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-17 05:12:25.868085 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:25.882129 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-17 05:12:25.890479 (Thread-4): finished collecting timing info
2020-10-17 05:12:25.891433 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 05:12:25.892244 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:26.429099 (Thread-2): finished collecting timing info
2020-10-17 05:12:26.431899 (Thread-2): 05:12:26 | 2 of 17 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.44s]
2020-10-17 05:12:26.433000 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-17 05:12:26.434982 (Thread-2): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:26.436933 (Thread-2): 05:12:26 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-17 05:12:26.438534 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-17 05:12:26.439178 (Thread-4): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-17 05:12:26.439909 (Thread-2): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:26.450239 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46940), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:26.451618 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46942), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:26.452850 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33092), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:26.453989 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33094), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:26.465695 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-17 05:12:26.472456 (Thread-2): finished collecting timing info
2020-10-17 05:12:26.473643 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:26.474674 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:26.786411 (Thread-1): finished collecting timing info
2020-10-17 05:12:26.788383 (Thread-1): 05:12:26 | 1 of 17 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.80s]
2020-10-17 05:12:26.789890 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-17 05:12:26.790777 (Thread-1): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:26.791754 (Thread-1): 05:12:26 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-17 05:12:26.793467 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-17 05:12:26.794189 (Thread-1): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:26.807014 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-17 05:12:26.817513 (Thread-1): finished collecting timing info
2020-10-17 05:12:26.818985 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:26.820045 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:26.986176 (Thread-3): finished collecting timing info
2020-10-17 05:12:26.988185 (Thread-3): 05:12:26 | 3 of 17 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.99s]
2020-10-17 05:12:26.989752 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-17 05:12:26.991102 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:26.992515 (Thread-3): 05:12:26 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-17 05:12:26.994066 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-17 05:12:26.995028 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:27.008932 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-17 05:12:27.019078 (Thread-3): finished collecting timing info
2020-10-17 05:12:27.020873 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 05:12:27.022287 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:27.085228 (Thread-2): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-17 05:12:27.391577 (Thread-1): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-17 05:12:27.587099 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-17 05:12:27.689830 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: _raw_desired_state at [10:7]')
2020-10-17 05:12:28.016748 (Thread-4): finished collecting timing info
2020-10-17 05:12:28.020374 (Thread-4): 05:12:28 | 5 of 17 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.15s]
2020-10-17 05:12:28.023140 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-17 05:12:28.025316 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:28.027226 (Thread-4): 05:12:28 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-17 05:12:28.029138 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-17 05:12:28.032072 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:28.048624 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-17 05:12:28.056619 (Thread-4): finished collecting timing info
2020-10-17 05:12:28.057704 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 05:12:28.058835 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:28.283959 (Thread-2): finished collecting timing info
2020-10-17 05:12:28.287064 (Thread-2): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: _raw_desired_state at [10:7]

(job ID: 289c1f2e-5598-4366-b128-587705be2c3c)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-17 05:12:28.288956 (Thread-2): 05:12:28 | 6 of 17 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 1.85s]
2020-10-17 05:12:28.290162 (Thread-2): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-17 05:12:28.291333 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-17 05:12:28.292450 (Thread-2): 05:12:28 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-17 05:12:28.293945 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-17 05:12:28.294991 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-17 05:12:28.321715 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-17 05:12:28.331299 (Thread-2): finished collecting timing info
2020-10-17 05:12:28.333675 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:28.334764 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:28.624231 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-17 05:12:28.901228 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:29.107178 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-17 05:12:29.112858 (Thread-3): finished collecting timing info
2020-10-17 05:12:29.119301 (Thread-3): 05:12:29 | 8 of 17 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.13s]
2020-10-17 05:12:29.120505 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-17 05:12:29.121785 (Thread-3): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-17 05:12:29.123101 (Thread-3): 05:12:29 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-17 05:12:29.124397 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-17 05:12:29.125417 (Thread-3): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-17 05:12:29.137872 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-17 05:12:29.144933 (Thread-3): finished collecting timing info
2020-10-17 05:12:29.146221 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 05:12:29.147759 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:29.449606 (Thread-1): finished collecting timing info
2020-10-17 05:12:29.452034 (Thread-1): 05:12:29 | 7 of 17 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.66s]
2020-10-17 05:12:29.453126 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-17 05:12:29.454053 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-17 05:12:29.455043 (Thread-1): 05:12:29 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-17 05:12:29.456382 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-17 05:12:29.457261 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-17 05:12:29.470648 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-17 05:12:29.480962 (Thread-1): finished collecting timing info
2020-10-17 05:12:29.482461 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:29.483752 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:29.493246 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-17 05:12:29.713664 (Thread-3): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:30.044132 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:30.400754 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-17 05:12:30.403322 (Thread-4): finished collecting timing info
2020-10-17 05:12:30.406524 (Thread-4): Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: e8b0093a-f286-41c4-bbc7-e59fd37afe50)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-17 05:12:30.408265 (Thread-4): 05:12:30 | 9 of 17 ERROR not_null_stg_commands_user_id.......................... [ERROR in 2.38s]
2020-10-17 05:12:30.409455 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-17 05:12:30.411179 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 05:12:30.412593 (Thread-4): 05:12:30 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-17 05:12:30.414144 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-17 05:12:30.415515 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-17 05:12:30.422845 (Thread-4): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33106), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:30.424241 (Thread-4): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46960), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:30.425423 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46964), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:30.426496 (Thread-4): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33110), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:30.427270 (Thread-4): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33114), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:30.428591 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46968), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:30.430326 (Thread-4): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 33118), raddr=('172.217.14.74', 443)>
2020-10-17 05:12:30.431688 (Thread-4): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 46972), raddr=('142.250.68.10', 443)>
2020-10-17 05:12:30.441055 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-17 05:12:30.448550 (Thread-4): finished collecting timing info
2020-10-17 05:12:30.449593 (Thread-4): Opening a new connection, currently in state closed
2020-10-17 05:12:30.451199 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:30.634328 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-17 05:12:30.754864 (Thread-2): finished collecting timing info
2020-10-17 05:12:30.757444 (Thread-2): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 1b958b86-d36e-4124-90f7-0178507e40c3)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-17 05:12:30.759819 (Thread-2): 05:12:30 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 2.47s]
2020-10-17 05:12:30.761073 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-17 05:12:30.762421 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 05:12:30.763811 (Thread-2): 05:12:30 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-17 05:12:30.765753 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-17 05:12:30.766911 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 05:12:30.782000 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-17 05:12:30.787236 (Thread-3): finished collecting timing info
2020-10-17 05:12:30.789286 (Thread-3): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 3264a2db-45e5-4092-b850-3e8e2c5b75fd)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-17 05:12:30.791146 (Thread-3): 05:12:30 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 1.67s]
2020-10-17 05:12:30.792557 (Thread-3): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-17 05:12:30.794283 (Thread-3): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 05:12:30.795860 (Thread-3): 05:12:30 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-17 05:12:30.798872 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-17 05:12:30.801097 (Thread-3): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 05:12:30.802549 (Thread-2): finished collecting timing info
2020-10-17 05:12:30.821182 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:30.822994 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:30.820927 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-17 05:12:30.835763 (Thread-3): finished collecting timing info
2020-10-17 05:12:30.837108 (Thread-3): Opening a new connection, currently in state closed
2020-10-17 05:12:30.838400 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:31.037314 (Thread-4): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:31.392662 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-17 05:12:31.417958 (Thread-3): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 05:12:31.606434 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-17 05:12:31.943730 (Thread-1): finished collecting timing info
2020-10-17 05:12:31.946898 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 660781a7-b230-43c9-a764-c85ae378b788)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-17 05:12:31.949609 (Thread-1): 05:12:31 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 2.49s]
2020-10-17 05:12:31.950672 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-17 05:12:31.952471 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 05:12:31.954038 (Thread-1): 05:12:31 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-17 05:12:31.955778 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-17 05:12:31.956926 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 05:12:31.972247 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-17 05:12:31.973664 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-17 05:12:31.980536 (Thread-1): finished collecting timing info
2020-10-17 05:12:31.981741 (Thread-1): Opening a new connection, currently in state closed
2020-10-17 05:12:31.982940 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:32.508624 (Thread-2): finished collecting timing info
2020-10-17 05:12:32.511252 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 535028c3-7179-41bb-8b1f-a4a07c90c3a0)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-17 05:12:32.513630 (Thread-2): 05:12:32 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.75s]
2020-10-17 05:12:32.515295 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-17 05:12:32.516909 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 05:12:32.518417 (Thread-2): 05:12:32 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-17 05:12:32.520535 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-17 05:12:32.521751 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-17 05:12:32.539376 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-17 05:12:32.540140 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 05:12:32.548951 (Thread-2): finished collecting timing info
2020-10-17 05:12:32.550096 (Thread-2): Opening a new connection, currently in state closed
2020-10-17 05:12:32.551054 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-17 05:12:32.894852 (Thread-4): finished collecting timing info
2020-10-17 05:12:32.896897 (Thread-4): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 780091e7-dc7a-4d08-b449-c41154c5c6c1)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-17 05:12:32.898445 (Thread-4): 05:12:32 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.48s]
2020-10-17 05:12:32.899287 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-17 05:12:33.110282 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-17 05:12:33.879289 (Thread-3): finished collecting timing info
2020-10-17 05:12:33.882114 (Thread-3): 05:12:33 | 15 of 17 FAIL 3342 unique_stg_command_actives_command_uuid........... [FAIL 3342 in 3.08s]
2020-10-17 05:12:33.884771 (Thread-3): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-17 05:12:34.547811 (Thread-1): finished collecting timing info
2020-10-17 05:12:34.551811 (Thread-1): 05:12:34 | 16 of 17 FAIL 3342 unique_stg_command_results_command_uuid........... [FAIL 3342 in 2.60s]
2020-10-17 05:12:34.555701 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-17 05:12:35.139551 (Thread-2): finished collecting timing info
2020-10-17 05:12:35.142897 (Thread-2): 05:12:35 | 17 of 17 FAIL 3342 unique_stg_commands_command_uuid.................. [FAIL 3342 in 2.62s]
2020-10-17 05:12:35.144770 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-17 05:12:35.149979 (MainThread): Acquiring new bigquery connection "master".
2020-10-17 05:12:35.151276 (MainThread): 05:12:35 | 
2020-10-17 05:12:35.152088 (MainThread): 05:12:35 | Finished running 17 tests in 12.45s.
2020-10-17 05:12:35.153036 (MainThread): Connection 'master' was properly closed.
2020-10-17 05:12:35.154045 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-17 05:12:35.154840 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-17 05:12:35.155611 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-17 05:12:35.156313 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-17 05:12:35.224131 (MainThread): 
2020-10-17 05:12:35.224810 (MainThread): Completed with 11 errors and 0 warnings:
2020-10-17 05:12:35.225596 (MainThread): 
2020-10-17 05:12:35.226505 (MainThread): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-17 05:12:35.227222 (MainThread):   Unrecognized name: is_hub_success at [10:7]
2020-10-17 05:12:35.227966 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-17 05:12:35.228772 (MainThread): 
2020-10-17 05:12:35.229584 (MainThread): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
2020-10-17 05:12:35.230523 (MainThread):   Unrecognized name: _raw_desired_state at [10:7]
2020-10-17 05:12:35.231515 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-17 05:12:35.232649 (MainThread): 
2020-10-17 05:12:35.233679 (MainThread): Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
2020-10-17 05:12:35.234525 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-17 05:12:35.235402 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-17 05:12:35.236818 (MainThread): 
2020-10-17 05:12:35.237728 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-17 05:12:35.238667 (MainThread):   Unrecognized name: command at [9:3]
2020-10-17 05:12:35.239806 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-17 05:12:35.240741 (MainThread): 
2020-10-17 05:12:35.241709 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-17 05:12:35.242614 (MainThread):   Unrecognized name: command at [9:3]
2020-10-17 05:12:35.243588 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-17 05:12:35.244497 (MainThread): 
2020-10-17 05:12:35.245487 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-17 05:12:35.246471 (MainThread):   Unrecognized name: command at [9:3]
2020-10-17 05:12:35.247375 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-17 05:12:35.248308 (MainThread): 
2020-10-17 05:12:35.249198 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-17 05:12:35.250034 (MainThread):   Unrecognized name: command at [9:3]
2020-10-17 05:12:35.250804 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-17 05:12:35.251594 (MainThread): 
2020-10-17 05:12:35.252645 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-17 05:12:35.253544 (MainThread):   Unrecognized name: command at [9:3]
2020-10-17 05:12:35.254313 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-17 05:12:35.255441 (MainThread): 
2020-10-17 05:12:35.256847 (MainThread): Failure in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-17 05:12:35.257647 (MainThread):   Got 3342 results, expected 0.
2020-10-17 05:12:35.258594 (MainThread): 
2020-10-17 05:12:35.259466 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_actives_command_uuid.sql
2020-10-17 05:12:35.260465 (MainThread): 
2020-10-17 05:12:35.261462 (MainThread): Failure in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-17 05:12:35.262413 (MainThread):   Got 3342 results, expected 0.
2020-10-17 05:12:35.263292 (MainThread): 
2020-10-17 05:12:35.264286 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_results_command_uuid.sql
2020-10-17 05:12:35.265539 (MainThread): 
2020-10-17 05:12:35.266634 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-17 05:12:35.267836 (MainThread):   Got 3342 results, expected 0.
2020-10-17 05:12:35.268891 (MainThread): 
2020-10-17 05:12:35.270253 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-17 05:12:35.271500 (MainThread): 
Done. PASS=6 WARN=0 ERROR=11 SKIP=0 TOTAL=17
2020-10-17 05:12:35.272868 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e301fafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e32cf9610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e32ce5d00>]}
2020-10-17 05:12:35.274008 (MainThread): Flushing usage events
2020-10-19 21:56:02.516177 (MainThread): Running with dbt=0.18.0
2020-10-19 21:56:02.861547 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-19 21:56:02.871788 (MainThread): Tracking: tracking
2020-10-19 21:56:02.876816 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f2c34d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f1f04a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f1f049d0>]}
2020-10-19 21:56:02.911613 (MainThread): Partial parsing not enabled
2020-10-19 21:56:02.915769 (MainThread): Parsing macros/etc.sql
2020-10-19 21:56:02.919304 (MainThread): Parsing macros/catalog.sql
2020-10-19 21:56:02.932775 (MainThread): Parsing macros/adapters.sql
2020-10-19 21:56:02.967049 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 21:56:02.974380 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 21:56:02.990848 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 21:56:03.012171 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 21:56:03.017212 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 21:56:03.025447 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 21:56:03.035443 (MainThread): Parsing macros/core.sql
2020-10-19 21:56:03.041963 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 21:56:03.058077 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 21:56:03.067925 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 21:56:03.079969 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 21:56:03.106416 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 21:56:03.133406 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 21:56:03.137785 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 21:56:03.190461 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 21:56:03.202849 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 21:56:03.207502 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 21:56:03.219819 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 21:56:03.256577 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 21:56:03.338646 (MainThread): Parsing macros/etc/query.sql
2020-10-19 21:56:03.341927 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 21:56:03.345538 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 21:56:03.349014 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 21:56:03.364390 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 21:56:03.369335 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 21:56:03.372257 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 21:56:03.376303 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 21:56:03.380003 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 21:56:03.385481 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 21:56:03.397204 (MainThread): Partial parsing not enabled
2020-10-19 21:56:03.487466 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 21:56:03.517565 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 21:56:03.534861 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 21:56:03.567241 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 21:56:03.583992 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 21:56:03.600013 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 21:56:03.616466 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 21:56:03.632705 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 21:56:04.172421 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 21:56:04.175720 (MainThread): 
2020-10-19 21:56:04.177388 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 21:56:04.209195 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 21:56:04.211796 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-19 21:56:04.215588 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:04.748220 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 21:56:05.419757 (MainThread): 21:56:05 | Concurrency: 4 threads (target='dev')
2020-10-19 21:56:05.422346 (MainThread): 21:56:05 | 
2020-10-19 21:56:05.444858 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 21:56:05.446286 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 21:56:05.446825 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 21:56:05.447914 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 21:56:05.448936 (Thread-1): 21:56:05 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-19 21:56:05.450372 (Thread-2): 21:56:05 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-19 21:56:05.451733 (Thread-3): 21:56:05 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-19 21:56:05.452931 (Thread-4): 21:56:05 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-19 21:56:05.454888 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-19 21:56:05.456957 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-19 21:56:05.458619 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-19 21:56:05.460884 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-19 21:56:05.463163 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 21:56:05.464953 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 21:56:05.467203 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 21:56:05.468355 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 21:56:05.512417 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-19 21:56:05.513713 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-19 21:56:05.542608 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-19 21:56:05.543876 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-19 21:56:05.553468 (Thread-3): finished collecting timing info
2020-10-19 21:56:05.553877 (Thread-1): finished collecting timing info
2020-10-19 21:56:05.554515 (Thread-4): finished collecting timing info
2020-10-19 21:56:05.554943 (Thread-2): finished collecting timing info
2020-10-19 21:56:05.555870 (Thread-3): Opening a new connection, currently in state init
2020-10-19 21:56:05.557204 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 21:56:05.558240 (Thread-4): Opening a new connection, currently in state init
2020-10-19 21:56:05.559426 (Thread-2): Opening a new connection, currently in state init
2020-10-19 21:56:05.561515 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:05.562555 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:05.563807 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:05.564752 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:06.139465 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-19 21:56:06.142276 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-19 21:56:06.142954 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-19 21:56:06.158943 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-19 21:56:07.162762 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: is_hub_success at [10:7]')
2020-10-19 21:56:08.071656 (Thread-4): finished collecting timing info
2020-10-19 21:56:08.076589 (Thread-4): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: is_hub_success at [10:7]

(job ID: 8bb14292-42d7-4e8b-aeac-94c5ba5fb110)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-19 21:56:08.086848 (Thread-4): 21:56:08 | 4 of 17 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 2.63s]
2020-10-19 21:56:08.088497 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 21:56:08.090541 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 21:56:08.092445 (Thread-4): 21:56:08 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-19 21:56:08.094296 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-19 21:56:08.095787 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 21:56:08.109562 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-19 21:56:08.116954 (Thread-4): finished collecting timing info
2020-10-19 21:56:08.119238 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 21:56:08.120831 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:08.461367 (Thread-1): finished collecting timing info
2020-10-19 21:56:08.464235 (Thread-1): 21:56:08 | 1 of 17 PASS not_null_stg_command_actives_command_uuid............... [PASS in 3.01s]
2020-10-19 21:56:08.465615 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 21:56:08.467081 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 21:56:08.468340 (Thread-1): 21:56:08 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-19 21:56:08.469855 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-19 21:56:08.471288 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 21:56:08.477867 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48788), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:08.479372 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48790), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:08.483280 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42522), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:08.484742 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42518), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:08.495653 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-19 21:56:08.504127 (Thread-1): finished collecting timing info
2020-10-19 21:56:08.506138 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 21:56:08.507613 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:08.673366 (Thread-4): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-19 21:56:08.681024 (Thread-2): finished collecting timing info
2020-10-19 21:56:08.683427 (Thread-2): 21:56:08 | 2 of 17 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 3.23s]
2020-10-19 21:56:08.685040 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 21:56:08.686312 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 21:56:08.687965 (Thread-2): 21:56:08 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-19 21:56:08.689908 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-19 21:56:08.691309 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 21:56:08.709061 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-19 21:56:08.711542 (Thread-3): finished collecting timing info
2020-10-19 21:56:08.715046 (Thread-3): 21:56:08 | 3 of 17 PASS not_null_stg_command_results_command_uuid............... [PASS in 3.26s]
2020-10-19 21:56:08.717142 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 21:56:08.718119 (Thread-2): finished collecting timing info
2020-10-19 21:56:08.719581 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 21:56:08.721873 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 21:56:08.723817 (Thread-3): 21:56:08 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-19 21:56:08.727911 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:08.730376 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-19 21:56:08.739625 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 21:56:08.756826 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-19 21:56:08.761634 (Thread-3): finished collecting timing info
2020-10-19 21:56:08.763437 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 21:56:08.765087 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:09.086405 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-19 21:56:09.299702 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-19 21:56:09.333899 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-19 21:56:09.519616 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: _raw_desired_state at [10:7]')
2020-10-19 21:56:10.507307 (Thread-4): finished collecting timing info
2020-10-19 21:56:10.511805 (Thread-4): 21:56:10 | 5 of 17 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.42s]
2020-10-19 21:56:10.514260 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 21:56:10.517735 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-19 21:56:10.520254 (Thread-4): 21:56:10 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-19 21:56:10.522328 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-19 21:56:10.525732 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-19 21:56:10.541583 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-19 21:56:10.549167 (Thread-4): finished collecting timing info
2020-10-19 21:56:10.550804 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 21:56:10.551990 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:10.780031 (Thread-1): finished collecting timing info
2020-10-19 21:56:10.783213 (Thread-1): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: _raw_desired_state at [10:7]

(job ID: 7ceb3d66-f396-4fd5-92b2-ffcf1cf05a80)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-19 21:56:10.785139 (Thread-1): 21:56:10 | 6 of 17 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 2.32s]
2020-10-19 21:56:10.786693 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 21:56:10.788331 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-19 21:56:10.789770 (Thread-1): 21:56:10 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-19 21:56:10.791494 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 21:56:10.792861 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-19 21:56:10.815583 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-19 21:56:10.822886 (Thread-1): finished collecting timing info
2020-10-19 21:56:10.824440 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 21:56:10.825848 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:11.026782 (Thread-3): finished collecting timing info
2020-10-19 21:56:11.030344 (Thread-3): 21:56:11 | 8 of 17 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.30s]
2020-10-19 21:56:11.032327 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 21:56:11.034324 (Thread-3): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-19 21:56:11.036280 (Thread-3): 21:56:11 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-19 21:56:11.039434 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 21:56:11.041572 (Thread-3): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-19 21:56:11.057539 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-19 21:56:11.065274 (Thread-3): finished collecting timing info
2020-10-19 21:56:11.067462 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 21:56:11.069214 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:11.095231 (Thread-2): finished collecting timing info
2020-10-19 21:56:11.098329 (Thread-2): 21:56:11 | 7 of 17 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.41s]
2020-10-19 21:56:11.099821 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 21:56:11.101298 (Thread-2): Began running node test.dwelo.stg_commands_switch_state
2020-10-19 21:56:11.102866 (Thread-2): 21:56:11 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-19 21:56:11.105029 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 21:56:11.106558 (Thread-2): Compiling test.dwelo.stg_commands_switch_state
2020-10-19 21:56:11.126730 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-19 21:56:11.133084 (Thread-2): finished collecting timing info
2020-10-19 21:56:11.135217 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 21:56:11.136972 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:11.144962 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-19 21:56:11.432599 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 21:56:11.641430 (Thread-3): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 21:56:11.706701 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-19 21:56:11.708131 (Thread-2): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 21:56:11.985090 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-19 21:56:12.167959 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-19 21:56:12.211527 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-19 21:56:12.677002 (Thread-2): finished collecting timing info
2020-10-19 21:56:12.679956 (Thread-4): finished collecting timing info
2020-10-19 21:56:12.682979 (Thread-2): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: c818814f-4259-458d-8dcc-c89159864de5)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-19 21:56:12.685878 (Thread-4): Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 1158c0ed-3906-4cbc-81a8-e27354be39cd)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-19 21:56:12.688204 (Thread-2): 21:56:12 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 1.58s]
2020-10-19 21:56:12.689826 (Thread-4): 21:56:12 | 9 of 17 ERROR not_null_stg_commands_user_id.......................... [ERROR in 2.17s]
2020-10-19 21:56:12.691568 (Thread-2): Finished running node test.dwelo.stg_commands_switch_state
2020-10-19 21:56:12.693367 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-19 21:56:12.695024 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-19 21:56:12.697035 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 21:56:12.698398 (Thread-2): 21:56:12 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-19 21:56:12.699615 (Thread-4): 21:56:12 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-19 21:56:12.701478 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 21:56:12.702539 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 21:56:12.703368 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-19 21:56:12.704441 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 21:56:12.710175 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42530), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:12.724317 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-19 21:56:12.725079 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48806), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:12.728395 (Thread-2): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42536), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:12.730158 (Thread-4): finished collecting timing info
2020-10-19 21:56:12.730830 (Thread-2): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42538), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:12.732416 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 21:56:12.734814 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48810), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:12.736165 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:12.737059 (Thread-2): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48812), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:12.742359 (Thread-2): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42542), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:12.744077 (Thread-2): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48818), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:12.745969 (Thread-2): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 48828), raddr=('142.250.72.234', 443)>
2020-10-19 21:56:12.747251 (Thread-2): unclosed <socket.socket fd=28, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42554), raddr=('172.217.14.74', 443)>
2020-10-19 21:56:12.759996 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-19 21:56:12.765245 (Thread-2): finished collecting timing info
2020-10-19 21:56:12.767090 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 21:56:12.769219 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:13.259274 (Thread-1): finished collecting timing info
2020-10-19 21:56:13.262432 (Thread-1): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 97e38963-0a99-4b90-9410-f839af50e067)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-19 21:56:13.265068 (Thread-1): 21:56:13 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 2.47s]
2020-10-19 21:56:13.267624 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-19 21:56:13.269821 (Thread-1): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 21:56:13.271616 (Thread-1): 21:56:13 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-19 21:56:13.274752 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-19 21:56:13.276921 (Thread-1): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 21:56:13.299168 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-19 21:56:13.300337 (Thread-4): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 21:56:13.307114 (Thread-1): finished collecting timing info
2020-10-19 21:56:13.309182 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 21:56:13.311116 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:13.347583 (Thread-2): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 21:56:13.608350 (Thread-3): finished collecting timing info
2020-10-19 21:56:13.611405 (Thread-3): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: dbba8267-6ea3-4401-992b-efff0d23f7fc)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-19 21:56:13.613456 (Thread-3): 21:56:13 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 2.58s]
2020-10-19 21:56:13.615249 (Thread-3): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-19 21:56:13.616868 (Thread-3): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 21:56:13.618223 (Thread-3): 21:56:13 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-19 21:56:13.620072 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-19 21:56:13.621578 (Thread-3): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 21:56:13.637067 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-19 21:56:13.644475 (Thread-3): finished collecting timing info
2020-10-19 21:56:13.646567 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 21:56:13.648438 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:13.869531 (Thread-1): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 21:56:13.884747 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-19 21:56:13.925949 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command at [9:3]')
2020-10-19 21:56:14.191057 (Thread-3): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 21:56:14.928558 (Thread-4): finished collecting timing info
2020-10-19 21:56:14.935353 (Thread-4): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 82edf5bc-b8fe-44af-aa46-09b9a02deb06)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-19 21:56:14.937914 (Thread-4): 21:56:14 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 2.24s]
2020-10-19 21:56:14.939930 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 21:56:14.942193 (Thread-4): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-19 21:56:14.944166 (Thread-4): 21:56:14 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-19 21:56:14.946217 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-19 21:56:14.947716 (Thread-4): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-19 21:56:14.961921 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-19 21:56:14.967448 (Thread-4): finished collecting timing info
2020-10-19 21:56:14.968820 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 21:56:14.970090 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:56:15.169778 (Thread-2): finished collecting timing info
2020-10-19 21:56:15.173514 (Thread-2): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command at [9:3]

(job ID: 3c58c342-811c-470a-b87e-3ae5afab87db)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: command at [9:3]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-19 21:56:15.175388 (Thread-2): 21:56:15 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.47s]
2020-10-19 21:56:15.176781 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-19 21:56:15.506015 (Thread-4): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 21:56:15.804985 (Thread-1): finished collecting timing info
2020-10-19 21:56:15.809004 (Thread-1): 21:56:15 | 15 of 17 FAIL 3342 unique_stg_command_actives_command_uuid........... [FAIL 3342 in 2.54s]
2020-10-19 21:56:15.811394 (Thread-1): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 21:56:16.427683 (Thread-3): finished collecting timing info
2020-10-19 21:56:16.432059 (Thread-3): 21:56:16 | 16 of 17 FAIL 3342 unique_stg_command_results_command_uuid........... [FAIL 3342 in 2.81s]
2020-10-19 21:56:16.434283 (Thread-3): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 21:56:18.608109 (Thread-4): finished collecting timing info
2020-10-19 21:56:18.611927 (Thread-4): 21:56:18 | 17 of 17 FAIL 3342 unique_stg_commands_command_uuid.................. [FAIL 3342 in 3.67s]
2020-10-19 21:56:18.614293 (Thread-4): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-19 21:56:18.620100 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 21:56:18.622170 (MainThread): 21:56:18 | 
2020-10-19 21:56:18.623820 (MainThread): 21:56:18 | Finished running 17 tests in 14.44s.
2020-10-19 21:56:18.625654 (MainThread): Connection 'master' was properly closed.
2020-10-19 21:56:18.627213 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-19 21:56:18.628423 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-19 21:56:18.629445 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-19 21:56:18.630614 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-19 21:56:18.694094 (MainThread): 
2020-10-19 21:56:18.695543 (MainThread): Completed with 11 errors and 0 warnings:
2020-10-19 21:56:18.697060 (MainThread): 
2020-10-19 21:56:18.698426 (MainThread): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-19 21:56:18.700020 (MainThread):   Unrecognized name: is_hub_success at [10:7]
2020-10-19 21:56:18.701597 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-19 21:56:18.703319 (MainThread): 
2020-10-19 21:56:18.705093 (MainThread): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/commands/schema.yml)
2020-10-19 21:56:18.706886 (MainThread):   Unrecognized name: _raw_desired_state at [10:7]
2020-10-19 21:56:18.708894 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-19 21:56:18.710734 (MainThread): 
2020-10-19 21:56:18.712739 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-19 21:56:18.715778 (MainThread):   Unrecognized name: command at [9:3]
2020-10-19 21:56:18.718314 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-19 21:56:18.721082 (MainThread): 
2020-10-19 21:56:18.723855 (MainThread): Database Error in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
2020-10-19 21:56:18.726525 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-19 21:56:18.729241 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-19 21:56:18.732437 (MainThread): 
2020-10-19 21:56:18.734499 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-19 21:56:18.735923 (MainThread):   Unrecognized name: command at [9:3]
2020-10-19 21:56:18.737369 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-19 21:56:18.738768 (MainThread): 
2020-10-19 21:56:18.740047 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-19 21:56:18.741255 (MainThread):   Unrecognized name: command at [9:3]
2020-10-19 21:56:18.742689 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-19 21:56:18.744169 (MainThread): 
2020-10-19 21:56:18.745592 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-19 21:56:18.746908 (MainThread):   Unrecognized name: command at [9:3]
2020-10-19 21:56:18.748128 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-19 21:56:18.749461 (MainThread): 
2020-10-19 21:56:18.751028 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-19 21:56:18.752875 (MainThread):   Unrecognized name: command at [9:3]
2020-10-19 21:56:18.754320 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-19 21:56:18.756183 (MainThread): 
2020-10-19 21:56:18.757861 (MainThread): Failure in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-19 21:56:18.759191 (MainThread):   Got 3342 results, expected 0.
2020-10-19 21:56:18.760765 (MainThread): 
2020-10-19 21:56:18.762127 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_actives_command_uuid.sql
2020-10-19 21:56:18.763647 (MainThread): 
2020-10-19 21:56:18.765568 (MainThread): Failure in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-19 21:56:18.767197 (MainThread):   Got 3342 results, expected 0.
2020-10-19 21:56:18.768644 (MainThread): 
2020-10-19 21:56:18.770059 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_results_command_uuid.sql
2020-10-19 21:56:18.771367 (MainThread): 
2020-10-19 21:56:18.772638 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/commands/schema.yml)
2020-10-19 21:56:18.774015 (MainThread):   Got 3342 results, expected 0.
2020-10-19 21:56:18.775202 (MainThread): 
2020-10-19 21:56:18.776555 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-19 21:56:18.777935 (MainThread): 
Done. PASS=6 WARN=0 ERROR=11 SKIP=0 TOTAL=17
2020-10-19 21:56:18.779414 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f1cabbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f1bba3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6f1dee670>]}
2020-10-19 21:56:18.780939 (MainThread): Flushing usage events
2020-10-19 21:59:49.514250 (MainThread): Running with dbt=0.18.0
2020-10-19 21:59:49.736834 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-19 21:59:49.741882 (MainThread): Tracking: tracking
2020-10-19 21:59:49.745089 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb7d31fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb707eca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb707ec70>]}
2020-10-19 21:59:49.777723 (MainThread): Partial parsing not enabled
2020-10-19 21:59:49.780343 (MainThread): Parsing macros/etc.sql
2020-10-19 21:59:49.783736 (MainThread): Parsing macros/catalog.sql
2020-10-19 21:59:49.796261 (MainThread): Parsing macros/adapters.sql
2020-10-19 21:59:49.828728 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 21:59:49.835115 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 21:59:49.851124 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 21:59:49.871305 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 21:59:49.875445 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 21:59:49.882807 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 21:59:49.888939 (MainThread): Parsing macros/core.sql
2020-10-19 21:59:49.895469 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 21:59:49.910939 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 21:59:49.920254 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 21:59:49.931408 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 21:59:49.957065 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 21:59:49.984628 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 21:59:49.988743 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 21:59:50.040903 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 21:59:50.052508 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 21:59:50.056397 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 21:59:50.067625 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 21:59:50.103815 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 21:59:50.182203 (MainThread): Parsing macros/etc/query.sql
2020-10-19 21:59:50.185137 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 21:59:50.188424 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 21:59:50.191849 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 21:59:50.207215 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 21:59:50.211684 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 21:59:50.213840 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 21:59:50.217523 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 21:59:50.221149 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 21:59:50.226225 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 21:59:50.239207 (MainThread): Partial parsing not enabled
2020-10-19 21:59:50.324994 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 21:59:50.357668 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 21:59:50.377544 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 21:59:50.410342 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 21:59:50.429560 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 21:59:50.448475 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 21:59:50.467994 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 21:59:50.487109 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 21:59:51.039944 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 21:59:51.043328 (MainThread): 
2020-10-19 21:59:51.045474 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 21:59:51.075269 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_source".
2020-10-19 21:59:51.076336 (ThreadPoolExecutor-1_1): Acquiring new bigquery connection "list_analytics-interview_dev_source_var('dataset')".
2020-10-19 21:59:51.077485 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-19 21:59:51.079130 (ThreadPoolExecutor-1_1): Opening a new connection, currently in state init
2020-10-19 21:59:51.083887 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:59:51.084132 (ThreadPoolExecutor-1_1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 21:59:51.627929 (ThreadPoolExecutor-1_1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 21:59:51.628373 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 21:59:52.072957 (MainThread): Connection 'master' was properly closed.
2020-10-19 21:59:52.075567 (MainThread): Connection 'list_analytics-interview_dev_source' was properly closed.
2020-10-19 21:59:52.077611 (MainThread): Connection 'list_analytics-interview_dev_source_var('dataset')' was properly closed.
2020-10-19 21:59:52.079645 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb6f25af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb7001c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb6ce6d90>]}
2020-10-19 21:59:52.081739 (MainThread): Flushing usage events
2020-10-19 21:59:52.451759 (MainThread): Encountered an error:
2020-10-19 21:59:52.455515 (MainThread): 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets/dev_source_var('dataset')/tables?maxResults=100000: Invalid dataset ID "dev_source_var('dataset')". Dataset IDs must be alphanumeric (plus underscores and dashes) and must be at most 1024 characters long.
2020-10-19 21:59:52.470563 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 395, in before_run
    self.populate_adapter_cache(adapter)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 359, in populate_adapter_cache
    adapter.set_relations_cache(self.manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 368, in set_relations_cache
    self._relations_cache_for_schemas(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 345, in _relations_cache_for_schemas
    for relation in future.result():
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 277, in list_relations_without_caching
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 277, in <listcomp>
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets/dev_source_var('dataset')/tables?maxResults=100000: Invalid dataset ID "dev_source_var('dataset')". Dataset IDs must be alphanumeric (plus underscores and dashes) and must be at most 1024 characters long.

2020-10-19 22:08:01.954642 (MainThread): Running with dbt=0.18.0
2020-10-19 22:08:02.178036 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:08:02.182693 (MainThread): Tracking: tracking
2020-10-19 22:08:02.186645 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ac9b2d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9abcfff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9abcfff40>]}
2020-10-19 22:08:02.219095 (MainThread): Partial parsing not enabled
2020-10-19 22:08:02.222190 (MainThread): Parsing macros/etc.sql
2020-10-19 22:08:02.225618 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:08:02.238083 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:08:02.270701 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:08:02.276717 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:08:02.293602 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:08:02.313720 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:08:02.318518 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:08:02.326025 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:08:02.332101 (MainThread): Parsing macros/core.sql
2020-10-19 22:08:02.338591 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:08:02.353851 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:08:02.363003 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:08:02.374137 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:08:02.399965 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:08:02.426645 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:08:02.430956 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:08:02.481292 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:08:02.493135 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:08:02.497582 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:08:02.509077 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:08:02.544900 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:08:02.622639 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:08:02.625798 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:08:02.629108 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:08:02.632611 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:08:02.647402 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:08:02.651834 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:08:02.654364 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:08:02.657940 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:08:02.661158 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:08:02.666097 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:08:02.678447 (MainThread): Partial parsing not enabled
2020-10-19 22:08:02.765039 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:08:02.797415 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:08:02.816475 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:08:02.846960 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:08:02.865995 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:08:02.884204 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:08:02.902424 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:08:02.920985 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:08:03.469176 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:08:03.472137 (MainThread): 
2020-10-19 22:08:03.474001 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:08:03.479881 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:08:03.481182 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:08:03.483987 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:08:04.496682 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_interview_source".
2020-10-19 22:08:04.499486 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_interview_source".
2020-10-19 22:08:04.501171 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.interview_source".
2020-10-19 22:08:04.502651 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:08:04.504182 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:08:05.030066 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:08:05.471962 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:08:05.474465 (MainThread): Connection 'create_analytics-interview_interview_source' was properly closed.
2020-10-19 22:08:05.477415 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9abb759a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ab95e8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9ab96b370>]}
2020-10-19 22:08:05.480036 (MainThread): Flushing usage events
2020-10-19 22:08:05.853783 (MainThread): Encountered an error:
2020-10-19 22:08:05.857377 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:08:05.864381 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:10:18.173353 (MainThread): Running with dbt=0.18.0
2020-10-19 22:10:18.393376 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:10:18.398060 (MainThread): Tracking: tracking
2020-10-19 22:10:18.401313 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79927c6fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7991b1cee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7991b1ceb0>]}
2020-10-19 22:10:18.434096 (MainThread): Partial parsing not enabled
2020-10-19 22:10:18.437145 (MainThread): Parsing macros/etc.sql
2020-10-19 22:10:18.440271 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:10:18.455088 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:10:18.488625 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:10:18.495255 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:10:18.512222 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:10:18.532271 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:10:18.536800 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:10:18.544125 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:10:18.550306 (MainThread): Parsing macros/core.sql
2020-10-19 22:10:18.557188 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:10:18.572681 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:10:18.582161 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:10:18.593123 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:10:18.618725 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:10:18.645048 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:10:18.649102 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:10:18.701024 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:10:18.711506 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:10:18.715872 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:10:18.727984 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:10:18.764549 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:10:18.840930 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:10:18.844719 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:10:18.848394 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:10:18.851855 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:10:18.866700 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:10:18.871608 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:10:18.874293 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:10:18.877941 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:10:18.881262 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:10:18.886324 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:10:18.897947 (MainThread): Partial parsing not enabled
2020-10-19 22:10:18.985325 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:10:19.016177 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:10:19.034960 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:10:19.065157 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:10:19.084333 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:10:19.102801 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:10:19.120878 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:10:19.139391 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:10:19.693649 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:10:19.697255 (MainThread): 
2020-10-19 22:10:19.699128 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:10:19.704947 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:10:19.706222 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:10:19.709169 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:20.924600 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:10:20.926358 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:10:20.928181 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:21.450218 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:10:21.840393 (MainThread): 22:10:21 | Concurrency: 4 threads (target='dev')
2020-10-19 22:10:21.843768 (MainThread): 22:10:21 | 
2020-10-19 22:10:21.853535 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-19 22:10:21.854298 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-19 22:10:21.854546 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-19 22:10:21.856767 (Thread-1): 22:10:21 | 1 of 3 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 22:10:21.859074 (Thread-2): 22:10:21 | 2 of 3 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 22:10:21.861401 (Thread-3): 22:10:21 | 3 of 3 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 22:10:21.863338 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:10:21.865038 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:10:21.866446 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:10:21.867697 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-19 22:10:21.868943 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-19 22:10:21.870557 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-19 22:10:21.931880 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:10:21.934784 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:10:21.941540 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:10:21.947846 (Thread-2): finished collecting timing info
2020-10-19 22:10:21.948348 (Thread-3): finished collecting timing info
2020-10-19 22:10:21.966188 (Thread-1): finished collecting timing info
2020-10-19 22:10:22.014156 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 40768), raddr=('172.217.5.74', 443)>
2020-10-19 22:10:22.016494 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:10:22.020478 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:10:22.021822 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42600), raddr=('172.217.14.74', 443)>
2020-10-19 22:10:22.026596 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 40772), raddr=('172.217.5.74', 443)>
2020-10-19 22:10:22.028674 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:10:22.029259 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42604), raddr=('172.217.14.74', 443)>
2020-10-19 22:10:22.030679 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:22.031379 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:10:22.034220 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:10:22.040815 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:22.047584 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:10:22.050125 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:22.479011 (MainThread): 22:10:22 | The bigquery adapter does not support query cancellation. Some queries may still be running!
2020-10-19 22:10:22.554908 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:10:22.555297 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:10:22.560921 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:10:23.905222 (Thread-1): finished collecting timing info
2020-10-19 22:10:23.908270 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ee607fc-d338-4bed-a69a-e227e18dc3e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7991784be0>]}
2020-10-19 22:10:23.910975 (Thread-1): 22:10:23 | 1 of 3 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.05s]
2020-10-19 22:10:23.912383 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:10:23.960742 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:10:23.962972 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:10:23.965028 (MainThread): Connection 'model.dwelo.stg_command_results' was left open.
2020-10-19 22:10:23.967204 (MainThread): Connection 'model.dwelo.stg_commands' was left open.
2020-10-19 22:10:23.969402 (MainThread): Flushing usage events
2020-10-19 22:10:24.074031 (Thread-3): finished collecting timing info
2020-10-19 22:10:24.077280 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ee607fc-d338-4bed-a69a-e227e18dc3e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f799061fcd0>]}
2020-10-19 22:10:24.125899 (Thread-2): finished collecting timing info
2020-10-19 22:10:24.129222 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4ee607fc-d338-4bed-a69a-e227e18dc3e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7991705ca0>]}
2020-10-19 22:10:24.350006 (MainThread): ctrl-c
2020-10-19 22:10:24.353958 (Thread-3): 22:10:24 | 3 of 3 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.21s]
2020-10-19 22:10:54.909238 (MainThread): Running with dbt=0.18.0
2020-10-19 22:10:55.130616 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:10:55.135683 (MainThread): Tracking: tracking
2020-10-19 22:10:55.138684 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a190ad2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a183a9eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a183a9e80>]}
2020-10-19 22:10:55.171846 (MainThread): Partial parsing not enabled
2020-10-19 22:10:55.175287 (MainThread): Parsing macros/etc.sql
2020-10-19 22:10:55.178548 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:10:55.191433 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:10:55.224280 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:10:55.231242 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:10:55.249020 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:10:55.268792 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:10:55.272505 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:10:55.279896 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:10:55.286010 (MainThread): Parsing macros/core.sql
2020-10-19 22:10:55.292631 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:10:55.308176 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:10:55.316845 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:10:55.328128 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:10:55.353649 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:10:55.379917 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:10:55.384607 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:10:55.435527 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:10:55.446729 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:10:55.450670 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:10:55.462233 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:10:55.497422 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:10:55.574932 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:10:55.577920 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:10:55.581405 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:10:55.584727 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:10:55.599813 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:10:55.604313 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:10:55.606779 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:10:55.611098 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:10:55.614654 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:10:55.619883 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:10:55.632212 (MainThread): Partial parsing not enabled
2020-10-19 22:10:55.718622 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:10:55.751208 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:10:55.771317 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:10:55.801788 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:10:55.821453 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:10:55.839727 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:10:55.858082 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:10:55.876689 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:10:56.435403 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:10:56.438663 (MainThread): 
2020-10-19 22:10:56.440548 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:10:56.446301 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:10:56.447631 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:10:56.450319 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:57.483338 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_source".
2020-10-19 22:10:57.484992 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:10:57.486790 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:58.016835 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:10:58.609393 (MainThread): 22:10:58 | Concurrency: 4 threads (target='dev')
2020-10-19 22:10:58.612469 (MainThread): 22:10:58 | 
2020-10-19 22:10:58.620801 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-19 22:10:58.621180 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-19 22:10:58.621670 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-19 22:10:58.623723 (Thread-1): 22:10:58 | 1 of 3 START view model dev_source.stg_command_actives............... [RUN]
2020-10-19 22:10:58.626545 (Thread-2): 22:10:58 | 2 of 3 START view model dev_source.stg_command_results............... [RUN]
2020-10-19 22:10:58.628775 (Thread-3): 22:10:58 | 3 of 3 START view model dev_source.stg_commands...................... [RUN]
2020-10-19 22:10:58.631117 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:10:58.633075 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:10:58.634663 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:10:58.635685 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-19 22:10:58.637239 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-19 22:10:58.638514 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-19 22:10:58.696865 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:10:58.697618 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:10:58.713663 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:10:58.717291 (Thread-1): finished collecting timing info
2020-10-19 22:10:58.719055 (Thread-2): finished collecting timing info
2020-10-19 22:10:58.725670 (Thread-3): finished collecting timing info
2020-10-19 22:10:58.767526 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 40790), raddr=('172.217.5.74', 443)>
2020-10-19 22:10:58.787658 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:10:58.793026 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:10:58.794430 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42622), raddr=('172.217.14.74', 443)>
2020-10-19 22:10:58.798397 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:10:58.799081 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 40794), raddr=('172.217.5.74', 443)>
2020-10-19 22:10:58.800067 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:10:58.801007 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:58.801748 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42626), raddr=('172.217.14.74', 443)>
2020-10-19 22:10:58.802979 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:58.811795 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:10:58.820071 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:10:58.822188 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:10:59.374601 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_source`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:10:59.384906 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_source`.`stg_commands`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:10:59.404323 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_source`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:11:00.107411 (Thread-1): finished collecting timing info
2020-10-19 22:11:00.111637 (Thread-1): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.

(job ID: 9b856061-2618-4304-85a1-f3a4d5c98cb5)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_source`.`stg_command_actives`
   5:  OPTIONS()
   6:  as with final as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`dev_source`.`interview_source`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:
  91:select *
  92:from final;
  93:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-19 22:11:00.119786 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83ae2422-00c0-40fe-8c21-c021b347652a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a146624c0>]}
2020-10-19 22:11:00.123302 (Thread-1): 22:11:00 | 1 of 3 ERROR creating view model dev_source.stg_command_actives...... [ERROR in 1.49s]
2020-10-19 22:11:00.124653 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:11:00.303646 (Thread-3): finished collecting timing info
2020-10-19 22:11:00.306933 (Thread-3): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.

(job ID: a0809c6a-8328-4635-9550-ce65201e7071)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_source`.`stg_commands`
   5:  OPTIONS()
   6:  as with final as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`dev_source`.`interview_source`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:
  91:select *
  92:from final;
  93:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-19 22:11:00.309639 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83ae2422-00c0-40fe-8c21-c021b347652a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a14658640>]}
2020-10-19 22:11:00.312917 (Thread-3): 22:11:00 | 3 of 3 ERROR creating view model dev_source.stg_commands............. [ERROR in 1.68s]
2020-10-19 22:11:00.314415 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-19 22:11:00.394069 (Thread-2): finished collecting timing info
2020-10-19 22:11:00.397970 (Thread-2): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.

(job ID: 300bf56c-fce9-4af0-bdcc-55b81c023dd2)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_source`.`stg_command_results`
   5:  OPTIONS()
   6:  as with final as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`dev_source`.`interview_source`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:
  91:select *
  92:from final;
  93:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-19 22:11:00.401212 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83ae2422-00c0-40fe-8c21-c021b347652a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a190ad2e0>]}
2020-10-19 22:11:00.404708 (Thread-2): 22:11:00 | 2 of 3 ERROR creating view model dev_source.stg_command_results...... [ERROR in 1.77s]
2020-10-19 22:11:00.406253 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-19 22:11:00.410373 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:11:00.412381 (MainThread): 22:11:00 | 
2020-10-19 22:11:00.413649 (MainThread): 22:11:00 | Finished running 3 view models in 3.97s.
2020-10-19 22:11:00.414977 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:11:00.416512 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:11:00.417581 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 22:11:00.418719 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 22:11:00.440542 (MainThread): 
2020-10-19 22:11:00.442254 (MainThread): Completed with 3 errors and 0 warnings:
2020-10-19 22:11:00.443616 (MainThread): 
2020-10-19 22:11:00.445136 (MainThread): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
2020-10-19 22:11:00.447203 (MainThread):   Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
2020-10-19 22:11:00.451252 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-19 22:11:00.453539 (MainThread): 
2020-10-19 22:11:00.456454 (MainThread): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
2020-10-19 22:11:00.458659 (MainThread):   Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
2020-10-19 22:11:00.460799 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-19 22:11:00.463756 (MainThread): 
2020-10-19 22:11:00.466707 (MainThread): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
2020-10-19 22:11:00.468829 (MainThread):   Access Denied: Dataset analytics-interview:dev_source: User does not have bigquery.tables.create permission for dataset analytics-interview:dev_source.
2020-10-19 22:11:00.471267 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-19 22:11:00.473274 (MainThread): 
Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
2020-10-19 22:11:00.475873 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a17faedc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a17faeca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7a17faef70>]}
2020-10-19 22:11:00.477665 (MainThread): Flushing usage events
2020-10-19 22:11:54.644935 (MainThread): Running with dbt=0.18.0
2020-10-19 22:11:54.868437 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:11:54.874093 (MainThread): Tracking: tracking
2020-10-19 22:11:54.877352 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda20adeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda13fcca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda13fcc70>]}
2020-10-19 22:11:54.911186 (MainThread): Partial parsing not enabled
2020-10-19 22:11:54.913767 (MainThread): Parsing macros/etc.sql
2020-10-19 22:11:54.917456 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:11:54.929740 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:11:54.962253 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:11:54.968850 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:11:54.985266 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:11:55.005834 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:11:55.010648 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:11:55.018110 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:11:55.024005 (MainThread): Parsing macros/core.sql
2020-10-19 22:11:55.030779 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:11:55.045948 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:11:55.054793 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:11:55.065870 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:11:55.091569 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:11:55.117613 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:11:55.122402 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:11:55.173297 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:11:55.183736 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:11:55.187677 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:11:55.198627 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:11:55.233955 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:11:55.313635 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:11:55.316700 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:11:55.319875 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:11:55.323295 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:11:55.337936 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:11:55.343228 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:11:55.346055 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:11:55.350038 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:11:55.353291 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:11:55.358259 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:11:55.369578 (MainThread): Partial parsing not enabled
2020-10-19 22:11:55.455379 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:11:55.487026 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:11:55.506131 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:11:55.536793 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:11:55.555760 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:11:55.574636 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:11:55.593382 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:11:55.611310 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:11:56.159827 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:11:56.162743 (MainThread): 
2020-10-19 22:11:56.164367 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:11:56.170032 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:11:56.171323 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:11:56.173363 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:11:57.319391 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_source_dev_sam".
2020-10-19 22:11:57.323895 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_source_dev_sam".
2020-10-19 22:11:57.325854 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.dev_source_dev_sam".
2020-10-19 22:11:57.327573 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:11:57.329617 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:11:57.854530 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:11:58.465742 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:11:58.468288 (MainThread): Connection 'create_analytics-interview_dev_source_dev_sam' was properly closed.
2020-10-19 22:11:58.470911 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda1272580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda10534c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feda10634f0>]}
2020-10-19 22:11:58.472966 (MainThread): Flushing usage events
2020-10-19 22:11:58.884042 (MainThread): Encountered an error:
2020-10-19 22:11:58.887729 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:11:58.894246 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:12:41.486144 (MainThread): Running with dbt=0.18.0
2020-10-19 22:12:41.707660 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:12:41.712515 (MainThread): Tracking: tracking
2020-10-19 22:12:41.716156 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f896abffd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8969f4ecd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8969f4eca0>]}
2020-10-19 22:12:41.749838 (MainThread): Partial parsing not enabled
2020-10-19 22:12:41.752852 (MainThread): Parsing macros/etc.sql
2020-10-19 22:12:41.756962 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:12:41.769536 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:12:41.802346 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:12:41.808837 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:12:41.825340 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:12:41.846215 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:12:41.850442 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:12:41.858618 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:12:41.865079 (MainThread): Parsing macros/core.sql
2020-10-19 22:12:41.871560 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:12:41.886861 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:12:41.895978 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:12:41.907423 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:12:41.932496 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:12:41.958923 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:12:41.963334 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:12:42.014087 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:12:42.025452 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:12:42.029190 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:12:42.040388 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:12:42.075885 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:12:42.154908 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:12:42.157792 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:12:42.161169 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:12:42.164555 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:12:42.180177 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:12:42.184554 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:12:42.187941 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:12:42.191887 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:12:42.195750 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:12:42.200813 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:12:42.212859 (MainThread): Partial parsing not enabled
2020-10-19 22:12:42.301663 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:12:42.334221 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:12:42.353372 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:12:42.383493 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:12:42.402350 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:12:42.420955 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:12:42.440134 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:12:42.459069 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:12:43.079297 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:12:43.082636 (MainThread): 
2020-10-19 22:12:43.084367 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:12:43.090018 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:12:43.091303 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:12:43.093312 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:12:43.992395 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:12:43.995597 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:12:43.997455 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.dev_sam_dev_sam".
2020-10-19 22:12:43.999280 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:12:44.001306 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:12:44.536667 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:12:44.962572 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:12:44.965231 (MainThread): Connection 'create_analytics-interview_dev_sam_dev_sam' was properly closed.
2020-10-19 22:12:44.967460 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8969dc55b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8969bb6520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8969bbf910>]}
2020-10-19 22:12:44.969405 (MainThread): Flushing usage events
2020-10-19 22:12:45.330357 (MainThread): Encountered an error:
2020-10-19 22:12:45.333657 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:12:45.340249 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:13:37.353598 (MainThread): Running with dbt=0.18.0
2020-10-19 22:13:37.573400 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{"dataset", "dev_sam"}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:13:37.578931 (MainThread): Tracking: tracking
2020-10-19 22:13:37.581881 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e4724cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e4659bca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e4659bc70>]}
2020-10-19 22:13:37.614059 (MainThread): Partial parsing not enabled
2020-10-19 22:13:37.616722 (MainThread): Parsing macros/etc.sql
2020-10-19 22:13:37.620198 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:13:37.632610 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:13:37.665708 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:13:37.672353 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:13:37.687914 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:13:37.708978 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:13:37.713988 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:13:37.722712 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:13:37.728540 (MainThread): Parsing macros/core.sql
2020-10-19 22:13:37.735223 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:13:37.751170 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:13:37.760464 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:13:37.771695 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:13:37.796972 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:13:37.823078 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:13:37.828015 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:13:37.878561 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:13:37.888609 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:13:37.892560 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:13:37.903774 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:13:37.940345 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:13:38.019225 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:13:38.021949 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:13:38.025399 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:13:38.028946 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:13:38.043502 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:13:38.047729 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:13:38.050107 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:13:38.053843 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:13:38.057211 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:13:38.062082 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:13:38.073877 (MainThread): Partial parsing not enabled
2020-10-19 22:13:38.159692 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:13:38.191824 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:13:38.211270 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:13:38.241706 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:13:38.260622 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:13:38.279316 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:13:38.298343 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:13:38.317264 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:13:38.866845 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:13:38.869993 (MainThread): 
2020-10-19 22:13:38.871676 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:13:38.877705 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:13:38.879006 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:13:38.880957 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:13:39.789842 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:13:39.793398 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:13:39.795674 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.dev_sam_dev_sam".
2020-10-19 22:13:39.796870 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:13:39.799021 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:13:40.326476 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:13:40.874896 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:13:40.877523 (MainThread): Connection 'create_analytics-interview_dev_sam_dev_sam' was properly closed.
2020-10-19 22:13:40.879974 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e46412580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e4620ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e46171d00>]}
2020-10-19 22:13:40.881723 (MainThread): Flushing usage events
2020-10-19 22:13:41.266478 (MainThread): Encountered an error:
2020-10-19 22:13:41.269364 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:13:41.276006 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:17:30.633762 (MainThread): Running with dbt=0.18.0
2020-10-19 22:17:30.866539 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:17:30.871791 (MainThread): Tracking: tracking
2020-10-19 22:17:30.875289 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d88b3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d7c08eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d7c08e80>]}
2020-10-19 22:17:30.909443 (MainThread): Partial parsing not enabled
2020-10-19 22:17:30.912877 (MainThread): Parsing macros/etc.sql
2020-10-19 22:17:30.916546 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:17:30.929064 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:17:30.963724 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:17:30.970499 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:17:30.987207 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:17:31.008142 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:17:31.012651 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:17:31.020168 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:17:31.026337 (MainThread): Parsing macros/core.sql
2020-10-19 22:17:31.033003 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:17:31.048286 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:17:31.057023 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:17:31.068371 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:17:31.097325 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:17:31.124122 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:17:31.129005 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:17:31.178489 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:17:31.190409 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:17:31.194547 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:17:31.205750 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:17:31.240766 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:17:31.318578 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:17:31.321976 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:17:31.325480 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:17:31.328843 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:17:31.343505 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:17:31.348069 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:17:31.350456 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:17:31.354309 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:17:31.358200 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:17:31.363523 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:17:31.376343 (MainThread): Partial parsing not enabled
2020-10-19 22:17:31.469043 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:17:31.503395 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:17:31.523256 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:17:31.554461 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:17:31.574216 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:17:31.594037 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:17:31.614004 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:17:31.632716 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:17:32.223529 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:17:32.227521 (MainThread): 
2020-10-19 22:17:32.229910 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:17:32.235844 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:17:32.237294 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:17:32.239583 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:17:33.225736 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:17:33.230178 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_sam_dev_sam".
2020-10-19 22:17:33.232458 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.dev_sam_dev_sam".
2020-10-19 22:17:33.234482 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:17:33.236941 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:17:33.779316 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:17:34.368764 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:17:34.371136 (MainThread): Connection 'create_analytics-interview_dev_sam_dev_sam' was properly closed.
2020-10-19 22:17:34.373571 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d7a775b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d7872a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f11d77d9970>]}
2020-10-19 22:17:34.375717 (MainThread): Flushing usage events
2020-10-19 22:17:34.750944 (MainThread): Encountered an error:
2020-10-19 22:17:34.754481 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:17:34.761557 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:18:57.860079 (MainThread): Running with dbt=0.18.0
2020-10-19 22:18:58.158855 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:18:58.167827 (MainThread): Tracking: tracking
2020-10-19 22:18:58.172704 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223b96ae20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223acbdf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223acbdee0>]}
2020-10-19 22:18:58.233959 (MainThread): Partial parsing not enabled
2020-10-19 22:18:58.238010 (MainThread): Parsing macros/etc.sql
2020-10-19 22:18:58.243047 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:18:58.259372 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:18:58.296777 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:18:58.304409 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:18:58.321194 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:18:58.345225 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:18:58.350206 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:18:58.358737 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:18:58.366025 (MainThread): Parsing macros/core.sql
2020-10-19 22:18:58.372712 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:18:58.388709 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:18:58.399177 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:18:58.412298 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:18:58.443636 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:18:58.477624 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:18:58.483627 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:18:58.544669 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:18:58.559928 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:18:58.565321 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:18:58.580023 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:18:58.625300 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:18:58.727074 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:18:58.731156 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:18:58.735756 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:18:58.740580 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:18:58.760130 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:18:58.766047 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:18:58.769714 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:18:58.774968 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:18:58.779931 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:18:58.786879 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:18:58.802626 (MainThread): Partial parsing not enabled
2020-10-19 22:18:58.916132 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:18:58.952404 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:18:58.973028 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:18:59.008276 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:18:59.028496 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:18:59.047852 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:18:59.069294 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:18:59.088639 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:18:59.788944 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:18:59.794386 (MainThread): 
2020-10-19 22:18:59.797544 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:18:59.807196 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:18:59.809528 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:18:59.813233 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:19:01.226737 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:19:01.228856 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:19:01.231202 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:19:01.896208 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:19:02.262377 (MainThread): 22:19:02 | Concurrency: 4 threads (target='dev')
2020-10-19 22:19:02.265397 (MainThread): 22:19:02 | 
2020-10-19 22:19:02.275566 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-19 22:19:02.276032 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-19 22:19:02.276453 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-19 22:19:02.279356 (Thread-1): 22:19:02 | 1 of 3 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 22:19:02.284154 (Thread-2): 22:19:02 | 2 of 3 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 22:19:02.288265 (Thread-3): 22:19:02 | 3 of 3 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 22:19:02.292058 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:19:02.295107 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:19:02.297660 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:19:02.299149 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-19 22:19:02.301511 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-19 22:19:02.303310 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-19 22:19:02.421849 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:19:02.426440 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:19:02.434525 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:19:02.444223 (Thread-1): finished collecting timing info
2020-10-19 22:19:02.444848 (Thread-2): finished collecting timing info
2020-10-19 22:19:02.463404 (Thread-3): finished collecting timing info
2020-10-19 22:19:02.523131 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:19:02.526692 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:19:02.535906 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:19:02.541102 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:19:02.544624 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:19:02.545385 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:19:02.547207 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:19:02.548170 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:19:02.555629 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:19:03.217515 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:19:03.233895 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:19:03.241028 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42688), raddr=('172.217.14.74', 443)>
2020-10-19 22:19:03.243565 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:19:03.245182 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42690), raddr=('172.217.14.74', 443)>
2020-10-19 22:19:04.165676 (Thread-3): finished collecting timing info
2020-10-19 22:19:04.169584 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8178688-acca-433e-9fee-463cdf055ab8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a9d4c10>]}
2020-10-19 22:19:04.173169 (Thread-3): 22:19:04 | 3 of 3 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.87s]
2020-10-19 22:19:04.174870 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-19 22:19:04.189870 (Thread-2): finished collecting timing info
2020-10-19 22:19:04.198279 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8178688-acca-433e-9fee-463cdf055ab8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a9d4af0>]}
2020-10-19 22:19:04.201384 (Thread-1): finished collecting timing info
2020-10-19 22:19:04.204111 (Thread-2): 22:19:04 | 2 of 3 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.90s]
2020-10-19 22:19:04.207120 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8178688-acca-433e-9fee-463cdf055ab8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a9d4fa0>]}
2020-10-19 22:19:04.209820 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-19 22:19:04.213012 (Thread-1): 22:19:04 | 1 of 3 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.92s]
2020-10-19 22:19:04.216181 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:19:04.219688 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:19:04.221526 (MainThread): 22:19:04 | 
2020-10-19 22:19:04.223099 (MainThread): 22:19:04 | Finished running 3 view models in 4.43s.
2020-10-19 22:19:04.224677 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:19:04.226344 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:19:04.228399 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 22:19:04.230580 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 22:19:04.279914 (MainThread): 
2020-10-19 22:19:04.283726 (MainThread): Completed successfully
2020-10-19 22:19:04.287274 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-10-19 22:19:04.291285 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a9db3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a9db5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f223a971130>]}
2020-10-19 22:19:04.294573 (MainThread): Flushing usage events
2020-10-19 22:21:28.873854 (MainThread): Running with dbt=0.18.0
2020-10-19 22:21:29.100669 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:21:29.105791 (MainThread): Tracking: tracking
2020-10-19 22:21:29.108894 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fe48ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fd7deeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fd7dee80>]}
2020-10-19 22:21:29.141083 (MainThread): Partial parsing not enabled
2020-10-19 22:21:29.144848 (MainThread): Parsing macros/etc.sql
2020-10-19 22:21:29.148128 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:21:29.160808 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:21:29.197059 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:21:29.203584 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:21:29.219738 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:21:29.240789 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:21:29.245997 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:21:29.253741 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:21:29.259475 (MainThread): Parsing macros/core.sql
2020-10-19 22:21:29.266327 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:21:29.281178 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:21:29.289961 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:21:29.301482 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:21:29.326853 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:21:29.354613 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:21:29.359042 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:21:29.409282 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:21:29.421354 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:21:29.425668 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:21:29.437018 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:21:29.471666 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:21:29.550281 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:21:29.553420 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:21:29.556806 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:21:29.560091 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:21:29.574790 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:21:29.579386 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:21:29.581692 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:21:29.585466 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:21:29.588957 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:21:29.594416 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:21:29.607331 (MainThread): Partial parsing not enabled
2020-10-19 22:21:29.697185 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:21:29.725717 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:21:29.742197 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:21:29.769842 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:21:29.785905 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:21:29.802199 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:21:29.818361 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:21:29.834176 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:21:30.366130 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:21:30.368976 (MainThread): 
2020-10-19 22:21:30.371225 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:21:30.377886 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:21:30.379304 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:21:30.381582 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:31.441706 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_test".
2020-10-19 22:21:31.447553 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "create_analytics-interview_dev_test".
2020-10-19 22:21:31.449757 (ThreadPoolExecutor-0_0): Creating schema "analytics-interview.dev_test".
2020-10-19 22:21:31.451906 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2020-10-19 22:21:31.454394 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:31.992783 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:21:32.570472 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:21:32.573273 (MainThread): Connection 'create_analytics-interview_dev_test' was properly closed.
2020-10-19 22:21:32.575715 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fd6c7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fd507a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f76fd490e80>]}
2020-10-19 22:21:32.577868 (MainThread): Flushing usage events
2020-10-19 22:21:32.580811 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42708), raddr=('172.217.14.74', 443)>
2020-10-19 22:21:32.582479 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42710), raddr=('172.217.14.74', 443)>
2020-10-19 22:21:32.966640 (MainThread): Encountered an error:
2020-10-19 22:21:32.970117 (MainThread): Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.
2020-10-19 22:21:32.977981 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 420, in fn
    return client.create_dataset(dataset, exists_ok=True)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 462, in create_dataset
    api_response = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.Forbidden: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets: Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 394, in before_run
    self.create_schemas(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 523, in create_schemas
    create_future.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 485, in create_schema
    adapter.create_schema(relation)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 303, in create_schema
    self.connections.create_dataset(database, schema)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 421, in create_dataset
    self._retry_and_handle(msg='create dataset', conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Access Denied: Project analytics-interview: User does not have bigquery.datasets.create permission in project analytics-interview.

2020-10-19 22:21:55.931924 (MainThread): Running with dbt=0.18.0
2020-10-19 22:21:56.160029 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:21:56.165024 (MainThread): Tracking: tracking
2020-10-19 22:21:56.168252 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1d82fee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1cb83f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1cb83ee0>]}
2020-10-19 22:21:56.204787 (MainThread): Partial parsing not enabled
2020-10-19 22:21:56.207907 (MainThread): Parsing macros/etc.sql
2020-10-19 22:21:56.211415 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:21:56.224002 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:21:56.257407 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:21:56.264712 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:21:56.281377 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:21:56.302366 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:21:56.306913 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:21:56.314231 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:21:56.320197 (MainThread): Parsing macros/core.sql
2020-10-19 22:21:56.327191 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:21:56.342908 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:21:56.351425 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:21:56.362676 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:21:56.387712 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:21:56.414112 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:21:56.419254 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:21:56.469456 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:21:56.481256 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:21:56.485093 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:21:56.496287 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:21:56.530797 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:21:56.610287 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:21:56.613623 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:21:56.617108 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:21:56.620499 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:21:56.635285 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:21:56.639868 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:21:56.642343 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:21:56.646237 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:21:56.649788 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:21:56.655105 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:21:56.667090 (MainThread): Partial parsing not enabled
2020-10-19 22:21:56.762787 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:21:56.792884 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:21:56.809138 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:21:56.836524 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:21:56.852582 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:21:56.868579 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:21:56.884993 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:21:56.900681 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:21:57.427942 (MainThread): Found 3 models, 17 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:21:57.431538 (MainThread): 
2020-10-19 22:21:57.434186 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:21:57.442223 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:21:57.444489 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:21:57.446697 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:58.527650 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:21:58.530218 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:21:58.532333 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:59.074980 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:21:59.569047 (MainThread): 22:21:59 | Concurrency: 4 threads (target='dev')
2020-10-19 22:21:59.571897 (MainThread): 22:21:59 | 
2020-10-19 22:21:59.581313 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-19 22:21:59.581600 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-19 22:21:59.581976 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-19 22:21:59.584052 (Thread-1): 22:21:59 | 1 of 3 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 22:21:59.586325 (Thread-2): 22:21:59 | 2 of 3 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 22:21:59.588653 (Thread-3): 22:21:59 | 3 of 3 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 22:21:59.591077 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:21:59.594344 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:21:59.596604 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:21:59.598341 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-19 22:21:59.599914 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-19 22:21:59.601478 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-19 22:21:59.668788 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:21:59.671704 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:21:59.698302 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:21:59.700064 (Thread-1): finished collecting timing info
2020-10-19 22:21:59.702965 (Thread-2): finished collecting timing info
2020-10-19 22:21:59.727843 (Thread-3): finished collecting timing info
2020-10-19 22:21:59.789586 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:21:59.792109 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:21:59.797544 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:21:59.801699 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:21:59.803134 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:21:59.804264 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:59.804954 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:21:59.827264 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:21:59.805559 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:22:00.397167 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:22:00.404111 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42724), raddr=('172.217.14.74', 443)>
2020-10-19 22:22:00.404890 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:22:00.405417 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:22:00.406050 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42726), raddr=('172.217.14.74', 443)>
2020-10-19 22:22:01.626391 (Thread-2): finished collecting timing info
2020-10-19 22:22:01.629914 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '160b2485-af15-4602-a882-ce1583eb7c8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c898580>]}
2020-10-19 22:22:01.633874 (Thread-2): 22:22:01 | 2 of 3 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.04s]
2020-10-19 22:22:01.639503 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-19 22:22:01.645063 (Thread-1): finished collecting timing info
2020-10-19 22:22:01.648266 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '160b2485-af15-4602-a882-ce1583eb7c8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b18ed2550>]}
2020-10-19 22:22:01.650840 (Thread-1): 22:22:01 | 1 of 3 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.06s]
2020-10-19 22:22:01.652114 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:22:01.791915 (Thread-3): finished collecting timing info
2020-10-19 22:22:01.795841 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '160b2485-af15-4602-a882-ce1583eb7c8d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c898b20>]}
2020-10-19 22:22:01.798889 (Thread-3): 22:22:01 | 3 of 3 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.20s]
2020-10-19 22:22:01.800909 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-19 22:22:01.804611 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:22:01.807085 (MainThread): 22:22:01 | 
2020-10-19 22:22:01.809365 (MainThread): 22:22:01 | Finished running 3 view models in 4.37s.
2020-10-19 22:22:01.811117 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:22:01.813193 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:22:01.814459 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 22:22:01.816015 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 22:22:01.838067 (MainThread): 
2020-10-19 22:22:01.840147 (MainThread): Completed successfully
2020-10-19 22:22:01.842283 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-10-19 22:22:01.844408 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1cb04af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c8a0ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b1c836df0>]}
2020-10-19 22:22:01.846210 (MainThread): Flushing usage events
2020-10-19 22:35:51.931262 (MainThread): Running with dbt=0.18.0
2020-10-19 22:35:52.222030 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:35:52.229928 (MainThread): Tracking: tracking
2020-10-19 22:35:52.232921 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f533beb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4690e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4690e50>]}
2020-10-19 22:35:52.268727 (MainThread): Partial parsing not enabled
2020-10-19 22:35:52.271915 (MainThread): Parsing macros/etc.sql
2020-10-19 22:35:52.274979 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:35:52.287512 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:35:52.319966 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:35:52.326785 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:35:52.342829 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:35:52.363335 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:35:52.367815 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:35:52.375469 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:35:52.381980 (MainThread): Parsing macros/core.sql
2020-10-19 22:35:52.388622 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:35:52.404801 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:35:52.414129 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:35:52.424855 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:35:52.449927 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:35:52.476018 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:35:52.480794 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:35:52.531678 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:35:52.543404 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:35:52.547841 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:35:52.559370 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:35:52.594661 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:35:52.672730 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:35:52.676858 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:35:52.680855 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:35:52.684289 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:35:52.699103 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:35:52.703636 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:35:52.706263 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:35:52.711076 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:35:52.716568 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:35:52.721995 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:35:52.734491 (MainThread): Partial parsing not enabled
2020-10-19 22:35:52.832680 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 22:35:52.862890 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:35:52.878938 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:35:52.897257 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:35:52.924798 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:35:52.940951 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:35:52.956077 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:35:52.971987 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:35:52.987870 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:35:53.466261 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-19 22:35:53.467806 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:35:53.469338 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:35:53.726221 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:35:53.730812 (MainThread): 
2020-10-19 22:35:53.733009 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:35:53.742615 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:35:53.744443 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:35:53.747067 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:54.903858 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:35:54.906420 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:35:54.908636 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:55.457100 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:35:55.990507 (MainThread): 22:35:55 | Concurrency: 4 threads (target='dev')
2020-10-19 22:35:55.993635 (MainThread): 22:35:55 | 
2020-10-19 22:35:56.002379 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-19 22:35:56.002687 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-19 22:35:56.003059 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-19 22:35:56.003336 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-19 22:35:56.005524 (Thread-1): 22:35:56 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-19 22:35:56.008429 (Thread-2): 22:35:56 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 22:35:56.012042 (Thread-3): 22:35:56 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 22:35:56.015446 (Thread-4): 22:35:56 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 22:35:56.017809 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 22:35:56.019892 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:35:56.022660 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:35:56.024108 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:35:56.025710 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-19 22:35:56.027095 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-19 22:35:56.028425 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-19 22:35:56.029695 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-19 22:35:56.129398 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:35:56.146042 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:35:56.148236 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:35:56.156565 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 22:35:56.161733 (Thread-2): finished collecting timing info
2020-10-19 22:35:56.163034 (Thread-4): finished collecting timing info
2020-10-19 22:35:56.166584 (Thread-3): finished collecting timing info
2020-10-19 22:35:56.198374 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42748), raddr=('172.217.14.74', 443)>
2020-10-19 22:35:56.220166 (Thread-1): finished collecting timing info
2020-10-19 22:35:56.247050 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:35:56.248182 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:35:56.248655 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49024), raddr=('142.250.72.234', 443)>
2020-10-19 22:35:56.256695 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 22:35:56.260674 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:35:56.279862 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:35:56.280223 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:35:56.282360 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:56.285577 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:56.292062 (Thread-4): Opening a new connection, currently in state init
2020-10-19 22:35:56.298278 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:35:56.300753 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:56.304025 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:35:56.884967 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:35:56.892541 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:35:56.899425 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_updates_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_updates_deduped_across_source_files
    inner join
      latest_command_uuids using(command_uuid, update_timestamp)
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    ,case
      when command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as thermostat_set_point
    ,case
      when command IN ('ThermostatMode')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as thermostat_mode
    ,case
      when command IN ('PinAssignment')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as slot
    ,case
      when command IN ('PinAssignment')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
      else null
    end as pin
    ,case
      when command IN ('SwitchState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as switch_state
    ,case
      when command IN ('DimmerState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as dimmer_state
    ,case
      when command IN ('DimmerState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
      else null
    end as dimmer_level
    ,case
      when command IN ('LockedState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as lock_state

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-19 22:35:56.907037 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:35:58.209751 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Table name "latest_command_uuids" missing dataset while no default dataset is set in the request.')
2020-10-19 22:35:58.629890 (Thread-1): finished collecting timing info
2020-10-19 22:35:58.634570 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d5c3a91-6904-4e20-8af5-660992d93568', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f448e1f0>]}
2020-10-19 22:35:58.639556 (Thread-1): 22:35:58 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 2.62s]
2020-10-19 22:35:58.641726 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-19 22:35:58.665654 (Thread-2): finished collecting timing info
2020-10-19 22:35:58.668774 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d5c3a91-6904-4e20-8af5-660992d93568', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f43e83d0>]}
2020-10-19 22:35:58.675043 (Thread-2): 22:35:58 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.65s]
2020-10-19 22:35:58.677063 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:35:58.847107 (Thread-3): finished collecting timing info
2020-10-19 22:35:58.850653 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d5c3a91-6904-4e20-8af5-660992d93568', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f0a29220>]}
2020-10-19 22:35:58.853924 (Thread-3): 22:35:58 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.83s]
2020-10-19 22:35:58.855750 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-19 22:35:59.451738 (Thread-4): finished collecting timing info
2020-10-19 22:35:59.455774 (Thread-4): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Table name "latest_command_uuids" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Table name "latest_command_uuids" missing dataset while no default dataset is set in the request.

(job ID: 11934b78-adc6-48c0-a9e7-5b8b7c3c9a97)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with command_updates_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`dev_source`.`interview_source`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,commands  as (
  91:    select
  92:      command_uuid
  93:      ,command_client
  94:      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
  95:      ,command_desired_state
  96:      ,command_user
  97:      ,item_data
  98:
  99:      ,update_timestamp
 100:      ,event_timestamp
 101:      ,device_id
 102:
 103:      ,_uid
 104:      ,_source_file
 105:    from
 106:      command_updates_deduped_across_source_files
 107:    inner join
 108:      latest_command_uuids using(command_uuid, update_timestamp)
 109:    where
 110:      item_key = 'Command'
 111:      and command_uuid is not null
 112:)
 113:,final as (
 114:  select
 115:    command_uuid
 116:    ,command_client
 117:    ,command
 118:    ,command_desired_state as _raw_desired_state
 119:    ,command_user as user_id
 120:
 121:    ,case
 122:      when command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
 123:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 124:      else null
 125:    end as thermostat_set_point
 126:    ,case
 127:      when command IN ('ThermostatMode')
 128:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 129:      else null
 130:    end as thermostat_mode
 131:    ,case
 132:      when command IN ('PinAssignment')
 133:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 134:      else null
 135:    end as slot
 136:    ,case
 137:      when command IN ('PinAssignment')
 138:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
 139:      else null
 140:    end as pin
 141:    ,case
 142:      when command IN ('SwitchState')
 143:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 144:      else null
 145:    end as switch_state
 146:    ,case
 147:      when command IN ('DimmerState')
 148:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 149:      else null
 150:    end as dimmer_state
 151:    ,case
 152:      when command IN ('DimmerState')
 153:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
 154:      else null
 155:    end as dimmer_level
 156:    ,case
 157:      when command IN ('LockedState')
 158:      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
 159:      else null
 160:    end as lock_state
 161:
 162:    ,update_timestamp
 163:    ,event_timestamp
 164:    ,device_id
 165:
 166:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
 167:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id
 168:
 169:    ,_uid
 170:    ,_source_file
 171:  from
 172:    commands
 173:)
 174:
 175:select *
 176:from final;
 177:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Table name "latest_command_uuids" missing dataset while no default dataset is set in the request.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-19 22:35:59.463453 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d5c3a91-6904-4e20-8af5-660992d93568', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f09ddb50>]}
2020-10-19 22:35:59.467429 (Thread-4): 22:35:59 | 4 of 4 ERROR creating view model dev_sam.stg_commands................ [ERROR in 3.44s]
2020-10-19 22:35:59.469110 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-19 22:35:59.473130 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:35:59.475082 (MainThread): 22:35:59 | 
2020-10-19 22:35:59.476466 (MainThread): 22:35:59 | Finished running 4 view models in 5.74s.
2020-10-19 22:35:59.477992 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:35:59.479389 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-19 22:35:59.480585 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:35:59.481741 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 22:35:59.483143 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 22:35:59.508050 (MainThread): 
2020-10-19 22:35:59.510191 (MainThread): Completed with 1 error and 0 warnings:
2020-10-19 22:35:59.511855 (MainThread): 
2020-10-19 22:35:59.513695 (MainThread): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
2020-10-19 22:35:59.516523 (MainThread):   Table name "latest_command_uuids" missing dataset while no default dataset is set in the request.
2020-10-19 22:35:59.519126 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-19 22:35:59.521375 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2020-10-19 22:35:59.524358 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f43877c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4387f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4387280>]}
2020-10-19 22:35:59.525982 (MainThread): Flushing usage events
2020-10-19 22:36:19.490712 (MainThread): Running with dbt=0.18.0
2020-10-19 22:36:19.715970 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 22:36:19.724337 (MainThread): Tracking: tracking
2020-10-19 22:36:19.728610 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122e0a0ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d3f4f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d3f4ee0>]}
2020-10-19 22:36:19.761868 (MainThread): Partial parsing not enabled
2020-10-19 22:36:19.765096 (MainThread): Parsing macros/etc.sql
2020-10-19 22:36:19.768235 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:36:19.781236 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:36:19.814322 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:36:19.820298 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:36:19.836660 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:36:19.858107 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:36:19.862496 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:36:19.870179 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:36:19.876609 (MainThread): Parsing macros/core.sql
2020-10-19 22:36:19.883556 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:36:19.898945 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:36:19.908362 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:36:19.919605 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:36:19.947737 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:36:19.974949 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:36:19.979942 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:36:20.030291 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:36:20.041503 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:36:20.045630 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:36:20.057218 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:36:20.092414 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:36:20.170039 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:36:20.173487 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:36:20.177404 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:36:20.181116 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:36:20.196093 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:36:20.200686 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:36:20.203034 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:36:20.206511 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:36:20.209815 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:36:20.214781 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:36:20.226196 (MainThread): Partial parsing not enabled
2020-10-19 22:36:20.321387 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 22:36:20.351317 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:36:20.367899 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:36:20.385611 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:36:20.413557 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:36:20.430304 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:36:20.446385 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:36:20.462741 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:36:20.478076 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:36:20.950248 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-19 22:36:20.952408 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:36:20.953920 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:36:21.155656 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:36:21.158951 (MainThread): 
2020-10-19 22:36:21.160463 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:36:21.167822 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 22:36:21.169500 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 22:36:21.171464 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:22.309348 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:36:22.311132 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 22:36:22.312855 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:22.850252 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:36:23.395104 (MainThread): 22:36:23 | Concurrency: 4 threads (target='dev')
2020-10-19 22:36:23.397291 (MainThread): 22:36:23 | 
2020-10-19 22:36:23.405439 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-19 22:36:23.405780 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-19 22:36:23.406334 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-19 22:36:23.406678 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-19 22:36:23.409046 (Thread-1): 22:36:23 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-19 22:36:23.411463 (Thread-2): 22:36:23 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 22:36:23.414001 (Thread-3): 22:36:23 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 22:36:23.417720 (Thread-4): 22:36:23 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 22:36:23.420460 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 22:36:23.429389 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-19 22:36:23.426007 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:36:23.428482 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:36:23.423145 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:36:23.449000 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-19 22:36:23.472165 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-19 22:36:23.485166 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-19 22:36:23.487283 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 22:36:23.507729 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:36:23.545342 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:36:23.545522 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 22:36:23.550707 (Thread-1): finished collecting timing info
2020-10-19 22:36:23.551981 (Thread-3): finished collecting timing info
2020-10-19 22:36:23.553348 (Thread-2): finished collecting timing info
2020-10-19 22:36:23.572180 (Thread-4): finished collecting timing info
2020-10-19 22:36:23.584554 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42774), raddr=('172.217.14.74', 443)>
2020-10-19 22:36:23.613784 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 22:36:23.616836 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 22:36:23.626680 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 22:36:23.628120 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49050), raddr=('142.250.72.234', 443)>
2020-10-19 22:36:23.633735 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:36:23.640411 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:36:23.640696 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 22:36:23.642983 (Thread-4): Opening a new connection, currently in state init
2020-10-19 22:36:23.643407 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:23.645495 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:23.649135 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:36:23.649568 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:23.660557 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:36:24.238458 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:36:24.239208 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:36:24.262508 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with final as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)

select *
from final;


2020-10-19 22:36:24.269638 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_updates_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_updates_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    ,case
      when command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as thermostat_set_point
    ,case
      when command IN ('ThermostatMode')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as thermostat_mode
    ,case
      when command IN ('PinAssignment')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as slot
    ,case
      when command IN ('PinAssignment')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
      else null
    end as pin
    ,case
      when command IN ('SwitchState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as switch_state
    ,case
      when command IN ('DimmerState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as dimmer_state
    ,case
      when command IN ('DimmerState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[2]')
      else null
    end as dimmer_level
    ,case
      when command IN ('LockedState')
      then JSON_EXTRACT_SCALAR(command_desired_state, '$[1]')
      else null
    end as lock_state

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-19 22:36:25.269792 (Thread-3): finished collecting timing info
2020-10-19 22:36:25.273274 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d3d6d16-cfad-4d8e-ba7b-16315437b166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d2527f0>]}
2020-10-19 22:36:25.279553 (Thread-2): finished collecting timing info
2020-10-19 22:36:25.283375 (Thread-3): 22:36:25 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.85s]
2020-10-19 22:36:25.285564 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d3d6d16-cfad-4d8e-ba7b-16315437b166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122c74f4c0>]}
2020-10-19 22:36:25.287238 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-19 22:36:25.291138 (Thread-2): 22:36:25 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.86s]
2020-10-19 22:36:25.294556 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-19 22:36:25.301160 (Thread-4): finished collecting timing info
2020-10-19 22:36:25.307810 (Thread-1): finished collecting timing info
2020-10-19 22:36:25.308929 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d3d6d16-cfad-4d8e-ba7b-16315437b166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d2130d0>]}
2020-10-19 22:36:25.311747 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d3d6d16-cfad-4d8e-ba7b-16315437b166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122c79b3d0>]}
2020-10-19 22:36:25.314632 (Thread-4): 22:36:25 | 4 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.88s]
2020-10-19 22:36:25.317626 (Thread-1): 22:36:25 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 1.89s]
2020-10-19 22:36:25.319619 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-19 22:36:25.321337 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-19 22:36:25.327742 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:36:25.329989 (MainThread): 22:36:25 | 
2020-10-19 22:36:25.331545 (MainThread): 22:36:25 | Finished running 4 view models in 4.17s.
2020-10-19 22:36:25.333037 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:36:25.334533 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-19 22:36:25.335856 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 22:36:25.337124 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 22:36:25.338839 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 22:36:25.374131 (MainThread): 
2020-10-19 22:36:25.377039 (MainThread): Completed successfully
2020-10-19 22:36:25.378743 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-19 22:36:25.380674 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d379040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d0b4460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f122d0e20d0>]}
2020-10-19 22:36:25.382093 (MainThread): Flushing usage events
2020-10-19 22:37:20.305710 (MainThread): Running with dbt=0.18.0
2020-10-19 22:37:20.529631 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-19 22:37:20.535251 (MainThread): Tracking: tracking
2020-10-19 22:37:20.538843 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f3e47e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f319bf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f319bee0>]}
2020-10-19 22:37:20.571420 (MainThread): Partial parsing not enabled
2020-10-19 22:37:20.574621 (MainThread): Parsing macros/etc.sql
2020-10-19 22:37:20.577984 (MainThread): Parsing macros/catalog.sql
2020-10-19 22:37:20.590770 (MainThread): Parsing macros/adapters.sql
2020-10-19 22:37:20.627297 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 22:37:20.633506 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 22:37:20.649377 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 22:37:20.670390 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 22:37:20.674736 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 22:37:20.682152 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 22:37:20.688034 (MainThread): Parsing macros/core.sql
2020-10-19 22:37:20.694889 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 22:37:20.710370 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 22:37:20.720069 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 22:37:20.731495 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 22:37:20.756737 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 22:37:20.784296 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 22:37:20.788424 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 22:37:20.838701 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 22:37:20.849106 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 22:37:20.852853 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 22:37:20.864069 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 22:37:20.899423 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 22:37:20.977316 (MainThread): Parsing macros/etc/query.sql
2020-10-19 22:37:20.981025 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 22:37:20.984468 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 22:37:20.987753 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 22:37:21.002687 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 22:37:21.007146 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 22:37:21.009511 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 22:37:21.012999 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 22:37:21.016315 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 22:37:21.021176 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 22:37:21.033579 (MainThread): Partial parsing not enabled
2020-10-19 22:37:21.123775 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 22:37:21.153654 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 22:37:21.170430 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 22:37:21.187609 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 22:37:21.214791 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:37:21.230884 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:37:21.246363 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:37:21.262245 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:37:21.277455 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:37:21.755620 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-19 22:37:21.757566 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:37:21.759178 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 22:37:22.002113 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 22:37:22.005959 (MainThread): 
2020-10-19 22:37:22.007975 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:37:22.046864 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 22:37:22.049501 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-19 22:37:22.052351 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:22.594150 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 22:37:23.243886 (MainThread): 22:37:23 | Concurrency: 4 threads (target='dev')
2020-10-19 22:37:23.246397 (MainThread): 22:37:23 | 
2020-10-19 22:37:23.255040 (Thread-1): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-19 22:37:23.255642 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 22:37:23.256425 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 22:37:23.256825 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 22:37:23.257223 (Thread-1): 22:37:23 | 1 of 19 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-19 22:37:23.259062 (Thread-2): 22:37:23 | 2 of 19 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-19 22:37:23.260838 (Thread-3): 22:37:23 | 3 of 19 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-19 22:37:23.262571 (Thread-4): 22:37:23 | 4 of 19 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-19 22:37:23.265489 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-19 22:37:23.267476 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-19 22:37:23.269347 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-19 22:37:23.271013 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-19 22:37:23.273034 (Thread-1): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-19 22:37:23.274558 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 22:37:23.276169 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 22:37:23.277828 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 22:37:23.322908 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-19 22:37:23.336924 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-19 22:37:23.342957 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-19 22:37:23.357244 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-19 22:37:23.361240 (Thread-2): finished collecting timing info
2020-10-19 22:37:23.363956 (Thread-3): finished collecting timing info
2020-10-19 22:37:23.370392 (Thread-2): Opening a new connection, currently in state init
2020-10-19 22:37:23.371909 (Thread-4): finished collecting timing info
2020-10-19 22:37:23.376083 (Thread-4): Opening a new connection, currently in state init
2020-10-19 22:37:23.373525 (Thread-1): finished collecting timing info
2020-10-19 22:37:23.375397 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:23.372587 (Thread-3): Opening a new connection, currently in state init
2020-10-19 22:37:23.384024 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:23.378643 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:37:23.377408 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:23.391185 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:23.980743 (Thread-4): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-19 22:37:23.987134 (Thread-2): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-19 22:37:24.002929 (Thread-3): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-19 22:37:24.014747 (Thread-1): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-19 22:37:25.660650 (Thread-3): finished collecting timing info
2020-10-19 22:37:25.665372 (Thread-3): 22:37:25 | 3 of 19 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.40s]
2020-10-19 22:37:25.668699 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-19 22:37:25.671387 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 22:37:25.673431 (Thread-3): 22:37:25 | 5 of 19 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-19 22:37:25.676343 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-19 22:37:25.677908 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 22:37:25.697246 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-19 22:37:25.707315 (Thread-3): finished collecting timing info
2020-10-19 22:37:25.709285 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 22:37:25.710865 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:26.037441 (Thread-1): finished collecting timing info
2020-10-19 22:37:26.040806 (Thread-1): 22:37:26 | 1 of 19 PASS not_null_fct_command_statuses_command_uuid.............. [PASS in 2.78s]
2020-10-19 22:37:26.042724 (Thread-4): finished collecting timing info
2020-10-19 22:37:26.044007 (Thread-1): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-19 22:37:26.045294 (Thread-4): 22:37:26 | 4 of 19 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.77s]
2020-10-19 22:37:26.046690 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 22:37:26.048192 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-19 22:37:26.049502 (Thread-1): 22:37:26 | 6 of 19 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-19 22:37:26.050826 (Thread-4): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 22:37:26.052721 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-19 22:37:26.054696 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 22:37:26.053394 (Thread-4): 22:37:26 | 7 of 19 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-19 22:37:26.060201 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49080), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:26.063103 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-19 22:37:26.064478 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42810), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:26.065668 (Thread-4): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 22:37:26.067865 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42812), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:26.087356 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-19 22:37:26.088019 (Thread-2): finished collecting timing info
2020-10-19 22:37:26.094805 (Thread-2): 22:37:26 | 2 of 19 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.83s]
2020-10-19 22:37:26.097724 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-19 22:37:26.096903 (Thread-4): finished collecting timing info
2020-10-19 22:37:26.090584 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49082), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:26.099388 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 22:37:26.100893 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 22:37:26.114564 (Thread-2): 22:37:26 | 8 of 19 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-19 22:37:26.124381 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-19 22:37:26.121753 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:26.117094 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-19 22:37:26.126254 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 22:37:26.153841 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-19 22:37:26.154576 (Thread-1): finished collecting timing info
2020-10-19 22:37:26.158656 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:37:26.161477 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:26.160220 (Thread-2): finished collecting timing info
2020-10-19 22:37:26.170389 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 22:37:26.174261 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:26.322736 (Thread-3): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-19 22:37:26.728418 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: is_hub_success at [10:7]')
2020-10-19 22:37:26.730540 (Thread-4): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-19 22:37:26.763392 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-19 22:37:26.775451 (Thread-1): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-19 22:37:28.051292 (Thread-3): finished collecting timing info
2020-10-19 22:37:28.055545 (Thread-3): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: is_hub_success at [10:7]

(job ID: 50dd4d7d-4680-42b1-ab5d-edf4eabd90bd)

                                                                    -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_command_results`
  10:where is_hub_success is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
  Unrecognized name: is_hub_success at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-19 22:37:28.060316 (Thread-3): 22:37:28 | 5 of 19 ERROR not_null_stg_command_results_is_hub_success............ [ERROR in 2.38s]
2020-10-19 22:37:28.062787 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-19 22:37:28.064787 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 22:37:28.066637 (Thread-3): 22:37:28 | 9 of 19 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-19 22:37:28.069320 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-19 22:37:28.070840 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 22:37:28.085349 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-19 22:37:28.091597 (Thread-3): finished collecting timing info
2020-10-19 22:37:28.093171 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 22:37:28.094464 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:28.255081 (Thread-1): finished collecting timing info
2020-10-19 22:37:28.260650 (Thread-1): 22:37:28 | 6 of 19 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.21s]
2020-10-19 22:37:28.262577 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-19 22:37:28.264383 (Thread-1): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-19 22:37:28.266098 (Thread-1): 22:37:28 | 10 of 19 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-19 22:37:28.268109 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-19 22:37:28.269746 (Thread-1): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-19 22:37:28.283395 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-19 22:37:28.288008 (Thread-1): finished collecting timing info
2020-10-19 22:37:28.289890 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:37:28.291439 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:28.581170 (Thread-2): finished collecting timing info
2020-10-19 22:37:28.584060 (Thread-2): 22:37:28 | 8 of 19 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.46s]
2020-10-19 22:37:28.586234 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-19 22:37:28.588168 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-19 22:37:28.589856 (Thread-2): 22:37:28 | 11 of 19 START test stg_commands_locked_state........................ [RUN]
2020-10-19 22:37:28.591934 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 22:37:28.593564 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-19 22:37:28.615065 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-19 22:37:28.621459 (Thread-2): finished collecting timing info
2020-10-19 22:37:28.624299 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 22:37:28.626677 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:28.660358 (Thread-4): finished collecting timing info
2020-10-19 22:37:28.666520 (Thread-4): 22:37:28 | 7 of 19 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.60s]
2020-10-19 22:37:28.669185 (Thread-4): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-19 22:37:28.673692 (Thread-4): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-19 22:37:28.679381 (Thread-4): 22:37:28 | 12 of 19 START test stg_commands_pin_assignment...................... [RUN]
2020-10-19 22:37:28.683531 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 22:37:28.685622 (Thread-4): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-19 22:37:28.708661 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-19 22:37:28.714834 (Thread-4): finished collecting timing info
2020-10-19 22:37:28.718021 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 22:37:28.720574 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:28.744390 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-19 22:37:28.930143 (Thread-1): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-19 22:37:29.234325 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 22:37:29.311104 (Thread-4): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 22:37:30.025673 (Thread-3): finished collecting timing info
2020-10-19 22:37:30.030030 (Thread-3): 22:37:30 | 9 of 19 PASS not_null_stg_commands_update_timestamp.................. [PASS in 1.96s]
2020-10-19 22:37:30.032734 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-19 22:37:30.035024 (Thread-3): Began running node test.dwelo.stg_commands_switch_state
2020-10-19 22:37:30.037260 (Thread-3): 22:37:30 | 13 of 19 START test stg_commands_switch_state........................ [RUN]
2020-10-19 22:37:30.039823 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 22:37:30.041648 (Thread-3): Compiling test.dwelo.stg_commands_switch_state
2020-10-19 22:37:30.046584 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49096), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:30.048077 (Thread-3): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42824), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:30.049520 (Thread-3): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42826), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:30.050843 (Thread-3): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42828), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:30.052181 (Thread-3): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49098), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:30.053416 (Thread-3): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49100), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:30.054725 (Thread-3): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42832), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:30.055798 (Thread-3): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49108), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:30.082794 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-19 22:37:30.088102 (Thread-3): finished collecting timing info
2020-10-19 22:37:30.090175 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 22:37:30.092076 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:30.663823 (Thread-3): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 22:37:30.814628 (Thread-1): finished collecting timing info
2020-10-19 22:37:30.819203 (Thread-1): 22:37:30 | 10 of 19 FAIL 99 not_null_stg_commands_user_id....................... [FAIL 99 in 2.55s]
2020-10-19 22:37:30.821694 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-19 22:37:30.824499 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-19 22:37:30.826989 (Thread-1): 22:37:30 | 14 of 19 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-19 22:37:30.830091 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 22:37:30.831969 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-19 22:37:30.845469 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-19 22:37:30.850311 (Thread-1): finished collecting timing info
2020-10-19 22:37:30.852287 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:37:30.854143 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:31.135142 (Thread-2): finished collecting timing info
2020-10-19 22:37:31.137710 (Thread-2): 22:37:31 | 11 of 19 PASS stg_commands_locked_state.............................. [PASS in 2.55s]
2020-10-19 22:37:31.139596 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-19 22:37:31.141745 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 22:37:31.143350 (Thread-2): 22:37:31 | 15 of 19 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-19 22:37:31.145379 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 22:37:31.146847 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 22:37:31.160083 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-19 22:37:31.165322 (Thread-2): finished collecting timing info
2020-10-19 22:37:31.167438 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 22:37:31.169251 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:31.331492 (Thread-4): finished collecting timing info
2020-10-19 22:37:31.334663 (Thread-4): 22:37:31 | 12 of 19 FAIL 1 stg_commands_pin_assignment.......................... [FAIL 1 in 2.65s]
2020-10-19 22:37:31.336497 (Thread-4): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-19 22:37:31.338154 (Thread-4): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-19 22:37:31.339458 (Thread-4): 22:37:31 | 16 of 19 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-19 22:37:31.341573 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-19 22:37:31.342971 (Thread-4): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-19 22:37:31.357469 (Thread-4): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-19 22:37:31.362832 (Thread-4): finished collecting timing info
2020-10-19 22:37:31.365084 (Thread-4): Opening a new connection, currently in state closed
2020-10-19 22:37:31.366931 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:31.471429 (Thread-1): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 22:37:31.766904 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-19 22:37:31.926647 (Thread-4): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 22:37:32.312808 (Thread-3): finished collecting timing info
2020-10-19 22:37:32.317785 (Thread-3): 22:37:32 | 13 of 19 PASS stg_commands_switch_state.............................. [PASS in 2.28s]
2020-10-19 22:37:32.320316 (Thread-3): Finished running node test.dwelo.stg_commands_switch_state
2020-10-19 22:37:32.323029 (Thread-3): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 22:37:32.325185 (Thread-3): 22:37:32 | 17 of 19 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-19 22:37:32.327631 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-19 22:37:32.329421 (Thread-3): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 22:37:32.345521 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-19 22:37:32.350525 (Thread-3): finished collecting timing info
2020-10-19 22:37:32.352862 (Thread-3): Opening a new connection, currently in state closed
2020-10-19 22:37:32.354564 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:32.909759 (Thread-3): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 22:37:33.438977 (Thread-1): finished collecting timing info
2020-10-19 22:37:33.443437 (Thread-1): 22:37:33 | 14 of 19 PASS stg_commands_thermostat_mode........................... [PASS in 2.61s]
2020-10-19 22:37:33.445822 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-19 22:37:33.449281 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 22:37:33.451571 (Thread-1): 22:37:33 | 18 of 19 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-19 22:37:33.454059 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-19 22:37:33.456183 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 22:37:33.474161 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-19 22:37:33.478926 (Thread-1): finished collecting timing info
2020-10-19 22:37:33.480530 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 22:37:33.482317 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:33.542902 (Thread-2): finished collecting timing info
2020-10-19 22:37:33.546790 (Thread-2): 22:37:33 | 15 of 19 PASS stg_commands_thermostat_setpoint....................... [PASS in 2.40s]
2020-10-19 22:37:33.553699 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-19 22:37:33.556103 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-19 22:37:33.557440 (Thread-2): 22:37:33 | 19 of 19 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-19 22:37:33.559675 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-19 22:37:33.561201 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-19 22:37:33.578517 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-19 22:37:33.584205 (Thread-2): finished collecting timing info
2020-10-19 22:37:33.586287 (Thread-2): Opening a new connection, currently in state closed
2020-10-19 22:37:33.588061 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 22:37:33.997598 (Thread-4): finished collecting timing info
2020-10-19 22:37:34.000942 (Thread-4): 22:37:33 | 16 of 19 FAIL 3342 unique_fct_command_statuses_command_uuid.......... [FAIL 3342 in 2.66s]
2020-10-19 22:37:34.003707 (Thread-4): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-19 22:37:34.065036 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 22:37:34.164112 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-19 22:37:34.845708 (Thread-3): finished collecting timing info
2020-10-19 22:37:34.849816 (Thread-3): 22:37:34 | 17 of 19 FAIL 3342 unique_stg_command_actives_command_uuid........... [FAIL 3342 in 2.52s]
2020-10-19 22:37:34.852451 (Thread-3): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-19 22:37:36.203572 (Thread-1): finished collecting timing info
2020-10-19 22:37:36.207445 (Thread-1): 22:37:36 | 18 of 19 FAIL 3342 unique_stg_command_results_command_uuid........... [FAIL 3342 in 2.75s]
2020-10-19 22:37:36.209840 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-19 22:37:36.235221 (Thread-2): finished collecting timing info
2020-10-19 22:37:36.238641 (Thread-2): 22:37:36 | 19 of 19 PASS unique_stg_commands_command_uuid....................... [PASS in 2.68s]
2020-10-19 22:37:36.241701 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-19 22:37:36.248941 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 22:37:36.252532 (MainThread): 22:37:36 | 
2020-10-19 22:37:36.255658 (MainThread): 22:37:36 | Finished running 19 tests in 14.24s.
2020-10-19 22:37:36.259135 (MainThread): Connection 'master' was properly closed.
2020-10-19 22:37:36.262341 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-19 22:37:36.265275 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-19 22:37:36.269239 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-19 22:37:36.273286 (MainThread): Connection 'test.dwelo.unique_fct_command_statuses_command_uuid' was properly closed.
2020-10-19 22:37:36.368798 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42848), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:36.371069 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49124), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:36.372652 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49128), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:36.374088 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42856), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:36.375654 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49136), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:36.377403 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42852), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:36.379604 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49132), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:36.382021 (MainThread): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42860), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:36.384676 (MainThread): unclosed <socket.socket fd=32, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 49146), raddr=('142.250.72.234', 443)>
2020-10-19 22:37:36.387829 (MainThread): unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42872), raddr=('172.217.14.74', 443)>
2020-10-19 22:37:36.405688 (MainThread): 
2020-10-19 22:37:36.407374 (MainThread): Completed with 6 errors and 0 warnings:
2020-10-19 22:37:36.408854 (MainThread): 
2020-10-19 22:37:36.410676 (MainThread): Database Error in test not_null_stg_command_results_is_hub_success (models/staging/commands/schema.yml)
2020-10-19 22:37:36.412157 (MainThread):   Unrecognized name: is_hub_success at [10:7]
2020-10-19 22:37:36.414076 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_command_results_is_hub_success.sql
2020-10-19 22:37:36.416048 (MainThread): 
2020-10-19 22:37:36.418608 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/commands/schema.yml)
2020-10-19 22:37:36.422162 (MainThread):   Got 99 results, expected 0.
2020-10-19 22:37:36.424694 (MainThread): 
2020-10-19 22:37:36.426999 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-19 22:37:36.428830 (MainThread): 
2020-10-19 22:37:36.430963 (MainThread): Failure in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-19 22:37:36.433194 (MainThread):   Got 1 result, expected 0.
2020-10-19 22:37:36.436011 (MainThread): 
2020-10-19 22:37:36.438651 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-19 22:37:36.441183 (MainThread): 
2020-10-19 22:37:36.443685 (MainThread): Failure in test unique_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
2020-10-19 22:37:36.445712 (MainThread):   Got 3342 results, expected 0.
2020-10-19 22:37:36.447692 (MainThread): 
2020-10-19 22:37:36.449992 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-19 22:37:36.452484 (MainThread): 
2020-10-19 22:37:36.454692 (MainThread): Failure in test unique_stg_command_actives_command_uuid (models/staging/commands/schema.yml)
2020-10-19 22:37:36.456419 (MainThread):   Got 3342 results, expected 0.
2020-10-19 22:37:36.458655 (MainThread): 
2020-10-19 22:37:36.460800 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_actives_command_uuid.sql
2020-10-19 22:37:36.462688 (MainThread): 
2020-10-19 22:37:36.464661 (MainThread): Failure in test unique_stg_command_results_command_uuid (models/staging/commands/schema.yml)
2020-10-19 22:37:36.466887 (MainThread):   Got 3342 results, expected 0.
2020-10-19 22:37:36.469671 (MainThread): 
2020-10-19 22:37:36.472233 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/commands/schema.yml/schema_test/unique_stg_command_results_command_uuid.sql
2020-10-19 22:37:36.475426 (MainThread): 
Done. PASS=13 WARN=0 ERROR=6 SKIP=0 TOTAL=19
2020-10-19 22:37:36.479752 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f041b580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f03c4a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1f2f9d070>]}
2020-10-19 22:37:36.483789 (MainThread): Flushing usage events
2020-10-19 23:01:58.390421 (MainThread): Running with dbt=0.18.0
2020-10-19 23:01:58.631545 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 23:01:58.637114 (MainThread): Tracking: tracking
2020-10-19 23:01:58.640315 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35eb7ecdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35eaac1f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35eaac1f10>]}
2020-10-19 23:01:58.674801 (MainThread): Partial parsing not enabled
2020-10-19 23:01:58.678163 (MainThread): Parsing macros/etc.sql
2020-10-19 23:01:58.681167 (MainThread): Parsing macros/catalog.sql
2020-10-19 23:01:58.693956 (MainThread): Parsing macros/adapters.sql
2020-10-19 23:01:58.727388 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 23:01:58.733599 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 23:01:58.749330 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 23:01:58.771260 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 23:01:58.776668 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 23:01:58.785415 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 23:01:58.792219 (MainThread): Parsing macros/core.sql
2020-10-19 23:01:58.799242 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 23:01:58.814448 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 23:01:58.823350 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 23:01:58.834518 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 23:01:58.860609 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 23:01:58.887063 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 23:01:58.892356 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 23:01:58.943510 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 23:01:58.954892 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 23:01:58.958825 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 23:01:58.970025 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 23:01:59.005904 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 23:01:59.088467 (MainThread): Parsing macros/etc/query.sql
2020-10-19 23:01:59.093516 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 23:01:59.097042 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 23:01:59.100610 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 23:01:59.115762 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 23:01:59.120961 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 23:01:59.124792 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 23:01:59.128996 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 23:01:59.132448 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 23:01:59.137570 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 23:01:59.149683 (MainThread): Partial parsing not enabled
2020-10-19 23:01:59.249048 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 23:01:59.276252 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 23:01:59.294833 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 23:01:59.313265 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 23:01:59.343960 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 23:01:59.360778 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 23:01:59.377354 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 23:01:59.394862 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 23:01:59.411100 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 23:01:59.905960 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-19 23:01:59.907762 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 23:01:59.909214 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 23:02:00.121212 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 23:02:00.124917 (MainThread): 
2020-10-19 23:02:00.127091 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 23:02:00.134478 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 23:02:00.136251 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 23:02:00.138463 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:01.186315 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 23:02:01.188231 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 23:02:01.190303 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:01.782091 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 23:02:02.179075 (MainThread): 23:02:02 | Concurrency: 4 threads (target='dev')
2020-10-19 23:02:02.181494 (MainThread): 23:02:02 | 
2020-10-19 23:02:02.191211 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-19 23:02:02.191485 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-19 23:02:02.191910 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-19 23:02:02.192097 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-19 23:02:02.193805 (Thread-1): 23:02:02 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-19 23:02:02.195957 (Thread-2): 23:02:02 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 23:02:02.198144 (Thread-3): 23:02:02 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 23:02:02.200295 (Thread-4): 23:02:02 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 23:02:02.202477 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 23:02:02.204688 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 23:02:02.206987 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 23:02:02.209470 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 23:02:02.210964 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-19 23:02:02.212321 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-19 23:02:02.213547 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-19 23:02:02.214679 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-19 23:02:02.279036 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 23:02:02.295058 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 23:02:02.304416 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 23:02:02.320458 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 23:02:02.327668 (Thread-1): finished collecting timing info
2020-10-19 23:02:02.329389 (Thread-3): finished collecting timing info
2020-10-19 23:02:02.329816 (Thread-2): finished collecting timing info
2020-10-19 23:02:02.341533 (Thread-4): finished collecting timing info
2020-10-19 23:02:02.365029 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42882), raddr=('172.217.14.74', 443)>
2020-10-19 23:02:02.428782 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 23:02:02.429272 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 47382), raddr=('172.217.5.202', 443)>
2020-10-19 23:02:02.431388 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 23:02:02.433424 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 23:02:02.446973 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 23:02:02.448308 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 23:02:02.453592 (Thread-4): Opening a new connection, currently in state init
2020-10-19 23:02:02.456987 (Thread-2): Opening a new connection, currently in state init
2020-10-19 23:02:02.457394 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:02.458459 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:02.458957 (Thread-3): Opening a new connection, currently in state init
2020-10-19 23:02:02.460348 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:02.469122 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:03.067144 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-19 23:02:03.075105 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-19 23:02:03.090777 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-19 23:02:03.096921 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-19 23:02:04.133493 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/c5b40056-04bf-471c-b5f0-9c328914b831?maxResults=0&location=US: CREATE VIEW columns must be named, but column 1 has no name at [6:6]')
2020-10-19 23:02:04.288226 (Thread-3): finished collecting timing info
2020-10-19 23:02:04.294635 (Thread-4): finished collecting timing info
2020-10-19 23:02:04.297328 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c873f75f-5169-4a59-93b7-f99a2ac0da33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35e8644c10>]}
2020-10-19 23:02:04.300387 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c873f75f-5169-4a59-93b7-f99a2ac0da33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ea8ba400>]}
2020-10-19 23:02:04.304287 (Thread-3): 23:02:04 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.09s]
2020-10-19 23:02:04.307564 (Thread-4): 23:02:04 | 4 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.09s]
2020-10-19 23:02:04.309904 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-19 23:02:04.312681 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-19 23:02:04.351366 (Thread-2): finished collecting timing info
2020-10-19 23:02:04.353944 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c873f75f-5169-4a59-93b7-f99a2ac0da33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ea968580>]}
2020-10-19 23:02:04.356316 (Thread-2): 23:02:04 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.15s]
2020-10-19 23:02:04.357529 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-19 23:02:05.636511 (Thread-1): finished collecting timing info
2020-10-19 23:02:05.640425 (Thread-1): Database Error in model fct_command_statuses (models/marts/core/fct_command_statuses.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [6:6]
  compiled SQL at target/run/dwelo/models/marts/core/fct_command_statuses.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/5d88ec61-bf28-4b82-8ba1-90eb5719ce9f?maxResults=0&location=US: CREATE VIEW columns must be named, but column 1 has no name at [6:6]

(job ID: 5d88ec61-bf28-4b82-8ba1-90eb5719ce9f)

                                                         -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
   5:  OPTIONS()
   6:  as with final as (
   7:    select 1 -- WRITE YOUR QUERY HERE
   8:)
   9:
  10:select *
  11:from final;
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model fct_command_statuses (models/marts/core/fct_command_statuses.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [6:6]
  compiled SQL at target/run/dwelo/models/marts/core/fct_command_statuses.sql
2020-10-19 23:02:05.649917 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c873f75f-5169-4a59-93b7-f99a2ac0da33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35e8635c10>]}
2020-10-19 23:02:05.654878 (Thread-1): 23:02:05 | 1 of 4 ERROR creating view model dev_sam.fct_command_statuses........ [ERROR in 3.45s]
2020-10-19 23:02:05.656919 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-19 23:02:05.661580 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 23:02:05.663412 (MainThread): 23:02:05 | 
2020-10-19 23:02:05.665015 (MainThread): 23:02:05 | Finished running 4 view models in 5.54s.
2020-10-19 23:02:05.667476 (MainThread): Connection 'master' was properly closed.
2020-10-19 23:02:05.669376 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-19 23:02:05.670595 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 23:02:05.672420 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 23:02:05.673993 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 23:02:05.707428 (MainThread): 
2020-10-19 23:02:05.709164 (MainThread): Completed with 1 error and 0 warnings:
2020-10-19 23:02:05.710954 (MainThread): 
2020-10-19 23:02:05.713885 (MainThread): Database Error in model fct_command_statuses (models/marts/core/fct_command_statuses.sql)
2020-10-19 23:02:05.715442 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [6:6]
2020-10-19 23:02:05.717287 (MainThread):   compiled SQL at target/run/dwelo/models/marts/core/fct_command_statuses.sql
2020-10-19 23:02:05.719061 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2020-10-19 23:02:05.721618 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ea7f9550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ea7ae880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f35ea7ae460>]}
2020-10-19 23:02:05.723257 (MainThread): Flushing usage events
2020-10-19 23:02:24.912816 (MainThread): Running with dbt=0.18.0
2020-10-19 23:02:25.138444 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-19 23:02:25.150556 (MainThread): Tracking: tracking
2020-10-19 23:02:25.153788 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77415ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77342ef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77342ef40>]}
2020-10-19 23:02:25.185500 (MainThread): Partial parsing not enabled
2020-10-19 23:02:25.188160 (MainThread): Parsing macros/etc.sql
2020-10-19 23:02:25.191199 (MainThread): Parsing macros/catalog.sql
2020-10-19 23:02:25.203578 (MainThread): Parsing macros/adapters.sql
2020-10-19 23:02:25.236630 (MainThread): Parsing macros/materializations/view.sql
2020-10-19 23:02:25.243329 (MainThread): Parsing macros/materializations/table.sql
2020-10-19 23:02:25.259018 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-19 23:02:25.280083 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-19 23:02:25.284887 (MainThread): Parsing macros/materializations/copy.sql
2020-10-19 23:02:25.293656 (MainThread): Parsing macros/materializations/seed.sql
2020-10-19 23:02:25.300014 (MainThread): Parsing macros/core.sql
2020-10-19 23:02:25.306568 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-19 23:02:25.322325 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-19 23:02:25.331557 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-19 23:02:25.342581 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-19 23:02:25.368190 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-19 23:02:25.395552 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-19 23:02:25.400682 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-19 23:02:25.450664 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-19 23:02:25.462038 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-19 23:02:25.466740 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-19 23:02:25.477955 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-19 23:02:25.513588 (MainThread): Parsing macros/adapters/common.sql
2020-10-19 23:02:25.590845 (MainThread): Parsing macros/etc/query.sql
2020-10-19 23:02:25.594100 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-19 23:02:25.597665 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-19 23:02:25.601323 (MainThread): Parsing macros/etc/datetime.sql
2020-10-19 23:02:25.616250 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-19 23:02:25.621225 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-19 23:02:25.625349 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-19 23:02:25.629381 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-19 23:02:25.633068 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-19 23:02:25.638217 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-19 23:02:25.650826 (MainThread): Partial parsing not enabled
2020-10-19 23:02:25.748746 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 23:02:25.776279 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 23:02:25.794128 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 23:02:25.811660 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 23:02:25.839552 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-19 23:02:25.855926 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-19 23:02:25.871570 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-19 23:02:25.888595 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-19 23:02:25.904421 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-19 23:02:26.373957 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-19 23:02:26.375854 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 23:02:26.377070 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-19 23:02:26.583202 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-19 23:02:26.586581 (MainThread): 
2020-10-19 23:02:26.588127 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 23:02:26.595308 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-19 23:02:26.596651 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-19 23:02:26.598597 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:27.562033 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-19 23:02:27.565770 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-19 23:02:27.567973 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:28.107611 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-19 23:02:28.635492 (MainThread): 23:02:28 | Concurrency: 4 threads (target='dev')
2020-10-19 23:02:28.637866 (MainThread): 23:02:28 | 
2020-10-19 23:02:28.646072 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-19 23:02:28.646639 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-19 23:02:28.647183 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-19 23:02:28.647463 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-19 23:02:28.649840 (Thread-1): 23:02:28 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-19 23:02:28.653335 (Thread-2): 23:02:28 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-19 23:02:28.655727 (Thread-3): 23:02:28 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-19 23:02:28.660945 (Thread-4): 23:02:28 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-19 23:02:28.663640 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-19 23:02:28.665766 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-19 23:02:28.668005 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-19 23:02:28.669619 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-19 23:02:28.671518 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-19 23:02:28.673230 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-19 23:02:28.674585 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-19 23:02:28.675714 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-19 23:02:28.775611 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-19 23:02:28.777050 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-19 23:02:28.780580 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 23:02:28.798060 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-19 23:02:28.802486 (Thread-2): finished collecting timing info
2020-10-19 23:02:28.803898 (Thread-3): finished collecting timing info
2020-10-19 23:02:28.816906 (Thread-1): finished collecting timing info
2020-10-19 23:02:28.838489 (Thread-4): finished collecting timing info
2020-10-19 23:02:28.851937 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42908), raddr=('172.217.14.74', 443)>
2020-10-19 23:02:28.874075 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-19 23:02:28.876657 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-19 23:02:28.884909 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-19 23:02:28.886460 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 47408), raddr=('172.217.5.202', 443)>
2020-10-19 23:02:28.890402 (Thread-2): Opening a new connection, currently in state init
2020-10-19 23:02:28.899479 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-19 23:02:28.900704 (Thread-1): Opening a new connection, currently in state closed
2020-10-19 23:02:28.901454 (Thread-4): Opening a new connection, currently in state init
2020-10-19 23:02:28.902134 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:28.904667 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:28.905927 (Thread-3): Opening a new connection, currently in state init
2020-10-19 23:02:28.907039 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:28.916490 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-19 23:02:29.487222 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-19 23:02:29.507799 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-19 23:02:29.526063 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-19 23:02:29.542892 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-19 23:02:30.267841 (Thread-2): finished collecting timing info
2020-10-19 23:02:30.277053 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ca1ecf-428c-4019-8289-926993b0e9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77313bd00>]}
2020-10-19 23:02:30.282002 (Thread-1): finished collecting timing info
2020-10-19 23:02:30.285024 (Thread-2): 23:02:30 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.61s]
2020-10-19 23:02:30.286938 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ca1ecf-428c-4019-8289-926993b0e9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75b79b2e0>]}
2020-10-19 23:02:30.288418 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-19 23:02:30.293202 (Thread-1): 23:02:30 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 1.62s]
2020-10-19 23:02:30.296404 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-19 23:02:30.486842 (Thread-3): finished collecting timing info
2020-10-19 23:02:30.490374 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ca1ecf-428c-4019-8289-926993b0e9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc75b7a8520>]}
2020-10-19 23:02:30.493365 (Thread-3): 23:02:30 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.82s]
2020-10-19 23:02:30.495131 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-19 23:02:30.513102 (Thread-4): finished collecting timing info
2020-10-19 23:02:30.515545 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15ca1ecf-428c-4019-8289-926993b0e9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7732311c0>]}
2020-10-19 23:02:30.518187 (Thread-4): 23:02:30 | 4 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.85s]
2020-10-19 23:02:30.519229 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-19 23:02:30.523154 (MainThread): Acquiring new bigquery connection "master".
2020-10-19 23:02:30.525038 (MainThread): 23:02:30 | 
2020-10-19 23:02:30.526297 (MainThread): 23:02:30 | Finished running 4 view models in 3.94s.
2020-10-19 23:02:30.527604 (MainThread): Connection 'master' was properly closed.
2020-10-19 23:02:30.528830 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-19 23:02:30.529748 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-19 23:02:30.530549 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-19 23:02:30.531598 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-19 23:02:30.568519 (MainThread): 
2020-10-19 23:02:30.570404 (MainThread): Completed successfully
2020-10-19 23:02:30.572888 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-19 23:02:30.576100 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77312c1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77312c3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77312cb50>]}
2020-10-19 23:02:30.578301 (MainThread): Flushing usage events
2020-10-20 18:57:01.500444 (MainThread): Running with dbt=0.18.0
2020-10-20 18:57:01.791524 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:57:01.800093 (MainThread): Tracking: tracking
2020-10-20 18:57:01.803646 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823b351f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a6a4eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a6a4e80>]}
2020-10-20 18:57:01.841342 (MainThread): Partial parsing not enabled
2020-10-20 18:57:01.844847 (MainThread): Parsing macros/etc.sql
2020-10-20 18:57:01.848971 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:57:01.863168 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:57:01.901711 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 18:57:01.909315 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 18:57:01.928586 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 18:57:01.952141 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 18:57:01.957393 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 18:57:01.967019 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 18:57:01.974482 (MainThread): Parsing macros/core.sql
2020-10-20 18:57:01.982742 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:57:02.001162 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:57:02.011332 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:57:02.024395 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:57:02.054034 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:57:02.083973 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:57:02.089298 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:57:02.144039 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:57:02.157199 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:57:02.162343 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:57:02.174715 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:57:02.216171 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:57:02.301275 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:57:02.305010 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:57:02.309795 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:57:02.314193 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:57:02.332220 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:57:02.337491 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:57:02.340614 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:57:02.344944 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:57:02.349346 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:57:02.355473 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:57:02.372057 (MainThread): Partial parsing not enabled
2020-10-20 18:57:02.479794 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 18:57:02.510719 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 18:57:02.529525 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 18:57:02.554817 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 18:57:02.591039 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 18:57:02.611153 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 18:57:02.631112 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 18:57:02.650302 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 18:57:02.670345 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 18:57:03.220110 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 18:57:03.222187 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 18:57:03.223717 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 18:57:03.456361 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 1 source
2020-10-20 18:57:03.460843 (MainThread): 
2020-10-20 18:57:03.463161 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 18:57:03.474176 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 18:57:03.475839 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:57:03.479856 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:04.698051 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 18:57:04.700241 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 18:57:04.703260 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:05.300193 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 18:57:05.687966 (MainThread): 18:57:05 | Concurrency: 4 threads (target='dev')
2020-10-20 18:57:05.690960 (MainThread): 18:57:05 | 
2020-10-20 18:57:05.701304 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 18:57:05.701534 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 18:57:05.702035 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 18:57:05.702291 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 18:57:05.704798 (Thread-1): 18:57:05 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 18:57:05.708371 (Thread-2): 18:57:05 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 18:57:05.713806 (Thread-3): 18:57:05 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 18:57:05.718673 (Thread-4): 18:57:05 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 18:57:05.721997 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 18:57:05.724022 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 18:57:05.726160 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 18:57:05.729422 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 18:57:05.731530 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 18:57:05.735396 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 18:57:05.738252 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 18:57:05.740274 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 18:57:05.833505 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 18:57:05.862209 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 18:57:05.872587 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 18:57:05.877380 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 18:57:05.878730 (Thread-2): finished collecting timing info
2020-10-20 18:57:05.885034 (Thread-4): finished collecting timing info
2020-10-20 18:57:05.910957 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42934), raddr=('172.217.14.74', 443)>
2020-10-20 18:57:05.922767 (Thread-3): finished collecting timing info
2020-10-20 18:57:05.934379 (Thread-1): finished collecting timing info
2020-10-20 18:57:05.939086 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 18:57:05.939333 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 41102), raddr=('172.217.5.74', 443)>
2020-10-20 18:57:05.947067 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 18:57:05.959038 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 18:57:05.971700 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 18:57:05.975328 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:57:05.981255 (Thread-3): Opening a new connection, currently in state init
2020-10-20 18:57:05.983224 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:05.987397 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:05.987957 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 18:57:05.988187 (Thread-4): Opening a new connection, currently in state init
2020-10-20 18:57:06.005338 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:06.002248 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:57:06.835492 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 18:57:06.848509 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 18:57:06.858514 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 18:57:06.868442 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`dev_source`.`interview_source`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 18:57:07.834902 (Thread-1): finished collecting timing info
2020-10-20 18:57:07.839369 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc1ddc0-4474-4a7b-b876-71be244dd97a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8238235cd0>]}
2020-10-20 18:57:07.844516 (Thread-1): 18:57:07 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 2.12s]
2020-10-20 18:57:07.847198 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 18:57:07.937171 (Thread-3): finished collecting timing info
2020-10-20 18:57:07.941237 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc1ddc0-4474-4a7b-b876-71be244dd97a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823824ca30>]}
2020-10-20 18:57:07.946909 (Thread-2): finished collecting timing info
2020-10-20 18:57:07.949354 (Thread-3): 18:57:07 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.21s]
2020-10-20 18:57:07.952016 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc1ddc0-4474-4a7b-b876-71be244dd97a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a5197f0>]}
2020-10-20 18:57:07.954782 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 18:57:07.958530 (Thread-2): 18:57:07 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.23s]
2020-10-20 18:57:07.963433 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 18:57:08.047283 (Thread-4): finished collecting timing info
2020-10-20 18:57:08.050822 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cdc1ddc0-4474-4a7b-b876-71be244dd97a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823821c970>]}
2020-10-20 18:57:08.055222 (Thread-4): 18:57:08 | 4 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.32s]
2020-10-20 18:57:08.058770 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 18:57:08.066391 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 18:57:08.070256 (MainThread): 18:57:08 | 
2020-10-20 18:57:08.073093 (MainThread): 18:57:08 | Finished running 4 view models in 4.61s.
2020-10-20 18:57:08.077091 (MainThread): Connection 'master' was properly closed.
2020-10-20 18:57:08.079335 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-20 18:57:08.081104 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 18:57:08.083156 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 18:57:08.085060 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 18:57:08.137649 (MainThread): 
2020-10-20 18:57:08.142211 (MainThread): Completed successfully
2020-10-20 18:57:08.144413 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-20 18:57:08.151363 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a3644c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a3edd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823a3ed6a0>]}
2020-10-20 18:57:08.156384 (MainThread): Flushing usage events
2020-10-20 18:59:47.601467 (MainThread): Running with dbt=0.18.0
2020-10-20 18:59:47.844639 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 18:59:47.850679 (MainThread): Tracking: tracking
2020-10-20 18:59:47.854318 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497b110d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497a3e2f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497a3e2f40>]}
2020-10-20 18:59:47.889736 (MainThread): Partial parsing not enabled
2020-10-20 18:59:47.893052 (MainThread): Parsing macros/etc.sql
2020-10-20 18:59:47.896679 (MainThread): Parsing macros/catalog.sql
2020-10-20 18:59:47.910135 (MainThread): Parsing macros/adapters.sql
2020-10-20 18:59:47.946635 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 18:59:47.953164 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 18:59:47.971100 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 18:59:47.993723 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 18:59:47.999549 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 18:59:48.008808 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 18:59:48.015186 (MainThread): Parsing macros/core.sql
2020-10-20 18:59:48.022450 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 18:59:48.040253 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 18:59:48.051479 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 18:59:48.063758 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 18:59:48.092480 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 18:59:48.119686 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 18:59:48.124472 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 18:59:48.177494 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 18:59:48.189848 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 18:59:48.194458 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 18:59:48.207545 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 18:59:48.243932 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 18:59:48.326734 (MainThread): Parsing macros/etc/query.sql
2020-10-20 18:59:48.331248 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 18:59:48.336151 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 18:59:48.340876 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 18:59:48.357152 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 18:59:48.362457 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 18:59:48.365353 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 18:59:48.369993 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 18:59:48.374005 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 18:59:48.379792 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 18:59:48.393960 (MainThread): Partial parsing not enabled
2020-10-20 18:59:48.487342 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 18:59:48.519757 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 18:59:48.538591 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 18:59:48.558721 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 18:59:48.588680 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 18:59:48.607243 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 18:59:48.624550 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 18:59:48.642577 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 18:59:48.659194 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 18:59:49.189185 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 18:59:49.191037 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 18:59:49.192543 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 18:59:49.411136 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 18:59:49.415258 (MainThread): 
2020-10-20 18:59:49.417448 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 18:59:49.425658 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 18:59:49.427526 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 18:59:49.430702 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:50.538832 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 18:59:50.540998 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 18:59:50.542945 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:51.120239 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 18:59:51.440095 (MainThread): 18:59:51 | Concurrency: 4 threads (target='dev')
2020-10-20 18:59:51.443096 (MainThread): 18:59:51 | 
2020-10-20 18:59:51.450696 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 18:59:51.450982 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 18:59:51.451365 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 18:59:51.451635 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 18:59:51.453996 (Thread-1): 18:59:51 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 18:59:51.456896 (Thread-2): 18:59:51 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 18:59:51.459567 (Thread-3): 18:59:51 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 18:59:51.464688 (Thread-4): 18:59:51 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 18:59:51.468928 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 18:59:51.471771 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 18:59:51.474227 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 18:59:51.480126 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 18:59:51.482850 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 18:59:51.485053 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 18:59:51.486874 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 18:59:51.488617 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 18:59:51.564540 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 18:59:51.588649 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 18:59:51.618117 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 18:59:51.620763 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 18:59:51.621247 (Thread-3): finished collecting timing info
2020-10-20 18:59:51.622121 (Thread-2): finished collecting timing info
2020-10-20 18:59:51.626736 (Thread-1): finished collecting timing info
2020-10-20 18:59:51.661877 (Thread-4): finished collecting timing info
2020-10-20 18:59:51.671208 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42960), raddr=('172.217.14.74', 443)>
2020-10-20 18:59:51.700136 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 18:59:51.703439 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 18:59:51.709409 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 18:59:51.710802 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 41128), raddr=('172.217.5.74', 443)>
2020-10-20 18:59:51.719206 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 18:59:51.719785 (Thread-2): Opening a new connection, currently in state init
2020-10-20 18:59:51.724223 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 18:59:51.725890 (Thread-4): Opening a new connection, currently in state init
2020-10-20 18:59:51.726757 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:51.729590 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:51.737688 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:51.746198 (Thread-3): Opening a new connection, currently in state init
2020-10-20 18:59:51.760643 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 18:59:52.400340 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 18:59:52.408329 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 18:59:52.415710 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 18:59:52.432321 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 18:59:53.187048 (Thread-4): finished collecting timing info
2020-10-20 18:59:53.189984 (Thread-4): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: 55a31317-e7c9-4662-84d2-5c172f5b1907)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,commands  as (
  91:    select
  92:      command_uuid
  93:      ,command_client
  94:      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
  95:      ,command_desired_state
  96:      ,command_user
  97:      ,item_data
  98:
  99:      ,update_timestamp
 100:      ,event_timestamp
 101:      ,device_id
 102:
 103:      ,_uid
 104:      ,_source_file
 105:    from
 106:      command_events_deduped_across_source_files
 107:    where
 108:      item_key = 'Command'
 109:      and command_uuid is not null
 110:)
 111:,final as (
 112:  select
 113:    command_uuid
 114:    ,command_client
 115:    ,command
 116:    ,command_desired_state as _raw_desired_state
 117:    ,command_user as user_id
 118:
 119:    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --
 120:
 121:    ,update_timestamp
 122:    ,event_timestamp
 123:    ,device_id
 124:
 125:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
 126:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id
 127:
 128:    ,_uid
 129:    ,_source_file
 130:  from
 131:    commands
 132:)
 133:
 134:select *
 135:from final;
 136:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-20 18:59:53.196792 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a69f07f-e53f-4407-bb22-a66e92d43dc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497875efd0>]}
2020-10-20 18:59:53.200623 (Thread-4): 18:59:53 | 4 of 4 ERROR creating view model dev_sam.stg_commands................ [ERROR in 1.72s]
2020-10-20 18:59:53.202129 (Thread-3): finished collecting timing info
2020-10-20 18:59:53.204095 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 18:59:53.205918 (Thread-3): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: a19954f4-82ef-43ef-bc5c-403244f4fb4e)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,final as (
  91:    select
  92:      command_uuid
  93:
  94:      ,command_result IN ('success', 'true') as is_hub_success
  95:      ,command_failure_string
  96:      ,command_node_id
  97:
  98:      ,update_timestamp
  99:      ,event_timestamp
 100:      ,event_uuid
 101:      ,device_id
 102:
 103:      ,_uid
 104:      ,_source_file
 105:    from
 106:      command_events_deduped_across_source_files
 107:    where
 108:      item_key = 'CommandResult'
 109:      and command_uuid is not null
 110:)
 111:
 112:select *
 113:from final;
 114:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-20 18:59:53.212821 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a69f07f-e53f-4407-bb22-a66e92d43dc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497875efd0>]}
2020-10-20 18:59:53.215827 (Thread-3): 18:59:53 | 3 of 4 ERROR creating view model dev_sam.stg_command_results......... [ERROR in 1.74s]
2020-10-20 18:59:53.218885 (Thread-2): finished collecting timing info
2020-10-20 18:59:53.219479 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 18:59:53.221563 (Thread-2): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: 340c10fe-654d-4790-8f2e-2ea1a73bde97)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,final as (
  91:    select
  92:      command_uuid
  93:      ,command_node_id
  94:
  95:      ,update_timestamp
  96:      ,event_timestamp
  97:      ,device_id
  98:
  99:      ,_uid
 100:      ,_source_file
 101:    from
 102:      command_events_deduped_across_source_files
 103:    where
 104:      item_key = 'CommandActive'
 105:      and command_uuid is not null
 106:)
 107:
 108:select *
 109:from final;
 110:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-20 18:59:53.226759 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a69f07f-e53f-4407-bb22-a66e92d43dc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497877e820>]}
2020-10-20 18:59:53.230197 (Thread-2): 18:59:53 | 2 of 4 ERROR creating view model dev_sam.stg_command_actives......... [ERROR in 1.76s]
2020-10-20 18:59:53.232266 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 18:59:53.571802 (Thread-1): finished collecting timing info
2020-10-20 18:59:53.575685 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a69f07f-e53f-4407-bb22-a66e92d43dc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497877beb0>]}
2020-10-20 18:59:53.579125 (Thread-1): 18:59:53 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 2.11s]
2020-10-20 18:59:53.581032 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 18:59:53.585302 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 18:59:53.587617 (MainThread): 18:59:53 | 
2020-10-20 18:59:53.589570 (MainThread): 18:59:53 | Finished running 4 view models in 4.17s.
2020-10-20 18:59:53.591683 (MainThread): Connection 'master' was properly closed.
2020-10-20 18:59:53.593759 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-20 18:59:53.595664 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 18:59:53.597814 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 18:59:53.599535 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 18:59:53.635881 (MainThread): 
2020-10-20 18:59:53.638901 (MainThread): Completed with 3 errors and 0 warnings:
2020-10-20 18:59:53.642475 (MainThread): 
2020-10-20 18:59:53.644866 (MainThread): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
2020-10-20 18:59:53.647294 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 18:59:53.649881 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-20 18:59:53.652882 (MainThread): 
2020-10-20 18:59:53.655301 (MainThread): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
2020-10-20 18:59:53.657827 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 18:59:53.660437 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-20 18:59:53.663480 (MainThread): 
2020-10-20 18:59:53.665711 (MainThread): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
2020-10-20 18:59:53.668061 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 18:59:53.670839 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-20 18:59:53.673773 (MainThread): 
Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
2020-10-20 18:59:53.677256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497a1e7100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497a0a1e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f497a237280>]}
2020-10-20 18:59:53.680236 (MainThread): Flushing usage events
2020-10-20 19:00:19.687465 (MainThread): Running with dbt=0.18.0
2020-10-20 19:00:19.932960 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 19:00:19.942554 (MainThread): Tracking: tracking
2020-10-20 19:00:19.946366 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837f414df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e6eaf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e6eaf10>]}
2020-10-20 19:00:19.984759 (MainThread): Partial parsing not enabled
2020-10-20 19:00:19.988326 (MainThread): Parsing macros/etc.sql
2020-10-20 19:00:19.991779 (MainThread): Parsing macros/catalog.sql
2020-10-20 19:00:20.005748 (MainThread): Parsing macros/adapters.sql
2020-10-20 19:00:20.042521 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 19:00:20.048549 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 19:00:20.067043 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 19:00:20.089510 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 19:00:20.094242 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 19:00:20.102666 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 19:00:20.109847 (MainThread): Parsing macros/core.sql
2020-10-20 19:00:20.118227 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 19:00:20.135675 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 19:00:20.146552 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 19:00:20.158970 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 19:00:20.187766 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 19:00:20.217877 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 19:00:20.222320 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 19:00:20.277169 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 19:00:20.288805 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 19:00:20.293660 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 19:00:20.305827 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 19:00:20.344566 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 19:00:20.426301 (MainThread): Parsing macros/etc/query.sql
2020-10-20 19:00:20.429716 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 19:00:20.433629 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 19:00:20.437894 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 19:00:20.454297 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 19:00:20.459828 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 19:00:20.462503 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 19:00:20.466607 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 19:00:20.470750 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 19:00:20.476373 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 19:00:20.489623 (MainThread): Partial parsing not enabled
2020-10-20 19:00:20.585481 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 19:00:20.618233 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 19:00:20.636286 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 19:00:20.655807 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 19:00:20.686428 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 19:00:20.704023 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 19:00:20.721524 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 19:00:20.738633 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 19:00:20.756011 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 19:00:21.289723 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 19:00:21.291610 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 19:00:21.293550 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 19:00:21.479722 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 19:00:21.483510 (MainThread): 
2020-10-20 19:00:21.485290 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 19:00:21.493301 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 19:00:21.495456 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 19:00:21.498625 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:22.497280 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 19:00:22.499225 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 19:00:22.500843 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:23.076471 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 19:00:23.476708 (MainThread): 19:00:23 | Concurrency: 4 threads (target='dev')
2020-10-20 19:00:23.479403 (MainThread): 19:00:23 | 
2020-10-20 19:00:23.487533 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 19:00:23.487801 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 19:00:23.488214 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 19:00:23.488438 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 19:00:23.491116 (Thread-1): 19:00:23 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 19:00:23.493872 (Thread-2): 19:00:23 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 19:00:23.496805 (Thread-3): 19:00:23 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 19:00:23.500720 (Thread-4): 19:00:23 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 19:00:23.503581 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 19:00:23.505319 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 19:00:23.518019 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 19:00:23.512562 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 19:00:23.515141 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 19:00:23.508605 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 19:00:23.538676 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 19:00:23.558701 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 19:00:23.576548 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 19:00:23.612360 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 19:00:23.619237 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 19:00:23.626059 (Thread-2): finished collecting timing info
2020-10-20 19:00:23.636815 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 19:00:23.647338 (Thread-1): finished collecting timing info
2020-10-20 19:00:23.659524 (Thread-4): finished collecting timing info
2020-10-20 19:00:23.706591 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 19:00:23.696314 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 42986), raddr=('172.217.14.74', 443)>
2020-10-20 19:00:23.700687 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 19:00:23.694985 (Thread-3): finished collecting timing info
2020-10-20 19:00:23.710475 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 41154), raddr=('172.217.5.74', 443)>
2020-10-20 19:00:23.725370 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 19:00:23.720462 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 19:00:23.721741 (Thread-2): Opening a new connection, currently in state init
2020-10-20 19:00:23.712245 (Thread-4): Opening a new connection, currently in state init
2020-10-20 19:00:23.730893 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 19:00:23.732424 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:23.733563 (Thread-3): Opening a new connection, currently in state init
2020-10-20 19:00:23.734112 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:23.735322 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:23.742644 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:00:24.406260 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 19:00:24.415121 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 19:00:24.425636 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 19:00:24.430042 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 19:00:24.997743 (Thread-4): finished collecting timing info
2020-10-20 19:00:25.001332 (Thread-4): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: 4563b7f5-637e-4996-9ab5-dae17e6fc6b0)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,commands  as (
  91:    select
  92:      command_uuid
  93:      ,command_client
  94:      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
  95:      ,command_desired_state
  96:      ,command_user
  97:      ,item_data
  98:
  99:      ,update_timestamp
 100:      ,event_timestamp
 101:      ,device_id
 102:
 103:      ,_uid
 104:      ,_source_file
 105:    from
 106:      command_events_deduped_across_source_files
 107:    where
 108:      item_key = 'Command'
 109:      and command_uuid is not null
 110:)
 111:,final as (
 112:  select
 113:    command_uuid
 114:    ,command_client
 115:    ,command
 116:    ,command_desired_state as _raw_desired_state
 117:    ,command_user as user_id
 118:
 119:    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --
 120:
 121:    ,update_timestamp
 122:    ,event_timestamp
 123:    ,device_id
 124:
 125:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
 126:    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id
 127:
 128:    ,_uid
 129:    ,_source_file
 130:  from
 131:    commands
 132:)
 133:
 134:select *
 135:from final;
 136:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-20 19:00:25.006677 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6d9f123-47aa-4eb4-91c5-61e23ed20855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837c22eee0>]}
2020-10-20 19:00:25.010683 (Thread-4): 19:00:25 | 4 of 4 ERROR creating view model dev_sam.stg_commands................ [ERROR in 1.49s]
2020-10-20 19:00:25.014211 (Thread-3): finished collecting timing info
2020-10-20 19:00:25.015095 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 19:00:25.018175 (Thread-3): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: 00e87322-9bbc-45b0-9c05-f02fcae359a7)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,final as (
  91:    select
  92:      command_uuid
  93:
  94:      ,command_result IN ('success', 'true') as is_hub_success
  95:      ,command_failure_string
  96:      ,command_node_id
  97:
  98:      ,update_timestamp
  99:      ,event_timestamp
 100:      ,event_uuid
 101:      ,device_id
 102:
 103:      ,_uid
 104:      ,_source_file
 105:    from
 106:      command_events_deduped_across_source_files
 107:    where
 108:      item_key = 'CommandResult'
 109:      and command_uuid is not null
 110:)
 111:
 112:select *
 113:from final;
 114:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-20 19:00:25.025191 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6d9f123-47aa-4eb4-91c5-61e23ed20855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837c275940>]}
2020-10-20 19:00:25.030166 (Thread-3): 19:00:25 | 3 of 4 ERROR creating view model dev_sam.stg_command_results......... [ERROR in 1.52s]
2020-10-20 19:00:25.032589 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 19:00:25.062731 (Thread-2): finished collecting timing info
2020-10-20 19:00:25.065470 (Thread-2): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.Forbidden: 403 Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.

(job ID: cf4ef33f-63d9-4550-9bf4-fbbd76ada05e)

                                                          -----Query Job SQL Follows-----                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
   5:  OPTIONS()
   6:  as with command_events_deduped_across_source_files as (
   7:    select * from (
   8:        select
   9:            EventType as event_type
  10:            ,DateCreated as update_timestamp
  11:            ,MapRevision as map_revision
  12:            ,ItemKey as item_key
  13:            ,ItemRevision as item_revision
  14:            ,EndpointId as twilio_sync_endpoint_id
  15:            ,ItemData as item_data
  16:            ,MapUniqueName as  device_id
  17:
  18:            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file
  19:
  20:            ,case
  21:             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  22:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  23:              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  24:              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  25:              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
  26:              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
  27:            end as event_timestamp
  28:            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  29:
  30:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  31:              case
  32:                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  33:                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  34:                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  35:              end
  36:              else null
  37:            end as command_uuid
  38:
  39:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  40:              JSON_EXTRACT_SCALAR(ItemData, '$.client')
  41:              else null
  42:            end as command_client
  43:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  44:              JSON_EXTRACT(ItemData, '$.desired_state')
  45:              else null
  46:            end as command_desired_state
  47:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  48:              JSON_EXTRACT_SCALAR(ItemData, '$.user')
  49:              else null
  50:            end as command_user
  51:
  52:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  53:              JSON_EXTRACT_SCALAR(ItemData, '$.result')
  54:              else null
  55:            end as command_result
  56:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  57:              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  58:              else null
  59:            end as command_failure_string
  60:            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  61:              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  62:              else null
  63:            end as command_node_id
  64:
  65:            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  66:         from `analytics-interview`.`interview_source`.`raw_sync_events`
  67:
  68:    )
  69:    group by
  70:        event_type
  71:        ,update_timestamp
  72:        ,map_revision
  73:        ,item_key
  74:        ,item_revision
  75:        ,twilio_sync_endpoint_id
  76:        ,item_data
  77:        ,device_id
  78:        ,_source_file
  79:        ,event_timestamp
  80:        ,event_uuid
  81:        ,command_uuid
  82:        ,command_client
  83:        ,command_desired_state
  84:        ,command_user
  85:        ,command_result
  86:        ,command_failure_string
  87:        ,command_node_id
  88:        ,_uid
  89:)
  90:,final as (
  91:    select
  92:      command_uuid
  93:      ,command_node_id
  94:
  95:      ,update_timestamp
  96:      ,event_timestamp
  97:      ,device_id
  98:
  99:      ,_uid
 100:      ,_source_file
 101:    from
 102:      command_events_deduped_across_source_files
 103:    where
 104:      item_key = 'CommandActive'
 105:      and command_uuid is not null
 106:)
 107:
 108:select *
 109:from final;
 110:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 111, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
  Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
  compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-20 19:00:25.067902 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6d9f123-47aa-4eb4-91c5-61e23ed20855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e3df520>]}
2020-10-20 19:00:25.070779 (Thread-2): 19:00:25 | 2 of 4 ERROR creating view model dev_sam.stg_command_actives......... [ERROR in 1.56s]
2020-10-20 19:00:25.072551 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 19:00:25.200267 (Thread-1): finished collecting timing info
2020-10-20 19:00:25.203388 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6d9f123-47aa-4eb4-91c5-61e23ed20855', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e52bd60>]}
2020-10-20 19:00:25.207113 (Thread-1): 19:00:25 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 1.70s]
2020-10-20 19:00:25.209286 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 19:00:25.213864 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 19:00:25.215460 (MainThread): 19:00:25 | 
2020-10-20 19:00:25.216822 (MainThread): 19:00:25 | Finished running 4 view models in 3.73s.
2020-10-20 19:00:25.218868 (MainThread): Connection 'master' was properly closed.
2020-10-20 19:00:25.221223 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-20 19:00:25.222886 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 19:00:25.225168 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 19:00:25.226892 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 19:00:25.261848 (MainThread): 
2020-10-20 19:00:25.265582 (MainThread): Completed with 3 errors and 0 warnings:
2020-10-20 19:00:25.267827 (MainThread): 
2020-10-20 19:00:25.270627 (MainThread): Database Error in model stg_commands (models/staging/commands/stg_commands.sql)
2020-10-20 19:00:25.272762 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 19:00:25.275213 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_commands.sql
2020-10-20 19:00:25.277290 (MainThread): 
2020-10-20 19:00:25.279877 (MainThread): Database Error in model stg_command_results (models/staging/commands/stg_command_results.sql)
2020-10-20 19:00:25.281689 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 19:00:25.284305 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_results.sql
2020-10-20 19:00:25.286689 (MainThread): 
2020-10-20 19:00:25.289189 (MainThread): Database Error in model stg_command_actives (models/staging/commands/stg_command_actives.sql)
2020-10-20 19:00:25.291478 (MainThread):   Access Denied: Table analytics-interview:interview_source.raw_sync_events: User does not have permission to query table analytics-interview:interview_source.raw_sync_events.
2020-10-20 19:00:25.293485 (MainThread):   compiled SQL at target/run/dwelo/models/staging/commands/stg_command_actives.sql
2020-10-20 19:00:25.297474 (MainThread): 
Done. PASS=1 WARN=0 ERROR=3 SKIP=0 TOTAL=4
2020-10-20 19:00:25.300096 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e53e1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e4ece20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f837e3fa160>]}
2020-10-20 19:00:25.302122 (MainThread): Flushing usage events
2020-10-20 19:00:56.746661 (MainThread): Running with dbt=0.18.0
2020-10-20 19:00:56.990022 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 19:00:56.995537 (MainThread): Tracking: tracking
2020-10-20 19:00:56.999121 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feecf9ebd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeced3feb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeced3fe80>]}
2020-10-20 19:00:57.037452 (MainThread): Partial parsing not enabled
2020-10-20 19:00:57.041162 (MainThread): Parsing macros/etc.sql
2020-10-20 19:00:57.044654 (MainThread): Parsing macros/catalog.sql
2020-10-20 19:00:57.058718 (MainThread): Parsing macros/adapters.sql
2020-10-20 19:00:57.096196 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 19:00:57.102677 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 19:00:57.121298 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 19:00:57.144610 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 19:00:57.149329 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 19:00:57.158804 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 19:00:57.167625 (MainThread): Parsing macros/core.sql
2020-10-20 19:00:57.175885 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 19:00:57.193212 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 19:00:57.203841 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 19:00:57.216944 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 19:00:57.245397 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 19:00:57.274319 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 19:00:57.279162 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 19:00:57.335604 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 19:00:57.347152 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 19:00:57.351699 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 19:00:57.364475 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 19:00:57.406051 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 19:00:57.493247 (MainThread): Parsing macros/etc/query.sql
2020-10-20 19:00:57.496531 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 19:00:57.500690 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 19:00:57.504841 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 19:00:57.520857 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 19:00:57.525584 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 19:00:57.529023 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 19:00:57.533215 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 19:00:57.537674 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 19:00:57.544033 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 19:00:57.557962 (MainThread): Partial parsing not enabled
2020-10-20 19:00:57.657608 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 19:00:57.690067 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 19:00:57.710122 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 19:00:57.729991 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 19:00:57.763822 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 19:00:57.780818 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 19:00:57.798323 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 19:00:57.822021 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 19:00:57.882780 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 19:00:58.638592 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 19:00:58.641271 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 19:00:58.643579 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 19:00:58.878585 (MainThread): Found 4 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 19:00:58.883086 (MainThread): 
2020-10-20 19:00:58.885860 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 19:00:58.894438 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 19:00:58.896315 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 19:00:58.899079 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:00.114589 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 19:01:00.117335 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 19:01:00.120605 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:00.759182 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 19:01:01.258850 (MainThread): 19:01:01 | Concurrency: 4 threads (target='dev')
2020-10-20 19:01:01.260998 (MainThread): 19:01:01 | 
2020-10-20 19:01:01.269194 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 19:01:01.269509 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 19:01:01.270094 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 19:01:01.270362 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 19:01:01.272870 (Thread-1): 19:01:01 | 1 of 4 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 19:01:01.276254 (Thread-2): 19:01:01 | 2 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 19:01:01.279633 (Thread-3): 19:01:01 | 3 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 19:01:01.283439 (Thread-4): 19:01:01 | 4 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 19:01:01.287419 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 19:01:01.291323 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 19:01:01.295560 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 19:01:01.297703 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 19:01:01.300399 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 19:01:01.302882 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 19:01:01.305677 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 19:01:01.308737 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 19:01:01.420795 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 19:01:01.440026 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 19:01:01.442553 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 19:01:01.444891 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 19:01:01.447795 (Thread-2): finished collecting timing info
2020-10-20 19:01:01.452758 (Thread-1): finished collecting timing info
2020-10-20 19:01:01.456239 (Thread-4): finished collecting timing info
2020-10-20 19:01:01.486141 (Thread-3): finished collecting timing info
2020-10-20 19:01:01.493112 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43012), raddr=('172.217.14.74', 443)>
2020-10-20 19:01:01.553110 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 19:01:01.553930 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 19:01:01.555920 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 19:01:01.556277 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 41180), raddr=('172.217.5.74', 443)>
2020-10-20 19:01:01.560888 (Thread-2): Opening a new connection, currently in state init
2020-10-20 19:01:01.568190 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 19:01:01.568555 (Thread-3): Opening a new connection, currently in state init
2020-10-20 19:01:01.571645 (Thread-4): Opening a new connection, currently in state init
2020-10-20 19:01:01.572579 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:01.576107 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:01.577625 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:01.577921 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 19:01:01.599862 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 19:01:02.405347 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 19:01:02.431083 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 19:01:02.442443 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 19:01:02.457743 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 19:01:03.436377 (Thread-1): finished collecting timing info
2020-10-20 19:01:03.447492 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45ba7bf7-913e-41ef-ad27-704d1cb1603a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feecebe6310>]}
2020-10-20 19:01:03.456546 (Thread-3): finished collecting timing info
2020-10-20 19:01:03.459966 (Thread-1): 19:01:03 | 1 of 4 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 2.16s]
2020-10-20 19:01:03.469595 (Thread-2): finished collecting timing info
2020-10-20 19:01:03.477610 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45ba7bf7-913e-41ef-ad27-704d1cb1603a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeceb5d8e0>]}
2020-10-20 19:01:03.478625 (Thread-4): finished collecting timing info
2020-10-20 19:01:03.481236 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 19:01:03.484415 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45ba7bf7-913e-41ef-ad27-704d1cb1603a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeceb5ad30>]}
2020-10-20 19:01:03.488895 (Thread-3): 19:01:03 | 3 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.18s]
2020-10-20 19:01:03.491701 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45ba7bf7-913e-41ef-ad27-704d1cb1603a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feecc0c5eb0>]}
2020-10-20 19:01:03.496716 (Thread-2): 19:01:03 | 2 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.19s]
2020-10-20 19:01:03.499573 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 19:01:03.504820 (Thread-4): 19:01:03 | 4 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.19s]
2020-10-20 19:01:03.507558 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 19:01:03.511892 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 19:01:03.522490 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 19:01:03.524865 (MainThread): 19:01:03 | 
2020-10-20 19:01:03.526605 (MainThread): 19:01:03 | Finished running 4 view models in 4.64s.
2020-10-20 19:01:03.529303 (MainThread): Connection 'master' was properly closed.
2020-10-20 19:01:03.531326 (MainThread): Connection 'model.dwelo.fct_command_statuses' was properly closed.
2020-10-20 19:01:03.534195 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 19:01:03.541415 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 19:01:03.545102 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 19:01:03.582288 (MainThread): 
2020-10-20 19:01:03.584292 (MainThread): Completed successfully
2020-10-20 19:01:03.586633 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-20 19:01:03.589557 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeceac1fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeceaa0730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feeceaa0a30>]}
2020-10-20 19:01:03.591883 (MainThread): Flushing usage events
2020-10-20 20:26:01.065923 (MainThread): Running with dbt=0.18.0
2020-10-20 20:26:01.312943 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 20:26:01.321743 (MainThread): Tracking: tracking
2020-10-20 20:26:01.325424 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e8e55d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e81a9eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e81a9e80>]}
2020-10-20 20:26:01.364395 (MainThread): Partial parsing not enabled
2020-10-20 20:26:01.368464 (MainThread): Parsing macros/etc.sql
2020-10-20 20:26:01.372355 (MainThread): Parsing macros/catalog.sql
2020-10-20 20:26:01.386579 (MainThread): Parsing macros/adapters.sql
2020-10-20 20:26:01.423114 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 20:26:01.429052 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 20:26:01.447025 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 20:26:01.469815 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 20:26:01.474533 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 20:26:01.483398 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 20:26:01.490114 (MainThread): Parsing macros/core.sql
2020-10-20 20:26:01.497959 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 20:26:01.515844 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 20:26:01.526242 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 20:26:01.538405 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 20:26:01.565628 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 20:26:01.595177 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 20:26:01.600362 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 20:26:01.655311 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 20:26:01.666285 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 20:26:01.670655 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 20:26:01.683201 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 20:26:01.721632 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 20:26:01.806722 (MainThread): Parsing macros/etc/query.sql
2020-10-20 20:26:01.810344 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 20:26:01.814400 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 20:26:01.818052 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 20:26:01.834301 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 20:26:01.840284 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 20:26:01.844021 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 20:26:01.848886 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 20:26:01.853214 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 20:26:01.859003 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 20:26:01.872619 (MainThread): Partial parsing not enabled
2020-10-20 20:26:01.973093 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:26:02.004542 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:26:02.024431 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:26:02.045219 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:26:02.065063 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:26:02.097886 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 20:26:02.116749 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 20:26:02.134120 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 20:26:02.152429 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 20:26:02.169503 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 20:26:02.708485 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 20:26:02.711011 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:26:02.713032 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:26:02.943502 (MainThread): Found 5 models, 19 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 20:26:02.947404 (MainThread): 
2020-10-20 20:26:02.949507 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:26:02.959142 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 20:26:02.960589 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 20:26:02.963055 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:04.259551 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 20:26:04.261609 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 20:26:04.263449 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:04.871413 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 20:26:05.388080 (MainThread): 20:26:05 | Concurrency: 4 threads (target='dev')
2020-10-20 20:26:05.391038 (MainThread): 20:26:05 | 
2020-10-20 20:26:05.400426 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 20:26:05.400983 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 20:26:05.401333 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 20:26:05.402370 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 20:26:05.403896 (Thread-1): 20:26:05 | 1 of 5 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 20:26:05.408334 (Thread-2): 20:26:05 | 2 of 5 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 20:26:05.411622 (Thread-3): 20:26:05 | 3 of 5 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 20:26:05.414618 (Thread-4): 20:26:05 | 4 of 5 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 20:26:05.417592 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:26:05.423512 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:26:05.439236 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 20:26:05.432214 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:26:05.435661 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 20:26:05.428443 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:26:05.462916 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 20:26:05.506631 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 20:26:05.578805 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 20:26:05.629774 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 20:26:05.634860 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 20:26:05.635242 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 20:26:05.643342 (Thread-1): finished collecting timing info
2020-10-20 20:26:05.644389 (Thread-4): finished collecting timing info
2020-10-20 20:26:05.651997 (Thread-3): finished collecting timing info
2020-10-20 20:26:05.667029 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43038), raddr=('172.217.14.74', 443)>
2020-10-20 20:26:05.720570 (Thread-2): finished collecting timing info
2020-10-20 20:26:05.733451 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43942), raddr=('216.58.217.202', 443)>
2020-10-20 20:26:05.779462 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 20:26:05.789450 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 20:26:05.806128 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 20:26:05.825149 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 20:26:05.838684 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:26:05.842796 (Thread-2): Opening a new connection, currently in state init
2020-10-20 20:26:05.854725 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:05.858437 (Thread-3): Opening a new connection, currently in state init
2020-10-20 20:26:05.860058 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:05.866893 (Thread-4): Opening a new connection, currently in state init
2020-10-20 20:26:05.883038 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:05.903496 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:07.232726 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 20:26:07.284913 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 20:26:07.287216 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 20:26:07.290739 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 20:26:08.433318 (Thread-1): finished collecting timing info
2020-10-20 20:26:08.438287 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43a6ac03-3f56-4dac-ad75-bb9a192fa062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e69f10>]}
2020-10-20 20:26:08.444310 (Thread-1): 20:26:08 | 1 of 5 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 3.02s]
2020-10-20 20:26:08.446344 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 20:26:08.448756 (Thread-1): Began running node model.dwelo.stg_users
2020-10-20 20:26:08.453517 (Thread-1): 20:26:08 | 5 of 5 START view model dev_sam.stg_users............................ [RUN]
2020-10-20 20:26:08.459433 (Thread-4): finished collecting timing info
2020-10-20 20:26:08.460277 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:26:08.473302 (Thread-1): Compiling model.dwelo.stg_users
2020-10-20 20:26:08.472762 (Thread-2): finished collecting timing info
2020-10-20 20:26:08.463209 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43a6ac03-3f56-4dac-ad75-bb9a192fa062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e72e80>]}
2020-10-20 20:26:08.492449 (Thread-4): 20:26:08 | 4 of 5 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 3.03s]
2020-10-20 20:26:08.489177 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43a6ac03-3f56-4dac-ad75-bb9a192fa062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e72b20>]}
2020-10-20 20:26:08.487460 (Thread-1): Writing injected SQL for node "model.dwelo.stg_users"
2020-10-20 20:26:08.494275 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 20:26:08.497415 (Thread-2): 20:26:08 | 2 of 5 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 3.07s]
2020-10-20 20:26:08.503657 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 20:26:08.506055 (Thread-1): finished collecting timing info
2020-10-20 20:26:08.513419 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_users"
2020-10-20 20:26:08.522564 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:26:08.525069 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:26:08.572230 (Thread-3): finished collecting timing info
2020-10-20 20:26:08.576102 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43a6ac03-3f56-4dac-ad75-bb9a192fa062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e72310>]}
2020-10-20 20:26:08.579516 (Thread-3): 20:26:08 | 3 of 5 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 3.15s]
2020-10-20 20:26:08.584122 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 20:26:09.133278 (Thread-1): On model.dwelo.stg_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
  OPTIONS()
  as with final as (
  select
    *
  from
    from `analytics-interview`.`interview_source`.`raw_users`
)

select
  *
from
  final;


2020-10-20 20:26:09.518975 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Syntax error: Unexpected keyword FROM at [10:5]')
2020-10-20 20:26:10.046020 (Thread-1): finished collecting timing info
2020-10-20 20:26:10.048939 (Thread-1): Database Error in model stg_users (models/staging/stg_users.sql)
  Syntax error: Unexpected keyword FROM at [10:5]
  compiled SQL at target/run/dwelo/models/staging/stg_users.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Unexpected keyword FROM at [10:5]

(job ID: d5cf9250-e2ed-46f9-86b9-5890edc217c0)

                                                    -----Query Job SQL Follows-----                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
   5:  OPTIONS()
   6:  as with final as (
   7:  select
   8:    *
   9:  from
  10:    from `analytics-interview`.`interview_source`.`raw_users`
  11:)
  12:
  13:select
  14:  *
  15:from
  16:  final;
  17:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_users (models/staging/stg_users.sql)
  Syntax error: Unexpected keyword FROM at [10:5]
  compiled SQL at target/run/dwelo/models/staging/stg_users.sql
2020-10-20 20:26:10.054663 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43a6ac03-3f56-4dac-ad75-bb9a192fa062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e4589ca0>]}
2020-10-20 20:26:10.058024 (Thread-1): 20:26:10 | 5 of 5 ERROR creating view model dev_sam.stg_users................... [ERROR in 1.59s]
2020-10-20 20:26:10.059757 (Thread-1): Finished running node model.dwelo.stg_users
2020-10-20 20:26:10.064691 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:26:10.066606 (MainThread): 20:26:10 | 
2020-10-20 20:26:10.068052 (MainThread): 20:26:10 | Finished running 5 view models in 7.12s.
2020-10-20 20:26:10.069889 (MainThread): Connection 'master' was properly closed.
2020-10-20 20:26:10.071914 (MainThread): Connection 'model.dwelo.stg_users' was properly closed.
2020-10-20 20:26:10.073700 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 20:26:10.075682 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 20:26:10.077562 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 20:26:10.122305 (MainThread): 
2020-10-20 20:26:10.124161 (MainThread): Completed with 1 error and 0 warnings:
2020-10-20 20:26:10.125794 (MainThread): 
2020-10-20 20:26:10.127279 (MainThread): Database Error in model stg_users (models/staging/stg_users.sql)
2020-10-20 20:26:10.129325 (MainThread):   Syntax error: Unexpected keyword FROM at [10:5]
2020-10-20 20:26:10.131321 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_users.sql
2020-10-20 20:26:10.133617 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2020-10-20 20:26:10.135551 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e9f9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e60790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f37e7e60e50>]}
2020-10-20 20:26:10.138479 (MainThread): Flushing usage events
2020-10-20 20:31:10.100295 (MainThread): Running with dbt=0.18.0
2020-10-20 20:31:10.345979 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 20:31:10.351812 (MainThread): Tracking: tracking
2020-10-20 20:31:10.355934 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9ea78e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9ddccf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7d9ddccee0>]}
2020-10-20 20:31:10.391600 (MainThread): Partial parsing not enabled
2020-10-20 20:31:10.394918 (MainThread): Parsing macros/etc.sql
2020-10-20 20:31:10.398779 (MainThread): Parsing macros/catalog.sql
2020-10-20 20:31:10.412729 (MainThread): Parsing macros/adapters.sql
2020-10-20 20:31:10.449517 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 20:31:10.456529 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 20:31:10.475583 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 20:31:10.497940 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 20:31:10.503745 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 20:31:10.512723 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 20:31:10.519314 (MainThread): Parsing macros/core.sql
2020-10-20 20:31:10.526513 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 20:31:10.544888 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 20:31:10.554675 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 20:31:10.570609 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 20:31:10.599411 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 20:31:10.628779 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 20:31:10.633633 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 20:31:10.688946 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 20:31:10.704025 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 20:31:10.708681 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 20:31:10.721886 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 20:31:10.760674 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 20:31:10.849002 (MainThread): Parsing macros/etc/query.sql
2020-10-20 20:31:10.853699 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 20:31:10.858290 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 20:31:10.862275 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 20:31:10.879083 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 20:31:10.883760 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 20:31:10.886595 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 20:31:10.890692 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 20:31:10.895182 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 20:31:10.901392 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 20:31:10.915377 (MainThread): Partial parsing not enabled
2020-10-20 20:31:11.017027 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:31:11.048362 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:31:11.067202 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:31:11.086471 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:31:11.106120 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:31:11.135550 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 20:31:11.153650 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 20:31:11.171027 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 20:31:11.189577 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 20:31:11.206733 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 20:31:11.887186 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 20:31:11.888801 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:11.890823 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:12.159206 (MainThread): Found 5 models, 25 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 20:31:12.163200 (MainThread): 
2020-10-20 20:31:12.165080 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:31:12.174766 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 20:31:12.176521 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 20:31:12.179125 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:13.358769 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 20:31:13.360648 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 20:31:13.362442 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:13.614793 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 20:31:13.958319 (MainThread): Connection 'master' was properly closed.
2020-10-20 20:31:13.960679 (MainThread): Connection 'list_analytics-interview_dev_sam' was properly closed.
2020-10-20 20:31:13.962453 (MainThread): Flushing usage events
2020-10-20 20:31:14.355960 (MainThread): ctrl-c
2020-10-20 20:31:26.581025 (MainThread): Running with dbt=0.18.0
2020-10-20 20:31:26.821992 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-20 20:31:26.831454 (MainThread): Tracking: tracking
2020-10-20 20:31:26.835102 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a9241df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8595ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8595eb0>]}
2020-10-20 20:31:26.869286 (MainThread): Partial parsing not enabled
2020-10-20 20:31:26.872442 (MainThread): Parsing macros/etc.sql
2020-10-20 20:31:26.875899 (MainThread): Parsing macros/catalog.sql
2020-10-20 20:31:26.891254 (MainThread): Parsing macros/adapters.sql
2020-10-20 20:31:26.942543 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 20:31:26.953124 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 20:31:26.974000 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 20:31:26.998049 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 20:31:27.002787 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 20:31:27.011260 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 20:31:27.018021 (MainThread): Parsing macros/core.sql
2020-10-20 20:31:27.024861 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 20:31:27.041948 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 20:31:27.051797 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 20:31:27.064151 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 20:31:27.091596 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 20:31:27.120292 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 20:31:27.125666 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 20:31:27.180460 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 20:31:27.191438 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 20:31:27.195755 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 20:31:27.208814 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 20:31:27.247460 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 20:31:27.331882 (MainThread): Parsing macros/etc/query.sql
2020-10-20 20:31:27.336038 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 20:31:27.340164 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 20:31:27.344419 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 20:31:27.360500 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 20:31:27.365387 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 20:31:27.368349 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 20:31:27.372505 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 20:31:27.376215 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 20:31:27.381811 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 20:31:27.395196 (MainThread): Partial parsing not enabled
2020-10-20 20:31:27.488910 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:31:27.518785 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:31:27.536695 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:31:27.555262 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:31:27.575536 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:31:27.605446 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 20:31:27.623293 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 20:31:27.640279 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 20:31:27.656650 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 20:31:27.673873 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 20:31:28.310934 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 20:31:28.312900 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:28.314436 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:28.582325 (MainThread): Found 5 models, 25 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 20:31:28.586631 (MainThread): 
2020-10-20 20:31:28.588809 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:31:28.598864 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-20 20:31:28.600699 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-20 20:31:28.602900 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:29.769625 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 20:31:29.771932 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-20 20:31:29.774264 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:30.345035 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 20:31:30.708291 (MainThread): 20:31:30 | Concurrency: 4 threads (target='dev')
2020-10-20 20:31:30.710707 (MainThread): 20:31:30 | 
2020-10-20 20:31:30.719864 (Thread-1): Began running node model.dwelo.fct_command_statuses
2020-10-20 20:31:30.720416 (Thread-2): Began running node model.dwelo.stg_command_actives
2020-10-20 20:31:30.721182 (Thread-3): Began running node model.dwelo.stg_command_results
2020-10-20 20:31:30.721441 (Thread-4): Began running node model.dwelo.stg_commands
2020-10-20 20:31:30.723495 (Thread-1): 20:31:30 | 1 of 5 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-20 20:31:30.726233 (Thread-2): 20:31:30 | 2 of 5 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-20 20:31:30.728493 (Thread-3): 20:31:30 | 3 of 5 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-20 20:31:30.731563 (Thread-4): 20:31:30 | 4 of 5 START view model dev_sam.stg_commands......................... [RUN]
2020-10-20 20:31:30.734379 (Thread-1): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:31:30.736697 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:31:30.739922 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:31:30.741544 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:31:30.743299 (Thread-1): Compiling model.dwelo.fct_command_statuses
2020-10-20 20:31:30.745100 (Thread-2): Compiling model.dwelo.stg_command_actives
2020-10-20 20:31:30.747308 (Thread-3): Compiling model.dwelo.stg_command_results
2020-10-20 20:31:30.749239 (Thread-4): Compiling model.dwelo.stg_commands
2020-10-20 20:31:30.837276 (Thread-3): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-20 20:31:30.853648 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-20 20:31:30.855903 (Thread-1): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 20:31:30.856619 (Thread-4): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-20 20:31:30.863743 (Thread-3): finished collecting timing info
2020-10-20 20:31:30.865397 (Thread-2): finished collecting timing info
2020-10-20 20:31:30.883713 (Thread-1): finished collecting timing info
2020-10-20 20:31:30.884690 (Thread-4): finished collecting timing info
2020-10-20 20:31:30.914302 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34092), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:30.946239 (Thread-1): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-20 20:31:30.953160 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-20 20:31:30.954624 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-20 20:31:30.956255 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43078), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:30.963270 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:30.975107 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-20 20:31:30.975524 (Thread-3): Opening a new connection, currently in state init
2020-10-20 20:31:30.976850 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:30.977438 (Thread-4): Opening a new connection, currently in state init
2020-10-20 20:31:30.981910 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:30.983657 (Thread-2): Opening a new connection, currently in state init
2020-10-20 20:31:30.989692 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:30.998707 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:31.640453 (Thread-4): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-20 20:31:31.642236 (Thread-1): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as with final as (
    select 1 as placeholder -- WRITE YOUR QUERY HERE
)

select *
from final;


2020-10-20 20:31:31.643045 (Thread-3): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-20 20:31:31.650472 (Thread-2): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-20 20:31:32.847087 (Thread-1): finished collecting timing info
2020-10-20 20:31:32.854727 (Thread-2): finished collecting timing info
2020-10-20 20:31:32.855790 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea5b4776-7d1b-405c-b063-fdb8e3920114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a83957c0>]}
2020-10-20 20:31:32.858772 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea5b4776-7d1b-405c-b063-fdb8e3920114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8395e80>]}
2020-10-20 20:31:32.863220 (Thread-1): 20:31:32 | 1 of 5 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 2.12s]
2020-10-20 20:31:32.867328 (Thread-2): 20:31:32 | 2 of 5 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 2.12s]
2020-10-20 20:31:32.869300 (Thread-1): Finished running node model.dwelo.fct_command_statuses
2020-10-20 20:31:32.877813 (Thread-3): finished collecting timing info
2020-10-20 20:31:32.879645 (Thread-2): Finished running node model.dwelo.stg_command_actives
2020-10-20 20:31:32.882359 (Thread-1): Began running node model.dwelo.stg_users
2020-10-20 20:31:32.886651 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea5b4776-7d1b-405c-b063-fdb8e3920114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a493eb80>]}
2020-10-20 20:31:32.893539 (Thread-1): 20:31:32 | 5 of 5 START view model dev_sam.stg_users............................ [RUN]
2020-10-20 20:31:32.896534 (Thread-3): 20:31:32 | 3 of 5 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 2.15s]
2020-10-20 20:31:32.898873 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:31:32.901303 (Thread-3): Finished running node model.dwelo.stg_command_results
2020-10-20 20:31:32.903162 (Thread-1): Compiling model.dwelo.stg_users
2020-10-20 20:31:32.926418 (Thread-1): Writing injected SQL for node "model.dwelo.stg_users"
2020-10-20 20:31:32.932757 (Thread-1): finished collecting timing info
2020-10-20 20:31:32.941241 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_users"
2020-10-20 20:31:32.946272 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:32.948437 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:33.160710 (Thread-4): finished collecting timing info
2020-10-20 20:31:33.165079 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea5b4776-7d1b-405c-b063-fdb8e3920114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a48a5f70>]}
2020-10-20 20:31:33.171288 (Thread-4): 20:31:33 | 4 of 5 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.42s]
2020-10-20 20:31:33.173709 (Thread-4): Finished running node model.dwelo.stg_commands
2020-10-20 20:31:33.537250 (Thread-1): On model.dwelo.stg_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
  OPTIONS()
  as with final as (
  select
    *
  from
    `analytics-interview`.`interview_source`.`raw_users`
)

select
  *
from
  final;


2020-10-20 20:31:34.493834 (Thread-1): finished collecting timing info
2020-10-20 20:31:34.497341 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ea5b4776-7d1b-405c-b063-fdb8e3920114', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a491bfd0>]}
2020-10-20 20:31:34.500846 (Thread-1): 20:31:34 | 5 of 5 OK created view model dev_sam.stg_users....................... [CREATE VIEW in 1.60s]
2020-10-20 20:31:34.502859 (Thread-1): Finished running node model.dwelo.stg_users
2020-10-20 20:31:34.507752 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:31:34.510224 (MainThread): 20:31:34 | 
2020-10-20 20:31:34.511901 (MainThread): 20:31:34 | Finished running 5 view models in 5.92s.
2020-10-20 20:31:34.513607 (MainThread): Connection 'master' was properly closed.
2020-10-20 20:31:34.515312 (MainThread): Connection 'model.dwelo.stg_users' was properly closed.
2020-10-20 20:31:34.517116 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-20 20:31:34.518785 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-20 20:31:34.520116 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-20 20:31:34.554192 (MainThread): 
2020-10-20 20:31:34.556019 (MainThread): Completed successfully
2020-10-20 20:31:34.557956 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-10-20 20:31:34.559960 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8419640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a83d9df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a83d9e20>]}
2020-10-20 20:31:34.562060 (MainThread): Flushing usage events
2020-10-20 20:31:45.442080 (MainThread): Running with dbt=0.18.0
2020-10-20 20:31:45.690165 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt/', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-20 20:31:45.696175 (MainThread): Tracking: tracking
2020-10-20 20:31:45.700026 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85528b3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8551b85fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8551b85f70>]}
2020-10-20 20:31:45.734257 (MainThread): Partial parsing not enabled
2020-10-20 20:31:45.738471 (MainThread): Parsing macros/etc.sql
2020-10-20 20:31:45.742582 (MainThread): Parsing macros/catalog.sql
2020-10-20 20:31:45.756405 (MainThread): Parsing macros/adapters.sql
2020-10-20 20:31:45.790990 (MainThread): Parsing macros/materializations/view.sql
2020-10-20 20:31:45.797313 (MainThread): Parsing macros/materializations/table.sql
2020-10-20 20:31:45.816033 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-20 20:31:45.839330 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-20 20:31:45.843731 (MainThread): Parsing macros/materializations/copy.sql
2020-10-20 20:31:45.852628 (MainThread): Parsing macros/materializations/seed.sql
2020-10-20 20:31:45.859997 (MainThread): Parsing macros/core.sql
2020-10-20 20:31:45.867290 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-20 20:31:45.884424 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-20 20:31:45.894289 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-20 20:31:45.911226 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-20 20:31:45.944439 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-20 20:31:45.977113 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-20 20:31:45.981719 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-20 20:31:46.042776 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-20 20:31:46.053717 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-20 20:31:46.024872 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-20 20:31:46.037869 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-20 20:31:46.079631 (MainThread): Parsing macros/adapters/common.sql
2020-10-20 20:31:46.165501 (MainThread): Parsing macros/etc/query.sql
2020-10-20 20:31:46.168483 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-20 20:31:46.172365 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-20 20:31:46.176286 (MainThread): Parsing macros/etc/datetime.sql
2020-10-20 20:31:46.193332 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-20 20:31:46.199151 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-20 20:31:46.202249 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-20 20:31:46.207163 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-20 20:31:46.211746 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-20 20:31:46.218906 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-20 20:31:46.233432 (MainThread): Partial parsing not enabled
2020-10-20 20:31:46.336669 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-20 20:31:46.365432 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-20 20:31:46.383871 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-20 20:31:46.402367 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-20 20:31:46.420050 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-20 20:31:46.449222 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 20:31:46.467162 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 20:31:46.483285 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 20:31:46.500342 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 20:31:46.517413 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 20:31:47.152185 (MainThread): WARNING: Found documentation for resource "dim_users" which was not found or is disabled
2020-10-20 20:31:47.154411 (MainThread): [WARNING]: Test 'test.dwelo.not_null_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:47.156314 (MainThread): [WARNING]: Test 'test.dwelo.unique_dim_users_user_id' (models/marts/core/schema.yml) depends on a node named 'dim_users' which was not found
2020-10-20 20:31:47.407875 (MainThread): Found 5 models, 25 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-20 20:31:47.412891 (MainThread): 
2020-10-20 20:31:47.415279 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:31:47.469148 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-20 20:31:47.471093 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-20 20:31:47.473445 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:48.039941 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-20 20:31:48.659456 (MainThread): 20:31:48 | Concurrency: 4 threads (target='dev')
2020-10-20 20:31:48.661638 (MainThread): 20:31:48 | 
2020-10-20 20:31:48.669830 (Thread-1): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-20 20:31:48.670178 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-20 20:31:48.670889 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-20 20:31:48.671230 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-20 20:31:48.672545 (Thread-1): 20:31:48 | 1 of 25 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-20 20:31:48.674494 (Thread-2): 20:31:48 | 2 of 25 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-20 20:31:48.676475 (Thread-3): 20:31:48 | 3 of 25 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-20 20:31:48.678268 (Thread-4): 20:31:48 | 4 of 25 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-20 20:31:48.680467 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-20 20:31:48.684130 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-20 20:31:48.687218 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-20 20:31:48.689209 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-20 20:31:48.691413 (Thread-1): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-20 20:31:48.693428 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-20 20:31:48.695471 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-20 20:31:48.697647 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-20 20:31:48.749184 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-20 20:31:48.773359 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-20 20:31:48.782155 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-20 20:31:48.783523 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-20 20:31:48.789999 (Thread-1): finished collecting timing info
2020-10-20 20:31:48.793126 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:48.795915 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:48.803625 (Thread-4): finished collecting timing info
2020-10-20 20:31:48.806618 (Thread-4): Opening a new connection, currently in state init
2020-10-20 20:31:48.805704 (Thread-2): finished collecting timing info
2020-10-20 20:31:48.812116 (Thread-2): Opening a new connection, currently in state init
2020-10-20 20:31:48.813902 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:48.810401 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:48.810753 (Thread-3): finished collecting timing info
2020-10-20 20:31:48.824510 (Thread-3): Opening a new connection, currently in state init
2020-10-20 20:31:48.826946 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:49.484976 (Thread-1): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-20 20:31:49.488590 (Thread-2): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-20 20:31:49.495635 (Thread-4): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-20 20:31:49.514604 (Thread-3): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-20 20:31:50.142870 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-20 20:31:50.509165 (Thread-1): finished collecting timing info
2020-10-20 20:31:50.512554 (Thread-1): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: 6dece9f8-4b58-416a-b1dc-3c78b44ad6c7)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-20 20:31:50.516948 (Thread-1): 20:31:50 | 1 of 25 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 1.84s]
2020-10-20 20:31:50.518649 (Thread-1): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-20 20:31:50.521198 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-20 20:31:50.523503 (Thread-1): 20:31:50 | 5 of 25 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-20 20:31:50.525562 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-20 20:31:50.527102 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-20 20:31:50.542795 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-20 20:31:50.550222 (Thread-1): finished collecting timing info
2020-10-20 20:31:50.552387 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:50.555137 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:51.136524 (Thread-1): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-20 20:31:51.252140 (Thread-3): finished collecting timing info
2020-10-20 20:31:51.255150 (Thread-3): 20:31:51 | 3 of 25 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.57s]
2020-10-20 20:31:51.257126 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-20 20:31:51.259525 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-20 20:31:51.261370 (Thread-3): 20:31:51 | 6 of 25 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-20 20:31:51.263222 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-20 20:31:51.264828 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-20 20:31:51.271262 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34122), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:51.272847 (Thread-3): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34128), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:51.274467 (Thread-3): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43120), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:51.277320 (Thread-3): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43118), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:51.289715 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-20 20:31:51.295960 (Thread-3): finished collecting timing info
2020-10-20 20:31:51.298079 (Thread-3): Opening a new connection, currently in state closed
2020-10-20 20:31:51.299941 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:51.432973 (Thread-4): finished collecting timing info
2020-10-20 20:31:51.437759 (Thread-4): 20:31:51 | 4 of 25 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.75s]
2020-10-20 20:31:51.440673 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-20 20:31:51.443146 (Thread-4): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-20 20:31:51.445287 (Thread-4): 20:31:51 | 7 of 25 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-20 20:31:51.448579 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-20 20:31:51.450724 (Thread-4): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-20 20:31:51.472567 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-20 20:31:51.476809 (Thread-2): finished collecting timing info
2020-10-20 20:31:51.479436 (Thread-2): 20:31:51 | 2 of 25 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.80s]
2020-10-20 20:31:51.481257 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-20 20:31:51.481760 (Thread-4): finished collecting timing info
2020-10-20 20:31:51.483497 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-20 20:31:51.485644 (Thread-4): Opening a new connection, currently in state closed
2020-10-20 20:31:51.487523 (Thread-2): 20:31:51 | 8 of 25 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-20 20:31:51.490779 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:51.493466 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-20 20:31:51.508365 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-20 20:31:51.537545 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-20 20:31:51.544438 (Thread-2): finished collecting timing info
2020-10-20 20:31:51.546470 (Thread-2): Opening a new connection, currently in state closed
2020-10-20 20:31:51.548783 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:51.935556 (Thread-3): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-20 20:31:52.106651 (Thread-4): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-20 20:31:52.197807 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-20 20:31:53.255066 (Thread-1): finished collecting timing info
2020-10-20 20:31:53.260416 (Thread-1): 20:31:53 | 5 of 25 PASS not_null_stg_command_results_is_hub_success............. [PASS in 2.73s]
2020-10-20 20:31:53.262767 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-20 20:31:53.265130 (Thread-1): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-20 20:31:53.267432 (Thread-1): 20:31:53 | 9 of 25 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-20 20:31:53.269587 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-20 20:31:53.271339 (Thread-1): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-20 20:31:53.288660 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-20 20:31:53.295484 (Thread-1): finished collecting timing info
2020-10-20 20:31:53.297326 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:53.299014 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:53.451010 (Thread-3): finished collecting timing info
2020-10-20 20:31:53.454338 (Thread-3): 20:31:53 | 6 of 25 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.19s]
2020-10-20 20:31:53.456511 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-20 20:31:53.458544 (Thread-3): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-20 20:31:53.460393 (Thread-3): 20:31:53 | 10 of 25 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-20 20:31:53.462750 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-20 20:31:53.464673 (Thread-3): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-20 20:31:53.480997 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-20 20:31:53.488319 (Thread-3): finished collecting timing info
2020-10-20 20:31:53.491965 (Thread-3): Opening a new connection, currently in state closed
2020-10-20 20:31:53.494845 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:53.875787 (Thread-4): finished collecting timing info
2020-10-20 20:31:53.881549 (Thread-4): 20:31:53 | 7 of 25 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.43s]
2020-10-20 20:31:53.888895 (Thread-4): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-20 20:31:53.891713 (Thread-1): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-20 20:31:53.892294 (Thread-4): Began running node test.dwelo.not_null_stg_users_date_registered
2020-10-20 20:31:53.898527 (Thread-4): 20:31:53 | 11 of 25 START test not_null_stg_users_date_registered............... [RUN]
2020-10-20 20:31:53.901432 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_date_registered".
2020-10-20 20:31:53.903973 (Thread-4): Compiling test.dwelo.not_null_stg_users_date_registered
2020-10-20 20:31:53.925076 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_users_date_registered"
2020-10-20 20:31:53.932981 (Thread-4): finished collecting timing info
2020-10-20 20:31:53.935497 (Thread-4): Opening a new connection, currently in state closed
2020-10-20 20:31:53.937840 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:54.101482 (Thread-3): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-20 20:31:54.154125 (Thread-2): finished collecting timing info
2020-10-20 20:31:54.157686 (Thread-2): 20:31:54 | 8 of 25 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.66s]
2020-10-20 20:31:54.159840 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-20 20:31:54.162089 (Thread-2): Began running node test.dwelo.not_null_stg_users_last_modified
2020-10-20 20:31:54.164321 (Thread-2): 20:31:54 | 12 of 25 START test not_null_stg_users_last_modified................. [RUN]
2020-10-20 20:31:54.168178 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_last_modified".
2020-10-20 20:31:54.169955 (Thread-2): Compiling test.dwelo.not_null_stg_users_last_modified
2020-10-20 20:31:54.191130 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_users_last_modified"
2020-10-20 20:31:54.199490 (Thread-2): finished collecting timing info
2020-10-20 20:31:54.203776 (Thread-2): Opening a new connection, currently in state closed
2020-10-20 20:31:54.205859 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:54.547884 (Thread-4): On test.dwelo.not_null_stg_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where date_registered is null



2020-10-20 20:31:54.797166 (Thread-2): On test.dwelo.not_null_stg_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where last_modified is null



2020-10-20 20:31:55.242603 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]')
2020-10-20 20:31:55.687525 (Thread-1): finished collecting timing info
2020-10-20 20:31:55.695581 (Thread-1): 20:31:55 | 9 of 25 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.43s]
2020-10-20 20:31:55.697898 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-20 20:31:55.700584 (Thread-1): Began running node test.dwelo.not_null_stg_users_user_id
2020-10-20 20:31:55.702888 (Thread-1): 20:31:55 | 13 of 25 START test not_null_stg_users_user_id....................... [RUN]
2020-10-20 20:31:55.704984 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_user_id".
2020-10-20 20:31:55.707212 (Thread-1): Compiling test.dwelo.not_null_stg_users_user_id
2020-10-20 20:31:55.715712 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43128), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:55.718556 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34146), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:55.720762 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34142), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:55.723405 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43134), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:55.725796 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43136), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:55.727660 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34148), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:55.730109 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34154), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:55.731556 (Thread-1): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43140), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:55.741898 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_user_id"
2020-10-20 20:31:55.748993 (Thread-1): finished collecting timing info
2020-10-20 20:31:55.750899 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:55.752606 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:55.957030 (Thread-3): finished collecting timing info
2020-10-20 20:31:55.960764 (Thread-3): 20:31:55 | 10 of 25 FAIL 101 not_null_stg_commands_user_id...................... [FAIL 101 in 2.50s]
2020-10-20 20:31:55.962962 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-20 20:31:55.966194 (Thread-3): Began running node test.dwelo.not_null_stg_users_username
2020-10-20 20:31:55.970321 (Thread-3): 20:31:55 | 14 of 25 START test not_null_stg_users_username...................... [RUN]
2020-10-20 20:31:55.972846 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_username".
2020-10-20 20:31:55.974619 (Thread-3): Compiling test.dwelo.not_null_stg_users_username
2020-10-20 20:31:56.024397 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34118), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:56.026708 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43104), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:56.033561 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43114), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:56.035627 (Thread-3): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43116), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:56.037345 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34138), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:56.039591 (Thread-3): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34124), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:56.041001 (Thread-3): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34126), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:56.049788 (Thread-3): unclosed <socket.socket fd=26, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43144), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:56.051560 (Thread-3): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43124), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:56.053484 (Thread-3): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34158), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:56.069074 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_username"
2020-10-20 20:31:56.077624 (Thread-3): finished collecting timing info
2020-10-20 20:31:56.080905 (Thread-3): Opening a new connection, currently in state closed
2020-10-20 20:31:56.083544 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:56.369417 (Thread-1): On test.dwelo.not_null_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where user_id is null



2020-10-20 20:31:56.472771 (Thread-2): finished collecting timing info
2020-10-20 20:31:56.477851 (Thread-2): 20:31:56 | 12 of 25 PASS not_null_stg_users_last_modified....................... [PASS in 2.31s]
2020-10-20 20:31:56.482602 (Thread-2): Finished running node test.dwelo.not_null_stg_users_last_modified
2020-10-20 20:31:56.484766 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-20 20:31:56.487169 (Thread-2): 20:31:56 | 15 of 25 START test stg_commands_locked_state........................ [RUN]
2020-10-20 20:31:56.489774 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-20 20:31:56.492020 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-20 20:31:56.521093 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-20 20:31:56.522146 (Thread-4): finished collecting timing info
2020-10-20 20:31:56.527632 (Thread-4): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]

(job ID: 53de8fef-dffa-470a-b2e5-72d05ef7f65d)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-20 20:31:56.530366 (Thread-4): 20:31:56 | 11 of 25 ERROR not_null_stg_users_date_registered.................... [ERROR in 2.63s]
2020-10-20 20:31:56.532098 (Thread-4): Finished running node test.dwelo.not_null_stg_users_date_registered
2020-10-20 20:31:56.534954 (Thread-4): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-20 20:31:56.535634 (Thread-2): finished collecting timing info
2020-10-20 20:31:56.538500 (Thread-4): 20:31:56 | 16 of 25 START test stg_commands_pin_assignment...................... [RUN]
2020-10-20 20:31:56.541441 (Thread-2): Opening a new connection, currently in state closed
2020-10-20 20:31:56.545471 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-20 20:31:56.549272 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:56.550770 (Thread-4): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-20 20:31:56.589049 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-20 20:31:56.596571 (Thread-4): finished collecting timing info
2020-10-20 20:31:56.599057 (Thread-4): Opening a new connection, currently in state closed
2020-10-20 20:31:56.601521 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:56.738075 (Thread-3): On test.dwelo.not_null_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where username is null



2020-10-20 20:31:57.001518 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-20 20:31:57.202633 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-20 20:31:57.203019 (Thread-4): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-20 20:31:57.743174 (Thread-1): finished collecting timing info
2020-10-20 20:31:57.746780 (Thread-1): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: ec1e4c05-6de3-4041-8b79-23e3301dadaa)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-20 20:31:57.749809 (Thread-1): 20:31:57 | 13 of 25 ERROR not_null_stg_users_user_id............................ [ERROR in 2.04s]
2020-10-20 20:31:57.756222 (Thread-1): Finished running node test.dwelo.not_null_stg_users_user_id
2020-10-20 20:31:57.758630 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-20 20:31:57.760162 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-20 20:31:57.764458 (Thread-1): 20:31:57 | 17 of 25 START test stg_commands_switch_state........................ [RUN]
2020-10-20 20:31:57.766240 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-20 20:31:57.768166 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-20 20:31:57.783880 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-20 20:31:57.784821 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-20 20:31:57.791398 (Thread-1): finished collecting timing info
2020-10-20 20:31:57.794494 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:57.796692 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:58.102112 (Thread-3): finished collecting timing info
2020-10-20 20:31:58.105885 (Thread-3): 20:31:58 | 14 of 25 PASS not_null_stg_users_username............................ [PASS in 2.13s]
2020-10-20 20:31:58.107700 (Thread-3): Finished running node test.dwelo.not_null_stg_users_username
2020-10-20 20:31:58.109650 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-20 20:31:58.111487 (Thread-3): 20:31:58 | 18 of 25 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-20 20:31:58.113360 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-20 20:31:58.115162 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-20 20:31:58.129647 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-20 20:31:58.136804 (Thread-3): finished collecting timing info
2020-10-20 20:31:58.139354 (Thread-3): Opening a new connection, currently in state closed
2020-10-20 20:31:58.141646 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:58.409435 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-20 20:31:58.470345 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43160), raddr=('172.217.14.74', 443)>
2020-10-20 20:31:58.473326 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34174), raddr=('172.217.11.74', 443)>
2020-10-20 20:31:58.737757 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-20 20:31:58.914790 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-20 20:31:59.029545 (Thread-2): finished collecting timing info
2020-10-20 20:31:59.032591 (Thread-2): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 8979ab70-487d-4dd1-b0b8-871052bfcaa3)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-20 20:31:59.035338 (Thread-2): 20:31:59 | 15 of 25 ERROR stg_commands_locked_state............................. [ERROR in 2.55s]
2020-10-20 20:31:59.037311 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-20 20:31:59.039613 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-20 20:31:59.041471 (Thread-2): 20:31:59 | 19 of 25 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-20 20:31:59.043782 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-20 20:31:59.046143 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-20 20:31:59.060570 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-20 20:31:59.066769 (Thread-2): finished collecting timing info
2020-10-20 20:31:59.068618 (Thread-2): Opening a new connection, currently in state closed
2020-10-20 20:31:59.070594 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:59.233349 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-20 20:31:59.242127 (Thread-4): finished collecting timing info
2020-10-20 20:31:59.245857 (Thread-4): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: ce71d211-5d04-4526-a0b4-4548749633ed)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-20 20:31:59.249155 (Thread-4): 20:31:59 | 16 of 25 ERROR stg_commands_pin_assignment........................... [ERROR in 2.70s]
2020-10-20 20:31:59.251356 (Thread-4): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-20 20:31:59.253685 (Thread-4): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-20 20:31:59.255883 (Thread-4): 20:31:59 | 20 of 25 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-20 20:31:59.258527 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-20 20:31:59.260780 (Thread-4): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-20 20:31:59.284325 (Thread-4): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-20 20:31:59.293640 (Thread-4): finished collecting timing info
2020-10-20 20:31:59.297241 (Thread-4): Opening a new connection, currently in state closed
2020-10-20 20:31:59.299864 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:59.510786 (Thread-1): finished collecting timing info
2020-10-20 20:31:59.513635 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: ff8a3707-da1e-47d2-a052-bb9d8883d3f7)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-20 20:31:59.515936 (Thread-1): 20:31:59 | 17 of 25 ERROR stg_commands_switch_state............................. [ERROR in 1.75s]
2020-10-20 20:31:59.518553 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-20 20:31:59.521094 (Thread-1): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-20 20:31:59.523434 (Thread-1): 20:31:59 | 21 of 25 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-20 20:31:59.526852 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-20 20:31:59.528881 (Thread-1): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-20 20:31:59.547555 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-20 20:31:59.555946 (Thread-1): finished collecting timing info
2020-10-20 20:31:59.558276 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:31:59.560435 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:31:59.707566 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-20 20:31:59.909594 (Thread-4): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-20 20:32:00.161263 (Thread-1): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-20 20:32:00.318330 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-20 20:32:00.341766 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [15:11]')
2020-10-20 20:32:00.487799 (Thread-3): finished collecting timing info
2020-10-20 20:32:00.491071 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 7cbc3fa2-2d62-4739-8969-abb669c9424f)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-20 20:32:00.493356 (Thread-3): 20:32:00 | 18 of 25 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.38s]
2020-10-20 20:32:00.494723 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-20 20:32:00.497218 (Thread-3): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-20 20:32:00.499253 (Thread-3): 20:32:00 | 22 of 25 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-20 20:32:00.501257 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-20 20:32:00.504768 (Thread-3): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-20 20:32:00.519891 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-20 20:32:00.526917 (Thread-3): finished collecting timing info
2020-10-20 20:32:00.529346 (Thread-3): Opening a new connection, currently in state closed
2020-10-20 20:32:00.532661 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:32:00.754170 (Thread-2): finished collecting timing info
2020-10-20 20:32:00.757510 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: b5a40ac7-4d1d-457f-b80b-ef8050916b4b)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-20 20:32:00.760359 (Thread-2): 20:32:00 | 19 of 25 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.72s]
2020-10-20 20:32:00.762564 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-20 20:32:00.765434 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-20 20:32:00.768740 (Thread-2): 20:32:00 | 23 of 25 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-20 20:32:00.772142 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-20 20:32:00.774831 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-20 20:32:00.791655 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-20 20:32:00.800994 (Thread-2): finished collecting timing info
2020-10-20 20:32:00.803449 (Thread-2): Opening a new connection, currently in state closed
2020-10-20 20:32:00.805436 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:32:01.128612 (Thread-3): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-20 20:32:01.389865 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-20 20:32:01.555296 (Thread-4): finished collecting timing info
2020-10-20 20:32:01.558206 (Thread-4): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [15:11]

(job ID: 7297d0bd-f106-44d6-8de3-1d001daac695)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-20 20:32:01.560814 (Thread-4): 20:32:01 | 20 of 25 ERROR unique_fct_command_statuses_command_uuid.............. [ERROR in 2.30s]
2020-10-20 20:32:01.562892 (Thread-4): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-20 20:32:01.564959 (Thread-4): Began running node test.dwelo.unique_stg_users_user_id
2020-10-20 20:32:01.566946 (Thread-4): 20:32:01 | 24 of 25 START test unique_stg_users_user_id......................... [RUN]
2020-10-20 20:32:01.568876 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_users_user_id".
2020-10-20 20:32:01.570764 (Thread-4): Compiling test.dwelo.unique_stg_users_user_id
2020-10-20 20:32:01.584703 (Thread-4): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43180), raddr=('172.217.14.74', 443)>
2020-10-20 20:32:01.593204 (Thread-4): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34194), raddr=('172.217.11.74', 443)>
2020-10-20 20:32:01.600602 (Thread-4): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 34198), raddr=('172.217.11.74', 443)>
2020-10-20 20:32:01.602691 (Thread-4): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.17.0.2', 43184), raddr=('172.217.14.74', 443)>
2020-10-20 20:32:01.610705 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_users_user_id"
2020-10-20 20:32:01.616545 (Thread-4): finished collecting timing info
2020-10-20 20:32:01.618596 (Thread-4): Opening a new connection, currently in state closed
2020-10-20 20:32:01.620631 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:32:01.977737 (Thread-1): finished collecting timing info
2020-10-20 20:32:01.980907 (Thread-1): 20:32:01 | 21 of 25 PASS unique_stg_command_actives_command_uuid................ [PASS in 2.45s]
2020-10-20 20:32:01.983072 (Thread-1): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-20 20:32:01.985290 (Thread-1): Began running node test.dwelo.unique_stg_users_username
2020-10-20 20:32:01.987390 (Thread-1): 20:32:01 | 25 of 25 START test unique_stg_users_username........................ [RUN]
2020-10-20 20:32:01.989412 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_users_username".
2020-10-20 20:32:01.991363 (Thread-1): Compiling test.dwelo.unique_stg_users_username
2020-10-20 20:32:02.008908 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_users_username"
2020-10-20 20:32:02.018549 (Thread-1): finished collecting timing info
2020-10-20 20:32:02.021348 (Thread-1): Opening a new connection, currently in state closed
2020-10-20 20:32:02.023533 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-20 20:32:02.222841 (Thread-4): On test.dwelo.unique_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`stg_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-20 20:32:02.618297 (Thread-1): On test.dwelo.unique_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`stg_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-20 20:32:02.773426 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-20 20:32:03.193689 (Thread-4): finished collecting timing info
2020-10-20 20:32:03.196854 (Thread-4): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: 1a883e70-97ed-4e63-87cf-f1932b82c358)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-20 20:32:03.199644 (Thread-4): 20:32:03 | 24 of 25 ERROR unique_stg_users_user_id.............................. [ERROR in 1.63s]
2020-10-20 20:32:03.201408 (Thread-4): Finished running node test.dwelo.unique_stg_users_user_id
2020-10-20 20:32:03.207606 (Thread-2): finished collecting timing info
2020-10-20 20:32:03.209914 (Thread-2): 20:32:03 | 23 of 25 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 2.44s]
2020-10-20 20:32:03.211347 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-20 20:32:03.304367 (Thread-3): finished collecting timing info
2020-10-20 20:32:03.307433 (Thread-3): 20:32:03 | 22 of 25 PASS unique_stg_command_results_command_uuid................ [PASS in 2.81s]
2020-10-20 20:32:03.309423 (Thread-3): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-20 20:32:04.129811 (Thread-1): finished collecting timing info
2020-10-20 20:32:04.133158 (Thread-1): 20:32:04 | 25 of 25 PASS unique_stg_users_username.............................. [PASS in 2.14s]
2020-10-20 20:32:04.135754 (Thread-1): Finished running node test.dwelo.unique_stg_users_username
2020-10-20 20:32:04.141320 (MainThread): Acquiring new bigquery connection "master".
2020-10-20 20:32:04.144156 (MainThread): 20:32:04 | 
2020-10-20 20:32:04.146595 (MainThread): 20:32:04 | Finished running 25 tests in 16.73s.
2020-10-20 20:32:04.148712 (MainThread): Connection 'master' was properly closed.
2020-10-20 20:32:04.150768 (MainThread): Connection 'test.dwelo.unique_stg_users_username' was properly closed.
2020-10-20 20:32:04.152552 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-20 20:32:04.154316 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-20 20:32:04.156526 (MainThread): Connection 'test.dwelo.unique_stg_users_user_id' was properly closed.
2020-10-20 20:32:04.264078 (MainThread): 
2020-10-20 20:32:04.265982 (MainThread): Completed with 12 errors and 0 warnings:
2020-10-20 20:32:04.267856 (MainThread): 
2020-10-20 20:32:04.269304 (MainThread): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
2020-10-20 20:32:04.270707 (MainThread):   Unrecognized name: command_uuid at [10:7]
2020-10-20 20:32:04.272676 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-20 20:32:04.274454 (MainThread): 
2020-10-20 20:32:04.276663 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-20 20:32:04.278935 (MainThread):   Got 101 results, expected 0.
2020-10-20 20:32:04.281162 (MainThread): 
2020-10-20 20:32:04.283561 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-20 20:32:04.286533 (MainThread): 
2020-10-20 20:32:04.288656 (MainThread): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
2020-10-20 20:32:04.290753 (MainThread):   Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
2020-10-20 20:32:04.292850 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-20 20:32:04.295365 (MainThread): 
2020-10-20 20:32:04.296993 (MainThread): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
2020-10-20 20:32:04.299655 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-20 20:32:04.301589 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-20 20:32:04.303910 (MainThread): 
2020-10-20 20:32:04.306380 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-20 20:32:04.308412 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-20 20:32:04.310286 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-20 20:32:04.312369 (MainThread): 
2020-10-20 20:32:04.314892 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-20 20:32:04.316704 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-20 20:32:04.319487 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-20 20:32:04.321118 (MainThread): 
2020-10-20 20:32:04.322825 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-20 20:32:04.324531 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-20 20:32:04.326610 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-20 20:32:04.328314 (MainThread): 
2020-10-20 20:32:04.331704 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-20 20:32:04.341327 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-20 20:32:04.343621 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-20 20:32:04.349950 (MainThread): 
2020-10-20 20:32:04.352281 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-20 20:32:04.355357 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-20 20:32:04.357521 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-20 20:32:04.359378 (MainThread): 
2020-10-20 20:32:04.361277 (MainThread): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/core/schema.yml)
2020-10-20 20:32:04.363296 (MainThread):   Unrecognized name: command_uuid at [15:11]
2020-10-20 20:32:04.365364 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/core/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-20 20:32:04.367343 (MainThread): 
2020-10-20 20:32:04.370366 (MainThread): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
2020-10-20 20:32:04.372174 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-20 20:32:04.374270 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-20 20:32:04.376343 (MainThread): 
2020-10-20 20:32:04.378966 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-20 20:32:04.381425 (MainThread):   Got 2 results, expected 0.
2020-10-20 20:32:04.383431 (MainThread): 
2020-10-20 20:32:04.386185 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-20 20:32:04.388255 (MainThread): 
Done. PASS=13 WARN=0 ERROR=12 SKIP=0 TOTAL=25
2020-10-20 20:32:04.390855 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f85504555b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8550446e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8551949b50>]}
2020-10-20 20:32:04.392940 (MainThread): Flushing usage events
2020-10-21 23:36:41.567414 (MainThread): Running with dbt=0.18.0
2020-10-21 23:36:41.840494 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 23:36:41.849333 (MainThread): Tracking: tracking
2020-10-21 23:36:41.852911 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe184034d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18330bbe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe18330bbb0>]}
2020-10-21 23:36:41.891026 (MainThread): Partial parsing not enabled
2020-10-21 23:36:41.895896 (MainThread): Parsing macros/etc.sql
2020-10-21 23:36:41.899564 (MainThread): Parsing macros/catalog.sql
2020-10-21 23:36:41.912815 (MainThread): Parsing macros/adapters.sql
2020-10-21 23:36:41.948758 (MainThread): Parsing macros/materializations/view.sql
2020-10-21 23:36:41.955447 (MainThread): Parsing macros/materializations/table.sql
2020-10-21 23:36:41.973385 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-21 23:36:41.995273 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-21 23:36:42.000578 (MainThread): Parsing macros/materializations/copy.sql
2020-10-21 23:36:42.008969 (MainThread): Parsing macros/materializations/seed.sql
2020-10-21 23:36:42.016091 (MainThread): Parsing macros/core.sql
2020-10-21 23:36:42.023239 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 23:36:42.040947 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 23:36:42.051057 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 23:36:42.063776 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 23:36:42.091102 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 23:36:42.120407 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 23:36:42.125966 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 23:36:42.180336 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 23:36:42.192179 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 23:36:42.196881 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 23:36:42.209158 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 23:36:42.248040 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 23:36:42.330689 (MainThread): Parsing macros/etc/query.sql
2020-10-21 23:36:42.335008 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 23:36:42.338800 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 23:36:42.343790 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 23:36:42.359506 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 23:36:42.364734 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 23:36:42.367901 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 23:36:42.371916 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 23:36:42.376036 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 23:36:42.381779 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 23:36:42.395319 (MainThread): Partial parsing not enabled
2020-10-21 23:36:42.501802 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-21 23:36:42.532920 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-21 23:36:42.549705 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-21 23:36:42.566520 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-21 23:36:42.587093 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-21 23:36:42.607940 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-21 23:36:42.628030 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-21 23:36:42.665797 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:36:42.688264 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:36:42.706668 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:36:42.725434 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:36:42.746209 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:36:43.798127 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-21 23:36:43.808371 (MainThread): 
2020-10-21 23:36:43.810694 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:36:43.896004 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_".
2020-10-21 23:36:43.898922 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 23:36:43.901882 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:36:44.536015 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-21 23:36:44.971273 (MainThread): Connection 'master' was properly closed.
2020-10-21 23:36:44.974774 (MainThread): Connection 'list_analytics-interview_' was properly closed.
2020-10-21 23:36:44.977413 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1831edac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe182f53fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe182f53a60>]}
2020-10-21 23:36:44.980808 (MainThread): Flushing usage events
2020-10-21 23:36:45.393971 (MainThread): Encountered an error:
2020-10-21 23:36:45.398594 (MainThread): 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets//tables?maxResults=100000: Invalid dataset ID "". Dataset IDs must be alphanumeric (plus underscores and dashes) and must be at most 1024 characters long.
2020-10-21 23:36:45.410023 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 124, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 202, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.8/site-packages/dbt/main.py", line 255, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 419, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 379, in execute_with_hooks
    self.before_run(adapter, selected_uids)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 395, in before_run
    self.populate_adapter_cache(adapter)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/runnable.py", line 359, in populate_adapter_cache
    adapter.set_relations_cache(self.manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 368, in set_relations_cache
    self._relations_cache_for_schemas(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 345, in _relations_cache_for_schemas
    for relation in future.result():
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 432, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 388, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/utils.py", line 469, in connected
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 277, in list_relations_without_caching
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/impl.py", line 277, in <listcomp>
    return [self._bq_table_to_relation(table) for table in all_tables]
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 212, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 243, in _page_iter
    page = self._next_page()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 369, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/page_iterator.py", line 418, in _get_next_page_response
    return self.api_request(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/datasets//tables?maxResults=100000: Invalid dataset ID "". Dataset IDs must be alphanumeric (plus underscores and dashes) and must be at most 1024 characters long.

2020-10-21 23:38:34.860633 (MainThread): Running with dbt=0.18.0
2020-10-21 23:38:35.111850 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 23:38:35.118860 (MainThread): Tracking: tracking
2020-10-21 23:38:35.122690 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cfa1c1e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cf9497c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cf9497c10>]}
2020-10-21 23:38:35.163164 (MainThread): Partial parsing not enabled
2020-10-21 23:38:35.166493 (MainThread): Parsing macros/etc.sql
2020-10-21 23:38:35.169798 (MainThread): Parsing macros/catalog.sql
2020-10-21 23:38:35.182785 (MainThread): Parsing macros/adapters.sql
2020-10-21 23:38:35.218875 (MainThread): Parsing macros/materializations/view.sql
2020-10-21 23:38:35.226816 (MainThread): Parsing macros/materializations/table.sql
2020-10-21 23:38:35.243441 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-21 23:38:35.265630 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-21 23:38:35.271618 (MainThread): Parsing macros/materializations/copy.sql
2020-10-21 23:38:35.280242 (MainThread): Parsing macros/materializations/seed.sql
2020-10-21 23:38:35.287506 (MainThread): Parsing macros/core.sql
2020-10-21 23:38:35.295497 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 23:38:35.312100 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 23:38:35.322150 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 23:38:35.334610 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 23:38:35.360669 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 23:38:35.388642 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 23:38:35.395690 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 23:38:35.448678 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 23:38:35.461031 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 23:38:35.465889 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 23:38:35.479431 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 23:38:35.516640 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 23:38:35.602189 (MainThread): Parsing macros/etc/query.sql
2020-10-21 23:38:35.608986 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 23:38:35.613716 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 23:38:35.617591 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 23:38:35.634530 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 23:38:35.639815 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 23:38:35.642862 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 23:38:35.647240 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 23:38:35.651419 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 23:38:35.656935 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 23:38:35.670861 (MainThread): Partial parsing not enabled
2020-10-21 23:38:35.778063 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-21 23:38:35.808897 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-21 23:38:35.825516 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-21 23:38:35.841433 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-21 23:38:35.860663 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-21 23:38:35.881820 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-21 23:38:35.901828 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-21 23:38:35.938551 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:38:35.957641 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:38:35.976862 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:38:35.995023 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:38:36.014175 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:38:37.060383 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-21 23:38:37.066989 (MainThread): 
2020-10-21 23:38:37.069005 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:38:37.135987 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-21 23:38:37.138763 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 23:38:37.141535 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:37.749049 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-21 23:38:38.207538 (MainThread): 23:38:38 | Concurrency: 4 threads (target='dev')
2020-10-21 23:38:38.209876 (MainThread): 23:38:38 | 
2020-10-21 23:38:38.235033 (Thread-1): Began running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:38:38.235450 (Thread-2): Began running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:38:38.236293 (Thread-3): Began running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:38:38.236688 (Thread-4): Began running node test.dwelo.not_null_dim_users_username
2020-10-21 23:38:38.237828 (Thread-1): 23:38:38 | 1 of 35 START test not_null_dim_users_date_registered................ [RUN]
2020-10-21 23:38:38.239973 (Thread-2): 23:38:38 | 2 of 35 START test not_null_dim_users_last_modified.................. [RUN]
2020-10-21 23:38:38.242244 (Thread-3): 23:38:38 | 3 of 35 START test not_null_dim_users_user_id........................ [RUN]
2020-10-21 23:38:38.243800 (Thread-4): 23:38:38 | 4 of 35 START test not_null_dim_users_username....................... [RUN]
2020-10-21 23:38:38.245965 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_date_registered".
2020-10-21 23:38:38.250966 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_last_modified".
2020-10-21 23:38:38.254187 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_user_id".
2020-10-21 23:38:38.255894 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_username".
2020-10-21 23:38:38.258016 (Thread-1): Compiling test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:38:38.259810 (Thread-2): Compiling test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:38:38.261785 (Thread-3): Compiling test.dwelo.not_null_dim_users_user_id
2020-10-21 23:38:38.263970 (Thread-4): Compiling test.dwelo.not_null_dim_users_username
2020-10-21 23:38:38.320595 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_dim_users_date_registered"
2020-10-21 23:38:38.329619 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_dim_users_last_modified"
2020-10-21 23:38:38.331051 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_dim_users_user_id"
2020-10-21 23:38:38.342630 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_dim_users_username"
2020-10-21 23:38:38.375828 (Thread-3): finished collecting timing info
2020-10-21 23:38:38.379278 (Thread-3): Opening a new connection, currently in state init
2020-10-21 23:38:38.379679 (Thread-2): finished collecting timing info
2020-10-21 23:38:38.382465 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:38.382807 (Thread-1): finished collecting timing info
2020-10-21 23:38:38.383474 (Thread-2): Opening a new connection, currently in state init
2020-10-21 23:38:38.384610 (Thread-4): finished collecting timing info
2020-10-21 23:38:38.390050 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:38.392591 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:38.394459 (Thread-4): Opening a new connection, currently in state init
2020-10-21 23:38:38.396826 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:38.403057 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:39.062049 (Thread-3): On test.dwelo.not_null_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:38:39.089726 (Thread-4): On test.dwelo.not_null_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:38:39.102912 (Thread-1): On test.dwelo.not_null_dim_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:38:39.125960 (Thread-2): On test.dwelo.not_null_dim_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:38:39.129864 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55904), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:39.131947 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51700), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:39.634091 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:38:39.636456 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:38:39.638226 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 1d5e505a-fee4-468d-a6a9-b2df7f50c2ff)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:39.640679 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: ff5f4b76-d2f7-4c30-810e-ebc3666f92eb)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:39.643046 (Thread-3): finished collecting timing info
2020-10-21 23:38:39.645774 (Thread-4): finished collecting timing info
2020-10-21 23:38:39.651635 (Thread-4): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: ff5f4b76-d2f7-4c30-810e-ebc3666f92eb)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: ff5f4b76-d2f7-4c30-810e-ebc3666f92eb)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: ff5f4b76-d2f7-4c30-810e-ebc3666f92eb)
2020-10-21 23:38:39.648488 (Thread-3): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 1d5e505a-fee4-468d-a6a9-b2df7f50c2ff)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 1d5e505a-fee4-468d-a6a9-b2df7f50c2ff)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 1d5e505a-fee4-468d-a6a9-b2df7f50c2ff)
2020-10-21 23:38:39.657678 (Thread-4): 23:38:39 | 4 of 35 ERROR not_null_dim_users_username............................ [ERROR in 1.40s]
2020-10-21 23:38:39.659449 (Thread-3): 23:38:39 | 3 of 35 ERROR not_null_dim_users_user_id............................. [ERROR in 1.41s]
2020-10-21 23:38:39.661017 (Thread-4): Finished running node test.dwelo.not_null_dim_users_username
2020-10-21 23:38:39.663488 (Thread-3): Finished running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:38:39.665531 (Thread-4): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:38:39.667805 (Thread-3): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:38:39.669300 (Thread-4): 23:38:39 | 5 of 35 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-21 23:38:39.670540 (Thread-3): 23:38:39 | 6 of 35 START test not_null_met_daily_command_count_by_user_id_num_of_commands [RUN]
2020-10-21 23:38:39.672388 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-21 23:38:39.674348 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands".
2020-10-21 23:38:39.676459 (Thread-4): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:38:39.678697 (Thread-3): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:38:39.695574 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-21 23:38:39.714325 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"
2020-10-21 23:38:39.716512 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:38:39.717055 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:38:39.722708 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: f30b5ce3-7c3c-4cc3-9815-7c0a84a988d5)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:39.725347 (Thread-4): finished collecting timing info
2020-10-21 23:38:39.727504 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 90a2daeb-a636-43cf-8c57-96c8e06653a1)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:39.728183 (Thread-3): finished collecting timing info
2020-10-21 23:38:39.730817 (Thread-1): finished collecting timing info
2020-10-21 23:38:39.733917 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:39.736435 (Thread-2): finished collecting timing info
2020-10-21 23:38:39.739021 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:39.741847 (Thread-1): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: f30b5ce3-7c3c-4cc3-9815-7c0a84a988d5)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: f30b5ce3-7c3c-4cc3-9815-7c0a84a988d5)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: f30b5ce3-7c3c-4cc3-9815-7c0a84a988d5)
2020-10-21 23:38:39.744229 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:39.745957 (Thread-2): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 90a2daeb-a636-43cf-8c57-96c8e06653a1)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 90a2daeb-a636-43cf-8c57-96c8e06653a1)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 90a2daeb-a636-43cf-8c57-96c8e06653a1)
2020-10-21 23:38:39.748594 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:39.749427 (Thread-1): 23:38:39 | 1 of 35 ERROR not_null_dim_users_date_registered..................... [ERROR in 1.50s]
2020-10-21 23:38:39.755967 (Thread-2): 23:38:39 | 2 of 35 ERROR not_null_dim_users_last_modified....................... [ERROR in 1.51s]
2020-10-21 23:38:39.764442 (Thread-1): Finished running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:38:39.769567 (Thread-2): Finished running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:38:39.770187 (Thread-1): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:38:39.773746 (Thread-2): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:39.776010 (Thread-1): 23:38:39 | 7 of 35 START test not_null_met_daily_command_count_by_user_id_timestamp_date [RUN]
2020-10-21 23:38:39.778442 (Thread-2): 23:38:39 | 8 of 35 START test not_null_met_daily_command_count_by_user_id_user_id [RUN]
2020-10-21 23:38:39.784257 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date".
2020-10-21 23:38:39.787324 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id".
2020-10-21 23:38:39.790397 (Thread-1): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:38:39.792789 (Thread-2): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:39.858030 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"
2020-10-21 23:38:39.861971 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"
2020-10-21 23:38:39.871486 (Thread-1): finished collecting timing info
2020-10-21 23:38:39.874012 (Thread-2): finished collecting timing info
2020-10-21 23:38:39.874966 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:39.877204 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:39.880534 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:39.884080 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:40.428987 (Thread-4): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-21 23:38:40.431689 (Thread-3): On test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:38:40.526511 (Thread-2): On test.dwelo.not_null_met_daily_command_count_by_user_id_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:38:40.536053 (Thread-1): On test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:38:40.869386 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-21 23:38:40.895067 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:38:40.899501 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 284df824-3eb6-4417-8c79-930651522905)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:40.902813 (Thread-3): finished collecting timing info
2020-10-21 23:38:40.905882 (Thread-3): Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 284df824-3eb6-4417-8c79-930651522905)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 284df824-3eb6-4417-8c79-930651522905)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 284df824-3eb6-4417-8c79-930651522905)
2020-10-21 23:38:40.908266 (Thread-3): 23:38:40 | 6 of 35 ERROR not_null_met_daily_command_count_by_user_id_num_of_commands [ERROR in 1.23s]
2020-10-21 23:38:40.909935 (Thread-3): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:38:40.912297 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:38:40.914330 (Thread-3): 23:38:40 | 9 of 35 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-21 23:38:40.916465 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-21 23:38:40.918451 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:38:40.932172 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-21 23:38:40.941799 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:38:40.943711 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 2604ea03-7e3e-41e3-8d98-21e8b084acd6)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:40.943999 (Thread-3): finished collecting timing info
2020-10-21 23:38:40.945769 (Thread-2): finished collecting timing info
2020-10-21 23:38:40.947703 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:40.949951 (Thread-2): Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 2604ea03-7e3e-41e3-8d98-21e8b084acd6)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 2604ea03-7e3e-41e3-8d98-21e8b084acd6)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 2604ea03-7e3e-41e3-8d98-21e8b084acd6)
2020-10-21 23:38:40.952859 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:40.954670 (Thread-2): 23:38:40 | 8 of 35 ERROR not_null_met_daily_command_count_by_user_id_user_id.... [ERROR in 1.17s]
2020-10-21 23:38:40.965981 (Thread-2): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:40.969312 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:38:40.972245 (Thread-2): 23:38:40 | 10 of 35 START test not_null_stg_command_actives_update_timestamp.... [RUN]
2020-10-21 23:38:40.975213 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-21 23:38:40.977645 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:38:41.005716 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:38:41.007996 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-21 23:38:41.011203 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 1065625e-73c0-4f8c-8d86-bdba9b7ea16f)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:41.018302 (Thread-1): finished collecting timing info
2020-10-21 23:38:41.022396 (Thread-2): finished collecting timing info
2020-10-21 23:38:41.021474 (Thread-1): Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 1065625e-73c0-4f8c-8d86-bdba9b7ea16f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 1065625e-73c0-4f8c-8d86-bdba9b7ea16f)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 1065625e-73c0-4f8c-8d86-bdba9b7ea16f)
2020-10-21 23:38:41.027955 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:41.032315 (Thread-1): 23:38:41 | 7 of 35 ERROR not_null_met_daily_command_count_by_user_id_timestamp_date [ERROR in 1.25s]
2020-10-21 23:38:41.038234 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:41.043284 (Thread-1): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:38:41.058606 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:38:41.063698 (Thread-1): 23:38:41 | 11 of 35 START test not_null_stg_command_results_command_uuid........ [RUN]
2020-10-21 23:38:41.068388 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-21 23:38:41.071029 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:38:41.096436 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-21 23:38:41.106740 (Thread-1): finished collecting timing info
2020-10-21 23:38:41.111300 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:41.115745 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:41.663764 (Thread-3): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-21 23:38:41.699335 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-21 23:38:41.726390 (Thread-1): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-21 23:38:41.860989 (Thread-3): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51724), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:41.864202 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51726), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:41.866494 (Thread-3): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55932), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:41.868809 (Thread-3): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51722), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:41.871021 (Thread-3): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55934), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:41.873034 (Thread-3): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55936), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.195693 (Thread-4): finished collecting timing info
2020-10-21 23:38:42.200105 (Thread-4): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: 78e14ba8-4c15-4e10-84e5-c05db99723a5)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-21 23:38:42.203704 (Thread-4): 23:38:42 | 5 of 35 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 2.53s]
2020-10-21 23:38:42.206461 (Thread-4): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:38:42.209710 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:38:42.212392 (Thread-4): 23:38:42 | 12 of 35 START test not_null_stg_command_results_is_hub_success...... [RUN]
2020-10-21 23:38:42.214599 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-21 23:38:42.216667 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:38:42.277013 (Thread-4): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51704), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:42.280970 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51706), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:42.284448 (Thread-4): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51708), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:42.295239 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51710), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:42.298748 (Thread-4): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55914), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.302971 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55916), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.315651 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55918), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.320729 (Thread-4): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55920), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.323871 (Thread-4): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55930), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:42.327222 (Thread-4): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51720), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:42.346040 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-21 23:38:42.357965 (Thread-4): finished collecting timing info
2020-10-21 23:38:42.361964 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:42.365101 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:42.955130 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-21 23:38:43.187698 (Thread-2): finished collecting timing info
2020-10-21 23:38:43.193583 (Thread-2): 23:38:43 | 10 of 35 PASS not_null_stg_command_actives_update_timestamp.......... [PASS in 2.22s]
2020-10-21 23:38:43.195995 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:38:43.198742 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:38:43.201437 (Thread-2): 23:38:43 | 13 of 35 START test not_null_stg_command_results_update_timestamp.... [RUN]
2020-10-21 23:38:43.203703 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-21 23:38:43.205730 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:38:43.224024 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-21 23:38:43.231689 (Thread-2): finished collecting timing info
2020-10-21 23:38:43.234648 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:43.236764 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:43.565183 (Thread-1): finished collecting timing info
2020-10-21 23:38:43.571079 (Thread-1): 23:38:43 | 11 of 35 PASS not_null_stg_command_results_command_uuid.............. [PASS in 2.50s]
2020-10-21 23:38:43.573970 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:38:43.576914 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:38:43.579670 (Thread-1): 23:38:43 | 14 of 35 START test not_null_stg_commands__raw_desired_state......... [RUN]
2020-10-21 23:38:43.583043 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-21 23:38:43.585596 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:38:43.607010 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-21 23:38:43.617637 (Thread-3): finished collecting timing info
2020-10-21 23:38:43.618415 (Thread-1): finished collecting timing info
2020-10-21 23:38:43.621906 (Thread-3): 23:38:43 | 9 of 35 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.71s]
2020-10-21 23:38:43.624372 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:43.626613 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:38:43.631262 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:43.633381 (Thread-3): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:38:43.646907 (Thread-3): 23:38:43 | 15 of 35 START test not_null_stg_commands_command_uuid............... [RUN]
2020-10-21 23:38:43.651356 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-21 23:38:43.654608 (Thread-3): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:38:43.680152 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-21 23:38:43.687569 (Thread-3): finished collecting timing info
2020-10-21 23:38:43.690111 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:43.692774 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:43.901913 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-21 23:38:44.278744 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-21 23:38:44.301960 (Thread-3): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-21 23:38:44.598612 (Thread-4): finished collecting timing info
2020-10-21 23:38:44.605070 (Thread-4): 23:38:44 | 12 of 35 PASS not_null_stg_command_results_is_hub_success............ [PASS in 2.39s]
2020-10-21 23:38:44.608055 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:38:44.611799 (Thread-4): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:38:44.614562 (Thread-4): 23:38:44 | 16 of 35 START test not_null_stg_commands_update_timestamp........... [RUN]
2020-10-21 23:38:44.616976 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-21 23:38:44.619255 (Thread-4): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:38:44.638300 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-21 23:38:44.646772 (Thread-4): finished collecting timing info
2020-10-21 23:38:44.648709 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:44.650721 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:45.249580 (Thread-4): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-21 23:38:45.310497 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51748), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:45.313723 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55952), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:45.689629 (Thread-2): finished collecting timing info
2020-10-21 23:38:45.694589 (Thread-2): 23:38:45 | 13 of 35 PASS not_null_stg_command_results_update_timestamp.......... [PASS in 2.49s]
2020-10-21 23:38:45.697253 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:38:45.699709 (Thread-2): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:38:45.703293 (Thread-2): 23:38:45 | 17 of 35 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-21 23:38:45.706052 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-21 23:38:45.708041 (Thread-2): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:38:45.725639 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-21 23:38:45.731608 (Thread-2): finished collecting timing info
2020-10-21 23:38:45.734228 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:45.736599 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:45.962360 (Thread-1): finished collecting timing info
2020-10-21 23:38:45.965236 (Thread-1): 23:38:45 | 14 of 35 PASS not_null_stg_commands__raw_desired_state............... [PASS in 2.38s]
2020-10-21 23:38:45.967213 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:38:45.969498 (Thread-1): Began running node test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:38:45.971862 (Thread-1): 23:38:45 | 18 of 35 START test not_null_stg_users_date_registered............... [RUN]
2020-10-21 23:38:45.974239 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_date_registered".
2020-10-21 23:38:45.976307 (Thread-1): Compiling test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:38:45.992927 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_date_registered"
2020-10-21 23:38:46.000374 (Thread-1): finished collecting timing info
2020-10-21 23:38:46.003937 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:46.006629 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:46.155787 (Thread-3): finished collecting timing info
2020-10-21 23:38:46.158753 (Thread-3): 23:38:46 | 15 of 35 PASS not_null_stg_commands_command_uuid..................... [PASS in 2.51s]
2020-10-21 23:38:46.160608 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:38:46.162715 (Thread-3): Began running node test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:38:46.164578 (Thread-3): 23:38:46 | 19 of 35 START test not_null_stg_users_last_modified................. [RUN]
2020-10-21 23:38:46.166667 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_last_modified".
2020-10-21 23:38:46.169271 (Thread-3): Compiling test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:38:46.185878 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_last_modified"
2020-10-21 23:38:46.193521 (Thread-3): finished collecting timing info
2020-10-21 23:38:46.196313 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:46.198569 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:46.373111 (Thread-2): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-21 23:38:46.590904 (Thread-1): On test.dwelo.not_null_stg_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where date_registered is null



2020-10-21 23:38:46.689246 (Thread-4): finished collecting timing info
2020-10-21 23:38:46.693238 (Thread-4): 23:38:46 | 16 of 35 PASS not_null_stg_commands_update_timestamp................. [PASS in 2.08s]
2020-10-21 23:38:46.695810 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:38:46.697888 (Thread-4): Began running node test.dwelo.not_null_stg_users_user_id
2020-10-21 23:38:46.699713 (Thread-4): 23:38:46 | 20 of 35 START test not_null_stg_users_user_id....................... [RUN]
2020-10-21 23:38:46.702373 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_user_id".
2020-10-21 23:38:46.704364 (Thread-4): Compiling test.dwelo.not_null_stg_users_user_id
2020-10-21 23:38:46.732716 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_users_user_id"
2020-10-21 23:38:46.742146 (Thread-4): finished collecting timing info
2020-10-21 23:38:46.758156 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:46.761511 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:46.804719 (Thread-3): On test.dwelo.not_null_stg_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where last_modified is null



2020-10-21 23:38:47.028109 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]')
2020-10-21 23:38:47.341034 (Thread-4): On test.dwelo.not_null_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where user_id is null



2020-10-21 23:38:47.534943 (Thread-1): finished collecting timing info
2020-10-21 23:38:47.539918 (Thread-1): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]

(job ID: 689fd2eb-0d95-49d8-8c21-8880df9e049a)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-21 23:38:47.546922 (Thread-1): 23:38:47 | 18 of 35 ERROR not_null_stg_users_date_registered.................... [ERROR in 1.57s]
2020-10-21 23:38:47.549455 (Thread-1): Finished running node test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:38:47.552255 (Thread-1): Began running node test.dwelo.not_null_stg_users_username
2020-10-21 23:38:47.555430 (Thread-1): 23:38:47 | 21 of 35 START test not_null_stg_users_username...................... [RUN]
2020-10-21 23:38:47.558459 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_username".
2020-10-21 23:38:47.560311 (Thread-1): Compiling test.dwelo.not_null_stg_users_username
2020-10-21 23:38:47.573878 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_username"
2020-10-21 23:38:47.583370 (Thread-1): finished collecting timing info
2020-10-21 23:38:47.585957 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:47.588156 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:47.897162 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-21 23:38:48.029310 (Thread-2): finished collecting timing info
2020-10-21 23:38:48.033058 (Thread-2): 23:38:48 | 17 of 35 FAIL 101 not_null_stg_commands_user_id...................... [FAIL 101 in 2.33s]
2020-10-21 23:38:48.035479 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:38:48.037817 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-21 23:38:48.039555 (Thread-2): 23:38:48 | 22 of 35 START test stg_commands_locked_state........................ [RUN]
2020-10-21 23:38:48.045057 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:38:48.047290 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-21 23:38:48.071576 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-21 23:38:48.087682 (Thread-2): finished collecting timing info
2020-10-21 23:38:48.090674 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:48.093820 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:48.194549 (Thread-1): On test.dwelo.not_null_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where username is null



2020-10-21 23:38:48.246060 (Thread-3): finished collecting timing info
2020-10-21 23:38:48.249267 (Thread-3): 23:38:48 | 19 of 35 PASS not_null_stg_users_last_modified....................... [PASS in 2.08s]
2020-10-21 23:38:48.251362 (Thread-3): Finished running node test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:38:48.253392 (Thread-3): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-21 23:38:48.255520 (Thread-3): 23:38:48 | 23 of 35 START test stg_commands_pin_assignment...................... [RUN]
2020-10-21 23:38:48.258006 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:38:48.260641 (Thread-3): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-21 23:38:48.269500 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51768), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:48.271466 (Thread-3): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51772), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:48.273554 (Thread-3): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55972), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:48.283584 (Thread-3): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55976), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:48.286345 (Thread-3): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55980), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:48.292758 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51776), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:48.306369 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-21 23:38:48.313871 (Thread-3): finished collecting timing info
2020-10-21 23:38:48.316559 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:48.318726 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:48.744941 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:38:48.906688 (Thread-3): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:38:49.163965 (Thread-4): finished collecting timing info
2020-10-21 23:38:49.166910 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-21 23:38:49.168993 (Thread-4): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: aad842b7-cfb3-4ecd-b654-b30afb21d3e6)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-21 23:38:49.175327 (Thread-4): 23:38:49 | 20 of 35 ERROR not_null_stg_users_user_id............................ [ERROR in 2.47s]
2020-10-21 23:38:49.177803 (Thread-4): Finished running node test.dwelo.not_null_stg_users_user_id
2020-10-21 23:38:49.179884 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-21 23:38:49.182489 (Thread-4): 23:38:49 | 24 of 35 START test stg_commands_switch_state........................ [RUN]
2020-10-21 23:38:49.184314 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:38:49.185990 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-21 23:38:49.202873 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-21 23:38:49.210701 (Thread-4): finished collecting timing info
2020-10-21 23:38:49.212978 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:49.214889 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:49.383875 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-21 23:38:49.758632 (Thread-1): finished collecting timing info
2020-10-21 23:38:49.762083 (Thread-1): 23:38:49 | 21 of 35 PASS not_null_stg_users_username............................ [PASS in 2.20s]
2020-10-21 23:38:49.765275 (Thread-1): Finished running node test.dwelo.not_null_stg_users_username
2020-10-21 23:38:49.767680 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:38:49.770305 (Thread-1): 23:38:49 | 25 of 35 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-21 23:38:49.773820 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:38:49.776026 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:38:49.797021 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-21 23:38:49.805472 (Thread-1): finished collecting timing info
2020-10-21 23:38:49.808776 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:49.811697 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:49.838625 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:38:50.271342 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-21 23:38:50.397840 (Thread-1): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:38:50.419047 (Thread-2): finished collecting timing info
2020-10-21 23:38:50.421952 (Thread-2): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 24d28406-ec6c-400c-8df0-e2c1e758294f)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-21 23:38:50.425807 (Thread-2): 23:38:50 | 22 of 35 ERROR stg_commands_locked_state............................. [ERROR in 2.38s]
2020-10-21 23:38:50.431003 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-21 23:38:50.433251 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:38:50.435285 (Thread-2): 23:38:50 | 26 of 35 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-21 23:38:50.436972 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:38:50.438578 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:38:50.453067 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-21 23:38:50.459916 (Thread-2): finished collecting timing info
2020-10-21 23:38:50.462644 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:50.464932 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:50.630781 (Thread-3): finished collecting timing info
2020-10-21 23:38:50.634284 (Thread-3): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: 2e8ac012-1c69-4d54-b933-ffe19b5ca969)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-21 23:38:50.636602 (Thread-3): 23:38:50 | 23 of 35 ERROR stg_commands_pin_assignment........................... [ERROR in 2.38s]
2020-10-21 23:38:50.638700 (Thread-3): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-21 23:38:50.640493 (Thread-3): Began running node test.dwelo.unique_dim_users_user_id
2020-10-21 23:38:50.642024 (Thread-3): 23:38:50 | 27 of 35 START test unique_dim_users_user_id......................... [RUN]
2020-10-21 23:38:50.644579 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_dim_users_user_id".
2020-10-21 23:38:50.646444 (Thread-3): Compiling test.dwelo.unique_dim_users_user_id
2020-10-21 23:38:50.662153 (Thread-3): Writing injected SQL for node "test.dwelo.unique_dim_users_user_id"
2020-10-21 23:38:50.669056 (Thread-3): finished collecting timing info
2020-10-21 23:38:50.671355 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:50.675835 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:50.882644 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-21 23:38:51.086591 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:38:51.277822 (Thread-3): On test.dwelo.unique_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`dim_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:38:51.523683 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-21 23:38:51.540485 (Thread-4): finished collecting timing info
2020-10-21 23:38:51.566561 (Thread-4): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: df64868d-b367-4c79-8b73-8e64e26615ab)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-21 23:38:51.569617 (Thread-4): 23:38:51 | 24 of 35 ERROR stg_commands_switch_state............................. [ERROR in 2.39s]
2020-10-21 23:38:51.571661 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-21 23:38:51.574749 (Thread-4): Began running node test.dwelo.unique_dim_users_username
2020-10-21 23:38:51.577922 (Thread-4): 23:38:51 | 28 of 35 START test unique_dim_users_username........................ [RUN]
2020-10-21 23:38:51.580794 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_dim_users_username".
2020-10-21 23:38:51.584026 (Thread-4): Compiling test.dwelo.unique_dim_users_username
2020-10-21 23:38:51.606875 (Thread-4): Writing injected SQL for node "test.dwelo.unique_dim_users_username"
2020-10-21 23:38:51.615968 (Thread-4): finished collecting timing info
2020-10-21 23:38:51.619881 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:51.622870 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:51.676276 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`dim_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:38:51.678378 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 14a068db-51df-4a9d-b735-3c7b6c51b15a)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:51.709397 (Thread-3): finished collecting timing info
2020-10-21 23:38:51.712241 (Thread-3): Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 14a068db-51df-4a9d-b735-3c7b6c51b15a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 14a068db-51df-4a9d-b735-3c7b6c51b15a)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 14a068db-51df-4a9d-b735-3c7b6c51b15a)
2020-10-21 23:38:51.714674 (Thread-3): 23:38:51 | 27 of 35 ERROR unique_dim_users_user_id.............................. [ERROR in 1.07s]
2020-10-21 23:38:51.716719 (Thread-3): Finished running node test.dwelo.unique_dim_users_user_id
2020-10-21 23:38:51.718422 (Thread-3): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:38:51.719937 (Thread-3): 23:38:51 | 29 of 35 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-21 23:38:51.721905 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-21 23:38:51.723600 (Thread-3): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:38:51.739628 (Thread-3): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-21 23:38:51.749369 (Thread-3): finished collecting timing info
2020-10-21 23:38:51.751774 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:51.753875 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:52.157579 (Thread-1): finished collecting timing info
2020-10-21 23:38:52.160599 (Thread-1): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 60bdbe69-5c4a-4bfc-94f5-4e076ef380f4)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-21 23:38:52.163224 (Thread-1): 23:38:52 | 25 of 35 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.39s]
2020-10-21 23:38:52.164883 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:38:52.167156 (Thread-1): Began running node test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:52.169388 (Thread-1): 23:38:52 | 30 of 35 START test unique_met_daily_command_count_by_user_id_user_id [RUN]
2020-10-21 23:38:52.172025 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_met_daily_command_count_by_user_id_user_id".
2020-10-21 23:38:52.173651 (Thread-1): Compiling test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:52.180290 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55996), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:52.182407 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51792), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:52.186195 (Thread-1): unclosed <socket.socket fd=30, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51800), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:52.189011 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51796), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:52.192207 (Thread-1): unclosed <socket.socket fd=31, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56000), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:52.195306 (Thread-1): unclosed <socket.socket fd=33, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56004), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:52.197608 (Thread-1): unclosed <socket.socket fd=36, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56012), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:52.201797 (Thread-1): unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51808), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:52.216102 (Thread-1): Writing injected SQL for node "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"
2020-10-21 23:38:52.223310 (Thread-1): finished collecting timing info
2020-10-21 23:38:52.227273 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:52.229827 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:52.247080 (Thread-4): On test.dwelo.unique_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`dim_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:38:52.360330 (Thread-3): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:38:52.408355 (Thread-2): finished collecting timing info
2020-10-21 23:38:52.413622 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: a80c8e8b-56ef-4973-a765-5276eba63715)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-21 23:38:52.417373 (Thread-2): 23:38:52 | 26 of 35 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.98s]
2020-10-21 23:38:52.420383 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:38:52.423484 (Thread-2): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:38:52.431625 (Thread-2): 23:38:52 | 31 of 35 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-21 23:38:52.435752 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-21 23:38:52.438056 (Thread-2): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:38:52.458685 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-21 23:38:52.468222 (Thread-2): finished collecting timing info
2020-10-21 23:38:52.471468 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:52.474065 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:52.723080 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`dim_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:38:52.725231 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 0ada76ff-2398-42e1-baff-c629f06aecc9)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:52.726963 (Thread-4): finished collecting timing info
2020-10-21 23:38:52.729493 (Thread-4): Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 0ada76ff-2398-42e1-baff-c629f06aecc9)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 0ada76ff-2398-42e1-baff-c629f06aecc9)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 0ada76ff-2398-42e1-baff-c629f06aecc9)
2020-10-21 23:38:52.731863 (Thread-4): 23:38:52 | 28 of 35 ERROR unique_dim_users_username............................. [ERROR in 1.15s]
2020-10-21 23:38:52.733925 (Thread-4): Finished running node test.dwelo.unique_dim_users_username
2020-10-21 23:38:52.735903 (Thread-4): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:38:52.738307 (Thread-4): 23:38:52 | 32 of 35 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-21 23:38:52.740847 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-21 23:38:52.742830 (Thread-4): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:38:52.759463 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-21 23:38:52.766412 (Thread-4): finished collecting timing info
2020-10-21 23:38:52.769853 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:38:52.773914 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:52.774603 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [15:11]')
2020-10-21 23:38:52.904273 (Thread-1): On test.dwelo.unique_met_daily_command_count_by_user_id_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:38:53.073144 (Thread-2): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:38:53.320274 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:38:53.322621 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: e6ac616e-9a4b-4471-b19a-3fb231cc2cfe)

                                                                       -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:38:53.324782 (Thread-1): finished collecting timing info
2020-10-21 23:38:53.327357 (Thread-1): Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: e6ac616e-9a4b-4471-b19a-3fb231cc2cfe)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: e6ac616e-9a4b-4471-b19a-3fb231cc2cfe)

                                                                       -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: e6ac616e-9a4b-4471-b19a-3fb231cc2cfe)
2020-10-21 23:38:53.329723 (Thread-1): 23:38:53 | 30 of 35 ERROR unique_met_daily_command_count_by_user_id_user_id..... [ERROR in 1.16s]
2020-10-21 23:38:53.332288 (Thread-1): Finished running node test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:38:53.336068 (Thread-1): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:38:53.338823 (Thread-1): 23:38:53 | 33 of 35 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-21 23:38:53.341673 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-21 23:38:53.343336 (Thread-1): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:38:53.359652 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-21 23:38:53.366297 (Thread-1): finished collecting timing info
2020-10-21 23:38:53.368429 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:38:53.370076 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:53.394466 (Thread-3): finished collecting timing info
2020-10-21 23:38:53.395811 (Thread-4): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:38:53.400607 (Thread-3): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [15:11]

(job ID: fff02746-3fb3-4b2d-86c5-8c079b433387)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-21 23:38:53.410367 (Thread-3): 23:38:53 | 29 of 35 ERROR unique_fct_command_statuses_command_uuid.............. [ERROR in 1.69s]
2020-10-21 23:38:53.413464 (Thread-3): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:38:53.415645 (Thread-3): Began running node test.dwelo.unique_stg_users_user_id
2020-10-21 23:38:53.418454 (Thread-3): 23:38:53 | 34 of 35 START test unique_stg_users_user_id......................... [RUN]
2020-10-21 23:38:53.423532 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_users_user_id".
2020-10-21 23:38:53.425878 (Thread-3): Compiling test.dwelo.unique_stg_users_user_id
2020-10-21 23:38:53.451057 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_users_user_id"
2020-10-21 23:38:53.459663 (Thread-3): finished collecting timing info
2020-10-21 23:38:53.462859 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:38:53.470992 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:53.983321 (Thread-1): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:38:54.061442 (Thread-3): On test.dwelo.unique_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`stg_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:38:54.474216 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-21 23:38:54.899095 (Thread-2): finished collecting timing info
2020-10-21 23:38:54.904587 (Thread-2): 23:38:54 | 31 of 35 PASS unique_stg_command_actives_command_uuid................ [PASS in 2.47s]
2020-10-21 23:38:54.908047 (Thread-2): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:38:54.912272 (Thread-2): Began running node test.dwelo.unique_stg_users_username
2020-10-21 23:38:54.915705 (Thread-2): 23:38:54 | 35 of 35 START test unique_stg_users_username........................ [RUN]
2020-10-21 23:38:54.919542 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_users_username".
2020-10-21 23:38:54.922472 (Thread-2): Compiling test.dwelo.unique_stg_users_username
2020-10-21 23:38:54.943548 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_users_username"
2020-10-21 23:38:54.951024 (Thread-2): finished collecting timing info
2020-10-21 23:38:54.953818 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:38:54.955918 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:38:55.294172 (Thread-4): finished collecting timing info
2020-10-21 23:38:55.296906 (Thread-4): 23:38:55 | 32 of 35 PASS unique_stg_command_results_command_uuid................ [PASS in 2.56s]
2020-10-21 23:38:55.299784 (Thread-4): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:38:55.606715 (Thread-2): On test.dwelo.unique_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`stg_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:38:55.742509 (Thread-3): finished collecting timing info
2020-10-21 23:38:55.747550 (Thread-3): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: e9d03163-e01c-46eb-bd62-70e861ab48cb)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-21 23:38:55.753875 (Thread-3): 23:38:55 | 34 of 35 ERROR unique_stg_users_user_id.............................. [ERROR in 2.33s]
2020-10-21 23:38:55.756390 (Thread-3): Finished running node test.dwelo.unique_stg_users_user_id
2020-10-21 23:38:55.863547 (Thread-1): finished collecting timing info
2020-10-21 23:38:55.867503 (Thread-1): 23:38:55 | 33 of 35 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 2.53s]
2020-10-21 23:38:55.870458 (Thread-1): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:38:57.131802 (Thread-2): finished collecting timing info
2020-10-21 23:38:57.135977 (Thread-2): 23:38:57 | 35 of 35 PASS unique_stg_users_username.............................. [PASS in 2.22s]
2020-10-21 23:38:57.138758 (Thread-2): Finished running node test.dwelo.unique_stg_users_username
2020-10-21 23:38:57.146270 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:38:57.148834 (MainThread): 23:38:57 | 
2020-10-21 23:38:57.151160 (MainThread): 23:38:57 | Finished running 35 tests in 20.08s.
2020-10-21 23:38:57.153531 (MainThread): Connection 'master' was properly closed.
2020-10-21 23:38:57.155991 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-21 23:38:57.158268 (MainThread): Connection 'test.dwelo.unique_stg_users_username' was properly closed.
2020-10-21 23:38:57.160339 (MainThread): Connection 'test.dwelo.unique_stg_users_user_id' was properly closed.
2020-10-21 23:38:57.162368 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-21 23:38:57.190235 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51820), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:57.192765 (MainThread): unclosed <socket.socket fd=37, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56028), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:57.194998 (MainThread): unclosed <socket.socket fd=36, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56024), raddr=('172.217.14.74', 443)>
2020-10-21 23:38:57.197059 (MainThread): unclosed <socket.socket fd=30, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 51824), raddr=('216.58.193.202', 443)>
2020-10-21 23:38:57.313811 (MainThread): 
2020-10-21 23:38:57.316520 (MainThread): Completed with 22 errors and 0 warnings:
2020-10-21 23:38:57.320156 (MainThread): 
2020-10-21 23:38:57.323883 (MainThread): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
2020-10-21 23:38:57.328167 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.331033 (MainThread):   
2020-10-21 23:38:57.334151 (MainThread):   (job ID: ff5f4b76-d2f7-4c30-810e-ebc3666f92eb)
2020-10-21 23:38:57.337712 (MainThread): 
2020-10-21 23:38:57.342053 (MainThread): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
2020-10-21 23:38:57.345260 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.350320 (MainThread):   
2020-10-21 23:38:57.353855 (MainThread):   (job ID: 1d5e505a-fee4-468d-a6a9-b2df7f50c2ff)
2020-10-21 23:38:57.356425 (MainThread): 
2020-10-21 23:38:57.358585 (MainThread): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
2020-10-21 23:38:57.360642 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.362750 (MainThread):   
2020-10-21 23:38:57.365203 (MainThread):   (job ID: f30b5ce3-7c3c-4cc3-9815-7c0a84a988d5)
2020-10-21 23:38:57.367228 (MainThread): 
2020-10-21 23:38:57.369541 (MainThread): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
2020-10-21 23:38:57.371905 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.374648 (MainThread):   
2020-10-21 23:38:57.377061 (MainThread):   (job ID: 90a2daeb-a636-43cf-8c57-96c8e06653a1)
2020-10-21 23:38:57.379367 (MainThread): 
2020-10-21 23:38:57.381833 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
2020-10-21 23:38:57.385695 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:38:57.391392 (MainThread):   
2020-10-21 23:38:57.395045 (MainThread):   (job ID: 284df824-3eb6-4417-8c79-930651522905)
2020-10-21 23:38:57.397954 (MainThread): 
2020-10-21 23:38:57.400290 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
2020-10-21 23:38:57.402257 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:38:57.404697 (MainThread):   
2020-10-21 23:38:57.407346 (MainThread):   (job ID: 2604ea03-7e3e-41e3-8d98-21e8b084acd6)
2020-10-21 23:38:57.409368 (MainThread): 
2020-10-21 23:38:57.411157 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
2020-10-21 23:38:57.413372 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:38:57.415326 (MainThread):   
2020-10-21 23:38:57.417259 (MainThread):   (job ID: 1065625e-73c0-4f8c-8d86-bdba9b7ea16f)
2020-10-21 23:38:57.418729 (MainThread): 
2020-10-21 23:38:57.420568 (MainThread): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-21 23:38:57.422598 (MainThread):   Unrecognized name: command_uuid at [10:7]
2020-10-21 23:38:57.424649 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-21 23:38:57.426505 (MainThread): 
2020-10-21 23:38:57.428515 (MainThread): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
2020-10-21 23:38:57.430787 (MainThread):   Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
2020-10-21 23:38:57.432928 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-21 23:38:57.435363 (MainThread): 
2020-10-21 23:38:57.438551 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-21 23:38:57.440871 (MainThread):   Got 101 results, expected 0.
2020-10-21 23:38:57.442912 (MainThread): 
2020-10-21 23:38:57.444707 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-21 23:38:57.446576 (MainThread): 
2020-10-21 23:38:57.448384 (MainThread): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
2020-10-21 23:38:57.449974 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-21 23:38:57.452321 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-21 23:38:57.454631 (MainThread): 
2020-10-21 23:38:57.456646 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-21 23:38:57.458299 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-21 23:38:57.460352 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-21 23:38:57.462546 (MainThread): 
2020-10-21 23:38:57.464545 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-21 23:38:57.466627 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-21 23:38:57.468653 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-21 23:38:57.470959 (MainThread): 
2020-10-21 23:38:57.473446 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-21 23:38:57.475022 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-21 23:38:57.478502 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-21 23:38:57.480647 (MainThread): 
2020-10-21 23:38:57.482268 (MainThread): Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
2020-10-21 23:38:57.483908 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.485513 (MainThread):   
2020-10-21 23:38:57.487194 (MainThread):   (job ID: 14a068db-51df-4a9d-b735-3c7b6c51b15a)
2020-10-21 23:38:57.488862 (MainThread): 
2020-10-21 23:38:57.490468 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-21 23:38:57.492825 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-21 23:38:57.494568 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-21 23:38:57.496347 (MainThread): 
2020-10-21 23:38:57.499199 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-21 23:38:57.501262 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-21 23:38:57.503333 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-21 23:38:57.506001 (MainThread): 
2020-10-21 23:38:57.508264 (MainThread): Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
2020-10-21 23:38:57.510806 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:38:57.512562 (MainThread):   
2020-10-21 23:38:57.514291 (MainThread):   (job ID: 0ada76ff-2398-42e1-baff-c629f06aecc9)
2020-10-21 23:38:57.516067 (MainThread): 
2020-10-21 23:38:57.517705 (MainThread): Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
2020-10-21 23:38:57.519414 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:38:57.521535 (MainThread):   
2020-10-21 23:38:57.523655 (MainThread):   (job ID: e6ac616e-9a4b-4471-b19a-3fb231cc2cfe)
2020-10-21 23:38:57.525408 (MainThread): 
2020-10-21 23:38:57.527334 (MainThread): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-21 23:38:57.529077 (MainThread):   Unrecognized name: command_uuid at [15:11]
2020-10-21 23:38:57.530758 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-21 23:38:57.532583 (MainThread): 
2020-10-21 23:38:57.534403 (MainThread): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
2020-10-21 23:38:57.536454 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-21 23:38:57.538255 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-21 23:38:57.540082 (MainThread): 
2020-10-21 23:38:57.542087 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-21 23:38:57.544708 (MainThread):   Got 2 results, expected 0.
2020-10-21 23:38:57.546525 (MainThread): 
2020-10-21 23:38:57.548262 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-21 23:38:57.549992 (MainThread): 
Done. PASS=13 WARN=0 ERROR=22 SKIP=0 TOTAL=35
2020-10-21 23:38:57.552286 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cf849db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cf9142df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8cf84c4af0>]}
2020-10-21 23:38:57.554760 (MainThread): Flushing usage events
2020-10-21 23:42:06.671754 (MainThread): Running with dbt=0.18.0
2020-10-21 23:42:06.933426 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 23:42:06.940170 (MainThread): Tracking: tracking
2020-10-21 23:42:06.943927 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa577640df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa576916be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa576916bb0>]}
2020-10-21 23:42:06.981582 (MainThread): Partial parsing not enabled
2020-10-21 23:42:06.984816 (MainThread): Parsing macros/etc.sql
2020-10-21 23:42:06.988165 (MainThread): Parsing macros/catalog.sql
2020-10-21 23:42:07.002040 (MainThread): Parsing macros/adapters.sql
2020-10-21 23:42:07.037215 (MainThread): Parsing macros/materializations/view.sql
2020-10-21 23:42:07.044589 (MainThread): Parsing macros/materializations/table.sql
2020-10-21 23:42:07.063111 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-21 23:42:07.087393 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-21 23:42:07.092715 (MainThread): Parsing macros/materializations/copy.sql
2020-10-21 23:42:07.101542 (MainThread): Parsing macros/materializations/seed.sql
2020-10-21 23:42:07.108841 (MainThread): Parsing macros/core.sql
2020-10-21 23:42:07.116557 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 23:42:07.133694 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 23:42:07.144523 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 23:42:07.157153 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 23:42:07.184845 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 23:42:07.212705 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 23:42:07.217871 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 23:42:07.272083 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 23:42:07.285264 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 23:42:07.289929 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 23:42:07.302573 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 23:42:07.340567 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 23:42:07.420971 (MainThread): Parsing macros/etc/query.sql
2020-10-21 23:42:07.425250 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 23:42:07.429148 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 23:42:07.433247 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 23:42:07.449084 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 23:42:07.454378 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 23:42:07.457517 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 23:42:07.462622 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 23:42:07.466881 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 23:42:07.472605 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 23:42:07.486618 (MainThread): Partial parsing not enabled
2020-10-21 23:42:07.594151 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-21 23:42:07.623622 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-21 23:42:07.640983 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-21 23:42:07.657021 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-21 23:42:07.676177 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-21 23:42:07.696335 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-21 23:42:07.716468 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-21 23:42:07.751751 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:42:07.770153 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:42:07.791436 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:42:07.808920 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:42:07.827081 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:42:08.875532 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-21 23:42:08.881339 (MainThread): 
2020-10-21 23:42:08.883905 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:42:08.958621 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-21 23:42:08.960822 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 23:42:08.963781 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:09.542802 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-21 23:42:09.960194 (MainThread): 23:42:09 | Concurrency: 4 threads (target='dev')
2020-10-21 23:42:09.962932 (MainThread): 23:42:09 | 
2020-10-21 23:42:09.991357 (Thread-1): Began running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:42:09.991759 (Thread-2): Began running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:42:09.992200 (Thread-3): Began running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:42:09.992865 (Thread-4): Began running node test.dwelo.not_null_dim_users_username
2020-10-21 23:42:09.994026 (Thread-1): 23:42:09 | 1 of 35 START test not_null_dim_users_date_registered................ [RUN]
2020-10-21 23:42:09.996612 (Thread-2): 23:42:09 | 2 of 35 START test not_null_dim_users_last_modified.................. [RUN]
2020-10-21 23:42:09.998571 (Thread-3): 23:42:09 | 3 of 35 START test not_null_dim_users_user_id........................ [RUN]
2020-10-21 23:42:10.000510 (Thread-4): 23:42:09 | 4 of 35 START test not_null_dim_users_username....................... [RUN]
2020-10-21 23:42:10.002963 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_date_registered".
2020-10-21 23:42:10.006469 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_last_modified".
2020-10-21 23:42:10.008981 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_user_id".
2020-10-21 23:42:10.010707 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_username".
2020-10-21 23:42:10.012856 (Thread-1): Compiling test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:42:10.014655 (Thread-2): Compiling test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:42:10.016324 (Thread-3): Compiling test.dwelo.not_null_dim_users_user_id
2020-10-21 23:42:10.018495 (Thread-4): Compiling test.dwelo.not_null_dim_users_username
2020-10-21 23:42:10.103242 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_dim_users_last_modified"
2020-10-21 23:42:10.123025 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_dim_users_username"
2020-10-21 23:42:10.127608 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_dim_users_user_id"
2020-10-21 23:42:10.134036 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_dim_users_date_registered"
2020-10-21 23:42:10.138870 (Thread-2): finished collecting timing info
2020-10-21 23:42:10.140340 (Thread-4): finished collecting timing info
2020-10-21 23:42:10.142319 (Thread-3): finished collecting timing info
2020-10-21 23:42:10.143123 (Thread-2): Opening a new connection, currently in state init
2020-10-21 23:42:10.150321 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:10.146258 (Thread-4): Opening a new connection, currently in state init
2020-10-21 23:42:10.148426 (Thread-3): Opening a new connection, currently in state init
2020-10-21 23:42:10.144233 (Thread-1): finished collecting timing info
2020-10-21 23:42:10.163721 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:42:10.160942 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:10.157454 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:10.168147 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:10.769061 (Thread-2): On test.dwelo.not_null_dim_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:42:10.812880 (Thread-3): On test.dwelo.not_null_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:42:10.813963 (Thread-4): On test.dwelo.not_null_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:42:10.827867 (Thread-1): On test.dwelo.not_null_dim_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:42:10.838046 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56052), raddr=('172.217.14.74', 443)>
2020-10-21 23:42:10.840861 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56050), raddr=('172.217.14.74', 443)>
2020-10-21 23:42:11.604759 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:42:11.608582 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 29df8b96-4d5e-47c9-aae4-a73981876b1f)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:11.611730 (Thread-3): finished collecting timing info
2020-10-21 23:42:11.615052 (Thread-3): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 29df8b96-4d5e-47c9-aae4-a73981876b1f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 29df8b96-4d5e-47c9-aae4-a73981876b1f)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 29df8b96-4d5e-47c9-aae4-a73981876b1f)
2020-10-21 23:42:11.620050 (Thread-3): 23:42:11 | 3 of 35 ERROR not_null_dim_users_user_id............................. [ERROR in 1.61s]
2020-10-21 23:42:11.621949 (Thread-3): Finished running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:42:11.626030 (Thread-3): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:42:11.628529 (Thread-3): 23:42:11 | 5 of 35 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-21 23:42:11.631614 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-21 23:42:11.635963 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:42:11.637977 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 3253b9a6-75f7-4a55-81bb-cde06387fe72)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:11.639674 (Thread-2): finished collecting timing info
2020-10-21 23:42:11.641954 (Thread-2): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 3253b9a6-75f7-4a55-81bb-cde06387fe72)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 3253b9a6-75f7-4a55-81bb-cde06387fe72)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 3253b9a6-75f7-4a55-81bb-cde06387fe72)
2020-10-21 23:42:11.644237 (Thread-2): 23:42:11 | 2 of 35 ERROR not_null_dim_users_last_modified....................... [ERROR in 1.64s]
2020-10-21 23:42:11.645943 (Thread-2): Finished running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:42:11.648928 (Thread-2): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:42:11.651683 (Thread-2): 23:42:11 | 6 of 35 START test not_null_met_daily_command_count_by_user_id_num_of_commands [RUN]
2020-10-21 23:42:11.655778 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands".
2020-10-21 23:42:11.658832 (Thread-2): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:42:11.657142 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:42:11.636220 (Thread-3): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:42:11.677028 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"
2020-10-21 23:42:11.678213 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 85cb9bec-91e6-4271-bfd1-920d177dd99e)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:11.709600 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-21 23:42:11.711551 (Thread-1): finished collecting timing info
2020-10-21 23:42:11.713157 (Thread-2): finished collecting timing info
2020-10-21 23:42:11.723548 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:42:11.721477 (Thread-3): finished collecting timing info
2020-10-21 23:42:11.719220 (Thread-1): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 85cb9bec-91e6-4271-bfd1-920d177dd99e)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 85cb9bec-91e6-4271-bfd1-920d177dd99e)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 85cb9bec-91e6-4271-bfd1-920d177dd99e)
2020-10-21 23:42:11.726336 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:11.729747 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:42:11.733036 (Thread-1): 23:42:11 | 1 of 35 ERROR not_null_dim_users_date_registered..................... [ERROR in 1.73s]
2020-10-21 23:42:11.745546 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:11.748278 (Thread-1): Finished running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:42:11.756780 (Thread-1): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:42:11.760316 (Thread-1): 23:42:11 | 7 of 35 START test not_null_met_daily_command_count_by_user_id_timestamp_date [RUN]
2020-10-21 23:42:11.767851 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date".
2020-10-21 23:42:11.772310 (Thread-1): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:42:11.791400 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:42:11.805637 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 773ed523-5678-4850-b9cc-5f0513438467)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:11.819653 (Thread-4): finished collecting timing info
2020-10-21 23:42:11.825150 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"
2020-10-21 23:42:11.827671 (Thread-4): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 773ed523-5678-4850-b9cc-5f0513438467)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 773ed523-5678-4850-b9cc-5f0513438467)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 773ed523-5678-4850-b9cc-5f0513438467)
2020-10-21 23:42:11.835159 (Thread-4): 23:42:11 | 4 of 35 ERROR not_null_dim_users_username............................ [ERROR in 1.82s]
2020-10-21 23:42:11.838340 (Thread-4): Finished running node test.dwelo.not_null_dim_users_username
2020-10-21 23:42:11.840567 (Thread-1): finished collecting timing info
2020-10-21 23:42:11.842552 (Thread-4): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:42:11.845022 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:42:11.847264 (Thread-4): 23:42:11 | 8 of 35 START test not_null_met_daily_command_count_by_user_id_user_id [RUN]
2020-10-21 23:42:11.851225 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:11.853243 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id".
2020-10-21 23:42:11.862750 (Thread-4): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:42:11.902680 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"
2020-10-21 23:42:11.912361 (Thread-4): finished collecting timing info
2020-10-21 23:42:11.917518 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:42:11.922295 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:42:12.482001 (Thread-2): On test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:42:12.497558 (MainThread): 23:42:12 | The bigquery adapter does not support query cancellation. Some queries may still be running!
2020-10-21 23:42:12.498346 (Thread-3): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-21 23:42:12.501563 (Thread-1): On test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:42:12.594286 (Thread-4): On test.dwelo.not_null_met_daily_command_count_by_user_id_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:42:12.896558 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:42:12.902012 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: f4f888cd-2a52-492b-a1ff-3a6a4ad8230a)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:12.905292 (Thread-1): finished collecting timing info
2020-10-21 23:42:12.908595 (Thread-1): Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: f4f888cd-2a52-492b-a1ff-3a6a4ad8230a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: f4f888cd-2a52-492b-a1ff-3a6a4ad8230a)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: f4f888cd-2a52-492b-a1ff-3a6a4ad8230a)
2020-10-21 23:42:12.911851 (Thread-1): 23:42:12 | 7 of 35 ERROR not_null_met_daily_command_count_by_user_id_timestamp_date [ERROR in 1.15s]
2020-10-21 23:42:12.914983 (Thread-1): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:42:12.916293 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:42:12.919313 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 416921ee-5683-4a31-b357-bd34508e2611)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:12.920972 (Thread-2): finished collecting timing info
2020-10-21 23:42:12.922897 (Thread-2): Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 416921ee-5683-4a31-b357-bd34508e2611)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 416921ee-5683-4a31-b357-bd34508e2611)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 416921ee-5683-4a31-b357-bd34508e2611)
2020-10-21 23:42:12.925007 (Thread-2): 23:42:12 | 6 of 35 ERROR not_null_met_daily_command_count_by_user_id_num_of_commands [ERROR in 1.27s]
2020-10-21 23:42:12.926492 (Thread-2): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:42:12.999363 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-21 23:42:13.036729 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:42:13.039265 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: d10806f4-13a2-4f59-ab1a-1a102608b8c9)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:42:13.041789 (Thread-4): finished collecting timing info
2020-10-21 23:42:13.044493 (Thread-4): Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: d10806f4-13a2-4f59-ab1a-1a102608b8c9)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: d10806f4-13a2-4f59-ab1a-1a102608b8c9)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: d10806f4-13a2-4f59-ab1a-1a102608b8c9)
2020-10-21 23:42:13.047101 (Thread-4): 23:42:13 | 8 of 35 ERROR not_null_met_daily_command_count_by_user_id_user_id.... [ERROR in 1.19s]
2020-10-21 23:42:13.052298 (Thread-4): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:42:14.259553 (Thread-3): finished collecting timing info
2020-10-21 23:42:14.264595 (Thread-3): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: cbc96e4c-1d38-46ae-b7e0-20b2f98b8104)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-21 23:42:14.267984 (Thread-3): 23:42:14 | 5 of 35 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 2.64s]
2020-10-21 23:42:14.270662 (Thread-3): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:42:14.274602 (MainThread): 
2020-10-21 23:42:14.277072 (MainThread): Exited because of keyboard interrupt.
2020-10-21 23:42:14.279703 (MainThread): 
2020-10-21 23:42:14.282230 (MainThread): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
2020-10-21 23:42:14.284638 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:42:14.286572 (MainThread):   
2020-10-21 23:42:14.288546 (MainThread):   (job ID: 29df8b96-4d5e-47c9-aae4-a73981876b1f)
2020-10-21 23:42:14.291711 (MainThread): 
2020-10-21 23:42:14.294063 (MainThread): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
2020-10-21 23:42:14.296928 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:42:14.299686 (MainThread):   
2020-10-21 23:42:14.302706 (MainThread):   (job ID: 3253b9a6-75f7-4a55-81bb-cde06387fe72)
2020-10-21 23:42:14.304718 (MainThread): 
2020-10-21 23:42:14.307261 (MainThread): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
2020-10-21 23:42:14.309626 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:42:14.311693 (MainThread):   
2020-10-21 23:42:14.313787 (MainThread):   (job ID: 85cb9bec-91e6-4271-bfd1-920d177dd99e)
2020-10-21 23:42:14.315630 (MainThread): 
2020-10-21 23:42:14.317894 (MainThread): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
2020-10-21 23:42:14.319878 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:42:14.322717 (MainThread):   
2020-10-21 23:42:14.325219 (MainThread):   (job ID: 773ed523-5678-4850-b9cc-5f0513438467)
2020-10-21 23:42:14.327795 (MainThread): 
Done. PASS=0 WARN=0 ERROR=4 SKIP=0 TOTAL=4
2020-10-21 23:42:14.330894 (MainThread): Connection 'master' was properly closed.
2020-10-21 23:42:14.333736 (MainThread): Connection 'test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date' was properly closed.
2020-10-21 23:42:14.336069 (MainThread): Connection 'test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands' was properly closed.
2020-10-21 23:42:14.339081 (MainThread): Connection 'test.dwelo.not_null_fct_command_statuses_command_uuid' was properly closed.
2020-10-21 23:42:14.341564 (MainThread): Connection 'test.dwelo.not_null_met_daily_command_count_by_user_id_user_id' was properly closed.
2020-10-21 23:42:14.344051 (MainThread): Flushing usage events
2020-10-21 23:42:14.720522 (MainThread): ctrl-c
2020-10-21 23:52:17.950575 (MainThread): Running with dbt=0.18.0
2020-10-21 23:52:18.208151 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-21 23:52:18.216346 (MainThread): Tracking: tracking
2020-10-21 23:52:18.220482 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffe802d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffdad7b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffdad7b50>]}
2020-10-21 23:52:18.257425 (MainThread): Partial parsing not enabled
2020-10-21 23:52:18.260681 (MainThread): Parsing macros/etc.sql
2020-10-21 23:52:18.264101 (MainThread): Parsing macros/catalog.sql
2020-10-21 23:52:18.277427 (MainThread): Parsing macros/adapters.sql
2020-10-21 23:52:18.312180 (MainThread): Parsing macros/materializations/view.sql
2020-10-21 23:52:18.319213 (MainThread): Parsing macros/materializations/table.sql
2020-10-21 23:52:18.336800 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-21 23:52:18.360452 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-21 23:52:18.365930 (MainThread): Parsing macros/materializations/copy.sql
2020-10-21 23:52:18.374155 (MainThread): Parsing macros/materializations/seed.sql
2020-10-21 23:52:18.381236 (MainThread): Parsing macros/core.sql
2020-10-21 23:52:18.388861 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-21 23:52:18.406126 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-21 23:52:18.416909 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-21 23:52:18.430151 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-21 23:52:18.458956 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-21 23:52:18.489200 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-21 23:52:18.495163 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-21 23:52:18.549174 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-21 23:52:18.561362 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-21 23:52:18.566378 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-21 23:52:18.578635 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-21 23:52:18.615919 (MainThread): Parsing macros/adapters/common.sql
2020-10-21 23:52:18.697909 (MainThread): Parsing macros/etc/query.sql
2020-10-21 23:52:18.704137 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-21 23:52:18.717961 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-21 23:52:18.721788 (MainThread): Parsing macros/etc/datetime.sql
2020-10-21 23:52:18.737681 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-21 23:52:18.742736 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-21 23:52:18.745907 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-21 23:52:18.750358 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-21 23:52:18.754363 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-21 23:52:18.760143 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-21 23:52:18.773473 (MainThread): Partial parsing not enabled
2020-10-21 23:52:18.874863 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-21 23:52:18.904152 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-21 23:52:18.919926 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-21 23:52:18.936113 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-21 23:52:18.961380 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-21 23:52:18.980623 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-21 23:52:19.000301 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-21 23:52:19.035227 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:52:19.053546 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:52:19.070961 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:52:19.088972 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:52:19.106747 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:52:20.125399 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-21 23:52:20.132018 (MainThread): 
2020-10-21 23:52:20.134343 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:52:20.205211 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-21 23:52:20.207142 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-21 23:52:20.209964 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:20.782872 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-21 23:52:21.230663 (MainThread): 23:52:21 | Concurrency: 4 threads (target='dev')
2020-10-21 23:52:21.233126 (MainThread): 23:52:21 | 
2020-10-21 23:52:21.255847 (Thread-1): Began running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:52:21.256179 (Thread-2): Began running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:52:21.256761 (Thread-3): Began running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:52:21.256990 (Thread-4): Began running node test.dwelo.not_null_dim_users_username
2020-10-21 23:52:21.258791 (Thread-1): 23:52:21 | 1 of 35 START test not_null_dim_users_date_registered................ [RUN]
2020-10-21 23:52:21.260783 (Thread-2): 23:52:21 | 2 of 35 START test not_null_dim_users_last_modified.................. [RUN]
2020-10-21 23:52:21.262592 (Thread-3): 23:52:21 | 3 of 35 START test not_null_dim_users_user_id........................ [RUN]
2020-10-21 23:52:21.264209 (Thread-4): 23:52:21 | 4 of 35 START test not_null_dim_users_username....................... [RUN]
2020-10-21 23:52:21.266184 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_date_registered".
2020-10-21 23:52:21.269601 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_last_modified".
2020-10-21 23:52:21.271365 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_user_id".
2020-10-21 23:52:21.274275 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_username".
2020-10-21 23:52:21.275569 (Thread-1): Compiling test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:52:21.277802 (Thread-2): Compiling test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:52:21.279826 (Thread-3): Compiling test.dwelo.not_null_dim_users_user_id
2020-10-21 23:52:21.281873 (Thread-4): Compiling test.dwelo.not_null_dim_users_username
2020-10-21 23:52:21.340756 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_dim_users_date_registered"
2020-10-21 23:52:21.367768 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_dim_users_user_id"
2020-10-21 23:52:21.370859 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_dim_users_last_modified"
2020-10-21 23:52:21.373086 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_dim_users_username"
2020-10-21 23:52:21.380164 (Thread-1): finished collecting timing info
2020-10-21 23:52:21.383848 (Thread-3): finished collecting timing info
2020-10-21 23:52:21.396656 (Thread-3): Opening a new connection, currently in state init
2020-10-21 23:52:21.386899 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:21.387311 (Thread-4): finished collecting timing info
2020-10-21 23:52:21.385000 (Thread-2): finished collecting timing info
2020-10-21 23:52:21.407912 (Thread-2): Opening a new connection, currently in state init
2020-10-21 23:52:21.404114 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:21.406041 (Thread-4): Opening a new connection, currently in state init
2020-10-21 23:52:21.402380 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:21.409755 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:21.418883 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:22.018294 (Thread-1): On test.dwelo.not_null_dim_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:52:22.035559 (Thread-3): On test.dwelo.not_null_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:52:22.077607 (Thread-2): On test.dwelo.not_null_dim_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:52:22.093758 (Thread-4): On test.dwelo.not_null_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:52:22.097626 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56092), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:22.099855 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52154), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:22.484247 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-21 23:52:22.486679 (Thread-1): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 37c48fd1-b10d-4e3d-98dc-c14f2122feee)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:22.488897 (Thread-1): finished collecting timing info
2020-10-21 23:52:22.492158 (Thread-1): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 37c48fd1-b10d-4e3d-98dc-c14f2122feee)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 37c48fd1-b10d-4e3d-98dc-c14f2122feee)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 37c48fd1-b10d-4e3d-98dc-c14f2122feee)
2020-10-21 23:52:22.496099 (Thread-1): 23:52:22 | 1 of 35 ERROR not_null_dim_users_date_registered..................... [ERROR in 1.23s]
2020-10-21 23:52:22.497524 (Thread-1): Finished running node test.dwelo.not_null_dim_users_date_registered
2020-10-21 23:52:22.500574 (Thread-1): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:52:22.502666 (Thread-1): 23:52:22 | 5 of 35 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-21 23:52:22.504250 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-21 23:52:22.505768 (Thread-1): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:52:22.522363 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-21 23:52:22.528148 (Thread-1): finished collecting timing info
2020-10-21 23:52:22.530583 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:22.532870 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:22.618067 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-21 23:52:22.620572 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 51007ca4-27e2-477e-a149-640267f08a74)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:22.622712 (Thread-4): finished collecting timing info
2020-10-21 23:52:22.625292 (Thread-4): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 51007ca4-27e2-477e-a149-640267f08a74)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 51007ca4-27e2-477e-a149-640267f08a74)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 51007ca4-27e2-477e-a149-640267f08a74)
2020-10-21 23:52:22.628958 (Thread-4): 23:52:22 | 4 of 35 ERROR not_null_dim_users_username............................ [ERROR in 1.36s]
2020-10-21 23:52:22.630752 (Thread-4): Finished running node test.dwelo.not_null_dim_users_username
2020-10-21 23:52:22.632629 (Thread-4): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:52:22.635957 (Thread-4): 23:52:22 | 6 of 35 START test not_null_met_daily_command_count_by_user_id_num_of_commands [RUN]
2020-10-21 23:52:22.638884 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands".
2020-10-21 23:52:22.641459 (Thread-4): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:52:22.661073 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-21 23:52:22.664281 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 01413c1a-3db8-47e2-9ed9-a16490a3cf1f)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:22.666668 (Thread-2): finished collecting timing info
2020-10-21 23:52:22.669726 (Thread-2): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 01413c1a-3db8-47e2-9ed9-a16490a3cf1f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 01413c1a-3db8-47e2-9ed9-a16490a3cf1f)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 01413c1a-3db8-47e2-9ed9-a16490a3cf1f)
2020-10-21 23:52:22.672251 (Thread-2): 23:52:22 | 2 of 35 ERROR not_null_dim_users_last_modified....................... [ERROR in 1.40s]
2020-10-21 23:52:22.674957 (Thread-2): Finished running node test.dwelo.not_null_dim_users_last_modified
2020-10-21 23:52:22.678195 (Thread-2): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:52:22.681047 (Thread-2): 23:52:22 | 7 of 35 START test not_null_met_daily_command_count_by_user_id_timestamp_date [RUN]
2020-10-21 23:52:22.683986 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date".
2020-10-21 23:52:22.690026 (Thread-2): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:52:22.663132 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"
2020-10-21 23:52:22.695112 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-21 23:52:22.718669 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"
2020-10-21 23:52:22.720093 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 5dbf2ff5-d0ee-494e-9291-58ec4c9268b3)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:22.722252 (Thread-4): finished collecting timing info
2020-10-21 23:52:22.726843 (Thread-3): finished collecting timing info
2020-10-21 23:52:22.729026 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:22.734697 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:22.731910 (Thread-3): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 5dbf2ff5-d0ee-494e-9291-58ec4c9268b3)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 5dbf2ff5-d0ee-494e-9291-58ec4c9268b3)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 5dbf2ff5-d0ee-494e-9291-58ec4c9268b3)
2020-10-21 23:52:22.729325 (Thread-2): finished collecting timing info
2020-10-21 23:52:22.742888 (Thread-3): 23:52:22 | 3 of 35 ERROR not_null_dim_users_user_id............................. [ERROR in 1.47s]
2020-10-21 23:52:22.746088 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:22.749134 (Thread-3): Finished running node test.dwelo.not_null_dim_users_user_id
2020-10-21 23:52:22.754710 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:22.758283 (Thread-3): Began running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:22.767640 (Thread-3): 23:52:22 | 8 of 35 START test not_null_met_daily_command_count_by_user_id_user_id [RUN]
2020-10-21 23:52:22.773668 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id".
2020-10-21 23:52:22.777082 (Thread-3): Compiling test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:22.799180 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"
2020-10-21 23:52:22.806533 (Thread-3): finished collecting timing info
2020-10-21 23:52:22.809624 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:22.812463 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:23.285407 (Thread-1): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-21 23:52:23.455115 (Thread-4): On test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:52:23.457946 (Thread-2): On test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:52:23.476499 (Thread-3): On test.dwelo.not_null_met_daily_command_count_by_user_id_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:52:23.812807 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-21 23:52:23.878444 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where num_of_commands is null



2020-10-21 23:52:23.882504 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: f58a3d00-f813-48fd-b82f-5da40012fc23)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:23.885998 (Thread-4): finished collecting timing info
2020-10-21 23:52:23.889973 (Thread-4): Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: f58a3d00-f813-48fd-b82f-5da40012fc23)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: f58a3d00-f813-48fd-b82f-5da40012fc23)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: f58a3d00-f813-48fd-b82f-5da40012fc23)
2020-10-21 23:52:23.893265 (Thread-4): 23:52:23 | 6 of 35 ERROR not_null_met_daily_command_count_by_user_id_num_of_commands [ERROR in 1.26s]
2020-10-21 23:52:23.895667 (Thread-4): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_num_of_commands
2020-10-21 23:52:23.898182 (Thread-4): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:52:23.900860 (Thread-4): 23:52:23 | 9 of 35 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-21 23:52:23.904151 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-21 23:52:23.905180 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where user_id is null



2020-10-21 23:52:23.906663 (Thread-4): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:52:23.908531 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 0ad17b5c-0324-46ed-a3e7-4c14039266d7)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:23.927163 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-21 23:52:23.927898 (Thread-3): finished collecting timing info
2020-10-21 23:52:23.933067 (Thread-3): Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 0ad17b5c-0324-46ed-a3e7-4c14039266d7)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 0ad17b5c-0324-46ed-a3e7-4c14039266d7)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 0ad17b5c-0324-46ed-a3e7-4c14039266d7)
2020-10-21 23:52:23.935634 (Thread-4): finished collecting timing info
2020-10-21 23:52:23.936506 (Thread-3): 23:52:23 | 8 of 35 ERROR not_null_met_daily_command_count_by_user_id_user_id.... [ERROR in 1.17s]
2020-10-21 23:52:23.938535 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:23.940306 (Thread-3): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:23.942196 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:23.943621 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:52:23.956871 (Thread-3): 23:52:23 | 10 of 35 START test not_null_stg_command_actives_update_timestamp.... [RUN]
2020-10-21 23:52:23.964809 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-21 23:52:23.967622 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:52:23.985758 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-21 23:52:23.993123 (Thread-3): finished collecting timing info
2020-10-21 23:52:23.996356 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:23.998999 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:24.014716 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
where timestamp_date is null



2020-10-21 23:52:24.017157 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 5bb939f2-759f-4b0b-ac98-7f0fd5638718)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:24.019334 (Thread-2): finished collecting timing info
2020-10-21 23:52:24.025279 (Thread-2): Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 5bb939f2-759f-4b0b-ac98-7f0fd5638718)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: 5bb939f2-759f-4b0b-ac98-7f0fd5638718)

                                                                            -----Query Job SQL Follows-----                                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: 5bb939f2-759f-4b0b-ac98-7f0fd5638718)
2020-10-21 23:52:24.029831 (Thread-2): 23:52:24 | 7 of 35 ERROR not_null_met_daily_command_count_by_user_id_timestamp_date [ERROR in 1.35s]
2020-10-21 23:52:24.033162 (Thread-2): Finished running node test.dwelo.not_null_met_daily_command_count_by_user_id_timestamp_date
2020-10-21 23:52:24.036378 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:52:24.039172 (Thread-2): 23:52:24 | 11 of 35 START test not_null_stg_command_results_command_uuid........ [RUN]
2020-10-21 23:52:24.043073 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-21 23:52:24.046820 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:52:24.077028 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-21 23:52:24.086939 (Thread-2): finished collecting timing info
2020-10-21 23:52:24.090575 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:24.093702 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:24.502996 (Thread-1): finished collecting timing info
2020-10-21 23:52:24.505950 (Thread-1): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: 210a000e-6799-40b7-bd34-a8176483acc2)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-21 23:52:24.508086 (Thread-1): 23:52:24 | 5 of 35 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 2.00s]
2020-10-21 23:52:24.510045 (Thread-1): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-21 23:52:24.511948 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:52:24.513904 (Thread-1): 23:52:24 | 12 of 35 START test not_null_stg_command_results_is_hub_success...... [RUN]
2020-10-21 23:52:24.516223 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-21 23:52:24.518009 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:52:24.534238 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-21 23:52:24.541505 (Thread-1): finished collecting timing info
2020-10-21 23:52:24.543546 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:24.545635 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:24.674091 (Thread-4): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-21 23:52:24.680129 (Thread-4): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56112), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.685348 (Thread-3): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-21 23:52:24.686198 (Thread-4): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52174), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.692358 (Thread-4): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52178), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.695162 (Thread-4): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52180), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.697615 (Thread-4): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52182), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.699832 (Thread-4): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56122), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.701749 (Thread-4): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56120), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.704258 (Thread-4): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56124), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.796776 (Thread-2): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-21 23:52:24.802942 (Thread-4): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52158), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.805785 (Thread-4): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52160), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.808001 (Thread-4): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52162), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.810802 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52164), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:24.813709 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56102), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.831287 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56104), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.833697 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56106), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:24.835843 (Thread-4): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56108), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:25.213886 (Thread-1): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-21 23:52:25.921291 (Thread-4): finished collecting timing info
2020-10-21 23:52:25.925386 (Thread-4): 23:52:25 | 9 of 35 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.02s]
2020-10-21 23:52:25.928082 (Thread-4): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-21 23:52:25.930978 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:52:25.933975 (Thread-4): 23:52:25 | 13 of 35 START test not_null_stg_command_results_update_timestamp.... [RUN]
2020-10-21 23:52:25.936536 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-21 23:52:25.938815 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:52:25.955161 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-21 23:52:25.961559 (Thread-4): finished collecting timing info
2020-10-21 23:52:25.964185 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:25.966528 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:26.042348 (Thread-3): finished collecting timing info
2020-10-21 23:52:26.047806 (Thread-2): finished collecting timing info
2020-10-21 23:52:26.049211 (Thread-3): 23:52:26 | 10 of 35 PASS not_null_stg_command_actives_update_timestamp.......... [PASS in 2.09s]
2020-10-21 23:52:26.051918 (Thread-2): 23:52:26 | 11 of 35 PASS not_null_stg_command_results_command_uuid.............. [PASS in 2.01s]
2020-10-21 23:52:26.053908 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-21 23:52:26.056211 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-21 23:52:26.058915 (Thread-3): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:52:26.061800 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:52:26.064015 (Thread-3): 23:52:26 | 14 of 35 START test not_null_stg_commands__raw_desired_state......... [RUN]
2020-10-21 23:52:26.066690 (Thread-2): 23:52:26 | 15 of 35 START test not_null_stg_commands_command_uuid............... [RUN]
2020-10-21 23:52:26.072075 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-21 23:52:26.075288 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-21 23:52:26.078556 (Thread-3): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:52:26.085120 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:52:26.119010 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-21 23:52:26.146497 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-21 23:52:26.147043 (Thread-3): finished collecting timing info
2020-10-21 23:52:26.151554 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:26.154713 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:26.155820 (Thread-2): finished collecting timing info
2020-10-21 23:52:26.164268 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:26.166319 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:26.533514 (Thread-1): finished collecting timing info
2020-10-21 23:52:26.536713 (Thread-1): 23:52:26 | 12 of 35 PASS not_null_stg_command_results_is_hub_success............ [PASS in 2.02s]
2020-10-21 23:52:26.538481 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-21 23:52:26.540723 (Thread-1): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:52:26.542472 (Thread-1): 23:52:26 | 16 of 35 START test not_null_stg_commands_update_timestamp........... [RUN]
2020-10-21 23:52:26.544638 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-21 23:52:26.546626 (Thread-1): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:52:26.565222 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-21 23:52:26.573944 (Thread-1): finished collecting timing info
2020-10-21 23:52:26.577496 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:26.581539 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:26.607164 (Thread-4): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-21 23:52:26.777877 (Thread-3): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-21 23:52:26.785712 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-21 23:52:27.209835 (Thread-1): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-21 23:52:27.745496 (Thread-4): finished collecting timing info
2020-10-21 23:52:27.753254 (Thread-4): 23:52:27 | 13 of 35 PASS not_null_stg_command_results_update_timestamp.......... [PASS in 1.82s]
2020-10-21 23:52:27.756755 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-21 23:52:27.760038 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:52:27.762840 (Thread-4): 23:52:27 | 17 of 35 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-21 23:52:27.765746 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-21 23:52:27.768278 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:52:27.774868 (Thread-4): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56136), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:27.777638 (Thread-4): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52194), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:27.780366 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52206), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:27.784344 (Thread-4): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56144), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:27.798911 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-21 23:52:27.804477 (Thread-4): finished collecting timing info
2020-10-21 23:52:27.806637 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:27.809204 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:28.028647 (Thread-2): finished collecting timing info
2020-10-21 23:52:28.031763 (Thread-2): 23:52:28 | 15 of 35 PASS not_null_stg_commands_command_uuid..................... [PASS in 1.96s]
2020-10-21 23:52:28.033725 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-21 23:52:28.036329 (Thread-2): Began running node test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:52:28.038305 (Thread-2): 23:52:28 | 18 of 35 START test not_null_stg_users_date_registered............... [RUN]
2020-10-21 23:52:28.040761 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_date_registered".
2020-10-21 23:52:28.045859 (Thread-2): Compiling test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:52:28.068077 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_users_date_registered"
2020-10-21 23:52:28.074996 (Thread-2): finished collecting timing info
2020-10-21 23:52:28.078044 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:28.080594 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:28.084364 (Thread-3): finished collecting timing info
2020-10-21 23:52:28.092656 (Thread-3): 23:52:28 | 14 of 35 PASS not_null_stg_commands__raw_desired_state............... [PASS in 2.02s]
2020-10-21 23:52:28.097258 (Thread-3): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-21 23:52:28.099384 (Thread-3): Began running node test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:52:28.101112 (Thread-3): 23:52:28 | 19 of 35 START test not_null_stg_users_last_modified................. [RUN]
2020-10-21 23:52:28.103614 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_last_modified".
2020-10-21 23:52:28.106119 (Thread-3): Compiling test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:52:28.128442 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_last_modified"
2020-10-21 23:52:28.137067 (Thread-3): finished collecting timing info
2020-10-21 23:52:28.141973 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:28.147679 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:28.298773 (Thread-1): finished collecting timing info
2020-10-21 23:52:28.301858 (Thread-1): 23:52:28 | 16 of 35 PASS not_null_stg_commands_update_timestamp................. [PASS in 1.76s]
2020-10-21 23:52:28.303802 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-21 23:52:28.305798 (Thread-1): Began running node test.dwelo.not_null_stg_users_user_id
2020-10-21 23:52:28.307733 (Thread-1): 23:52:28 | 20 of 35 START test not_null_stg_users_user_id....................... [RUN]
2020-10-21 23:52:28.310689 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_user_id".
2020-10-21 23:52:28.313199 (Thread-1): Compiling test.dwelo.not_null_stg_users_user_id
2020-10-21 23:52:28.334435 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_user_id"
2020-10-21 23:52:28.341833 (Thread-1): finished collecting timing info
2020-10-21 23:52:28.344515 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:28.346709 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:28.465270 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-21 23:52:28.737838 (Thread-2): On test.dwelo.not_null_stg_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where date_registered is null



2020-10-21 23:52:28.795255 (Thread-3): On test.dwelo.not_null_stg_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where last_modified is null



2020-10-21 23:52:28.969761 (Thread-1): On test.dwelo.not_null_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where user_id is null



2020-10-21 23:52:29.189195 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]')
2020-10-21 23:52:29.448183 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-21 23:52:29.493011 (Thread-4): finished collecting timing info
2020-10-21 23:52:29.497739 (Thread-4): 23:52:29 | 17 of 35 FAIL 101 not_null_stg_commands_user_id...................... [FAIL 101 in 1.73s]
2020-10-21 23:52:29.500237 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-21 23:52:29.503775 (Thread-4): Began running node test.dwelo.not_null_stg_users_username
2020-10-21 23:52:29.506169 (Thread-4): 23:52:29 | 21 of 35 START test not_null_stg_users_username...................... [RUN]
2020-10-21 23:52:29.508364 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_username".
2020-10-21 23:52:29.510883 (Thread-4): Compiling test.dwelo.not_null_stg_users_username
2020-10-21 23:52:29.527233 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_users_username"
2020-10-21 23:52:29.533906 (Thread-4): finished collecting timing info
2020-10-21 23:52:29.538969 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:29.541105 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:29.826881 (Thread-3): finished collecting timing info
2020-10-21 23:52:29.830601 (Thread-3): 23:52:29 | 19 of 35 PASS not_null_stg_users_last_modified....................... [PASS in 1.73s]
2020-10-21 23:52:29.832361 (Thread-3): Finished running node test.dwelo.not_null_stg_users_last_modified
2020-10-21 23:52:29.834285 (Thread-3): Began running node test.dwelo.stg_commands_locked_state
2020-10-21 23:52:29.835940 (Thread-3): 23:52:29 | 22 of 35 START test stg_commands_locked_state........................ [RUN]
2020-10-21 23:52:29.838003 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-21 23:52:29.839984 (Thread-3): Compiling test.dwelo.stg_commands_locked_state
2020-10-21 23:52:29.862356 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-21 23:52:29.871130 (Thread-3): finished collecting timing info
2020-10-21 23:52:29.874571 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:29.876976 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:30.122143 (Thread-4): On test.dwelo.not_null_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where username is null



2020-10-21 23:52:30.447076 (Thread-3): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:52:30.539932 (Thread-2): finished collecting timing info
2020-10-21 23:52:30.547741 (Thread-2): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]

(job ID: 97733191-6e22-41ae-8a86-4362b824fb5d)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-21 23:52:30.553201 (Thread-2): 23:52:30 | 18 of 35 ERROR not_null_stg_users_date_registered.................... [ERROR in 2.51s]
2020-10-21 23:52:30.555984 (Thread-2): Finished running node test.dwelo.not_null_stg_users_date_registered
2020-10-21 23:52:30.559362 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-21 23:52:30.562265 (Thread-2): 23:52:30 | 23 of 35 START test stg_commands_pin_assignment...................... [RUN]
2020-10-21 23:52:30.565682 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-21 23:52:30.567895 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-21 23:52:30.576740 (Thread-2): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56160), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:30.582802 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52222), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:30.585220 (Thread-2): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56168), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:30.587674 (Thread-2): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56166), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:30.594713 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52226), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:30.597500 (Thread-2): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52228), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:30.610888 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-21 23:52:30.623084 (Thread-2): finished collecting timing info
2020-10-21 23:52:30.626473 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:30.628767 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:30.757015 (Thread-1): finished collecting timing info
2020-10-21 23:52:30.760995 (Thread-1): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 83c11fa7-02a4-40a9-aeef-9035d1c33a89)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-21 23:52:30.763580 (Thread-1): 23:52:30 | 20 of 35 ERROR not_null_stg_users_user_id............................ [ERROR in 2.45s]
2020-10-21 23:52:30.765645 (Thread-1): Finished running node test.dwelo.not_null_stg_users_user_id
2020-10-21 23:52:30.767518 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-21 23:52:30.769657 (Thread-1): 23:52:30 | 24 of 35 START test stg_commands_switch_state........................ [RUN]
2020-10-21 23:52:30.772112 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-21 23:52:30.773748 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-21 23:52:30.787166 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-21 23:52:30.794110 (Thread-1): finished collecting timing info
2020-10-21 23:52:30.796462 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:30.798290 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:30.927329 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-21 23:52:31.177750 (Thread-4): finished collecting timing info
2020-10-21 23:52:31.181005 (Thread-4): 23:52:31 | 21 of 35 PASS not_null_stg_users_username............................ [PASS in 1.67s]
2020-10-21 23:52:31.183237 (Thread-4): Finished running node test.dwelo.not_null_stg_users_username
2020-10-21 23:52:31.186269 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:52:31.188296 (Thread-4): 23:52:31 | 25 of 35 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-21 23:52:31.191133 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-21 23:52:31.193443 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:52:31.208894 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-21 23:52:31.219910 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:52:31.220144 (Thread-4): finished collecting timing info
2020-10-21 23:52:31.227507 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:31.230050 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:31.394371 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:52:31.468078 (Thread-3): finished collecting timing info
2020-10-21 23:52:31.471571 (Thread-3): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 935a52e6-8410-4c21-a7aa-cb84b25669a2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-21 23:52:31.474729 (Thread-3): 23:52:31 | 22 of 35 ERROR stg_commands_locked_state............................. [ERROR in 1.64s]
2020-10-21 23:52:31.476780 (Thread-3): Finished running node test.dwelo.stg_commands_locked_state
2020-10-21 23:52:31.479345 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:52:31.483296 (Thread-3): 23:52:31 | 26 of 35 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-21 23:52:31.500297 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-21 23:52:31.502705 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:52:31.524370 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-21 23:52:31.534912 (Thread-3): finished collecting timing info
2020-10-21 23:52:31.540052 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:31.544877 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:31.631774 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-21 23:52:31.801981 (Thread-4): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:52:31.875947 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-21 23:52:32.124619 (Thread-3): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-21 23:52:32.355283 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-21 23:52:32.613055 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-21 23:52:32.913241 (Thread-2): finished collecting timing info
2020-10-21 23:52:32.918275 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: c7c7f022-21bc-4552-b964-b26f32bea222)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-21 23:52:32.921661 (Thread-2): 23:52:32 | 23 of 35 ERROR stg_commands_pin_assignment........................... [ERROR in 2.36s]
2020-10-21 23:52:32.923696 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-21 23:52:32.927016 (Thread-2): Began running node test.dwelo.unique_dim_users_user_id
2020-10-21 23:52:32.929957 (Thread-2): 23:52:32 | 27 of 35 START test unique_dim_users_user_id......................... [RUN]
2020-10-21 23:52:32.932756 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_dim_users_user_id".
2020-10-21 23:52:32.935246 (Thread-2): Compiling test.dwelo.unique_dim_users_user_id
2020-10-21 23:52:32.952640 (Thread-2): Writing injected SQL for node "test.dwelo.unique_dim_users_user_id"
2020-10-21 23:52:32.958575 (Thread-2): finished collecting timing info
2020-10-21 23:52:32.960871 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:32.964392 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:33.012767 (Thread-4): finished collecting timing info
2020-10-21 23:52:33.016970 (Thread-4): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 9c3f15fd-2e55-4ee2-ac89-d897c7480fe3)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-21 23:52:33.019253 (Thread-4): 23:52:33 | 25 of 35 ERROR stg_commands_thermostat_mode.......................... [ERROR in 1.83s]
2020-10-21 23:52:33.020863 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-21 23:52:33.022906 (Thread-4): Began running node test.dwelo.unique_dim_users_username
2020-10-21 23:52:33.025002 (Thread-4): 23:52:33 | 28 of 35 START test unique_dim_users_username........................ [RUN]
2020-10-21 23:52:33.027581 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_dim_users_username".
2020-10-21 23:52:33.030084 (Thread-4): Compiling test.dwelo.unique_dim_users_username
2020-10-21 23:52:33.048376 (Thread-4): Writing injected SQL for node "test.dwelo.unique_dim_users_username"
2020-10-21 23:52:33.056553 (Thread-4): finished collecting timing info
2020-10-21 23:52:33.060413 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:33.063985 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:33.105809 (Thread-1): finished collecting timing info
2020-10-21 23:52:33.110053 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: baf3149d-4e12-498d-98be-720d58dd913d)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-21 23:52:33.114722 (Thread-1): 23:52:33 | 24 of 35 ERROR stg_commands_switch_state............................. [ERROR in 2.34s]
2020-10-21 23:52:33.117648 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-21 23:52:33.121385 (Thread-1): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:52:33.124158 (Thread-1): 23:52:33 | 29 of 35 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-21 23:52:33.130126 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-21 23:52:33.133398 (Thread-1): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:52:33.152280 (Thread-1): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-21 23:52:33.157954 (Thread-1): finished collecting timing info
2020-10-21 23:52:33.160613 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:33.163170 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:33.536215 (Thread-3): finished collecting timing info
2020-10-21 23:52:33.539549 (Thread-3): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: aea2750f-1e75-4c62-b970-524d5fc89c1b)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-21 23:52:33.542411 (Thread-3): 23:52:33 | 26 of 35 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 2.04s]
2020-10-21 23:52:33.544481 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-21 23:52:33.546508 (Thread-3): Began running node test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:33.548568 (Thread-3): 23:52:33 | 30 of 35 START test unique_met_daily_command_count_by_user_id_user_id [RUN]
2020-10-21 23:52:33.550959 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_met_daily_command_count_by_user_id_user_id".
2020-10-21 23:52:33.552680 (Thread-3): Compiling test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:33.563754 (Thread-3): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52246), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:33.565735 (Thread-3): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52250), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:33.568183 (Thread-3): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56184), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:33.570514 (Thread-3): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56188), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:33.572796 (Thread-3): unclosed <socket.socket fd=31, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56192), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:33.575009 (Thread-3): unclosed <socket.socket fd=32, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56196), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:33.577655 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52254), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:33.579953 (Thread-3): unclosed <socket.socket fd=30, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52258), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:33.592354 (Thread-3): Writing injected SQL for node "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"
2020-10-21 23:52:33.597903 (Thread-3): finished collecting timing info
2020-10-21 23:52:33.600156 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:33.602395 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:33.625256 (Thread-2): On test.dwelo.unique_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`dim_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:52:33.724002 (Thread-4): On test.dwelo.unique_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`dim_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:52:33.835273 (Thread-1): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.135207 (Thread-4): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`dim_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.137190 (Thread-4): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 77cd1c32-0c7a-414f-aa56-b538867f13b2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:34.138864 (Thread-4): finished collecting timing info
2020-10-21 23:52:34.141200 (Thread-4): Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 77cd1c32-0c7a-414f-aa56-b538867f13b2)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 77cd1c32-0c7a-414f-aa56-b538867f13b2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 77cd1c32-0c7a-414f-aa56-b538867f13b2)
2020-10-21 23:52:34.143250 (Thread-4): 23:52:34 | 28 of 35 ERROR unique_dim_users_username............................. [ERROR in 1.12s]
2020-10-21 23:52:34.144915 (Thread-4): Finished running node test.dwelo.unique_dim_users_username
2020-10-21 23:52:34.147129 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:52:34.149040 (Thread-4): 23:52:34 | 31 of 35 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-21 23:52:34.151137 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-21 23:52:34.152684 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:52:34.167908 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-21 23:52:34.175866 (Thread-4): finished collecting timing info
2020-10-21 23:52:34.178168 (Thread-4): Opening a new connection, currently in state closed
2020-10-21 23:52:34.180289 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:34.211360 (Thread-2): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`dim_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.215730 (Thread-2): 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 31e1cec3-e8ec-453a-9221-065b31433359)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:34.218899 (Thread-2): finished collecting timing info
2020-10-21 23:52:34.223223 (Thread-2): Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 31e1cec3-e8ec-453a-9221-065b31433359)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US

(job ID: 31e1cec3-e8ec-453a-9221-065b31433359)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
  
  (job ID: 31e1cec3-e8ec-453a-9221-065b31433359)
2020-10-21 23:52:34.226132 (Thread-2): 23:52:34 | 27 of 35 ERROR unique_dim_users_user_id.............................. [ERROR in 1.29s]
2020-10-21 23:52:34.228153 (Thread-2): Finished running node test.dwelo.unique_dim_users_user_id
2020-10-21 23:52:34.231501 (Thread-2): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:52:34.234488 (Thread-2): 23:52:34 | 32 of 35 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-21 23:52:34.238599 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-21 23:52:34.241587 (Thread-2): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:52:34.260699 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-21 23:52:34.267751 (Thread-2): finished collecting timing info
2020-10-21 23:52:34.272014 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:34.275897 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:34.284730 (Thread-3): On test.dwelo.unique_met_daily_command_count_by_user_id_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.300860 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [15:11]')
2020-10-21 23:52:34.697369 (Thread-3): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.699807 (Thread-3): 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: ec098669-cf45-403b-a821-0e1b5ac391b0)

                                                                       -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2020-10-21 23:52:34.701784 (Thread-3): finished collecting timing info
2020-10-21 23:52:34.704594 (Thread-3): Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: ec098669-cf45-403b-a821-0e1b5ac391b0)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US

(job ID: ec098669-cf45-403b-a821-0e1b5ac391b0)

                                                                       -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_user_id_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
  404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
  
  (job ID: ec098669-cf45-403b-a821-0e1b5ac391b0)
2020-10-21 23:52:34.707482 (Thread-3): 23:52:34 | 30 of 35 ERROR unique_met_daily_command_count_by_user_id_user_id..... [ERROR in 1.16s]
2020-10-21 23:52:34.709554 (Thread-3): Finished running node test.dwelo.unique_met_daily_command_count_by_user_id_user_id
2020-10-21 23:52:34.713881 (Thread-3): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:52:34.716139 (Thread-3): 23:52:34 | 33 of 35 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-21 23:52:34.719059 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-21 23:52:34.721561 (Thread-3): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:52:34.741774 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-21 23:52:34.749283 (Thread-3): finished collecting timing info
2020-10-21 23:52:34.753288 (Thread-3): Opening a new connection, currently in state closed
2020-10-21 23:52:34.756239 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:34.862207 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:52:34.904930 (Thread-2): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:52:35.369775 (Thread-3): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-21 23:52:35.556324 (Thread-1): finished collecting timing info
2020-10-21 23:52:35.560259 (Thread-1): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [15:11]

(job ID: d2d1a821-9505-4f91-8ec1-c8955ab68db3)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-21 23:52:35.563418 (Thread-1): 23:52:35 | 29 of 35 ERROR unique_fct_command_statuses_command_uuid.............. [ERROR in 2.43s]
2020-10-21 23:52:35.565290 (Thread-1): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-21 23:52:35.568009 (Thread-1): Began running node test.dwelo.unique_stg_users_user_id
2020-10-21 23:52:35.571034 (Thread-1): 23:52:35 | 34 of 35 START test unique_stg_users_user_id......................... [RUN]
2020-10-21 23:52:35.572995 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_users_user_id".
2020-10-21 23:52:35.575423 (Thread-1): Compiling test.dwelo.unique_stg_users_user_id
2020-10-21 23:52:35.595338 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_users_user_id"
2020-10-21 23:52:35.603700 (Thread-1): finished collecting timing info
2020-10-21 23:52:35.606764 (Thread-1): Opening a new connection, currently in state closed
2020-10-21 23:52:35.609440 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:36.072035 (Thread-2): finished collecting timing info
2020-10-21 23:52:36.075207 (Thread-2): 23:52:36 | 32 of 35 PASS unique_stg_command_results_command_uuid................ [PASS in 1.84s]
2020-10-21 23:52:36.077058 (Thread-2): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-21 23:52:36.079425 (Thread-2): Began running node test.dwelo.unique_stg_users_username
2020-10-21 23:52:36.081444 (Thread-2): 23:52:36 | 35 of 35 START test unique_stg_users_username........................ [RUN]
2020-10-21 23:52:36.083598 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_users_username".
2020-10-21 23:52:36.085704 (Thread-2): Compiling test.dwelo.unique_stg_users_username
2020-10-21 23:52:36.090513 (Thread-4): finished collecting timing info
2020-10-21 23:52:36.106158 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_users_username"
2020-10-21 23:52:36.107845 (Thread-4): 23:52:36 | 31 of 35 PASS unique_stg_command_actives_command_uuid................ [PASS in 1.96s]
2020-10-21 23:52:36.113221 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-21 23:52:36.115699 (Thread-2): finished collecting timing info
2020-10-21 23:52:36.118610 (Thread-2): Opening a new connection, currently in state closed
2020-10-21 23:52:36.120658 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-21 23:52:36.245809 (Thread-1): On test.dwelo.unique_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`stg_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-21 23:52:36.490495 (Thread-3): finished collecting timing info
2020-10-21 23:52:36.494450 (Thread-3): 23:52:36 | 33 of 35 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 1.78s]
2020-10-21 23:52:36.496679 (Thread-3): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-21 23:52:36.741279 (Thread-2): On test.dwelo.unique_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`stg_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-21 23:52:36.803824 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-21 23:52:37.963398 (Thread-2): finished collecting timing info
2020-10-21 23:52:37.968183 (Thread-2): 23:52:37 | 35 of 35 PASS unique_stg_users_username.............................. [PASS in 1.88s]
2020-10-21 23:52:37.970996 (Thread-2): Finished running node test.dwelo.unique_stg_users_username
2020-10-21 23:52:38.117831 (Thread-1): finished collecting timing info
2020-10-21 23:52:38.122974 (Thread-1): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: 072e0819-7613-4eba-8c4a-89f95906680f)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-21 23:52:38.126533 (Thread-1): 23:52:38 | 34 of 35 ERROR unique_stg_users_user_id.............................. [ERROR in 2.55s]
2020-10-21 23:52:38.128930 (Thread-1): Finished running node test.dwelo.unique_stg_users_user_id
2020-10-21 23:52:38.138658 (MainThread): Acquiring new bigquery connection "master".
2020-10-21 23:52:38.142011 (MainThread): 23:52:38 | 
2020-10-21 23:52:38.144669 (MainThread): 23:52:38 | Finished running 35 tests in 18.01s.
2020-10-21 23:52:38.147887 (MainThread): Connection 'master' was properly closed.
2020-10-21 23:52:38.152189 (MainThread): Connection 'test.dwelo.unique_stg_users_user_id' was properly closed.
2020-10-21 23:52:38.154967 (MainThread): Connection 'test.dwelo.unique_stg_users_username' was properly closed.
2020-10-21 23:52:38.157851 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-21 23:52:38.159959 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-21 23:52:38.207332 (MainThread): unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56212), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:38.212602 (MainThread): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52274), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:38.216973 (MainThread): unclosed <socket.socket fd=37, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56220), raddr=('172.217.14.74', 443)>
2020-10-21 23:52:38.219871 (MainThread): unclosed <socket.socket fd=33, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 52280), raddr=('172.217.11.170', 443)>
2020-10-21 23:52:38.333631 (MainThread): 
2020-10-21 23:52:38.335301 (MainThread): Completed with 22 errors and 0 warnings:
2020-10-21 23:52:38.337699 (MainThread): 
2020-10-21 23:52:38.339471 (MainThread): Runtime Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
2020-10-21 23:52:38.341258 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.343163 (MainThread):   
2020-10-21 23:52:38.345026 (MainThread):   (job ID: 37c48fd1-b10d-4e3d-98dc-c14f2122feee)
2020-10-21 23:52:38.346850 (MainThread): 
2020-10-21 23:52:38.348696 (MainThread): Runtime Error in test not_null_dim_users_username (models/marts/schema.yml)
2020-10-21 23:52:38.350522 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.352645 (MainThread):   
2020-10-21 23:52:38.355969 (MainThread):   (job ID: 51007ca4-27e2-477e-a149-640267f08a74)
2020-10-21 23:52:38.358555 (MainThread): 
2020-10-21 23:52:38.361294 (MainThread): Runtime Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
2020-10-21 23:52:38.363373 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.365219 (MainThread):   
2020-10-21 23:52:38.368165 (MainThread):   (job ID: 01413c1a-3db8-47e2-9ed9-a16490a3cf1f)
2020-10-21 23:52:38.370430 (MainThread): 
2020-10-21 23:52:38.372296 (MainThread): Runtime Error in test not_null_dim_users_user_id (models/marts/schema.yml)
2020-10-21 23:52:38.374276 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.376508 (MainThread):   
2020-10-21 23:52:38.378965 (MainThread):   (job ID: 5dbf2ff5-d0ee-494e-9291-58ec4c9268b3)
2020-10-21 23:52:38.381186 (MainThread): 
2020-10-21 23:52:38.383279 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_num_of_commands (models/marts/schema.yml)
2020-10-21 23:52:38.385040 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:52:38.387709 (MainThread):   
2020-10-21 23:52:38.393200 (MainThread):   (job ID: f58a3d00-f813-48fd-b82f-5da40012fc23)
2020-10-21 23:52:38.395543 (MainThread): 
2020-10-21 23:52:38.397920 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
2020-10-21 23:52:38.400596 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:52:38.402764 (MainThread):   
2020-10-21 23:52:38.404684 (MainThread):   (job ID: 0ad17b5c-0324-46ed-a3e7-4c14039266d7)
2020-10-21 23:52:38.407150 (MainThread): 
2020-10-21 23:52:38.409592 (MainThread): Runtime Error in test not_null_met_daily_command_count_by_user_id_timestamp_date (models/marts/schema.yml)
2020-10-21 23:52:38.411719 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:52:38.413835 (MainThread):   
2020-10-21 23:52:38.416476 (MainThread):   (job ID: 5bb939f2-759f-4b0b-ac98-7f0fd5638718)
2020-10-21 23:52:38.418492 (MainThread): 
2020-10-21 23:52:38.420245 (MainThread): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-21 23:52:38.422801 (MainThread):   Unrecognized name: command_uuid at [10:7]
2020-10-21 23:52:38.425464 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-21 23:52:38.427277 (MainThread): 
2020-10-21 23:52:38.429365 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-21 23:52:38.431091 (MainThread):   Got 101 results, expected 0.
2020-10-21 23:52:38.432909 (MainThread): 
2020-10-21 23:52:38.434807 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-21 23:52:38.436789 (MainThread): 
2020-10-21 23:52:38.438558 (MainThread): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
2020-10-21 23:52:38.440407 (MainThread):   Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
2020-10-21 23:52:38.442224 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-21 23:52:38.443962 (MainThread): 
2020-10-21 23:52:38.445560 (MainThread): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
2020-10-21 23:52:38.447279 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-21 23:52:38.448826 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-21 23:52:38.450684 (MainThread): 
2020-10-21 23:52:38.452433 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-21 23:52:38.454022 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-21 23:52:38.456025 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-21 23:52:38.458271 (MainThread): 
2020-10-21 23:52:38.460496 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-21 23:52:38.463563 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-21 23:52:38.466031 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-21 23:52:38.468646 (MainThread): 
2020-10-21 23:52:38.470876 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-21 23:52:38.472620 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-21 23:52:38.474651 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-21 23:52:38.476588 (MainThread): 
2020-10-21 23:52:38.479124 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-21 23:52:38.481109 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-21 23:52:38.483124 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-21 23:52:38.484794 (MainThread): 
2020-10-21 23:52:38.486499 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-21 23:52:38.488108 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-21 23:52:38.490195 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-21 23:52:38.492650 (MainThread): 
2020-10-21 23:52:38.494702 (MainThread): Runtime Error in test unique_dim_users_username (models/marts/schema.yml)
2020-10-21 23:52:38.496492 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.498185 (MainThread):   
2020-10-21 23:52:38.499840 (MainThread):   (job ID: 77cd1c32-0c7a-414f-aa56-b538867f13b2)
2020-10-21 23:52:38.501692 (MainThread): 
2020-10-21 23:52:38.503629 (MainThread): Runtime Error in test unique_dim_users_user_id (models/marts/schema.yml)
2020-10-21 23:52:38.505264 (MainThread):   404 Not found: Table analytics-interview:dev_sam.dim_users was not found in location US
2020-10-21 23:52:38.506996 (MainThread):   
2020-10-21 23:52:38.508965 (MainThread):   (job ID: 31e1cec3-e8ec-453a-9221-065b31433359)
2020-10-21 23:52:38.510871 (MainThread): 
2020-10-21 23:52:38.512533 (MainThread): Runtime Error in test unique_met_daily_command_count_by_user_id_user_id (models/marts/schema.yml)
2020-10-21 23:52:38.514868 (MainThread):   404 Not found: Table analytics-interview:dev_sam.met_daily_command_count_by_user_id was not found in location US
2020-10-21 23:52:38.516289 (MainThread):   
2020-10-21 23:52:38.517808 (MainThread):   (job ID: ec098669-cf45-403b-a821-0e1b5ac391b0)
2020-10-21 23:52:38.519436 (MainThread): 
2020-10-21 23:52:38.521000 (MainThread): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-21 23:52:38.522694 (MainThread):   Unrecognized name: command_uuid at [15:11]
2020-10-21 23:52:38.524609 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-21 23:52:38.526648 (MainThread): 
2020-10-21 23:52:38.528627 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-21 23:52:38.530555 (MainThread):   Got 2 results, expected 0.
2020-10-21 23:52:38.532618 (MainThread): 
2020-10-21 23:52:38.534605 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-21 23:52:38.536752 (MainThread): 
2020-10-21 23:52:38.538676 (MainThread): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
2020-10-21 23:52:38.540403 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-21 23:52:38.542187 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-21 23:52:38.544405 (MainThread): 
Done. PASS=13 WARN=0 ERROR=22 SKIP=0 TOTAL=35
2020-10-21 23:52:38.546934 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffd919ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffd97ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faffc35dfa0>]}
2020-10-21 23:52:38.549864 (MainThread): Flushing usage events
2020-10-22 02:02:59.094700 (MainThread): Running with dbt=0.18.0
2020-10-22 02:02:59.362732 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-22 02:02:59.370447 (MainThread): Tracking: tracking
2020-10-22 02:02:59.374334 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b85547e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8481ec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8481ebe0>]}
2020-10-22 02:02:59.412012 (MainThread): Partial parsing not enabled
2020-10-22 02:02:59.416745 (MainThread): Parsing macros/etc.sql
2020-10-22 02:02:59.420366 (MainThread): Parsing macros/catalog.sql
2020-10-22 02:02:59.433605 (MainThread): Parsing macros/adapters.sql
2020-10-22 02:02:59.467931 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 02:02:59.474729 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 02:02:59.496388 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 02:02:59.518183 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 02:02:59.522767 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 02:02:59.530734 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 02:02:59.537662 (MainThread): Parsing macros/core.sql
2020-10-22 02:02:59.545276 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 02:02:59.561723 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 02:02:59.571096 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 02:02:59.584859 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 02:02:59.611981 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 02:02:59.640153 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 02:02:59.645814 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 02:02:59.699123 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 02:02:59.711193 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 02:02:59.715816 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 02:02:59.728020 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 02:02:59.765761 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 02:02:59.846980 (MainThread): Parsing macros/etc/query.sql
2020-10-22 02:02:59.850807 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 02:02:59.854891 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 02:02:59.858583 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 02:02:59.876083 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 02:02:59.884997 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 02:02:59.888461 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 02:02:59.893169 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 02:02:59.897162 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 02:02:59.902996 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 02:02:59.917655 (MainThread): Partial parsing not enabled
2020-10-22 02:03:00.015503 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 02:03:00.046282 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 02:03:00.062591 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 02:03:00.078740 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 02:03:00.098795 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 02:03:00.117413 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 02:03:00.136663 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 02:03:00.171495 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 02:03:00.191778 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 02:03:00.210168 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 02:03:00.228333 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 02:03:00.245681 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 02:03:01.269684 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 02:03:01.274450 (MainThread): 
2020-10-22 02:03:01.276605 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 02:03:01.288708 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-22 02:03:01.290617 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-22 02:03:01.293349 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:02.349384 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 02:03:02.352113 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-22 02:03:02.355112 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:02.903445 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 02:03:03.312202 (MainThread): 02:03:03 | Concurrency: 4 threads (target='dev')
2020-10-22 02:03:03.314668 (MainThread): 02:03:03 | 
2020-10-22 02:03:03.339893 (Thread-1): Began running node model.dwelo.dim_users
2020-10-22 02:03:03.340480 (Thread-2): Began running node model.dwelo.fct_command_statuses
2020-10-22 02:03:03.341067 (Thread-3): Began running node model.dwelo.met_daily_command_count_by_user_id
2020-10-22 02:03:03.341724 (Thread-4): Began running node model.dwelo.stg_command_actives
2020-10-22 02:03:03.344340 (Thread-1): 02:03:03 | 1 of 7 START view model dev_sam.dim_users............................ [RUN]
2020-10-22 02:03:03.346974 (Thread-2): 02:03:03 | 2 of 7 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-22 02:03:03.355789 (Thread-2): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 02:03:03.352256 (Thread-4): 02:03:03 | 4 of 7 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-22 02:03:03.354534 (Thread-1): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 02:03:03.349674 (Thread-3): 02:03:03 | 3 of 7 START view model dev_sam.met_daily_command_count_by_user_id... [RUN]
2020-10-22 02:03:03.357423 (Thread-2): Compiling model.dwelo.fct_command_statuses
2020-10-22 02:03:03.360803 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 02:03:03.361716 (Thread-1): Compiling model.dwelo.dim_users
2020-10-22 02:03:03.365530 (Thread-3): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 02:03:03.383429 (Thread-4): Compiling model.dwelo.stg_command_actives
2020-10-22 02:03:03.415255 (Thread-2): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-22 02:03:03.419646 (Thread-1): Writing injected SQL for node "model.dwelo.dim_users"
2020-10-22 02:03:03.420932 (Thread-3): Compiling model.dwelo.met_daily_command_count_by_user_id
2020-10-22 02:03:03.438657 (Thread-4): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-22 02:03:03.454003 (Thread-3): Writing injected SQL for node "model.dwelo.met_daily_command_count_by_user_id"
2020-10-22 02:03:03.456160 (Thread-2): finished collecting timing info
2020-10-22 02:03:03.459552 (Thread-1): finished collecting timing info
2020-10-22 02:03:03.465462 (Thread-2): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56244), raddr=('172.217.14.74', 443)>
2020-10-22 02:03:03.479698 (Thread-3): finished collecting timing info
2020-10-22 02:03:03.485759 (Thread-4): finished collecting timing info
2020-10-22 02:03:03.491741 (Thread-2): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 46950), raddr=('142.250.68.74', 443)>
2020-10-22 02:03:03.530573 (Thread-3): Writing runtime SQL for node "model.dwelo.met_daily_command_count_by_user_id"
2020-10-22 02:03:03.532540 (Thread-1): Writing runtime SQL for node "model.dwelo.dim_users"
2020-10-22 02:03:03.539472 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-22 02:03:03.550185 (Thread-2): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-22 02:03:03.558480 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 02:03:03.559914 (Thread-4): Opening a new connection, currently in state init
2020-10-22 02:03:03.561256 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:03.562888 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:03.564209 (Thread-3): Opening a new connection, currently in state init
2020-10-22 02:03:03.568493 (Thread-2): Opening a new connection, currently in state init
2020-10-22 02:03:03.576540 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:03.577558 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:04.179112 (Thread-1): On model.dwelo.dim_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.dim_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`dim_users`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-22 02:03:04.183639 (Thread-4): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-22 02:03:04.207305 (Thread-2): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-22 02:03:04.227021 (Thread-3): On model.dwelo.met_daily_command_count_by_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.met_daily_command_count_by_user_id"} */


  create or replace view `analytics-interview`.`dev_sam`.`met_daily_command_count_by_user_id`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-22 02:03:05.248563 (Thread-2): finished collecting timing info
2020-10-22 02:03:05.251863 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b846bb250>]}
2020-10-22 02:03:05.255321 (Thread-2): 02:03:05 | 2 of 7 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 1.90s]
2020-10-22 02:03:05.257074 (Thread-2): Finished running node model.dwelo.fct_command_statuses
2020-10-22 02:03:05.259407 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-22 02:03:05.262472 (Thread-2): 02:03:05 | 5 of 7 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-22 02:03:05.264744 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 02:03:05.266348 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-22 02:03:05.283178 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-22 02:03:05.291908 (Thread-2): finished collecting timing info
2020-10-22 02:03:05.300406 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-22 02:03:05.306455 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 02:03:05.308067 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:05.322978 (Thread-1): finished collecting timing info
2020-10-22 02:03:05.329079 (Thread-4): finished collecting timing info
2020-10-22 02:03:05.331508 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b845dce20>]}
2020-10-22 02:03:05.334266 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b83b5a310>]}
2020-10-22 02:03:05.337099 (Thread-1): 02:03:05 | 1 of 7 OK created view model dev_sam.dim_users....................... [CREATE VIEW in 1.98s]
2020-10-22 02:03:05.339847 (Thread-4): 02:03:05 | 4 of 7 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.97s]
2020-10-22 02:03:05.341544 (Thread-1): Finished running node model.dwelo.dim_users
2020-10-22 02:03:05.344310 (Thread-4): Finished running node model.dwelo.stg_command_actives
2020-10-22 02:03:05.346708 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-22 02:03:05.354434 (Thread-1): 02:03:05 | 6 of 7 START view model dev_sam.stg_commands......................... [RUN]
2020-10-22 02:03:05.357650 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 02:03:05.363253 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-22 02:03:05.349830 (Thread-4): Began running node model.dwelo.stg_users
2020-10-22 02:03:05.394484 (Thread-4): 02:03:05 | 7 of 7 START view model dev_sam.stg_users............................ [RUN]
2020-10-22 02:03:05.412125 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-22 02:03:05.413584 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 02:03:05.416681 (Thread-4): Compiling model.dwelo.stg_users
2020-10-22 02:03:05.443735 (Thread-4): Writing injected SQL for node "model.dwelo.stg_users"
2020-10-22 02:03:05.452429 (Thread-3): finished collecting timing info
2020-10-22 02:03:05.456743 (Thread-1): finished collecting timing info
2020-10-22 02:03:05.460310 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b845ea970>]}
2020-10-22 02:03:05.470878 (Thread-4): finished collecting timing info
2020-10-22 02:03:05.479309 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-22 02:03:05.482403 (Thread-3): 02:03:05 | 3 of 7 OK created view model dev_sam.met_daily_command_count_by_user_id [CREATE VIEW in 2.10s]
2020-10-22 02:03:05.490529 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_users"
2020-10-22 02:03:05.494193 (Thread-3): Finished running node model.dwelo.met_daily_command_count_by_user_id
2020-10-22 02:03:05.498183 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 02:03:05.500029 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 02:03:05.501250 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:05.503202 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 02:03:06.000856 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-22 02:03:06.102090 (Thread-4): On model.dwelo.stg_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
  OPTIONS()
  as with final as (
  select
    *
  from
    `analytics-interview`.`interview_source`.`raw_users`
)

select
  *
from
  final;


2020-10-22 02:03:06.107761 (Thread-4): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 46954), raddr=('142.250.68.74', 443)>
2020-10-22 02:03:06.110724 (Thread-4): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 46956), raddr=('142.250.68.74', 443)>
2020-10-22 02:03:06.113424 (Thread-4): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 46958), raddr=('142.250.68.74', 443)>
2020-10-22 02:03:06.116240 (Thread-4): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56256), raddr=('172.217.14.74', 443)>
2020-10-22 02:03:06.118840 (Thread-4): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56254), raddr=('172.217.14.74', 443)>
2020-10-22 02:03:06.121543 (Thread-4): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56258), raddr=('172.217.14.74', 443)>
2020-10-22 02:03:06.145094 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with command_events_deduped_across_source_files as (
    select * from (
        select
            EventType as event_type
            ,DateCreated as update_timestamp
            ,MapRevision as map_revision
            ,ItemKey as item_key
            ,ItemRevision as item_revision
            ,EndpointId as twilio_sync_endpoint_id
            ,ItemData as item_data
            ,MapUniqueName as  device_id

            ,first_value(_source_file) over (partition by MapUniqueName, MapRevision, DateCreated order by _source_file desc) as _source_file

            ,case
             when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
              then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
              when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
              then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
            end as event_timestamp
            ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              case
                when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
                then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
                else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
              end
              else null
            end as command_uuid

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.client')
              else null
            end as command_client
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT(ItemData, '$.desired_state')
              else null
            end as command_desired_state
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.user')
              else null
            end as command_user

            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.result')
              else null
            end as command_result
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
              else null
            end as command_failure_string
            ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
              JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
              else null
            end as command_node_id

            ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
         from `analytics-interview`.`interview_source`.`raw_sync_events`

    )
    group by
        event_type
        ,update_timestamp
        ,map_revision
        ,item_key
        ,item_revision
        ,twilio_sync_endpoint_id
        ,item_data
        ,device_id
        ,_source_file
        ,event_timestamp
        ,event_uuid
        ,command_uuid
        ,command_client
        ,command_desired_state
        ,command_user
        ,command_result
        ,command_failure_string
        ,command_node_id
        ,_uid
)
,commands  as (
    select
      command_uuid
      ,command_client
      ,JSON_EXTRACT_SCALAR(command_desired_state, '$[0]') as command
      ,command_desired_state
      ,command_user
      ,item_data

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      command_events_deduped_across_source_files
    where
      item_key = 'Command'
      and command_uuid is not null
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    commands
)

select *
from final;


2020-10-22 02:03:06.373876 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 46946), raddr=('142.250.68.74', 443)>
2020-10-22 02:03:06.377788 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56240), raddr=('172.217.14.74', 443)>
2020-10-22 02:03:06.862835 (Thread-2): finished collecting timing info
2020-10-22 02:03:06.866265 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b83b8ebb0>]}
2020-10-22 02:03:06.869472 (Thread-2): 02:03:06 | 5 of 7 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.60s]
2020-10-22 02:03:06.871192 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-22 02:03:07.010788 (Thread-1): finished collecting timing info
2020-10-22 02:03:07.013802 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b844b1a00>]}
2020-10-22 02:03:07.017227 (Thread-1): 02:03:07 | 6 of 7 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.66s]
2020-10-22 02:03:07.019184 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-22 02:03:07.090940 (Thread-4): finished collecting timing info
2020-10-22 02:03:07.094039 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43008019-6820-4990-bc69-ab23ab14e73d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b844610d0>]}
2020-10-22 02:03:07.097703 (Thread-4): 02:03:07 | 7 of 7 OK created view model dev_sam.stg_users....................... [CREATE VIEW in 1.68s]
2020-10-22 02:03:07.099433 (Thread-4): Finished running node model.dwelo.stg_users
2020-10-22 02:03:07.103414 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 02:03:07.105325 (MainThread): 02:03:07 | 
2020-10-22 02:03:07.107205 (MainThread): 02:03:07 | Finished running 7 view models in 5.83s.
2020-10-22 02:03:07.109463 (MainThread): Connection 'master' was properly closed.
2020-10-22 02:03:07.111345 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-22 02:03:07.113287 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-22 02:03:07.115176 (MainThread): Connection 'model.dwelo.stg_users' was properly closed.
2020-10-22 02:03:07.116799 (MainThread): Connection 'model.dwelo.met_daily_command_count_by_user_id' was properly closed.
2020-10-22 02:03:07.155016 (MainThread): 
2020-10-22 02:03:07.156571 (MainThread): Completed successfully
2020-10-22 02:03:07.159185 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2020-10-22 02:03:07.161520 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b8470db20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b844c8c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4b84781df0>]}
2020-10-22 02:03:07.163494 (MainThread): Flushing usage events
2020-10-22 23:24:39.168152 (MainThread): Running with dbt=0.18.0
2020-10-22 23:24:39.412379 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:24:39.420903 (MainThread): Tracking: tracking
2020-10-22 23:24:39.424842 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf50617c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf435af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf435aee0>]}
2020-10-22 23:24:39.468577 (MainThread): Partial parsing not enabled
2020-10-22 23:24:39.471901 (MainThread): Parsing macros/etc.sql
2020-10-22 23:24:39.475492 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:24:39.489146 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:24:39.523476 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:24:39.530412 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:24:39.548554 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:24:39.572119 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:24:39.576963 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:24:39.585032 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:24:39.591495 (MainThread): Parsing macros/core.sql
2020-10-22 23:24:39.598441 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:24:39.614661 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:24:39.624429 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:24:39.636175 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:24:39.662475 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:24:39.689946 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:24:39.694552 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:24:39.746310 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:24:39.758915 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:24:39.766499 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:24:39.778959 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:24:39.816375 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:24:39.897631 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:24:39.901122 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:24:39.904547 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:24:39.908266 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:24:39.924036 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:24:39.928654 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:24:39.931361 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:24:39.935912 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:24:39.939539 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:24:39.945252 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:24:39.957866 (MainThread): Partial parsing not enabled
2020-10-22 23:24:40.059755 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:24:40.092312 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:24:40.109497 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:24:40.125607 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:24:40.144957 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:24:40.167339 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:24:40.187630 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:24:40.223096 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:24:40.241477 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:24:40.259201 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:24:40.276351 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:24:40.294037 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:24:41.561022 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:24:41.565267 (MainThread): 
2020-10-22 23:24:41.567294 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:24:41.632995 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:24:41.637118 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:24:41.640562 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:47.356314 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:24:48.041301 (MainThread): 23:24:48 | Concurrency: 4 threads (target='dev')
2020-10-22 23:24:48.043743 (MainThread): 23:24:48 | 
2020-10-22 23:24:48.051682 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:24:48.052034 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:24:48.052333 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:24:48.052763 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:24:48.053963 (Thread-1): 23:24:48 | 1 of 10 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-22 23:24:48.055486 (Thread-2): 23:24:48 | 2 of 10 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-22 23:24:48.057067 (Thread-3): 23:24:48 | 3 of 10 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-22 23:24:48.058372 (Thread-4): 23:24:48 | 4 of 10 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-22 23:24:48.060497 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-22 23:24:48.063186 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-22 23:24:48.066475 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-22 23:24:48.069252 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-22 23:24:48.071722 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:24:48.074958 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:24:48.077292 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:24:48.079376 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:24:48.156801 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-22 23:24:48.164169 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-22 23:24:48.169290 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-22 23:24:48.182185 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-22 23:24:48.196242 (Thread-3): finished collecting timing info
2020-10-22 23:24:48.201056 (Thread-1): finished collecting timing info
2020-10-22 23:24:48.209061 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:24:48.204770 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:24:48.205675 (Thread-2): finished collecting timing info
2020-10-22 23:24:48.202100 (Thread-4): finished collecting timing info
2020-10-22 23:24:48.219019 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:24:48.215775 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:48.217286 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:24:48.213652 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:48.221312 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:48.228284 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:48.946821 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-22 23:24:48.948139 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-22 23:24:48.959278 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-22 23:24:48.959646 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-22 23:24:49.179992 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 47510), raddr=('142.250.68.74', 443)>
2020-10-22 23:24:49.182409 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56804), raddr=('172.217.14.74', 443)>
2020-10-22 23:24:50.790450 (Thread-3): finished collecting timing info
2020-10-22 23:24:50.800887 (Thread-3): 23:24:50 | 3 of 10 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.73s]
2020-10-22 23:24:50.809927 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:24:50.813651 (Thread-3): Began running node test.dwelo.stg_commands_locked_state
2020-10-22 23:24:50.817208 (Thread-3): 23:24:50 | 5 of 10 START test stg_commands_locked_state......................... [RUN]
2020-10-22 23:24:50.819921 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:24:50.822448 (Thread-3): Compiling test.dwelo.stg_commands_locked_state
2020-10-22 23:24:50.858298 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-22 23:24:50.872882 (Thread-3): finished collecting timing info
2020-10-22 23:24:50.875463 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:24:50.879502 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:50.903061 (Thread-2): finished collecting timing info
2020-10-22 23:24:50.908201 (Thread-2): 23:24:50 | 2 of 10 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.85s]
2020-10-22 23:24:50.910896 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:24:50.914670 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:24:50.916565 (Thread-2): 23:24:50 | 6 of 10 START test stg_commands_pin_assignment....................... [RUN]
2020-10-22 23:24:50.927540 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:24:50.931599 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-22 23:24:50.957423 (Thread-4): finished collecting timing info
2020-10-22 23:24:50.983794 (Thread-4): 23:24:50 | 4 of 10 FAIL 101 not_null_stg_commands_user_id....................... [FAIL 101 in 2.91s]
2020-10-22 23:24:51.003656 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:24:51.011610 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-22 23:24:51.017725 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-22 23:24:51.033347 (Thread-4): 23:24:51 | 7 of 10 START test stg_commands_switch_state......................... [RUN]
2020-10-22 23:24:51.038249 (Thread-2): finished collecting timing info
2020-10-22 23:24:51.044127 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:24:51.054153 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:24:51.067010 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:51.059019 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-22 23:24:51.121275 (Thread-1): finished collecting timing info
2020-10-22 23:24:51.137731 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-22 23:24:51.146890 (Thread-1): 23:24:51 | 1 of 10 PASS not_null_stg_commands__raw_desired_state................ [PASS in 3.09s]
2020-10-22 23:24:51.170747 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:24:51.176344 (Thread-4): finished collecting timing info
2020-10-22 23:24:51.180424 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:24:51.184101 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:24:51.189713 (Thread-1): 23:24:51 | 8 of 10 START test stg_commands_thermostat_mode...................... [RUN]
2020-10-22 23:24:51.195454 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:51.204160 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:24:51.229267 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:24:51.314600 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-22 23:24:51.347965 (Thread-1): finished collecting timing info
2020-10-22 23:24:51.360168 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:24:51.373819 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:52.284484 (Thread-3): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:24:52.420821 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:24:52.456891 (Thread-1): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:24:52.527924 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:24:52.943819 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-22 23:24:52.974225 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-22 23:24:53.118871 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-22 23:24:53.139639 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-22 23:24:54.186828 (Thread-3): finished collecting timing info
2020-10-22 23:24:54.190170 (Thread-3): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 77863b06-01ad-42d2-98e6-485d359d531e)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:24:54.195240 (Thread-3): 23:24:54 | 5 of 10 ERROR stg_commands_locked_state.............................. [ERROR in 3.38s]
2020-10-22 23:24:54.197075 (Thread-3): Finished running node test.dwelo.stg_commands_locked_state
2020-10-22 23:24:54.199879 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:24:54.202044 (Thread-3): 23:24:54 | 9 of 10 START test stg_commands_thermostat_setpoint.................. [RUN]
2020-10-22 23:24:54.203604 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:24:54.205512 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:24:54.220477 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-22 23:24:54.229866 (Thread-3): finished collecting timing info
2020-10-22 23:24:54.232072 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:24:54.234252 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:54.243267 (Thread-1): finished collecting timing info
2020-10-22 23:24:54.245794 (Thread-1): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: ffc8bc5e-a067-42a4-ba9d-72ce57792892)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:24:54.248272 (Thread-1): 23:24:54 | 8 of 10 ERROR stg_commands_thermostat_mode........................... [ERROR in 3.05s]
2020-10-22 23:24:54.250095 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:24:54.252152 (Thread-1): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:24:54.254076 (Thread-1): 23:24:54 | 10 of 10 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-22 23:24:54.256088 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-22 23:24:54.258230 (Thread-1): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:24:54.274871 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-22 23:24:54.282733 (Thread-1): finished collecting timing info
2020-10-22 23:24:54.285337 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:24:54.287561 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:24:54.395114 (Thread-2): finished collecting timing info
2020-10-22 23:24:54.397101 (Thread-4): finished collecting timing info
2020-10-22 23:24:54.402069 (Thread-4): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 68b5d530-2e84-47ae-aa19-2bd00e14a9e4)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:24:54.404304 (Thread-4): 23:24:54 | 7 of 10 ERROR stg_commands_switch_state.............................. [ERROR in 3.36s]
2020-10-22 23:24:54.405915 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-22 23:24:54.399023 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: b93394d6-a66b-431a-92ce-08b2a19992c7)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:24:54.410848 (Thread-2): 23:24:54 | 6 of 10 ERROR stg_commands_pin_assignment............................ [ERROR in 3.49s]
2020-10-22 23:24:54.412668 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:24:54.990487 (Thread-3): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:24:55.029966 (Thread-1): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:24:55.610219 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-22 23:24:56.186219 (Thread-3): finished collecting timing info
2020-10-22 23:24:56.190061 (Thread-3): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: d9394c7e-d3d3-436a-b807-97f16c831791)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:24:56.192694 (Thread-3): 23:24:56 | 9 of 10 ERROR stg_commands_thermostat_setpoint....................... [ERROR in 1.99s]
2020-10-22 23:24:56.194939 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:24:57.373321 (Thread-1): finished collecting timing info
2020-10-22 23:24:57.377553 (Thread-1): 23:24:57 | 10 of 10 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 3.12s]
2020-10-22 23:24:57.380593 (Thread-1): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:24:57.386508 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:24:57.388893 (MainThread): 23:24:57 | 
2020-10-22 23:24:57.390897 (MainThread): 23:24:57 | Finished running 10 tests in 15.82s.
2020-10-22 23:24:57.392895 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:24:57.394591 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-22 23:24:57.396454 (MainThread): Connection 'test.dwelo.stg_commands_pin_assignment' was properly closed.
2020-10-22 23:24:57.398041 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-22 23:24:57.399621 (MainThread): Connection 'test.dwelo.stg_commands_switch_state' was properly closed.
2020-10-22 23:24:57.445639 (MainThread): 
2020-10-22 23:24:57.447597 (MainThread): Completed with 7 errors and 0 warnings:
2020-10-22 23:24:57.449706 (MainThread): 
2020-10-22 23:24:57.451851 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-22 23:24:57.454139 (MainThread):   Got 101 results, expected 0.
2020-10-22 23:24:57.456367 (MainThread): 
2020-10-22 23:24:57.458360 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-22 23:24:57.460733 (MainThread): 
2020-10-22 23:24:57.462965 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-22 23:24:57.465936 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-22 23:24:57.468616 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:24:57.470893 (MainThread): 
2020-10-22 23:24:57.472677 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-22 23:24:57.475628 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-22 23:24:57.479588 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:24:57.482856 (MainThread): 
2020-10-22 23:24:57.485040 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-22 23:24:57.488318 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-22 23:24:57.492126 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:24:57.495350 (MainThread): 
2020-10-22 23:24:57.497691 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-22 23:24:57.500267 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-22 23:24:57.502479 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:24:57.504482 (MainThread): 
2020-10-22 23:24:57.506972 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-22 23:24:57.510011 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-22 23:24:57.512740 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:24:57.515418 (MainThread): 
2020-10-22 23:24:57.517882 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-22 23:24:57.520521 (MainThread):   Got 2 results, expected 0.
2020-10-22 23:24:57.523195 (MainThread): 
2020-10-22 23:24:57.525599 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-22 23:24:57.528165 (MainThread): 
Done. PASS=3 WARN=0 ERROR=7 SKIP=0 TOTAL=10
2020-10-22 23:24:57.529968 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf41ef400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf400eee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbbf400e100>]}
2020-10-22 23:24:57.532077 (MainThread): Flushing usage events
2020-10-22 23:34:04.454642 (MainThread): Running with dbt=0.18.0
2020-10-22 23:34:04.685942 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:34:04.692300 (MainThread): Tracking: tracking
2020-10-22 23:34:04.696316 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba04073b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0336beb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0336be80>]}
2020-10-22 23:34:04.731933 (MainThread): Partial parsing not enabled
2020-10-22 23:34:04.735726 (MainThread): Parsing macros/etc.sql
2020-10-22 23:34:04.739207 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:34:04.752254 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:34:04.786486 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:34:04.794035 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:34:04.810813 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:34:04.832870 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:34:04.838126 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:34:04.846296 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:34:04.853179 (MainThread): Parsing macros/core.sql
2020-10-22 23:34:04.860273 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:34:04.876641 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:34:04.886266 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:34:04.898665 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:34:04.924731 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:34:04.952311 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:34:04.957094 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:34:05.009343 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:34:05.021619 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:34:05.026040 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:34:05.037831 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:34:05.074321 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:34:05.156061 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:34:05.160264 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:34:05.164540 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:34:05.168330 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:34:05.184057 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:34:05.189004 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:34:05.191929 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:34:05.196042 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:34:05.200073 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:34:05.205679 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:34:05.218838 (MainThread): Partial parsing not enabled
2020-10-22 23:34:05.312670 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:34:05.342707 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:34:05.359182 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:34:05.377664 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:34:05.398521 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:34:05.420531 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:34:05.443415 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:34:05.477428 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:34:05.497949 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:34:05.518496 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:34:05.538685 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:34:05.559383 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:34:06.616366 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:34:06.620637 (MainThread): 
2020-10-22 23:34:06.622730 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:34:06.689730 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:34:06.692616 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:34:06.695466 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:07.240609 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:34:07.892247 (MainThread): 23:34:07 | Concurrency: 4 threads (target='dev')
2020-10-22 23:34:07.895099 (MainThread): 23:34:07 | 
2020-10-22 23:34:07.902335 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:34:07.902613 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:34:07.903030 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:34:07.903427 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:34:07.904549 (Thread-1): 23:34:07 | 1 of 10 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-22 23:34:07.906346 (Thread-2): 23:34:07 | 2 of 10 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-22 23:34:07.908291 (Thread-3): 23:34:07 | 3 of 10 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-22 23:34:07.909846 (Thread-4): 23:34:07 | 4 of 10 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-22 23:34:07.912017 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-22 23:34:07.914045 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-22 23:34:07.916709 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-22 23:34:07.918906 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-22 23:34:07.921199 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:34:07.923112 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:34:07.924829 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:34:07.926566 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:34:07.978911 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-22 23:34:07.984486 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-22 23:34:07.997948 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-22 23:34:08.003611 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-22 23:34:08.009997 (Thread-2): finished collecting timing info
2020-10-22 23:34:08.014662 (Thread-3): finished collecting timing info
2020-10-22 23:34:08.016331 (Thread-1): finished collecting timing info
2020-10-22 23:34:08.019659 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:34:08.026105 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:34:08.026474 (Thread-4): finished collecting timing info
2020-10-22 23:34:08.028490 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:34:08.030861 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:08.032652 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:08.033658 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:34:08.035241 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:08.046160 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:08.640825 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-22 23:34:08.650925 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-22 23:34:08.652392 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-22 23:34:08.682513 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-22 23:34:08.862326 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56848), raddr=('172.217.14.74', 443)>
2020-10-22 23:34:08.864260 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56850), raddr=('172.217.14.74', 443)>
2020-10-22 23:34:10.036784 (Thread-4): finished collecting timing info
2020-10-22 23:34:10.042011 (Thread-4): 23:34:10 | 4 of 10 FAIL 101 not_null_stg_commands_user_id....................... [FAIL 101 in 2.12s]
2020-10-22 23:34:10.044369 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:34:10.047679 (Thread-4): Began running node test.dwelo.stg_commands_locked_state
2020-10-22 23:34:10.050229 (Thread-4): 23:34:10 | 5 of 10 START test stg_commands_locked_state......................... [RUN]
2020-10-22 23:34:10.052881 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:34:10.054883 (Thread-4): Compiling test.dwelo.stg_commands_locked_state
2020-10-22 23:34:10.084789 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-22 23:34:10.085413 (Thread-2): finished collecting timing info
2020-10-22 23:34:10.089184 (Thread-2): 23:34:10 | 2 of 10 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.18s]
2020-10-22 23:34:10.090919 (Thread-4): finished collecting timing info
2020-10-22 23:34:10.092558 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:34:10.095858 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:34:10.097812 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:34:10.102523 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:10.104504 (Thread-2): 23:34:10 | 6 of 10 START test stg_commands_pin_assignment....................... [RUN]
2020-10-22 23:34:10.119498 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:34:10.122061 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-22 23:34:10.138577 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-22 23:34:10.145106 (Thread-2): finished collecting timing info
2020-10-22 23:34:10.151234 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:34:10.153859 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:10.149539 (Thread-1): finished collecting timing info
2020-10-22 23:34:10.163352 (Thread-1): 23:34:10 | 1 of 10 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.25s]
2020-10-22 23:34:10.165992 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:34:10.168215 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-22 23:34:10.170667 (Thread-1): 23:34:10 | 7 of 10 START test stg_commands_switch_state......................... [RUN]
2020-10-22 23:34:10.174724 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:34:10.177116 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-22 23:34:10.195734 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-22 23:34:10.203972 (Thread-1): finished collecting timing info
2020-10-22 23:34:10.206486 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:34:10.208669 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:10.236308 (Thread-3): finished collecting timing info
2020-10-22 23:34:10.240438 (Thread-3): 23:34:10 | 3 of 10 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.32s]
2020-10-22 23:34:10.243379 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:34:10.245940 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:34:10.248554 (Thread-3): 23:34:10 | 8 of 10 START test stg_commands_thermostat_mode...................... [RUN]
2020-10-22 23:34:10.252564 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:34:10.255607 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:34:10.278098 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-22 23:34:10.286901 (Thread-3): finished collecting timing info
2020-10-22 23:34:10.290399 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:34:10.294877 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:10.786402 (Thread-4): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:34:10.839380 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:34:10.868087 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:34:10.955542 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:34:11.340857 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-22 23:34:11.416548 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-22 23:34:11.429392 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-22 23:34:11.475802 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-22 23:34:12.263710 (Thread-2): finished collecting timing info
2020-10-22 23:34:12.269716 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: 0c3ebc44-5ee8-433a-bd6b-3a69a9d00e43)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:34:12.279073 (Thread-2): 23:34:12 | 6 of 10 ERROR stg_commands_pin_assignment............................ [ERROR in 2.16s]
2020-10-22 23:34:12.282593 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:34:12.288329 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:34:12.292558 (Thread-2): 23:34:12 | 9 of 10 START test stg_commands_thermostat_setpoint.................. [RUN]
2020-10-22 23:34:12.298012 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:34:12.306770 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:34:12.342242 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-22 23:34:12.357176 (Thread-2): finished collecting timing info
2020-10-22 23:34:12.360189 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:34:12.362878 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:12.630523 (Thread-1): finished collecting timing info
2020-10-22 23:34:12.634749 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 458057f2-8911-46a4-b4c9-5de8e663e082)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:34:12.638304 (Thread-1): 23:34:12 | 7 of 10 ERROR stg_commands_switch_state.............................. [ERROR in 2.46s]
2020-10-22 23:34:12.641559 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-22 23:34:12.646861 (Thread-1): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:34:12.651605 (Thread-1): 23:34:12 | 10 of 10 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-22 23:34:12.659182 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-22 23:34:12.661913 (Thread-1): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:34:12.694096 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-22 23:34:12.695383 (Thread-3): finished collecting timing info
2020-10-22 23:34:12.699538 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: c7a8aefe-bfeb-4dbf-b24d-769b88621e00)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:34:12.702132 (Thread-3): 23:34:12 | 8 of 10 ERROR stg_commands_thermostat_mode........................... [ERROR in 2.45s]
2020-10-22 23:34:12.703563 (Thread-1): finished collecting timing info
2020-10-22 23:34:12.704988 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:34:12.707416 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:34:12.711718 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:34:12.750588 (Thread-4): finished collecting timing info
2020-10-22 23:34:12.753631 (Thread-4): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: e62cc40b-3356-48a1-8c5e-8a2fe17316a4)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:34:12.755948 (Thread-4): 23:34:12 | 5 of 10 ERROR stg_commands_locked_state.............................. [ERROR in 2.70s]
2020-10-22 23:34:12.757571 (Thread-4): Finished running node test.dwelo.stg_commands_locked_state
2020-10-22 23:34:12.991677 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:34:13.291966 (Thread-1): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:34:13.577127 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-22 23:34:14.871375 (Thread-2): finished collecting timing info
2020-10-22 23:34:14.875005 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: fec1b1b2-4835-4f06-8f39-5f4cf79113e6)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:34:14.878667 (Thread-2): 23:34:14 | 9 of 10 ERROR stg_commands_thermostat_setpoint....................... [ERROR in 2.58s]
2020-10-22 23:34:14.882030 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:34:17.791988 (MainThread): 23:34:17 | The bigquery adapter does not support query cancellation. Some queries may still be running!
2020-10-22 23:34:19.667622 (Thread-1): finished collecting timing info
2020-10-22 23:34:19.672054 (Thread-1): 23:34:19 | 10 of 10 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 7.01s]
2020-10-22 23:34:19.674658 (Thread-1): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:34:19.678692 (MainThread): 
2020-10-22 23:34:19.680786 (MainThread): Exited because of keyboard interrupt.
2020-10-22 23:34:19.682837 (MainThread): 
2020-10-22 23:34:19.685598 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-22 23:34:19.687656 (MainThread):   Got 101 results, expected 0.
2020-10-22 23:34:19.689687 (MainThread): 
2020-10-22 23:34:19.692230 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-22 23:34:19.694407 (MainThread): 
2020-10-22 23:34:19.696990 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-22 23:34:19.699291 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-22 23:34:19.701885 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:34:19.705375 (MainThread): 
2020-10-22 23:34:19.708142 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-22 23:34:19.710041 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-22 23:34:19.712189 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:34:19.714183 (MainThread): 
2020-10-22 23:34:19.716314 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-22 23:34:19.718887 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-22 23:34:19.721361 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:34:19.723558 (MainThread): 
2020-10-22 23:34:19.725634 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-22 23:34:19.728391 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-22 23:34:19.730404 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:34:19.732249 (MainThread): 
2020-10-22 23:34:19.733947 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-22 23:34:19.736134 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-22 23:34:19.738010 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:34:19.740069 (MainThread): 
Done. PASS=3 WARN=0 ERROR=6 SKIP=0 TOTAL=9
2020-10-22 23:34:19.741893 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:34:19.743536 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-22 23:34:19.745711 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-22 23:34:19.747902 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-22 23:34:19.749675 (MainThread): Connection 'test.dwelo.stg_commands_locked_state' was properly closed.
2020-10-22 23:34:19.752103 (MainThread): Flushing usage events
2020-10-22 23:34:20.182468 (MainThread): ctrl-c
2020-10-22 23:34:21.810604 (MainThread): Running with dbt=0.18.0
2020-10-22 23:34:22.042516 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:34:22.048490 (MainThread): Tracking: tracking
2020-10-22 23:34:22.053448 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe4986820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe3c7fe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe3c7fe50>]}
2020-10-22 23:34:22.087575 (MainThread): Partial parsing not enabled
2020-10-22 23:34:22.090981 (MainThread): Parsing macros/etc.sql
2020-10-22 23:34:22.094411 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:34:22.107605 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:34:22.142605 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:34:22.149615 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:34:22.166741 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:34:22.190321 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:34:22.195629 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:34:22.203903 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:34:22.210557 (MainThread): Parsing macros/core.sql
2020-10-22 23:34:22.217896 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:34:22.234116 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:34:22.243793 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:34:22.257199 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:34:22.283756 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:34:22.311159 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:34:22.316002 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:34:22.369075 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:34:22.380134 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:34:22.384653 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:34:22.396461 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:34:22.432934 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:34:22.513436 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:34:22.517590 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:34:22.521844 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:34:22.525446 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:34:22.541365 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:34:22.546085 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:34:22.548812 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:34:22.552709 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:34:22.556512 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:34:22.561962 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:34:22.575250 (MainThread): Partial parsing not enabled
2020-10-22 23:34:22.667371 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:34:22.696545 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:34:22.713057 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:34:22.730131 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:34:22.750357 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:34:22.770471 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:34:22.791889 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:34:22.823382 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:34:22.843595 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:34:22.862960 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:34:22.883448 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:34:22.902986 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:34:23.751818 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dwelo.staging.stg_command*

2020-10-22 23:34:23.980240 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:34:23.982396 (MainThread): The selector 'tag:part_one' does not match any nodes and will be ignored
2020-10-22 23:34:23.985995 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-10-22 23:34:23.988202 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe3884b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe3884a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5fe3884ac0>]}
2020-10-22 23:34:23.990164 (MainThread): Flushing usage events
2020-10-22 23:34:24.366537 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-22 23:34:58.526856 (MainThread): Running with dbt=0.18.0
2020-10-22 23:34:58.762844 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:34:58.768403 (MainThread): Tracking: tracking
2020-10-22 23:34:58.771984 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d62048d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d6461dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d62056070>]}
2020-10-22 23:34:58.808562 (MainThread): Partial parsing not enabled
2020-10-22 23:34:58.812040 (MainThread): Parsing macros/etc.sql
2020-10-22 23:34:58.815320 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:34:58.828465 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:34:58.863120 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:34:58.870597 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:34:58.888165 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:34:58.909480 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:34:58.914121 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:34:58.922215 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:34:58.928671 (MainThread): Parsing macros/core.sql
2020-10-22 23:34:58.935930 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:34:58.951827 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:34:58.961231 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:34:58.972895 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:34:58.999194 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:34:59.027438 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:34:59.032522 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:34:59.085222 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:34:59.096723 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:34:59.101174 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:34:59.112905 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:34:59.150146 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:34:59.231920 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:34:59.235936 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:34:59.239768 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:34:59.243446 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:34:59.259349 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:34:59.264224 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:34:59.266868 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:34:59.270759 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:34:59.274492 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:34:59.279979 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:34:59.292630 (MainThread): Partial parsing not enabled
2020-10-22 23:34:59.384577 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:34:59.414795 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:34:59.431492 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:34:59.449334 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:34:59.473265 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:34:59.496248 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:34:59.517747 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:34:59.548810 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:34:59.568968 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:34:59.588384 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:34:59.608064 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:34:59.627905 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:35:00.717917 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:35:00.725909 (MainThread): 
2020-10-22 23:35:00.729355 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:00.800345 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:35:00.803046 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:35:00.805993 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:01.358966 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:35:01.960705 (MainThread): 23:35:01 | Concurrency: 4 threads (target='dev')
2020-10-22 23:35:01.963113 (MainThread): 23:35:01 | 
2020-10-22 23:35:01.973229 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:01.974215 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:01.974511 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:01.974992 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:01.975465 (Thread-1): 23:35:01 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-22 23:35:01.977155 (Thread-2): 23:35:01 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-22 23:35:01.978644 (Thread-3): 23:35:01 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-22 23:35:01.980219 (Thread-4): 23:35:01 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-22 23:35:01.982246 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-22 23:35:01.984980 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-22 23:35:01.987142 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-22 23:35:01.990031 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-22 23:35:01.991958 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:01.993516 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:01.995348 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:01.996933 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:02.044707 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-22 23:35:02.050960 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-22 23:35:02.060029 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-22 23:35:02.072854 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-22 23:35:02.080262 (Thread-2): finished collecting timing info
2020-10-22 23:35:02.082682 (Thread-3): finished collecting timing info
2020-10-22 23:35:02.083825 (Thread-1): finished collecting timing info
2020-10-22 23:35:02.086183 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:35:02.088702 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:35:02.089349 (Thread-4): finished collecting timing info
2020-10-22 23:35:02.090695 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:02.092931 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:02.094641 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:02.096072 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:35:02.098270 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56896), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:02.114467 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:02.115694 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56898), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:02.124539 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:02.709341 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-22 23:35:02.711855 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-22 23:35:02.725700 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-22 23:35:02.746428 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-22 23:35:04.428373 (Thread-2): finished collecting timing info
2020-10-22 23:35:04.434040 (Thread-2): 23:35:04 | 2 of 17 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.45s]
2020-10-22 23:35:04.436902 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:04.439938 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:04.442259 (Thread-2): 23:35:04 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-22 23:35:04.445481 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-22 23:35:04.449893 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:04.489890 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-22 23:35:04.512208 (Thread-2): finished collecting timing info
2020-10-22 23:35:04.521503 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:04.532073 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:04.670314 (Thread-3): finished collecting timing info
2020-10-22 23:35:04.673369 (Thread-3): 23:35:04 | 3 of 17 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.69s]
2020-10-22 23:35:04.675070 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:04.676859 (Thread-3): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:04.678644 (Thread-3): 23:35:04 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-22 23:35:04.680901 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-22 23:35:04.682599 (Thread-3): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:04.706464 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-22 23:35:04.716069 (Thread-3): finished collecting timing info
2020-10-22 23:35:04.721986 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:04.734463 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:05.087345 (Thread-1): finished collecting timing info
2020-10-22 23:35:05.095842 (Thread-1): 23:35:05 | 1 of 17 PASS not_null_stg_command_actives_command_uuid............... [PASS in 3.11s]
2020-10-22 23:35:05.100653 (Thread-4): finished collecting timing info
2020-10-22 23:35:05.107005 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:05.107725 (Thread-4): 23:35:05 | 4 of 17 PASS not_null_stg_command_results_is_hub_success............. [PASS in 3.12s]
2020-10-22 23:35:05.110596 (Thread-1): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:05.115096 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:05.118084 (Thread-1): 23:35:05 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-22 23:35:05.120792 (Thread-4): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:05.124157 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-22 23:35:05.127357 (Thread-4): 23:35:05 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-22 23:35:05.130478 (Thread-1): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:05.137001 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-22 23:35:05.160119 (Thread-4): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:05.168860 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-22 23:35:05.188230 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-22 23:35:05.193326 (Thread-1): finished collecting timing info
2020-10-22 23:35:05.195349 (Thread-4): finished collecting timing info
2020-10-22 23:35:05.196375 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:05.198719 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:05.201152 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:05.204160 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:05.357526 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-22 23:35:05.478479 (Thread-3): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-22 23:35:05.831350 (Thread-1): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-22 23:35:05.850152 (Thread-4): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-22 23:35:06.920676 (Thread-3): finished collecting timing info
2020-10-22 23:35:06.924608 (Thread-3): 23:35:06 | 6 of 17 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.24s]
2020-10-22 23:35:06.930840 (Thread-3): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:06.937427 (Thread-3): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:06.945760 (Thread-2): finished collecting timing info
2020-10-22 23:35:06.951437 (Thread-3): 23:35:06 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-22 23:35:06.960021 (Thread-2): 23:35:06 | 5 of 17 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.52s]
2020-10-22 23:35:06.971474 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-22 23:35:06.977212 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:06.984626 (Thread-3): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:06.991550 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-22 23:35:07.025651 (Thread-2): 23:35:07 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-22 23:35:07.038046 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:35:07.059661 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-22 23:35:07.060368 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-22 23:35:07.087487 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-22 23:35:07.089357 (Thread-3): finished collecting timing info
2020-10-22 23:35:07.092208 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:07.093886 (Thread-2): finished collecting timing info
2020-10-22 23:35:07.095630 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:07.097046 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:07.104253 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:07.275675 (Thread-1): finished collecting timing info
2020-10-22 23:35:07.280284 (Thread-1): 23:35:07 | 7 of 17 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.16s]
2020-10-22 23:35:07.282679 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:07.285753 (Thread-1): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:07.288451 (Thread-1): 23:35:07 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-22 23:35:07.291775 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:35:07.294154 (Thread-1): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:07.302441 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56904), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.304727 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56906), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.307439 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56912), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.310327 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56914), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.313290 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56918), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.319812 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56920), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.326935 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56916), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.335033 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56924), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.342625 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56922), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.350364 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56930), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:07.372320 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-22 23:35:07.380245 (Thread-1): finished collecting timing info
2020-10-22 23:35:07.384362 (Thread-4): finished collecting timing info
2020-10-22 23:35:07.387378 (Thread-4): 23:35:07 | 8 of 17 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.25s]
2020-10-22 23:35:07.390281 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:07.392323 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-22 23:35:07.394371 (Thread-4): 23:35:07 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-22 23:35:07.397712 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:35:07.399813 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-22 23:35:07.385032 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:07.421477 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:07.418680 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-22 23:35:07.438814 (Thread-4): finished collecting timing info
2020-10-22 23:35:07.444006 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:07.447464 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:07.902296 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:07.922047 (Thread-3): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-22 23:35:08.255266 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:08.269989 (Thread-1): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:08.396450 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-22 23:35:08.711516 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-22 23:35:08.863179 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-22 23:35:08.869738 (Thread-2): finished collecting timing info
2020-10-22 23:35:08.873420 (Thread-2): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: eb6c6ec7-be97-4df2-aa47-443952c25fee)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:35:08.878470 (Thread-2): 23:35:08 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 1.84s]
2020-10-22 23:35:08.882329 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-22 23:35:08.886514 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:08.890993 (Thread-2): 23:35:08 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-22 23:35:08.893749 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:35:08.896871 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:08.914779 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-22 23:35:08.920701 (Thread-2): finished collecting timing info
2020-10-22 23:35:08.922935 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:08.925052 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:09.214260 (Thread-3): finished collecting timing info
2020-10-22 23:35:09.220375 (Thread-3): 23:35:09 | 9 of 17 FAIL 101 not_null_stg_commands_user_id....................... [FAIL 101 in 2.26s]
2020-10-22 23:35:09.222884 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:09.225222 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:09.227433 (Thread-3): 23:35:09 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-22 23:35:09.230727 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:35:09.234175 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:09.261202 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-22 23:35:09.267414 (Thread-3): finished collecting timing info
2020-10-22 23:35:09.270403 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:09.273083 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:09.557422 (Thread-2): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:09.654430 (Thread-4): finished collecting timing info
2020-10-22 23:35:09.657129 (Thread-4): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 6dc56edf-db20-40b4-b4cc-99a245fa31a2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:35:09.659662 (Thread-4): 23:35:09 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 2.26s]
2020-10-22 23:35:09.663404 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-22 23:35:09.665422 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:09.667658 (Thread-4): 23:35:09 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-22 23:35:09.670670 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-22 23:35:09.673072 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:09.694274 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-22 23:35:09.712359 (Thread-4): finished collecting timing info
2020-10-22 23:35:09.725464 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:09.730781 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:09.966586 (Thread-3): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:10.001563 (Thread-1): finished collecting timing info
2020-10-22 23:35:10.009260 (Thread-1): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: 6a41f23d-f750-4bc3-9bc1-1c3874050479)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:35:10.014427 (Thread-1): 23:35:10 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 2.72s]
2020-10-22 23:35:10.018118 (Thread-1): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:10.023034 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:10.027519 (Thread-1): 23:35:10 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-22 23:35:10.033003 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-22 23:35:10.037355 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-22 23:35:10.045051 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:10.071297 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-22 23:35:10.077985 (Thread-1): finished collecting timing info
2020-10-22 23:35:10.080519 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:10.083087 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:10.374142 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:10.444327 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-22 23:35:10.699128 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:10.854846 (Thread-3): finished collecting timing info
2020-10-22 23:35:10.861078 (Thread-3): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: 890019e6-a979-4931-87fe-4fd84890a17a)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:35:10.867960 (Thread-3): 23:35:10 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.64s]
2020-10-22 23:35:10.871587 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:10.875266 (Thread-3): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:10.880309 (Thread-3): 23:35:10 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-22 23:35:10.883906 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-22 23:35:10.885908 (Thread-3): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:10.906454 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-22 23:35:10.911905 (Thread-3): finished collecting timing info
2020-10-22 23:35:10.914044 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:10.917297 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:11.312252 (Thread-2): finished collecting timing info
2020-10-22 23:35:11.322485 (Thread-2): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: bf7bebdb-47ab-49bb-b05c-5dbd6e427cb9)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:35:11.329257 (Thread-2): 23:35:11 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.44s]
2020-10-22 23:35:11.332572 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:11.589925 (Thread-3): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:12.114388 (Thread-4): finished collecting timing info
2020-10-22 23:35:12.119297 (Thread-4): 23:35:12 | 15 of 17 PASS unique_stg_command_actives_command_uuid................ [PASS in 2.45s]
2020-10-22 23:35:12.122454 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:12.541529 (Thread-1): finished collecting timing info
2020-10-22 23:35:12.546289 (Thread-1): 23:35:12 | 16 of 17 PASS unique_stg_command_results_command_uuid................ [PASS in 2.51s]
2020-10-22 23:35:12.549976 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:12.718402 (Thread-3): finished collecting timing info
2020-10-22 23:35:12.722671 (Thread-3): 23:35:12 | 17 of 17 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 1.84s]
2020-10-22 23:35:12.724691 (Thread-3): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:12.729775 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:12.731689 (MainThread): 23:35:12 | 
2020-10-22 23:35:12.732993 (MainThread): 23:35:12 | Finished running 17 tests in 12.00s.
2020-10-22 23:35:12.734689 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:35:12.736334 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-22 23:35:12.737658 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-22 23:35:12.739341 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-22 23:35:12.740763 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-22 23:35:12.796250 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56940), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.802403 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56944), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.805372 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56946), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.808230 (MainThread): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56942), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.816344 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56952), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.821172 (MainThread): unclosed <socket.socket fd=26, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56954), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:12.880081 (MainThread): 
2020-10-22 23:35:12.882500 (MainThread): Completed with 7 errors and 0 warnings:
2020-10-22 23:35:12.885048 (MainThread): 
2020-10-22 23:35:12.887090 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-22 23:35:12.890396 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-22 23:35:12.900394 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:35:12.910841 (MainThread): 
2020-10-22 23:35:12.916393 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-22 23:35:12.920416 (MainThread):   Got 101 results, expected 0.
2020-10-22 23:35:12.923180 (MainThread): 
2020-10-22 23:35:12.926451 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-22 23:35:12.929425 (MainThread): 
2020-10-22 23:35:12.932355 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-22 23:35:12.935315 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-22 23:35:12.938759 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:35:12.942286 (MainThread): 
2020-10-22 23:35:12.946450 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-22 23:35:12.949994 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-22 23:35:12.952405 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:35:12.954797 (MainThread): 
2020-10-22 23:35:12.956888 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-22 23:35:12.959137 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-22 23:35:12.961105 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:35:12.963173 (MainThread): 
2020-10-22 23:35:12.964988 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-22 23:35:12.966786 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-22 23:35:12.968690 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:35:12.970350 (MainThread): 
2020-10-22 23:35:12.971775 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-22 23:35:12.973670 (MainThread):   Got 2 results, expected 0.
2020-10-22 23:35:12.975509 (MainThread): 
2020-10-22 23:35:12.977318 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-22 23:35:12.979754 (MainThread): 
Done. PASS=10 WARN=0 ERROR=7 SKIP=0 TOTAL=17
2020-10-22 23:35:12.982317 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d601f5070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d61c7b940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d61cf1760>]}
2020-10-22 23:35:12.984532 (MainThread): Flushing usage events
2020-10-22 23:35:15.967768 (MainThread): Running with dbt=0.18.0
2020-10-22 23:35:16.204322 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:35:16.210469 (MainThread): Tracking: tracking
2020-10-22 23:35:16.214531 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3914bf7f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3913f4ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3913f4cdf0>]}
2020-10-22 23:35:16.248965 (MainThread): Partial parsing not enabled
2020-10-22 23:35:16.252968 (MainThread): Parsing macros/etc.sql
2020-10-22 23:35:16.256954 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:35:16.270027 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:35:16.303893 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:35:16.310482 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:35:16.327785 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:35:16.349571 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:35:16.354525 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:35:16.362699 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:35:16.369524 (MainThread): Parsing macros/core.sql
2020-10-22 23:35:16.376935 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:35:16.393430 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:35:16.402997 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:35:16.415251 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:35:16.441343 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:35:16.468380 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:35:16.473340 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:35:16.525850 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:35:16.537395 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:35:16.542182 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:35:16.554154 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:35:16.591329 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:35:16.672403 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:35:16.676665 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:35:16.680587 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:35:16.684255 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:35:16.699807 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:35:16.704817 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:35:16.708745 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:35:16.712889 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:35:16.717258 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:35:16.723053 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:35:16.735990 (MainThread): Partial parsing not enabled
2020-10-22 23:35:16.827627 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:35:16.856874 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:35:16.872650 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:35:16.889053 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:35:16.909920 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:35:16.931148 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:35:16.951867 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:35:16.983274 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:35:17.002997 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:35:17.022699 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:35:17.042302 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:35:17.061516 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:35:18.119166 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:35:18.123289 (MainThread): 
2020-10-22 23:35:18.125192 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:18.194936 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:35:18.196751 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:35:18.199178 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:18.749557 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:35:19.141754 (MainThread): 23:35:19 | Concurrency: 4 threads (target='dev')
2020-10-22 23:35:19.144104 (MainThread): 23:35:19 | 
2020-10-22 23:35:19.152411 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:19.152858 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:19.153603 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:19.153914 (Thread-4): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:19.155223 (Thread-1): 23:35:19 | 1 of 4 START test not_null_stg_command_results_command_uuid.......... [RUN]
2020-10-22 23:35:19.156767 (Thread-2): 23:35:19 | 2 of 4 START test not_null_stg_command_results_is_hub_success........ [RUN]
2020-10-22 23:35:19.158577 (Thread-3): 23:35:19 | 3 of 4 START test not_null_stg_command_results_update_timestamp...... [RUN]
2020-10-22 23:35:19.160235 (Thread-4): 23:35:19 | 4 of 4 START test unique_stg_command_results_command_uuid............ [RUN]
2020-10-22 23:35:19.163100 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-22 23:35:19.164819 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-22 23:35:19.166918 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-22 23:35:19.170294 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-22 23:35:19.173105 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:19.175259 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:19.177066 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:19.178780 (Thread-4): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:19.228638 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-22 23:35:19.234941 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-22 23:35:19.241314 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-22 23:35:19.256026 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-22 23:35:19.261646 (Thread-2): finished collecting timing info
2020-10-22 23:35:19.267044 (Thread-1): finished collecting timing info
2020-10-22 23:35:19.268100 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:35:19.268296 (Thread-3): finished collecting timing info
2020-10-22 23:35:19.269867 (Thread-4): finished collecting timing info
2020-10-22 23:35:19.270782 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:19.273743 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:19.275279 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:35:19.277246 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:35:19.279424 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:19.285413 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:19.287645 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:19.897031 (Thread-2): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-22 23:35:19.916944 (Thread-1): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-22 23:35:19.919589 (Thread-3): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-22 23:35:19.930349 (Thread-4): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:20.145205 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56970), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:20.148590 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56972), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:20.994778 (Thread-3): finished collecting timing info
2020-10-22 23:35:21.000014 (Thread-3): 23:35:20 | 3 of 4 PASS not_null_stg_command_results_update_timestamp............ [PASS in 1.83s]
2020-10-22 23:35:21.003859 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:21.083613 (Thread-2): finished collecting timing info
2020-10-22 23:35:21.086885 (Thread-2): 23:35:21 | 2 of 4 PASS not_null_stg_command_results_is_hub_success.............. [PASS in 1.92s]
2020-10-22 23:35:21.089619 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:21.095324 (Thread-1): finished collecting timing info
2020-10-22 23:35:21.097883 (Thread-1): 23:35:21 | 1 of 4 PASS not_null_stg_command_results_command_uuid................ [PASS in 1.94s]
2020-10-22 23:35:21.100099 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:21.229985 (Thread-4): finished collecting timing info
2020-10-22 23:35:21.234400 (Thread-4): 23:35:21 | 4 of 4 PASS unique_stg_command_results_command_uuid.................. [PASS in 2.07s]
2020-10-22 23:35:21.237813 (Thread-4): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:21.243297 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:21.245504 (MainThread): 23:35:21 | 
2020-10-22 23:35:21.247563 (MainThread): 23:35:21 | Finished running 4 tests in 3.12s.
2020-10-22 23:35:21.249479 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:35:21.251558 (MainThread): Connection 'test.dwelo.not_null_stg_command_results_command_uuid' was properly closed.
2020-10-22 23:35:21.253089 (MainThread): Connection 'test.dwelo.not_null_stg_command_results_is_hub_success' was properly closed.
2020-10-22 23:35:21.254541 (MainThread): Connection 'test.dwelo.not_null_stg_command_results_update_timestamp' was properly closed.
2020-10-22 23:35:21.256389 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-22 23:35:21.278355 (MainThread): 
2020-10-22 23:35:21.280100 (MainThread): Completed successfully
2020-10-22 23:35:21.282019 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-22 23:35:21.284377 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3913bf4100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3913b94b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3913b94ca0>]}
2020-10-22 23:35:21.286192 (MainThread): Flushing usage events
2020-10-22 23:35:45.159389 (MainThread): Running with dbt=0.18.0
2020-10-22 23:35:45.394910 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:35:45.400036 (MainThread): Tracking: tracking
2020-10-22 23:35:45.403567 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cee425df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf09f9f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cee433100>]}
2020-10-22 23:35:45.441224 (MainThread): Partial parsing not enabled
2020-10-22 23:35:45.444906 (MainThread): Parsing macros/etc.sql
2020-10-22 23:35:45.448432 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:35:45.461291 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:35:45.495138 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:35:45.502008 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:35:45.519620 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:35:45.541071 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:35:45.545878 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:35:45.553990 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:35:45.560534 (MainThread): Parsing macros/core.sql
2020-10-22 23:35:45.567722 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:35:45.583665 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:35:45.593202 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:35:45.605100 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:35:45.632039 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:35:45.658816 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:35:45.663485 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:35:45.714817 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:35:45.726500 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:35:45.730685 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:35:45.742811 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:35:45.779756 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:35:45.860406 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:35:45.864467 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:35:45.868282 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:35:45.872036 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:35:45.887368 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:35:45.892046 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:35:45.894832 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:35:45.898842 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:35:45.902464 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:35:45.908005 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:35:45.921000 (MainThread): Partial parsing not enabled
2020-10-22 23:35:46.011536 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:35:46.039350 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:35:46.054844 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:35:46.074738 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:35:46.098897 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:35:46.120734 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:35:46.142353 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:35:46.173411 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:35:46.194089 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:35:46.213716 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:35:46.233358 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:35:46.252941 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:35:47.096949 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dwelo.staging.fct_command_statuses

2020-10-22 23:35:47.322245 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:35:47.326663 (MainThread): 
2020-10-22 23:35:47.328662 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:47.394970 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:35:47.396968 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:35:47.399520 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:47.943280 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:35:48.324044 (MainThread): 23:35:48 | Concurrency: 4 threads (target='dev')
2020-10-22 23:35:48.326680 (MainThread): 23:35:48 | 
2020-10-22 23:35:48.334888 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:48.335194 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:48.335551 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:48.336038 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:48.337250 (Thread-1): 23:35:48 | 1 of 17 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-22 23:35:48.338832 (Thread-2): 23:35:48 | 2 of 17 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-22 23:35:48.340164 (Thread-3): 23:35:48 | 3 of 17 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-22 23:35:48.341818 (Thread-4): 23:35:48 | 4 of 17 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-22 23:35:48.344052 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-22 23:35:48.345203 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-22 23:35:48.347213 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-22 23:35:48.350401 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-22 23:35:48.352375 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:48.354054 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:48.355703 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:48.357248 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:48.396927 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-22 23:35:48.411640 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-22 23:35:48.418188 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-22 23:35:48.439993 (Thread-1): finished collecting timing info
2020-10-22 23:35:48.435841 (Thread-4): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56992), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:48.441954 (Thread-2): finished collecting timing info
2020-10-22 23:35:48.442676 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:48.444179 (Thread-3): finished collecting timing info
2020-10-22 23:35:48.446230 (Thread-4): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56994), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:48.447224 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:35:48.449135 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:48.450267 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:35:48.456121 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-22 23:35:48.457538 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:48.464109 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:48.472938 (Thread-4): finished collecting timing info
2020-10-22 23:35:48.480763 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:35:48.483267 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:49.089779 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-22 23:35:49.090819 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-22 23:35:49.093599 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-22 23:35:49.108800 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-22 23:35:50.210309 (Thread-3): finished collecting timing info
2020-10-22 23:35:50.215417 (Thread-3): 23:35:50 | 3 of 17 PASS not_null_stg_command_results_command_uuid............... [PASS in 1.87s]
2020-10-22 23:35:50.217587 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:35:50.220963 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:50.223475 (Thread-3): 23:35:50 | 5 of 17 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-22 23:35:50.225779 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-22 23:35:50.227416 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:50.246133 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-22 23:35:50.252010 (Thread-3): finished collecting timing info
2020-10-22 23:35:50.253845 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:50.255689 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:50.375380 (Thread-4): finished collecting timing info
2020-10-22 23:35:50.379230 (Thread-4): 23:35:50 | 4 of 17 PASS not_null_stg_command_results_is_hub_success............. [PASS in 2.03s]
2020-10-22 23:35:50.380894 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:35:50.382997 (Thread-4): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:50.386646 (Thread-1): finished collecting timing info
2020-10-22 23:35:50.387401 (Thread-2): finished collecting timing info
2020-10-22 23:35:50.387699 (Thread-4): 23:35:50 | 6 of 17 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-22 23:35:50.390284 (Thread-1): 23:35:50 | 1 of 17 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.05s]
2020-10-22 23:35:50.392811 (Thread-2): 23:35:50 | 2 of 17 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.05s]
2020-10-22 23:35:50.396844 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-22 23:35:50.399136 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:35:50.400406 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:35:50.402513 (Thread-4): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:50.404368 (Thread-1): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:50.406727 (Thread-2): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:50.426031 (Thread-1): 23:35:50 | 7 of 17 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-22 23:35:50.430450 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-22 23:35:50.427812 (Thread-2): 23:35:50 | 8 of 17 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-22 23:35:50.425836 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-22 23:35:50.432432 (Thread-1): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:50.434501 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-22 23:35:50.454652 (Thread-2): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:50.454192 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-22 23:35:50.455549 (Thread-4): finished collecting timing info
2020-10-22 23:35:50.472740 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:50.475841 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:50.475055 (Thread-1): finished collecting timing info
2020-10-22 23:35:50.469984 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-22 23:35:50.482234 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:50.487094 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:50.488647 (Thread-2): finished collecting timing info
2020-10-22 23:35:50.494890 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:50.497521 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:50.892655 (Thread-3): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-22 23:35:51.113212 (Thread-1): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-22 23:35:51.113753 (Thread-4): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-22 23:35:51.134604 (Thread-2): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-22 23:35:52.136693 (Thread-3): finished collecting timing info
2020-10-22 23:35:52.140661 (Thread-3): 23:35:52 | 5 of 17 PASS not_null_stg_command_results_update_timestamp........... [PASS in 1.92s]
2020-10-22 23:35:52.142982 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:35:52.144969 (Thread-3): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:52.147205 (Thread-3): 23:35:52 | 9 of 17 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-22 23:35:52.149269 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-22 23:35:52.151895 (Thread-3): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:52.168348 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-22 23:35:52.173123 (Thread-3): finished collecting timing info
2020-10-22 23:35:52.175550 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:52.178766 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:52.265450 (Thread-4): finished collecting timing info
2020-10-22 23:35:52.270826 (Thread-4): 23:35:52 | 6 of 17 PASS not_null_stg_commands__raw_desired_state................ [PASS in 1.88s]
2020-10-22 23:35:52.273383 (Thread-4): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:35:52.275974 (Thread-4): Began running node test.dwelo.stg_commands_locked_state
2020-10-22 23:35:52.278223 (Thread-4): 23:35:52 | 10 of 17 START test stg_commands_locked_state........................ [RUN]
2020-10-22 23:35:52.284538 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:35:52.290096 (Thread-4): Compiling test.dwelo.stg_commands_locked_state
2020-10-22 23:35:52.358452 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-22 23:35:52.368863 (Thread-4): finished collecting timing info
2020-10-22 23:35:52.375085 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:52.379205 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:52.410377 (Thread-2): finished collecting timing info
2020-10-22 23:35:52.415462 (Thread-2): 23:35:52 | 8 of 17 PASS not_null_stg_commands_update_timestamp.................. [PASS in 1.98s]
2020-10-22 23:35:52.419619 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:35:52.422243 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:52.424441 (Thread-2): 23:35:52 | 11 of 17 START test stg_commands_pin_assignment...................... [RUN]
2020-10-22 23:35:52.428286 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:35:52.430583 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:52.445619 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56996), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.449139 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 56998), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.452410 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57000), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.454929 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57002), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.458130 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57004), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.460656 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57008), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.462913 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57010), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.465598 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57006), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.467958 (Thread-2): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57018), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.471028 (Thread-2): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57014), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.473152 (Thread-2): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57012), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.475135 (Thread-2): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57022), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.476892 (Thread-2): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57024), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.478959 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57020), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:52.492774 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-22 23:35:52.499465 (Thread-2): finished collecting timing info
2020-10-22 23:35:52.503996 (Thread-1): finished collecting timing info
2020-10-22 23:35:52.506847 (Thread-1): 23:35:52 | 7 of 17 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.08s]
2020-10-22 23:35:52.509051 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:35:52.511671 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-22 23:35:52.513745 (Thread-1): 23:35:52 | 12 of 17 START test stg_commands_switch_state........................ [RUN]
2020-10-22 23:35:52.516282 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:35:52.518694 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-22 23:35:52.504647 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:52.538181 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:52.536671 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-22 23:35:52.551874 (Thread-1): finished collecting timing info
2020-10-22 23:35:52.555495 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:52.558134 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:52.969193 (Thread-3): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-22 23:35:53.086848 (Thread-4): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:53.353691 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:53.444041 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:53.851922 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-22 23:35:54.019072 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-22 23:35:54.217170 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-22 23:35:54.280056 (Thread-3): finished collecting timing info
2020-10-22 23:35:54.289118 (Thread-3): 23:35:54 | 9 of 17 FAIL 101 not_null_stg_commands_user_id....................... [FAIL 101 in 2.14s]
2020-10-22 23:35:54.293111 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:35:54.298781 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:54.303969 (Thread-3): 23:35:54 | 13 of 17 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-22 23:35:54.309306 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:35:54.319352 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:54.353806 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-22 23:35:54.371730 (Thread-3): finished collecting timing info
2020-10-22 23:35:54.376243 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:54.379568 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:55.133218 (Thread-4): finished collecting timing info
2020-10-22 23:35:55.141640 (Thread-4): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 4604f29c-e5aa-4275-8337-adee25a21b79)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:35:55.152476 (Thread-1): finished collecting timing info
2020-10-22 23:35:55.160470 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 9d199f05-6092-46eb-ae84-ec8b066b7dd2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:35:55.171476 (Thread-1): 23:35:55 | 12 of 17 ERROR stg_commands_switch_state............................. [ERROR in 2.66s]
2020-10-22 23:35:55.174102 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-22 23:35:55.180716 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:55.184568 (Thread-1): 23:35:55 | 14 of 17 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-22 23:35:55.188565 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:35:55.191631 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:55.154896 (Thread-4): 23:35:55 | 10 of 17 ERROR stg_commands_locked_state............................. [ERROR in 2.87s]
2020-10-22 23:35:55.239181 (Thread-4): Finished running node test.dwelo.stg_commands_locked_state
2020-10-22 23:35:55.283311 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:55.262366 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-22 23:35:55.289998 (Thread-2): finished collecting timing info
2020-10-22 23:35:55.296473 (Thread-4): 23:35:55 | 15 of 17 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-22 23:35:55.305941 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: 1ad3966d-3c18-4c21-a73c-fed6a8bc5768)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:35:55.314151 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-22 23:35:55.314797 (Thread-1): finished collecting timing info
2020-10-22 23:35:55.325390 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:35:55.322484 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:55.319010 (Thread-2): 23:35:55 | 11 of 17 ERROR stg_commands_pin_assignment........................... [ERROR in 2.89s]
2020-10-22 23:35:55.329555 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:55.358617 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:35:55.393874 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-22 23:35:55.397351 (Thread-2): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:55.403778 (Thread-2): 23:35:55 | 16 of 17 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-22 23:35:55.404613 (Thread-4): finished collecting timing info
2020-10-22 23:35:55.409122 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-22 23:35:55.410621 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:35:55.412948 (Thread-2): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:55.415811 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:55.484395 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-22 23:35:55.496893 (Thread-2): finished collecting timing info
2020-10-22 23:35:55.502163 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:35:55.506332 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:55.834034 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:56.340087 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-22 23:35:56.521874 (Thread-1): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:35:56.540604 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:56.606757 (Thread-2): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:56.832507 (Thread-3): finished collecting timing info
2020-10-22 23:35:56.836024 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 6241b28f-2b9c-4845-be82-ab874d21340e)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:35:56.838588 (Thread-3): 23:35:56 | 13 of 17 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.53s]
2020-10-22 23:35:56.840893 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:35:56.843643 (Thread-3): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:56.847562 (Thread-3): 23:35:56 | 17 of 17 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-22 23:35:56.851882 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-22 23:35:56.855606 (Thread-3): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:56.884631 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-22 23:35:56.896444 (Thread-3): finished collecting timing info
2020-10-22 23:35:56.903158 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:35:56.908917 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:35:57.104336 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-22 23:35:57.621696 (Thread-3): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:35:57.741153 (Thread-4): finished collecting timing info
2020-10-22 23:35:57.745766 (Thread-4): 23:35:57 | 15 of 17 PASS unique_stg_command_actives_command_uuid................ [PASS in 2.43s]
2020-10-22 23:35:57.747735 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:35:58.036211 (Thread-2): finished collecting timing info
2020-10-22 23:35:58.043349 (Thread-2): 23:35:58 | 16 of 17 PASS unique_stg_command_results_command_uuid................ [PASS in 2.63s]
2020-10-22 23:35:58.047243 (Thread-2): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:35:58.146915 (Thread-1): finished collecting timing info
2020-10-22 23:35:58.152985 (Thread-1): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: 41114fbc-e706-4351-958b-302eb4a21fce)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:35:58.157835 (Thread-1): 23:35:58 | 14 of 17 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 2.97s]
2020-10-22 23:35:58.159606 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:35:58.983063 (Thread-3): finished collecting timing info
2020-10-22 23:35:58.989881 (Thread-3): 23:35:58 | 17 of 17 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 2.14s]
2020-10-22 23:35:58.993404 (Thread-3): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:35:59.003920 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:35:59.007094 (MainThread): 23:35:59 | 
2020-10-22 23:35:59.009261 (MainThread): 23:35:59 | Finished running 17 tests in 11.68s.
2020-10-22 23:35:59.011651 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:35:59.017870 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-22 23:35:59.025939 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-22 23:35:59.031388 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-22 23:35:59.038800 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-22 23:35:59.151542 (MainThread): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57028), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.154269 (MainThread): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57036), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.156213 (MainThread): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57038), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.158220 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57032), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.159578 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57040), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.161169 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57042), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.162968 (MainThread): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57044), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.165002 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57046), raddr=('172.217.14.74', 443)>
2020-10-22 23:35:59.180086 (MainThread): 
2020-10-22 23:35:59.181999 (MainThread): Completed with 7 errors and 0 warnings:
2020-10-22 23:35:59.183906 (MainThread): 
2020-10-22 23:35:59.186195 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-22 23:35:59.188562 (MainThread):   Got 101 results, expected 0.
2020-10-22 23:35:59.190791 (MainThread): 
2020-10-22 23:35:59.193166 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-22 23:35:59.195530 (MainThread): 
2020-10-22 23:35:59.197431 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-22 23:35:59.199949 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-22 23:35:59.202260 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:35:59.204163 (MainThread): 
2020-10-22 23:35:59.208457 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-22 23:35:59.210592 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-22 23:35:59.212863 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:35:59.215598 (MainThread): 
2020-10-22 23:35:59.219809 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-22 23:35:59.225208 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-22 23:35:59.228657 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:35:59.240304 (MainThread): 
2020-10-22 23:35:59.243579 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-22 23:35:59.246991 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-22 23:35:59.252257 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:35:59.256694 (MainThread): 
2020-10-22 23:35:59.261929 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-22 23:35:59.273287 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-22 23:35:59.280125 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:35:59.285209 (MainThread): 
2020-10-22 23:35:59.291414 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-22 23:35:59.299126 (MainThread):   Got 2 results, expected 0.
2020-10-22 23:35:59.309514 (MainThread): 
2020-10-22 23:35:59.318000 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-22 23:35:59.324267 (MainThread): 
Done. PASS=10 WARN=0 ERROR=7 SKIP=0 TOTAL=17
2020-10-22 23:35:59.331910 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cee275640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cec5fb4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cee0cdaf0>]}
2020-10-22 23:35:59.335245 (MainThread): Flushing usage events
2020-10-22 23:36:03.322504 (MainThread): Running with dbt=0.18.0
2020-10-22 23:36:03.561629 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-22 23:36:03.566712 (MainThread): Tracking: tracking
2020-10-22 23:36:03.570338 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b9c3ad90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1bc20dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b9c480a0>]}
2020-10-22 23:36:03.606579 (MainThread): Partial parsing not enabled
2020-10-22 23:36:03.610687 (MainThread): Parsing macros/etc.sql
2020-10-22 23:36:03.614758 (MainThread): Parsing macros/catalog.sql
2020-10-22 23:36:03.628229 (MainThread): Parsing macros/adapters.sql
2020-10-22 23:36:03.663906 (MainThread): Parsing macros/materializations/view.sql
2020-10-22 23:36:03.669983 (MainThread): Parsing macros/materializations/table.sql
2020-10-22 23:36:03.687600 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-22 23:36:03.709587 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-22 23:36:03.714452 (MainThread): Parsing macros/materializations/copy.sql
2020-10-22 23:36:03.722458 (MainThread): Parsing macros/materializations/seed.sql
2020-10-22 23:36:03.729137 (MainThread): Parsing macros/core.sql
2020-10-22 23:36:03.736482 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-22 23:36:03.752732 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-22 23:36:03.762418 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-22 23:36:03.774437 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-22 23:36:03.802273 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-22 23:36:03.830115 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-22 23:36:03.835236 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-22 23:36:03.889205 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-22 23:36:03.901855 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-22 23:36:03.906472 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-22 23:36:03.918427 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-22 23:36:03.955773 (MainThread): Parsing macros/adapters/common.sql
2020-10-22 23:36:04.037333 (MainThread): Parsing macros/etc/query.sql
2020-10-22 23:36:04.040790 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-22 23:36:04.044632 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-22 23:36:04.048678 (MainThread): Parsing macros/etc/datetime.sql
2020-10-22 23:36:04.064584 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-22 23:36:04.069407 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-22 23:36:04.071945 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-22 23:36:04.075882 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-22 23:36:04.079604 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-22 23:36:04.085907 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-22 23:36:04.098977 (MainThread): Partial parsing not enabled
2020-10-22 23:36:04.192303 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-22 23:36:04.224001 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-22 23:36:04.246059 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-22 23:36:04.265154 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-22 23:36:04.287543 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-22 23:36:04.310251 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-22 23:36:04.331449 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-22 23:36:04.362229 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:36:04.382469 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:36:04.403105 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:36:04.427781 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:36:04.448499 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:36:05.603928 (MainThread): Found 7 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-22 23:36:05.610137 (MainThread): 
2020-10-22 23:36:05.613746 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:36:05.692148 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-22 23:36:05.694110 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-22 23:36:05.697094 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:06.328408 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-22 23:36:06.693195 (MainThread): 23:36:06 | Concurrency: 4 threads (target='dev')
2020-10-22 23:36:06.695628 (MainThread): 23:36:06 | 
2020-10-22 23:36:06.704185 (Thread-1): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-22 23:36:06.704610 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:36:06.704970 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:36:06.705383 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:36:06.706710 (Thread-1): 23:36:06 | 1 of 19 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-22 23:36:06.708898 (Thread-2): 23:36:06 | 2 of 19 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-22 23:36:06.711008 (Thread-3): 23:36:06 | 3 of 19 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-22 23:36:06.713057 (Thread-4): 23:36:06 | 4 of 19 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-22 23:36:06.716346 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-22 23:36:06.720461 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-22 23:36:06.722786 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-22 23:36:06.725638 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-22 23:36:06.728652 (Thread-1): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-22 23:36:06.732895 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:36:06.736911 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:36:06.739576 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:36:06.809481 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-22 23:36:06.836267 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-22 23:36:06.838982 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-22 23:36:06.847140 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-22 23:36:06.857683 (Thread-2): finished collecting timing info
2020-10-22 23:36:06.860004 (Thread-1): finished collecting timing info
2020-10-22 23:36:06.861001 (Thread-3): finished collecting timing info
2020-10-22 23:36:06.873740 (Thread-3): Opening a new connection, currently in state init
2020-10-22 23:36:06.864660 (Thread-4): finished collecting timing info
2020-10-22 23:36:06.871020 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:36:06.864011 (Thread-2): Opening a new connection, currently in state init
2020-10-22 23:36:06.876251 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:06.877885 (Thread-4): Opening a new connection, currently in state init
2020-10-22 23:36:06.882069 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57066), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:06.884361 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:06.893464 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:06.896142 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57068), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:06.915231 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:07.755952 (Thread-2): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-22 23:36:07.768109 (Thread-3): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-22 23:36:07.783983 (Thread-1): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-22 23:36:07.815812 (Thread-4): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-22 23:36:08.342688 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-22 23:36:08.626206 (Thread-1): finished collecting timing info
2020-10-22 23:36:08.631247 (Thread-1): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: 73b6f64c-ae0e-486e-9ff3-6f398541330e)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-22 23:36:08.635630 (Thread-1): 23:36:08 | 1 of 19 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 1.92s]
2020-10-22 23:36:08.637405 (Thread-1): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-22 23:36:08.639823 (Thread-1): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:36:08.641993 (Thread-1): 23:36:08 | 5 of 19 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-22 23:36:08.644083 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-22 23:36:08.646036 (Thread-1): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:36:08.667007 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-22 23:36:08.674005 (Thread-1): finished collecting timing info
2020-10-22 23:36:08.676650 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:36:08.679042 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:08.884026 (Thread-4): finished collecting timing info
2020-10-22 23:36:08.889104 (Thread-4): 23:36:08 | 4 of 19 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.16s]
2020-10-22 23:36:08.891896 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-22 23:36:08.895794 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:36:08.899337 (Thread-4): 23:36:08 | 6 of 19 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-22 23:36:08.903447 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-22 23:36:08.906280 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:36:08.932314 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-22 23:36:08.942015 (Thread-4): finished collecting timing info
2020-10-22 23:36:08.945045 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:36:08.950210 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:08.951990 (Thread-3): finished collecting timing info
2020-10-22 23:36:08.963224 (Thread-3): 23:36:08 | 3 of 19 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.24s]
2020-10-22 23:36:08.966033 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-22 23:36:08.968826 (Thread-3): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:36:08.971231 (Thread-3): 23:36:08 | 7 of 19 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-22 23:36:08.975408 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-22 23:36:08.979561 (Thread-3): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:36:09.008032 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-22 23:36:09.015858 (Thread-3): finished collecting timing info
2020-10-22 23:36:09.020228 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:36:09.023678 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:09.178095 (Thread-2): finished collecting timing info
2020-10-22 23:36:09.182269 (Thread-2): 23:36:09 | 2 of 19 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.46s]
2020-10-22 23:36:09.184927 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-22 23:36:09.187907 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:36:09.190536 (Thread-2): 23:36:09 | 8 of 19 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-22 23:36:09.193842 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-22 23:36:09.195984 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:36:09.221524 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-22 23:36:09.227731 (Thread-2): finished collecting timing info
2020-10-22 23:36:09.230757 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:36:09.235742 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:09.533343 (Thread-1): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-22 23:36:09.834953 (Thread-4): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-22 23:36:09.898703 (Thread-3): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-22 23:36:10.052196 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-22 23:36:10.786176 (Thread-1): finished collecting timing info
2020-10-22 23:36:10.789539 (Thread-1): 23:36:10 | 5 of 19 PASS not_null_stg_command_results_is_hub_success............. [PASS in 2.15s]
2020-10-22 23:36:10.791718 (Thread-1): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-22 23:36:10.794551 (Thread-1): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:36:10.796947 (Thread-1): 23:36:10 | 9 of 19 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-22 23:36:10.800614 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-22 23:36:10.802807 (Thread-1): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:36:10.826629 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-22 23:36:10.834245 (Thread-1): finished collecting timing info
2020-10-22 23:36:10.837667 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:36:10.841543 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:10.870001 (Thread-4): finished collecting timing info
2020-10-22 23:36:10.874872 (Thread-4): 23:36:10 | 6 of 19 PASS not_null_stg_command_results_update_timestamp........... [PASS in 1.97s]
2020-10-22 23:36:10.878401 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-22 23:36:10.881405 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:36:10.883905 (Thread-4): 23:36:10 | 10 of 19 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-22 23:36:10.888285 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-22 23:36:10.891243 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:36:10.921464 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-22 23:36:10.930441 (Thread-4): finished collecting timing info
2020-10-22 23:36:10.934340 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:36:10.939071 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:10.976224 (Thread-3): finished collecting timing info
2020-10-22 23:36:10.979965 (Thread-3): 23:36:10 | 7 of 19 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.01s]
2020-10-22 23:36:10.982734 (Thread-3): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-22 23:36:10.985684 (Thread-3): Began running node test.dwelo.stg_commands_locked_state
2020-10-22 23:36:10.988175 (Thread-3): 23:36:10 | 11 of 19 START test stg_commands_locked_state........................ [RUN]
2020-10-22 23:36:10.992018 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-22 23:36:10.994659 (Thread-3): Compiling test.dwelo.stg_commands_locked_state
2020-10-22 23:36:11.019919 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57070), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.023161 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57076), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.025935 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57082), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.028768 (Thread-3): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57084), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.031240 (Thread-3): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57088), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.033732 (Thread-3): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57086), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.042484 (Thread-3): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57096), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.045588 (Thread-3): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57090), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.048078 (Thread-3): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57094), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.051004 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57092), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:11.068380 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-22 23:36:11.075101 (Thread-3): finished collecting timing info
2020-10-22 23:36:11.078045 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:36:11.080867 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:11.388941 (Thread-2): finished collecting timing info
2020-10-22 23:36:11.393798 (Thread-2): 23:36:11 | 8 of 19 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.20s]
2020-10-22 23:36:11.397757 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-22 23:36:11.402029 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:36:11.405481 (Thread-2): 23:36:11 | 12 of 19 START test stg_commands_pin_assignment...................... [RUN]
2020-10-22 23:36:11.413660 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-22 23:36:11.417234 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-22 23:36:11.445767 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-22 23:36:11.455483 (Thread-2): finished collecting timing info
2020-10-22 23:36:11.460186 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:36:11.464580 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:11.721540 (Thread-1): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-22 23:36:11.841884 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-22 23:36:11.952794 (Thread-3): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:36:12.240566 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    slot IS NULL
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:36:12.528331 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-22 23:36:12.768120 (Thread-1): finished collecting timing info
2020-10-22 23:36:12.772010 (Thread-1): 23:36:12 | 9 of 19 PASS not_null_stg_commands_update_timestamp.................. [PASS in 1.97s]
2020-10-22 23:36:12.773910 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-22 23:36:12.777199 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-22 23:36:12.779573 (Thread-1): 23:36:12 | 13 of 19 START test stg_commands_switch_state........................ [RUN]
2020-10-22 23:36:12.782459 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-22 23:36:12.784121 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-22 23:36:12.810269 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-22 23:36:12.811115 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:5]')
2020-10-22 23:36:12.822628 (Thread-1): finished collecting timing info
2020-10-22 23:36:12.825499 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:36:12.828154 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:13.181602 (Thread-4): finished collecting timing info
2020-10-22 23:36:13.187431 (Thread-4): 23:36:13 | 10 of 19 FAIL 101 not_null_stg_commands_user_id...................... [FAIL 101 in 2.30s]
2020-10-22 23:36:13.189896 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-22 23:36:13.194173 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:36:13.196953 (Thread-4): 23:36:13 | 14 of 19 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-22 23:36:13.200109 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-22 23:36:13.202935 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:36:13.224797 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-22 23:36:13.232182 (Thread-4): finished collecting timing info
2020-10-22 23:36:13.235502 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:36:13.238664 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:13.478267 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:36:13.756681 (Thread-3): finished collecting timing info
2020-10-22 23:36:13.760846 (Thread-3): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: df00c4b2-44db-4264-9d1a-a1ec2e9e2aeb)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:36:13.764261 (Thread-3): 23:36:13 | 11 of 19 ERROR stg_commands_locked_state............................. [ERROR in 2.77s]
2020-10-22 23:36:13.766803 (Thread-3): Finished running node test.dwelo.stg_commands_locked_state
2020-10-22 23:36:13.770486 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:36:13.773337 (Thread-3): 23:36:13 | 15 of 19 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-22 23:36:13.782678 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-22 23:36:13.789627 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:36:13.820557 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-22 23:36:13.829122 (Thread-3): finished collecting timing info
2020-10-22 23:36:13.831807 (Thread-3): Opening a new connection, currently in state closed
2020-10-22 23:36:13.834932 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:13.886239 (Thread-4): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:36:13.936878 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-22 23:36:14.072045 (Thread-2): finished collecting timing info
2020-10-22 23:36:14.075795 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:5]

(job ID: ba948e9a-019b-4600-84e9-cc26a0f72fd3)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    slot IS NULL
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:36:14.078960 (Thread-2): 23:36:14 | 12 of 19 ERROR stg_commands_pin_assignment........................... [ERROR in 2.67s]
2020-10-22 23:36:14.082283 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-22 23:36:14.084988 (Thread-2): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-22 23:36:14.087627 (Thread-2): 23:36:14 | 16 of 19 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-22 23:36:14.091495 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-22 23:36:14.099864 (Thread-2): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-22 23:36:14.122327 (Thread-2): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-22 23:36:14.132289 (Thread-2): finished collecting timing info
2020-10-22 23:36:14.135787 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:36:14.138934 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:14.464169 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-22 23:36:14.522109 (Thread-3): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-22 23:36:14.773475 (Thread-2): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:36:14.942978 (Thread-4): finished collecting timing info
2020-10-22 23:36:14.950116 (Thread-4): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 3c2bb8b4-d619-4b05-aa42-3621b5aa782e)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:36:14.954305 (Thread-4): 23:36:14 | 14 of 19 ERROR stg_commands_thermostat_mode.......................... [ERROR in 1.75s]
2020-10-22 23:36:14.957304 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-22 23:36:14.959431 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:36:14.961527 (Thread-4): 23:36:14 | 17 of 19 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-22 23:36:14.963779 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-22 23:36:14.965720 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:36:14.980858 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-22 23:36:14.986818 (Thread-4): finished collecting timing info
2020-10-22 23:36:14.988951 (Thread-4): Opening a new connection, currently in state closed
2020-10-22 23:36:14.991876 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:15.118227 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-22 23:36:15.176813 (Thread-1): finished collecting timing info
2020-10-22 23:36:15.180705 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: da076ab6-ae13-492a-b13f-f9c7b169a03f)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:36:15.183273 (Thread-1): 23:36:15 | 13 of 19 ERROR stg_commands_switch_state............................. [ERROR in 2.40s]
2020-10-22 23:36:15.185281 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-22 23:36:15.187048 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:36:15.188814 (Thread-1): 23:36:15 | 18 of 19 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-22 23:36:15.190677 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-22 23:36:15.192250 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:36:15.202747 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57108), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.205098 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57106), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.207522 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57102), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.209493 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57116), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.211972 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57112), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.214973 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57114), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.217570 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57118), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.219760 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57120), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.222039 (Thread-1): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57124), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.225389 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57122), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.234305 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-22 23:36:15.239827 (Thread-1): finished collecting timing info
2020-10-22 23:36:15.242440 (Thread-1): Opening a new connection, currently in state closed
2020-10-22 23:36:15.244509 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:15.271266 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [15:11]')
2020-10-22 23:36:15.577102 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:36:15.607613 (Thread-2): finished collecting timing info
2020-10-22 23:36:15.611759 (Thread-2): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [15:11]

(job ID: 1f1f4ad2-e484-44a2-a7ef-7d73f78d7c18)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-22 23:36:15.615446 (Thread-2): 23:36:15 | 16 of 19 ERROR unique_fct_command_statuses_command_uuid.............. [ERROR in 1.52s]
2020-10-22 23:36:15.618745 (Thread-2): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-22 23:36:15.622473 (Thread-2): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:36:15.626539 (Thread-2): 23:36:15 | 19 of 19 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-22 23:36:15.630611 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-22 23:36:15.633302 (Thread-2): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:36:15.689047 (Thread-3): finished collecting timing info
2020-10-22 23:36:15.693107 (Thread-3): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: 5d955274-94f6-4837-abb9-0d07fe698ab8)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:36:15.695783 (Thread-3): 23:36:15 | 15 of 19 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 1.91s]
2020-10-22 23:36:15.697652 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-22 23:36:15.712897 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57080), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.727291 (Thread-2): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57100), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.729944 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57078), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.732509 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57072), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.735086 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57074), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.738057 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57098), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.742874 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57104), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.750694 (Thread-2): unclosed <socket.socket fd=26, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57130), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.752735 (Thread-2): unclosed <socket.socket fd=28, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57132), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.754550 (Thread-2): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57110), raddr=('172.217.14.74', 443)>
2020-10-22 23:36:15.776098 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-22 23:36:15.783869 (Thread-2): finished collecting timing info
2020-10-22 23:36:15.786446 (Thread-2): Opening a new connection, currently in state closed
2020-10-22 23:36:15.788751 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-22 23:36:15.870752 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:36:16.368535 (Thread-2): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-22 23:36:16.848104 (Thread-4): finished collecting timing info
2020-10-22 23:36:16.852926 (Thread-4): 23:36:16 | 17 of 19 PASS unique_stg_command_actives_command_uuid................ [PASS in 1.89s]
2020-10-22 23:36:16.855936 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-22 23:36:17.035550 (Thread-1): finished collecting timing info
2020-10-22 23:36:17.040092 (Thread-1): 23:36:17 | 18 of 19 PASS unique_stg_command_results_command_uuid................ [PASS in 1.85s]
2020-10-22 23:36:17.043277 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-22 23:36:17.542484 (Thread-2): finished collecting timing info
2020-10-22 23:36:17.546612 (Thread-2): 23:36:17 | 19 of 19 FAIL 2 unique_stg_commands_command_uuid..................... [FAIL 2 in 1.92s]
2020-10-22 23:36:17.548810 (Thread-2): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-22 23:36:17.554082 (MainThread): Acquiring new bigquery connection "master".
2020-10-22 23:36:17.556572 (MainThread): 23:36:17 | 
2020-10-22 23:36:17.558444 (MainThread): 23:36:17 | Finished running 19 tests in 11.94s.
2020-10-22 23:36:17.560433 (MainThread): Connection 'master' was properly closed.
2020-10-22 23:36:17.562453 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-22 23:36:17.564268 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-22 23:36:17.565676 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-22 23:36:17.567296 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-22 23:36:17.643920 (MainThread): 
2020-10-22 23:36:17.645775 (MainThread): Completed with 9 errors and 0 warnings:
2020-10-22 23:36:17.648104 (MainThread): 
2020-10-22 23:36:17.650583 (MainThread): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-22 23:36:17.653910 (MainThread):   Unrecognized name: command_uuid at [10:7]
2020-10-22 23:36:17.656501 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-22 23:36:17.659825 (MainThread): 
2020-10-22 23:36:17.662166 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-22 23:36:17.664132 (MainThread):   Got 101 results, expected 0.
2020-10-22 23:36:17.666141 (MainThread): 
2020-10-22 23:36:17.667635 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-22 23:36:17.669583 (MainThread): 
2020-10-22 23:36:17.671940 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-22 23:36:17.674054 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-22 23:36:17.676782 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-22 23:36:17.679337 (MainThread): 
2020-10-22 23:36:17.681549 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-22 23:36:17.683357 (MainThread):   Unrecognized name: slot at [11:5]
2020-10-22 23:36:17.684898 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-22 23:36:17.686938 (MainThread): 
2020-10-22 23:36:17.689122 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-22 23:36:17.691405 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-22 23:36:17.693371 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-22 23:36:17.695677 (MainThread): 
2020-10-22 23:36:17.697322 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-22 23:36:17.699266 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-22 23:36:17.701109 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-22 23:36:17.702742 (MainThread): 
2020-10-22 23:36:17.704156 (MainThread): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-22 23:36:17.706323 (MainThread):   Unrecognized name: command_uuid at [15:11]
2020-10-22 23:36:17.707824 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-22 23:36:17.709413 (MainThread): 
2020-10-22 23:36:17.711147 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-22 23:36:17.712714 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-22 23:36:17.714560 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-22 23:36:17.716299 (MainThread): 
2020-10-22 23:36:17.717874 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-22 23:36:17.719598 (MainThread):   Got 2 results, expected 0.
2020-10-22 23:36:17.721180 (MainThread): 
2020-10-22 23:36:17.723282 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-22 23:36:17.725626 (MainThread): 
Done. PASS=10 WARN=0 ERROR=9 SKIP=0 TOTAL=19
2020-10-22 23:36:17.728314 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b9a8a880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b98e2940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1b995e070>]}
2020-10-22 23:36:17.730567 (MainThread): Flushing usage events
2020-10-23 00:14:39.967729 (MainThread): Running with dbt=0.18.0
2020-10-23 00:14:40.219574 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 00:14:40.233403 (MainThread): Tracking: tracking
2020-10-23 00:14:40.238068 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54e5e5e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc550bb9f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54e5f1130>]}
2020-10-23 00:14:40.272541 (MainThread): Partial parsing not enabled
2020-10-23 00:14:40.277287 (MainThread): Parsing macros/etc.sql
2020-10-23 00:14:40.281110 (MainThread): Parsing macros/catalog.sql
2020-10-23 00:14:40.294741 (MainThread): Parsing macros/adapters.sql
2020-10-23 00:14:40.329061 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 00:14:40.337086 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 00:14:40.354834 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 00:14:40.376098 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 00:14:40.381078 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 00:14:40.389405 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 00:14:40.396568 (MainThread): Parsing macros/core.sql
2020-10-23 00:14:40.404153 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 00:14:40.420103 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 00:14:40.429950 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 00:14:40.442059 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 00:14:40.469958 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 00:14:40.499451 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 00:14:40.505580 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 00:14:40.557943 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 00:14:40.569895 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 00:14:40.574535 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 00:14:40.586310 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 00:14:40.623210 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 00:14:40.703780 (MainThread): Parsing macros/etc/query.sql
2020-10-23 00:14:40.710553 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 00:14:40.714848 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 00:14:40.718838 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 00:14:40.734536 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 00:14:40.740102 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 00:14:40.742861 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 00:14:40.746927 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 00:14:40.750913 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 00:14:40.756792 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 00:14:40.770568 (MainThread): Partial parsing not enabled
2020-10-23 00:14:40.877092 (MainThread): Acquiring new bigquery connection "model.dwelo.cur_command_users".
2020-10-23 00:14:40.909936 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 00:14:40.928645 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 00:14:40.947669 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_user_id".
2020-10-23 00:14:40.968181 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 00:14:40.992409 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 00:14:41.021910 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 00:14:41.043198 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 00:14:41.074707 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 00:14:41.094827 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 00:14:41.115616 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 00:14:41.135803 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 00:14:41.156975 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 00:14:42.199399 (MainThread): Found 8 models, 35 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 00:14:42.208201 (MainThread): 
2020-10-23 00:14:42.211268 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 00:14:42.215596 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 00:14:42.217386 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 00:14:42.219816 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 00:14:43.353670 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 00:14:43.356560 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 00:14:43.358836 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 00:14:43.933129 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 00:14:44.374810 (MainThread): 00:14:44 | Concurrency: 4 threads (target='dev')
2020-10-23 00:14:44.377218 (MainThread): 00:14:44 | 
2020-10-23 00:14:44.385064 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 00:14:44.388161 (Thread-1): 00:14:44 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 00:14:44.390623 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 00:14:44.392739 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 00:14:44.436524 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 00:14:44.443955 (Thread-1): finished collecting timing info
2020-10-23 00:14:44.512163 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57150), raddr=('172.217.14.74', 443)>
2020-10-23 00:14:44.517668 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44800), raddr=('172.217.5.74', 443)>
2020-10-23 00:14:44.523520 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57154), raddr=('172.217.14.74', 443)>
2020-10-23 00:14:44.530265 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44804), raddr=('172.217.5.74', 443)>
2020-10-23 00:14:44.536357 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 00:14:44.557320 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 00:14:44.561672 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 00:14:45.152212 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with extract_event_values as (
  select
      EventType as event_type
      ,DateCreated as update_timestamp
      ,MapRevision as map_revision
      ,ItemKey as item_key
      ,ItemRevision as item_revision
      ,EndpointId as twilio_sync_endpoint_id
      ,ItemData as item_data
      ,MapUniqueName as  device_id

      ,_source_file

      ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command

      ,case
       when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
        then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
        when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
        then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
        when JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') is not null
        then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.last_set_tz') as timestamp)
      end as event_timestamp
      ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        case
          when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
          then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
          else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
        end
        else null
      end as command_uuid

      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT_SCALAR(ItemData, '$.client')
        else null
      end as command_client
      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT(ItemData, '$.desired_state')
        else null
      end as command_desired_state
      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT_SCALAR(ItemData, '$.user')
        else null
      end as command_user

      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT_SCALAR(ItemData, '$.result')
        else null
      end as command_result
      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
        else null
      end as command_failure_string
      ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
        JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
        else null
      end as command_node_id

      ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
   from `analytics-interview`.`interview_source`.`raw_sync_events`
)
,final as (
  select
    command_uuid
    ,command_client
    ,command
    ,command_desired_state as _raw_desired_state
    ,command_user as user_id

    -- NEW COLUMNS PARSING command_desired_state CAN BE ADDED HERE --

    ,update_timestamp
    ,event_timestamp
    ,device_id

    ,JSON_EXTRACT_SCALAR(item_data, '$.origin') as command_origin
    ,JSON_EXTRACT_SCALAR(item_data, '$.origin_id') as command_origin_id

    ,_uid
    ,_source_file
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 00:14:46.720026 (Thread-1): finished collecting timing info
2020-10-23 00:14:46.724438 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd25a12f-e014-4dec-a011-37014122a33d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54c0eabe0>]}
2020-10-23 00:14:46.728652 (Thread-1): 00:14:46 | 1 of 1 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.33s]
2020-10-23 00:14:46.730756 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 00:14:46.735520 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 00:14:46.737799 (MainThread): 00:14:46 | 
2020-10-23 00:14:46.739554 (MainThread): 00:14:46 | Finished running 1 view model in 4.53s.
2020-10-23 00:14:46.741640 (MainThread): Connection 'master' was properly closed.
2020-10-23 00:14:46.743549 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 00:14:46.756150 (MainThread): 
2020-10-23 00:14:46.758159 (MainThread): Completed successfully
2020-10-23 00:14:46.759849 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-23 00:14:46.761774 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54d938880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54d938460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc54d938790>]}
2020-10-23 00:14:46.763789 (MainThread): Flushing usage events
2020-10-23 20:45:43.112651 (MainThread): Running with dbt=0.18.0
2020-10-23 20:45:43.464091 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-23 20:45:43.484283 (MainThread): Tracking: tracking
2020-10-23 20:45:43.488238 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ce7c6aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cea24b0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ce7c771f0>]}
2020-10-23 20:45:43.526419 (MainThread): Partial parsing not enabled
2020-10-23 20:45:43.530923 (MainThread): Parsing macros/etc.sql
2020-10-23 20:45:43.534408 (MainThread): Parsing macros/catalog.sql
2020-10-23 20:45:43.548599 (MainThread): Parsing macros/adapters.sql
2020-10-23 20:45:43.584575 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 20:45:43.591477 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 20:45:43.608822 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 20:45:43.631496 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 20:45:43.636698 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 20:45:43.644680 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 20:45:43.651845 (MainThread): Parsing macros/core.sql
2020-10-23 20:45:43.659437 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 20:45:43.675165 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 20:45:43.684605 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 20:45:43.698077 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 20:45:43.725024 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 20:45:43.752775 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 20:45:43.758852 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 20:45:43.810234 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 20:45:43.822588 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 20:45:43.827634 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 20:45:43.839793 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 20:45:43.877349 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 20:45:43.975894 (MainThread): Parsing macros/etc/query.sql
2020-10-23 20:45:43.982468 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 20:45:43.996782 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 20:45:44.003144 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 20:45:44.025730 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 20:45:44.033979 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 20:45:44.038227 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 20:45:44.042923 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 20:45:44.047565 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 20:45:44.055174 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 20:45:44.073826 (MainThread): Partial parsing not enabled
2020-10-23 20:45:44.200868 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 20:45:44.239484 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 20:45:44.262429 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 20:45:44.289780 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 20:45:44.316985 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 20:45:44.341410 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 20:45:44.377350 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 20:45:44.435939 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 20:45:44.465692 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 20:45:44.494977 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 20:45:44.522759 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 20:45:44.549962 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 20:45:45.736995 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 20:45:45.742631 (MainThread): 
2020-10-23 20:45:45.745229 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 20:45:45.815282 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 20:45:45.817305 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-23 20:45:45.820081 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:46.507022 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 20:45:47.059993 (MainThread): 20:45:47 | Concurrency: 4 threads (target='dev')
2020-10-23 20:45:47.062280 (MainThread): 20:45:47 | 
2020-10-23 20:45:47.075452 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 20:45:47.075882 (Thread-2): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 20:45:47.076279 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 20:45:47.076849 (Thread-4): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-23 20:45:47.078342 (Thread-1): 20:45:47 | 1 of 10 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-23 20:45:47.080208 (Thread-2): 20:45:47 | 2 of 10 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-23 20:45:47.082045 (Thread-3): 20:45:47 | 3 of 10 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-23 20:45:47.083697 (Thread-4): 20:45:47 | 4 of 10 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-23 20:45:47.087232 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-23 20:45:47.090417 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-23 20:45:47.092640 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-23 20:45:47.096609 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-23 20:45:47.097823 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 20:45:47.100035 (Thread-2): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 20:45:47.102057 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 20:45:47.103761 (Thread-4): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-23 20:45:47.175245 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 54918), raddr=('142.250.68.10', 443)>
2020-10-23 20:45:47.203078 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-23 20:45:47.204554 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-23 20:45:47.217619 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57164), raddr=('172.217.14.74', 443)>
2020-10-23 20:45:47.217906 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-23 20:45:47.279073 (Thread-3): finished collecting timing info
2020-10-23 20:45:47.279717 (Thread-1): finished collecting timing info
2020-10-23 20:45:47.286791 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-23 20:45:47.288997 (Thread-3): Opening a new connection, currently in state init
2020-10-23 20:45:47.291093 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 20:45:47.292355 (Thread-4): finished collecting timing info
2020-10-23 20:45:47.296016 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:47.297741 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:47.298787 (Thread-2): finished collecting timing info
2020-10-23 20:45:47.299922 (Thread-4): Opening a new connection, currently in state init
2020-10-23 20:45:47.326330 (Thread-2): Opening a new connection, currently in state init
2020-10-23 20:45:47.329686 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:47.332247 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:47.933329 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-23 20:45:47.937186 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-23 20:45:47.971845 (Thread-2): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-23 20:45:47.974273 (Thread-4): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-23 20:45:49.498541 (Thread-1): finished collecting timing info
2020-10-23 20:45:49.502130 (Thread-1): 20:45:49 | 1 of 10 PASS not_null_stg_commands__raw_desired_state................ [PASS in 2.42s]
2020-10-23 20:45:49.504251 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 20:45:49.507234 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-23 20:45:49.509761 (Thread-1): 20:45:49 | 5 of 10 START test stg_commands_locked_state......................... [RUN]
2020-10-23 20:45:49.511942 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 20:45:49.515072 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-23 20:45:49.567780 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-23 20:45:49.600287 (Thread-1): finished collecting timing info
2020-10-23 20:45:49.604642 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 20:45:49.611752 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:49.931652 (Thread-4): finished collecting timing info
2020-10-23 20:45:49.933650 (Thread-2): finished collecting timing info
2020-10-23 20:45:49.939601 (Thread-2): 20:45:49 | 2 of 10 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.85s]
2020-10-23 20:45:49.941180 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 20:45:49.944421 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-23 20:45:49.943973 (Thread-3): finished collecting timing info
2020-10-23 20:45:49.937532 (Thread-4): 20:45:49 | 4 of 10 FAIL 101 not_null_stg_commands_user_id....................... [FAIL 101 in 2.84s]
2020-10-23 20:45:49.946778 (Thread-2): 20:45:49 | 6 of 10 START test stg_commands_pin_assignment....................... [RUN]
2020-10-23 20:45:49.949079 (Thread-3): 20:45:49 | 3 of 10 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.86s]
2020-10-23 20:45:49.950897 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-23 20:45:49.953717 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 20:45:49.954987 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 20:45:49.956915 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-23 20:45:49.959095 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-23 20:45:49.961033 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 20:45:49.964924 (Thread-4): 20:45:49 | 7 of 10 START test stg_commands_switch_state......................... [RUN]
2020-10-23 20:45:49.987426 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 20:45:49.984800 (Thread-3): 20:45:49 | 8 of 10 START test stg_commands_thermostat_mode...................... [RUN]
2020-10-23 20:45:49.984555 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-23 20:45:49.989133 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-23 20:45:49.992045 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 20:45:50.012978 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-23 20:45:50.017305 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-23 20:45:50.017746 (Thread-2): finished collecting timing info
2020-10-23 20:45:50.031699 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-23 20:45:50.033848 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 20:45:50.038356 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:50.037310 (Thread-4): finished collecting timing info
2020-10-23 20:45:50.046837 (Thread-4): Opening a new connection, currently in state closed
2020-10-23 20:45:50.051725 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:50.047348 (Thread-3): finished collecting timing info
2020-10-23 20:45:50.059762 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 20:45:50.062278 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:50.360562 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 20:45:50.711342 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 20:45:50.717675 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 54922), raddr=('142.250.68.10', 443)>
2020-10-23 20:45:50.721233 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 54924), raddr=('142.250.68.10', 443)>
2020-10-23 20:45:50.723826 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 54926), raddr=('142.250.68.10', 443)>
2020-10-23 20:45:50.726233 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57180), raddr=('172.217.14.74', 443)>
2020-10-23 20:45:50.728624 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57176), raddr=('172.217.14.74', 443)>
2020-10-23 20:45:50.731679 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57174), raddr=('172.217.14.74', 443)>
2020-10-23 20:45:50.734647 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57178), raddr=('172.217.14.74', 443)>
2020-10-23 20:45:50.739367 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 54928), raddr=('142.250.68.10', 443)>
2020-10-23 20:45:50.740069 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 20:45:50.761479 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 20:45:50.842448 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-23 20:45:51.268120 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:6]')
2020-10-23 20:45:51.274174 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-23 20:45:51.344214 (Thread-1): finished collecting timing info
2020-10-23 20:45:51.348946 (Thread-1): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: c3598363-efd7-44ae-857d-968856d6d312)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 20:45:51.355390 (Thread-1): 20:45:51 | 5 of 10 ERROR stg_commands_locked_state.............................. [ERROR in 1.84s]
2020-10-23 20:45:51.358160 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-23 20:45:51.360776 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 20:45:51.362880 (Thread-1): 20:45:51 | 9 of 10 START test stg_commands_thermostat_setpoint.................. [RUN]
2020-10-23 20:45:51.365131 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 20:45:51.367387 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 20:45:51.392257 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-23 20:45:51.393823 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-23 20:45:51.402463 (Thread-1): finished collecting timing info
2020-10-23 20:45:51.404927 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 20:45:51.407159 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:52.069982 (Thread-1): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 20:45:52.158237 (Thread-3): finished collecting timing info
2020-10-23 20:45:52.162654 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 1b10e818-5cf9-4063-b325-78591d96d878)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 20:45:52.165824 (Thread-3): 20:45:52 | 8 of 10 ERROR stg_commands_thermostat_mode........................... [ERROR in 2.17s]
2020-10-23 20:45:52.168243 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 20:45:52.174916 (Thread-3): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-23 20:45:52.177639 (Thread-3): 20:45:52 | 10 of 10 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-23 20:45:52.180409 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-23 20:45:52.183720 (Thread-3): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-23 20:45:52.202443 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-23 20:45:52.214843 (Thread-3): finished collecting timing info
2020-10-23 20:45:52.217989 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 20:45:52.220412 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 20:45:52.535020 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-23 20:45:52.549358 (Thread-2): finished collecting timing info
2020-10-23 20:45:52.552228 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:6]

(job ID: b40889a2-8c05-472f-b0c5-5009d659e4cd)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 20:45:52.555467 (Thread-2): 20:45:52 | 6 of 10 ERROR stg_commands_pin_assignment............................ [ERROR in 2.60s]
2020-10-23 20:45:52.557607 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-23 20:45:52.676969 (Thread-4): finished collecting timing info
2020-10-23 20:45:52.679777 (Thread-4): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: e62e5722-4583-4db0-bcc3-5b798634c19c)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 20:45:52.681733 (Thread-4): 20:45:52 | 7 of 10 ERROR stg_commands_switch_state.............................. [ERROR in 2.69s]
2020-10-23 20:45:52.683806 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-23 20:45:52.829263 (Thread-3): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-23 20:45:53.811957 (Thread-1): finished collecting timing info
2020-10-23 20:45:53.818170 (Thread-1): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: 361cf73c-3421-43c3-bd07-514206b43d87)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 20:45:53.822640 (Thread-1): 20:45:53 | 9 of 10 ERROR stg_commands_thermostat_setpoint....................... [ERROR in 2.46s]
2020-10-23 20:45:53.825923 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 20:45:54.183390 (Thread-3): finished collecting timing info
2020-10-23 20:45:54.187947 (Thread-3): 20:45:54 | 10 of 10 FAIL 112 unique_stg_commands_command_uuid................... [FAIL 112 in 2.01s]
2020-10-23 20:45:54.190332 (Thread-3): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-23 20:45:54.195909 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 20:45:54.198160 (MainThread): 20:45:54 | 
2020-10-23 20:45:54.199996 (MainThread): 20:45:54 | Finished running 10 tests in 8.45s.
2020-10-23 20:45:54.202449 (MainThread): Connection 'master' was properly closed.
2020-10-23 20:45:54.205344 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-23 20:45:54.207639 (MainThread): Connection 'test.dwelo.stg_commands_pin_assignment' was properly closed.
2020-10-23 20:45:54.210434 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-23 20:45:54.213226 (MainThread): Connection 'test.dwelo.stg_commands_switch_state' was properly closed.
2020-10-23 20:45:54.262708 (MainThread): 
2020-10-23 20:45:54.265092 (MainThread): Completed with 7 errors and 0 warnings:
2020-10-23 20:45:54.266808 (MainThread): 
2020-10-23 20:45:54.268725 (MainThread): Failure in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-23 20:45:54.270441 (MainThread):   Got 101 results, expected 0.
2020-10-23 20:45:54.272865 (MainThread): 
2020-10-23 20:45:54.274591 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-23 20:45:54.276699 (MainThread): 
2020-10-23 20:45:54.278749 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-23 20:45:54.280748 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-23 20:45:54.282741 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 20:45:54.284752 (MainThread): 
2020-10-23 20:45:54.287259 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-23 20:45:54.291090 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-23 20:45:54.293950 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 20:45:54.296813 (MainThread): 
2020-10-23 20:45:54.299028 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-23 20:45:54.302003 (MainThread):   Unrecognized name: slot at [11:6]
2020-10-23 20:45:54.305266 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 20:45:54.312640 (MainThread): 
2020-10-23 20:45:54.316088 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-23 20:45:54.322444 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-23 20:45:54.325890 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 20:45:54.329064 (MainThread): 
2020-10-23 20:45:54.336175 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-23 20:45:54.339102 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-23 20:45:54.341906 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 20:45:54.344436 (MainThread): 
2020-10-23 20:45:54.348245 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-23 20:45:54.351003 (MainThread):   Got 112 results, expected 0.
2020-10-23 20:45:54.355004 (MainThread): 
2020-10-23 20:45:54.358022 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-23 20:45:54.360232 (MainThread): 
Done. PASS=3 WARN=0 ERROR=7 SKIP=0 TOTAL=10
2020-10-23 20:45:54.362386 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ce7842520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ce79c10a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ce77df5e0>]}
2020-10-23 20:45:54.364325 (MainThread): Flushing usage events
2020-10-23 21:04:27.721502 (MainThread): Running with dbt=0.18.0
2020-10-23 21:04:27.983178 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['staging.commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-23 21:04:27.990195 (MainThread): Tracking: tracking
2020-10-23 21:04:27.993761 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598a7d7d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598cdaceb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598a7e5070>]}
2020-10-23 21:04:28.026261 (MainThread): Partial parsing not enabled
2020-10-23 21:04:28.029494 (MainThread): Parsing macros/etc.sql
2020-10-23 21:04:28.033340 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:04:28.047173 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:04:28.081696 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:04:28.089011 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:04:28.107186 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:04:28.128955 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:04:28.134074 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:04:28.142039 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:04:28.149002 (MainThread): Parsing macros/core.sql
2020-10-23 21:04:28.156230 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:04:28.172814 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:04:28.182589 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:04:28.194821 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:04:28.221247 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:04:28.250815 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:04:28.256193 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:04:28.308929 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:04:28.321310 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:04:28.326426 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:04:28.338678 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:04:28.378341 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:04:28.459761 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:04:28.464537 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:04:28.468654 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:04:28.472476 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:04:28.488056 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:04:28.493441 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:04:28.496805 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:04:28.501499 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:04:28.505799 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:04:28.511672 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:04:28.525730 (MainThread): Partial parsing not enabled
2020-10-23 21:04:28.628246 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:04:28.660315 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:04:28.679776 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:04:28.701111 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:04:28.726230 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:04:28.750292 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:04:28.771964 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:04:28.808106 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:04:28.829967 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:04:28.850317 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:04:28.870923 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:04:28.895678 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:04:29.981915 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:04:29.989895 (MainThread): 
2020-10-23 21:04:29.992496 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:04:30.062829 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:04:30.065335 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-23 21:04:30.067774 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:30.670419 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:04:31.243868 (MainThread): 21:04:31 | Concurrency: 4 threads (target='dev')
2020-10-23 21:04:31.246511 (MainThread): 21:04:31 | 
2020-10-23 21:04:31.255287 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-23 21:04:31.255850 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-23 21:04:31.256147 (Thread-3): Began running node test.dwelo.stg_commands_switch_state
2020-10-23 21:04:31.256533 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:04:31.257699 (Thread-1): 21:04:31 | 1 of 5 START test stg_commands_locked_state.......................... [RUN]
2020-10-23 21:04:31.259343 (Thread-2): 21:04:31 | 2 of 5 START test stg_commands_pin_assignment........................ [RUN]
2020-10-23 21:04:31.260799 (Thread-3): 21:04:31 | 3 of 5 START test stg_commands_switch_state.......................... [RUN]
2020-10-23 21:04:31.262689 (Thread-4): 21:04:31 | 4 of 5 START test stg_commands_thermostat_mode....................... [RUN]
2020-10-23 21:04:31.265981 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:04:31.267865 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:04:31.270967 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:04:31.272300 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:04:31.274431 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-23 21:04:31.275957 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-23 21:04:31.277654 (Thread-3): Compiling test.dwelo.stg_commands_switch_state
2020-10-23 21:04:31.279559 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:04:31.334148 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-23 21:04:31.334592 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44862), raddr=('142.250.68.42', 443)>
2020-10-23 21:04:31.340972 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-23 21:04:31.375147 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-23 21:04:31.380499 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57210), raddr=('172.217.14.74', 443)>
2020-10-23 21:04:31.384629 (Thread-2): finished collecting timing info
2020-10-23 21:04:31.392819 (Thread-1): finished collecting timing info
2020-10-23 21:04:31.490537 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:04:31.472338 (Thread-2): Opening a new connection, currently in state init
2020-10-23 21:04:31.469582 (Thread-4): finished collecting timing info
2020-10-23 21:04:31.502005 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-23 21:04:31.502932 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:31.505803 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:31.507642 (Thread-4): Opening a new connection, currently in state init
2020-10-23 21:04:31.520214 (Thread-3): finished collecting timing info
2020-10-23 21:04:31.526809 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:31.528615 (Thread-3): Opening a new connection, currently in state init
2020-10-23 21:04:31.540143 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:32.246712 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:04:32.248297 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:04:32.251483 (Thread-4): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:04:32.253469 (Thread-3): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:04:32.916205 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-23 21:04:32.936728 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-23 21:04:32.940433 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:6]')
2020-10-23 21:04:32.968971 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-23 21:04:33.648064 (Thread-3): finished collecting timing info
2020-10-23 21:04:33.652814 (Thread-3): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: a1abd831-0403-4549-9648-4a846f0b26d2)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 21:04:33.658030 (Thread-3): 21:04:33 | 3 of 5 ERROR stg_commands_switch_state............................... [ERROR in 2.39s]
2020-10-23 21:04:33.659960 (Thread-3): Finished running node test.dwelo.stg_commands_switch_state
2020-10-23 21:04:33.662612 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:04:33.666603 (Thread-3): 21:04:33 | 5 of 5 START test stg_commands_thermostat_setpoint................... [RUN]
2020-10-23 21:04:33.671017 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:04:33.674698 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:04:33.692448 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-23 21:04:33.702293 (Thread-3): finished collecting timing info
2020-10-23 21:04:33.704297 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:04:33.706071 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:04:34.204824 (Thread-2): finished collecting timing info
2020-10-23 21:04:34.208903 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:6]

(job ID: 430b419d-1dd2-4fa5-944e-a262d21dafb4)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 21:04:34.212757 (Thread-2): 21:04:34 | 2 of 5 ERROR stg_commands_pin_assignment............................. [ERROR in 2.95s]
2020-10-23 21:04:34.215636 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-23 21:04:34.228088 (Thread-4): finished collecting timing info
2020-10-23 21:04:34.231469 (Thread-4): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 70b9475b-87ee-48a2-b834-f84a44af09df)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 21:04:34.235172 (Thread-4): 21:04:34 | 4 of 5 ERROR stg_commands_thermostat_mode............................ [ERROR in 2.96s]
2020-10-23 21:04:34.238292 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:04:34.318366 (Thread-3): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:04:34.332146 (Thread-1): finished collecting timing info
2020-10-23 21:04:34.334888 (Thread-1): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: f5fe791f-5492-44d8-abdb-2d926a2c0f6c)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 21:04:34.337064 (Thread-1): 21:04:34 | 1 of 5 ERROR stg_commands_locked_state............................... [ERROR in 3.07s]
2020-10-23 21:04:34.338730 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-23 21:04:34.916977 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-23 21:04:35.677715 (Thread-3): finished collecting timing info
2020-10-23 21:04:35.682284 (Thread-3): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: a2188da8-a694-479e-bf75-3d3b9e0571a4)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 21:04:35.685614 (Thread-3): 21:04:35 | 5 of 5 ERROR stg_commands_thermostat_setpoint........................ [ERROR in 2.01s]
2020-10-23 21:04:35.687872 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:04:35.694183 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:04:35.697140 (MainThread): 21:04:35 | 
2020-10-23 21:04:35.699178 (MainThread): 21:04:35 | Finished running 5 tests in 5.70s.
2020-10-23 21:04:35.701518 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:04:35.703808 (MainThread): Connection 'test.dwelo.stg_commands_locked_state' was properly closed.
2020-10-23 21:04:35.705280 (MainThread): Connection 'test.dwelo.stg_commands_pin_assignment' was properly closed.
2020-10-23 21:04:35.706792 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-23 21:04:35.709316 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-23 21:04:35.738653 (MainThread): 
2020-10-23 21:04:35.741238 (MainThread): Completed with 5 errors and 0 warnings:
2020-10-23 21:04:35.744347 (MainThread): 
2020-10-23 21:04:35.747922 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-23 21:04:35.750907 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-23 21:04:35.753755 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 21:04:35.756064 (MainThread): 
2020-10-23 21:04:35.758098 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-23 21:04:35.761176 (MainThread):   Unrecognized name: slot at [11:6]
2020-10-23 21:04:35.763068 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 21:04:35.764975 (MainThread): 
2020-10-23 21:04:35.767213 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-23 21:04:35.769057 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-23 21:04:35.770880 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 21:04:35.772785 (MainThread): 
2020-10-23 21:04:35.774893 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-23 21:04:35.776692 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-23 21:04:35.778658 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 21:04:35.780378 (MainThread): 
2020-10-23 21:04:35.782294 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-23 21:04:35.784531 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-23 21:04:35.787044 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 21:04:35.789005 (MainThread): 
Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
2020-10-23 21:04:35.791713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598a442340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598a303430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f598a38c0d0>]}
2020-10-23 21:04:35.795606 (MainThread): Flushing usage events
2020-10-23 21:04:41.455350 (MainThread): Running with dbt=0.18.0
2020-10-23 21:04:41.694200 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['staging.commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:04:41.699786 (MainThread): Tracking: tracking
2020-10-23 21:04:41.703528 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82cfa5e970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82ced53f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82ced53f40>]}
2020-10-23 21:04:41.739315 (MainThread): Partial parsing not enabled
2020-10-23 21:04:41.743408 (MainThread): Parsing macros/etc.sql
2020-10-23 21:04:41.748152 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:04:41.763336 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:04:41.799428 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:04:41.807029 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:04:41.826040 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:04:41.847562 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:04:41.853355 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:04:41.861710 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:04:41.868486 (MainThread): Parsing macros/core.sql
2020-10-23 21:04:41.875720 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:04:41.891936 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:04:41.903639 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:04:41.916114 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:04:41.942701 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:04:41.971505 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:04:41.977243 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:04:42.029584 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:04:42.041233 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:04:42.046938 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:04:42.058999 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:04:42.096731 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:04:42.177562 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:04:42.181963 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:04:42.186450 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:04:42.190283 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:04:42.206192 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:04:42.211649 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:04:42.214344 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:04:42.218258 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:04:42.222161 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:04:42.228003 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:04:42.241698 (MainThread): Partial parsing not enabled
2020-10-23 21:04:42.338652 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:04:42.369764 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:04:42.389155 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:04:42.408065 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:04:42.431844 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:04:42.455897 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:04:42.477751 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:04:42.509877 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:04:42.530614 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:04:42.550211 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:04:42.570756 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:04:42.591238 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:04:43.707429 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:04:43.712541 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-10-23 21:04:43.715231 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82ce978a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82ce978b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82ce95a370>]}
2020-10-23 21:04:43.717405 (MainThread): Flushing usage events
2020-10-23 21:04:44.107129 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-23 21:05:01.366522 (MainThread): Running with dbt=0.18.0
2020-10-23 21:05:01.607001 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:05:01.613848 (MainThread): Tracking: tracking
2020-10-23 21:05:01.617994 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a18c28e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a0bb8fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a0bc72e0>]}
2020-10-23 21:05:01.655033 (MainThread): Partial parsing not enabled
2020-10-23 21:05:01.658696 (MainThread): Parsing macros/etc.sql
2020-10-23 21:05:01.662392 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:05:01.676749 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:05:01.713455 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:05:01.719573 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:05:01.737628 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:05:01.759141 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:05:01.763927 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:05:01.771948 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:05:01.779238 (MainThread): Parsing macros/core.sql
2020-10-23 21:05:01.786383 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:05:01.802170 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:05:01.811879 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:05:01.824044 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:05:01.851545 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:05:01.880458 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:05:01.886208 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:05:01.939980 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:05:01.952576 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:05:01.957865 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:05:01.970276 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:05:02.007541 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:05:02.088168 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:05:02.092407 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:05:02.096988 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:05:02.101378 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:05:02.117097 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:05:02.122203 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:05:02.124950 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:05:02.129244 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:05:02.133827 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:05:02.139567 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:05:02.153727 (MainThread): Partial parsing not enabled
2020-10-23 21:05:02.252360 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:05:02.283129 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:05:02.302265 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:05:02.321235 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:05:02.342937 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:05:02.365015 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:05:02.387784 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:05:02.419511 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:05:02.440160 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:05:02.460539 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:05:02.481127 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:05:02.501653 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:05:03.606336 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:05:03.611467 (MainThread): 
2020-10-23 21:05:03.614271 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:05:03.627207 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:05:03.629646 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:05:03.634830 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:04.678331 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:05:04.680663 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:05:04.682670 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:05.270048 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:05:05.819790 (MainThread): 21:05:05 | Concurrency: 4 threads (target='dev')
2020-10-23 21:05:05.822342 (MainThread): 21:05:05 | 
2020-10-23 21:05:05.832250 (Thread-1): Began running node model.dwelo.dim_users
2020-10-23 21:05:05.832940 (Thread-2): Began running node model.dwelo.fct_command_statuses
2020-10-23 21:05:05.833977 (Thread-3): Began running node model.dwelo.met_daily_command_count_by_username
2020-10-23 21:05:05.834450 (Thread-4): Began running node model.dwelo.stg_command_actives
2020-10-23 21:05:05.836574 (Thread-1): 21:05:05 | 1 of 7 START view model dev_sam.dim_users............................ [RUN]
2020-10-23 21:05:05.839815 (Thread-2): 21:05:05 | 2 of 7 START view model dev_sam.fct_command_statuses................. [RUN]
2020-10-23 21:05:05.843035 (Thread-3): 21:05:05 | 3 of 7 START view model dev_sam.met_daily_command_count_by_username.. [RUN]
2020-10-23 21:05:05.846963 (Thread-4): 21:05:05 | 4 of 7 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-23 21:05:05.851643 (Thread-1): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:05:05.855212 (Thread-2): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:05:05.857565 (Thread-3): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:05:05.860496 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:05:05.861524 (Thread-1): Compiling model.dwelo.dim_users
2020-10-23 21:05:05.863987 (Thread-2): Compiling model.dwelo.fct_command_statuses
2020-10-23 21:05:05.865836 (Thread-3): Compiling model.dwelo.met_daily_command_count_by_username
2020-10-23 21:05:05.868187 (Thread-4): Compiling model.dwelo.stg_command_actives
2020-10-23 21:05:05.917537 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44890), raddr=('142.250.68.42', 443)>
2020-10-23 21:05:05.947597 (Thread-2): Writing injected SQL for node "model.dwelo.fct_command_statuses"
2020-10-23 21:05:05.950756 (Thread-3): Writing injected SQL for node "model.dwelo.met_daily_command_count_by_username"
2020-10-23 21:05:05.972261 (Thread-4): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-23 21:05:05.972580 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57238), raddr=('172.217.14.74', 443)>
2020-10-23 21:05:05.979801 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57242), raddr=('172.217.14.74', 443)>
2020-10-23 21:05:05.986169 (Thread-2): finished collecting timing info
2020-10-23 21:05:05.987224 (Thread-4): finished collecting timing info
2020-10-23 21:05:05.988151 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44894), raddr=('142.250.68.42', 443)>
2020-10-23 21:05:05.988324 (Thread-3): finished collecting timing info
2020-10-23 21:05:06.154690 (Thread-2): Writing runtime SQL for node "model.dwelo.fct_command_statuses"
2020-10-23 21:05:06.164631 (Thread-3): Writing runtime SQL for node "model.dwelo.met_daily_command_count_by_username"
2020-10-23 21:05:06.165610 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-23 21:05:06.167004 (Thread-1): Writing injected SQL for node "model.dwelo.dim_users"
2020-10-23 21:05:06.177685 (Thread-3): Opening a new connection, currently in state init
2020-10-23 21:05:06.180269 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:06.182633 (Thread-2): Opening a new connection, currently in state init
2020-10-23 21:05:06.189585 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:06.190863 (Thread-4): Opening a new connection, currently in state init
2020-10-23 21:05:06.191135 (Thread-1): finished collecting timing info
2020-10-23 21:05:06.202766 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:06.229333 (Thread-1): Writing runtime SQL for node "model.dwelo.dim_users"
2020-10-23 21:05:06.239836 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:05:06.243320 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:06.797607 (Thread-2): On model.dwelo.fct_command_statuses: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.fct_command_statuses"} */


  create or replace view `analytics-interview`.`dev_sam`.`fct_command_statuses`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-23 21:05:06.855308 (Thread-3): On model.dwelo.met_daily_command_count_by_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.met_daily_command_count_by_username"} */


  create or replace view `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-23 21:05:06.863943 (Thread-4): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with extract_event_values as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      JSON_EXTRACT(ItemData, '$.desired_state')
      else null
    end as _raw_command_desired_state

    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid

    ,case
     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp


    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.client')
      else null
    end as command_client
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.user')
      else null
    end as command_user
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.result')
      else null
    end as command_result
    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
      else null
    end as command_failure_string

    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
      else null
    end as command_node_id

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
      end
      else null
    end as command_uuid

  from `analytics-interview`.`interview_source`.`raw_sync_events`
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      extract_event_values
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-23 21:05:06.923886 (Thread-1): On model.dwelo.dim_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.dim_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`dim_users`
  OPTIONS()
  as -- REPLACE the contents of this file with your query
with final as (
    select 1 as placeholder
)

select *
from final;


2020-10-23 21:05:07.805770 (Thread-2): finished collecting timing info
2020-10-23 21:05:07.810788 (Thread-3): finished collecting timing info
2020-10-23 21:05:07.812684 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a0a94bb0>]}
2020-10-23 21:05:07.815238 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f079fe3fb50>]}
2020-10-23 21:05:07.818426 (Thread-2): 21:05:07 | 2 of 7 OK created view model dev_sam.fct_command_statuses............ [CREATE VIEW in 1.96s]
2020-10-23 21:05:07.821618 (Thread-3): 21:05:07 | 3 of 7 OK created view model dev_sam.met_daily_command_count_by_username [CREATE VIEW in 1.96s]
2020-10-23 21:05:07.823160 (Thread-2): Finished running node model.dwelo.fct_command_statuses
2020-10-23 21:05:07.826545 (Thread-3): Finished running node model.dwelo.met_daily_command_count_by_username
2020-10-23 21:05:07.827890 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-23 21:05:07.831126 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-23 21:05:07.832012 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/8e449111-d1df-45a7-b5ad-f814578cbd1b?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]')
2020-10-23 21:05:07.834051 (Thread-2): 21:05:07 | 5 of 7 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-23 21:05:07.836607 (Thread-3): 21:05:07 | 6 of 7 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:05:07.839928 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:05:07.844025 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:05:07.845084 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-23 21:05:07.846887 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-23 21:05:07.871214 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-23 21:05:07.902415 (Thread-1): finished collecting timing info
2020-10-23 21:05:07.921422 (Thread-2): finished collecting timing info
2020-10-23 21:05:07.923434 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 47952), raddr=('142.250.68.74', 443)>
2020-10-23 21:05:07.926060 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f079cdf8eb0>]}
2020-10-23 21:05:07.943219 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-23 21:05:07.945229 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 47954), raddr=('142.250.68.74', 443)>
2020-10-23 21:05:07.948261 (Thread-1): 21:05:07 | 1 of 7 OK created view model dev_sam.dim_users....................... [CREATE VIEW in 2.07s]
2020-10-23 21:05:07.953872 (Thread-3): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57252), raddr=('172.217.14.74', 443)>
2020-10-23 21:05:07.955743 (Thread-1): Finished running node model.dwelo.dim_users
2020-10-23 21:05:07.958261 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:05:07.959205 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57254), raddr=('172.217.14.74', 443)>
2020-10-23 21:05:07.960778 (Thread-1): Began running node model.dwelo.stg_users
2020-10-23 21:05:07.964467 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:07.969842 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:05:07.973224 (Thread-1): 21:05:07 | 7 of 7 START view model dev_sam.stg_users............................ [RUN]
2020-10-23 21:05:07.989930 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:05:07.995159 (Thread-1): Compiling model.dwelo.stg_users
2020-10-23 21:05:07.995874 (Thread-3): finished collecting timing info
2020-10-23 21:05:08.031818 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:05:08.037688 (Thread-1): Writing injected SQL for node "model.dwelo.stg_users"
2020-10-23 21:05:08.043561 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:05:08.044983 (Thread-1): finished collecting timing info
2020-10-23 21:05:08.046470 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:08.055427 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_users"
2020-10-23 21:05:08.067201 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:05:08.070267 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:05:08.586998 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with extract_event_values as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      JSON_EXTRACT(ItemData, '$.desired_state')
      else null
    end as _raw_command_desired_state

    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid

    ,case
     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp


    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.client')
      else null
    end as command_client
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.user')
      else null
    end as command_user
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.result')
      else null
    end as command_result
    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
      else null
    end as command_failure_string

    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
      else null
    end as command_node_id

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
      end
      else null
    end as command_uuid

  from `analytics-interview`.`interview_source`.`raw_sync_events`
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      extract_event_values
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-23 21:05:08.671350 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with extract_event_values as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid

    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      JSON_EXTRACT(ItemData, '$.desired_state')
      else null
    end as _raw_command_desired_state

    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid

    ,case
     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp


    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.client')
      else null
    end as command_client
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(ItemData, '$.user')
      else null
    end as command_user
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.result')
      else null
    end as command_result
    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
      else null
    end as command_failure_string

    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
      else null
    end as command_node_id

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from `analytics-interview`.`interview_source`.`raw_sync_events`
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:05:08.677771 (Thread-1): On model.dwelo.stg_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
  OPTIONS()
  as with final as (
  select
    *
  from
    `analytics-interview`.`interview_source`.`raw_users`
)

select
  *
from
  final;


2020-10-23 21:05:09.311489 (Thread-4): finished collecting timing info
2020-10-23 21:05:09.316058 (Thread-4): Database Error in model stg_command_actives (models/staging/stg_command_actives.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_command_actives.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/08b32fe7-2e91-4400-8344-07b4edadb321?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]

(job ID: 08b32fe7-2e91-4400-8344-07b4edadb321)

                                                         -----Query Job SQL Follows-----                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
   5:  OPTIONS()
   6:  as with extract_event_values as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  19:
  20:    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command
  21:
  22:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  23:      JSON_EXTRACT(ItemData, '$.desired_state')
  24:      else null
  25:    end as _raw_command_desired_state
  26:
  27:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  28:
  29:    ,case
  30:     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  31:      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  32:      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  33:      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  34:    end as event_timestamp
  35:
  36:
  37:    ,case when ItemKey IN ('Command') then
  38:      JSON_EXTRACT_SCALAR(ItemData, '$.client')
  39:      else null
  40:    end as command_client
  41:    ,case when ItemKey IN ('Command') then
  42:      JSON_EXTRACT_SCALAR(ItemData, '$.user')
  43:      else null
  44:    end as command_user
  45:    ,case when ItemKey IN ('Command') then
  46:      JSON_EXTRACT_SCALAR(item_data, '$.origin')
  47:      else null
  48:     end as command_origin
  49:    ,case when ItemKey IN ('Command') then
  50:      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
  51:      else null
  52:     end as command_origin_id
  53:
  54:    ,case when ItemKey IN ('CommandResult') then
  55:      JSON_EXTRACT_SCALAR(ItemData, '$.result')
  56:      else null
  57:    end as command_result
  58:    ,case when ItemKey IN ('CommandResult') then
  59:      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  60:      else null
  61:    end as command_failure_string
  62:
  63:    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
  64:      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  65:      else null
  66:    end as command_node_id
  67:
  68:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  69:      case
  70:        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  71:        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  72:        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  73:      end
  74:      else null
  75:    end as command_uuid
  76:
  77:  from `analytics-interview`.`interview_source`.`raw_sync_events`
  78:)
  79:,final as (
  80:    select
  81:      command_uuid
  82:      ,command_node_id
  83:
  84:      ,update_timestamp
  85:      ,event_timestamp
  86:      ,device_id
  87:
  88:      ,_uid
  89:      ,_source_file
  90:    from
  91:      extract_event_values
  92:    where
  93:      item_key = 'CommandActive'
  94:      and command_uuid is not null
  95:)
  96:
  97:select *
  98:from final;
  99:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_actives (models/staging/stg_command_actives.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_command_actives.sql
2020-10-23 21:05:09.329197 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f079cdd7970>]}
2020-10-23 21:05:09.332967 (Thread-4): 21:05:09 | 4 of 7 ERROR creating view model dev_sam.stg_command_actives......... [ERROR in 3.47s]
2020-10-23 21:05:09.334991 (Thread-4): Finished running node model.dwelo.stg_command_actives
2020-10-23 21:05:09.460776 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/88ff83a0-eced-4748-a8ae-b59fe731a508?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]')
2020-10-23 21:05:09.570660 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/12b76361-1db7-4238-b828-f57557244593?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]')
2020-10-23 21:05:10.032722 (Thread-1): finished collecting timing info
2020-10-23 21:05:10.036892 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f079ce0e250>]}
2020-10-23 21:05:10.041192 (Thread-1): 21:05:10 | 7 of 7 OK created view model dev_sam.stg_users....................... [CREATE VIEW in 2.05s]
2020-10-23 21:05:10.044033 (Thread-1): Finished running node model.dwelo.stg_users
2020-10-23 21:05:10.588969 (Thread-2): finished collecting timing info
2020-10-23 21:05:10.593093 (Thread-2): Database Error in model stg_command_results (models/staging/stg_command_results.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_command_results.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/b067427c-ddf7-4aa0-83d9-76c22fbf2c6b?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]

(job ID: b067427c-ddf7-4aa0-83d9-76c22fbf2c6b)

                                                         -----Query Job SQL Follows-----                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
   5:  OPTIONS()
   6:  as with extract_event_values as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  19:
  20:    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command
  21:
  22:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  23:      JSON_EXTRACT(ItemData, '$.desired_state')
  24:      else null
  25:    end as _raw_command_desired_state
  26:
  27:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  28:
  29:    ,case
  30:     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  31:      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  32:      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  33:      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  34:    end as event_timestamp
  35:
  36:
  37:    ,case when ItemKey IN ('Command') then
  38:      JSON_EXTRACT_SCALAR(ItemData, '$.client')
  39:      else null
  40:    end as command_client
  41:    ,case when ItemKey IN ('Command') then
  42:      JSON_EXTRACT_SCALAR(ItemData, '$.user')
  43:      else null
  44:    end as command_user
  45:    ,case when ItemKey IN ('Command') then
  46:      JSON_EXTRACT_SCALAR(item_data, '$.origin')
  47:      else null
  48:     end as command_origin
  49:    ,case when ItemKey IN ('Command') then
  50:      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
  51:      else null
  52:     end as command_origin_id
  53:
  54:    ,case when ItemKey IN ('CommandResult') then
  55:      JSON_EXTRACT_SCALAR(ItemData, '$.result')
  56:      else null
  57:    end as command_result
  58:    ,case when ItemKey IN ('CommandResult') then
  59:      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  60:      else null
  61:    end as command_failure_string
  62:
  63:    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
  64:      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  65:      else null
  66:    end as command_node_id
  67:
  68:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  69:      case
  70:        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  71:        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  72:        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  73:      end
  74:      else null
  75:    end as command_uuid
  76:
  77:  from `analytics-interview`.`interview_source`.`raw_sync_events`
  78:)
  79:,final as (
  80:    select
  81:      command_uuid
  82:
  83:      ,command_result IN ('success', 'true') as is_hub_success
  84:      ,command_failure_string
  85:      ,command_node_id
  86:
  87:      ,update_timestamp
  88:      ,event_timestamp
  89:      ,event_uuid
  90:      ,device_id
  91:
  92:      ,_uid
  93:      ,_source_file
  94:    from
  95:      extract_event_values
  96:    where
  97:      item_key = 'CommandResult'
  98:      and command_uuid is not null
  99:)
 100:
 101:select *
 102:from final;
 103:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_command_results (models/staging/stg_command_results.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_command_results.sql
2020-10-23 21:05:10.596837 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a09ce850>]}
2020-10-23 21:05:10.600665 (Thread-2): 21:05:10 | 5 of 7 ERROR creating view model dev_sam.stg_command_results......... [ERROR in 2.76s]
2020-10-23 21:05:10.603014 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-23 21:05:11.318433 (Thread-3): finished collecting timing info
2020-10-23 21:05:11.324201 (Thread-3): Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/35e8c7db-d70f-4fb8-b8a1-934c66124dba?maxResults=0&location=US: Unrecognized name: item_data; Did you mean ItemData? at [46:27]

(job ID: 35e8c7db-d70f-4fb8-b8a1-934c66124dba)

                                                      -----Query Job SQL Follows-----                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with extract_event_values as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,JSON_EXTRACT_SCALAR(ItemData, '$.uuid') as event_uuid
  19:
  20:    ,JSON_EXTRACT_SCALAR(ItemData, '$.desired_state[0]') as command
  21:
  22:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  23:      JSON_EXTRACT(ItemData, '$.desired_state')
  24:      else null
  25:    end as _raw_command_desired_state
  26:
  27:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  28:
  29:    ,case
  30:     when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) < 26
  31:      then safe_cast(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') as timestamp)
  32:      when JSON_EXTRACT_SCALAR(ItemData, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp')) > 26
  33:      then safe_cast(substr(JSON_EXTRACT_SCALAR(ItemData, '$.timestamp'),0,26) as timestamp)
  34:    end as event_timestamp
  35:
  36:
  37:    ,case when ItemKey IN ('Command') then
  38:      JSON_EXTRACT_SCALAR(ItemData, '$.client')
  39:      else null
  40:    end as command_client
  41:    ,case when ItemKey IN ('Command') then
  42:      JSON_EXTRACT_SCALAR(ItemData, '$.user')
  43:      else null
  44:    end as command_user
  45:    ,case when ItemKey IN ('Command') then
  46:      JSON_EXTRACT_SCALAR(item_data, '$.origin')
  47:      else null
  48:     end as command_origin
  49:    ,case when ItemKey IN ('Command') then
  50:      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
  51:      else null
  52:     end as command_origin_id
  53:
  54:    ,case when ItemKey IN ('CommandResult') then
  55:      JSON_EXTRACT_SCALAR(ItemData, '$.result')
  56:      else null
  57:    end as command_result
  58:    ,case when ItemKey IN ('CommandResult') then
  59:      JSON_EXTRACT_SCALAR(ItemData, '$.failure_string')
  60:      else null
  61:    end as command_failure_string
  62:
  63:    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
  64:      JSON_EXTRACT_SCALAR(ItemData, '$.node_id')
  65:      else null
  66:    end as command_node_id
  67:
  68:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  69:      case
  70:        when JSON_EXTRACT_SCALAR(ItemData, '$.command_id') is not null
  71:        then JSON_EXTRACT_SCALAR(ItemData, '$.command_id')
  72:        else JSON_EXTRACT_SCALAR(ItemData, '$.uuid')
  73:      end
  74:      else null
  75:    end as command_uuid
  76:
  77:    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --
  78:
  79:  from `analytics-interview`.`interview_source`.`raw_sync_events`
  80:)
  81:,final as (
  82:  select
  83:    *
  84:  from
  85:    extract_event_values
  86:  where
  87:    item_key = 'Command'
  88:    and command_uuid is not null
  89:)
  90:
  91:select *
  92:from final;
  93:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: item_data; Did you mean ItemData? at [46:27]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:05:11.328025 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dce1ad6b-fad9-4a0d-9d09-82d7157de535', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a096b820>]}
2020-10-23 21:05:11.331547 (Thread-3): 21:05:11 | 6 of 7 ERROR creating view model dev_sam.stg_commands................ [ERROR in 3.48s]
2020-10-23 21:05:11.333573 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-23 21:05:11.341949 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:05:11.344431 (MainThread): 21:05:11 | 
2020-10-23 21:05:11.346111 (MainThread): 21:05:11 | Finished running 7 view models in 7.73s.
2020-10-23 21:05:11.348155 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:05:11.350459 (MainThread): Connection 'model.dwelo.stg_users' was properly closed.
2020-10-23 21:05:11.351905 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-23 21:05:11.353593 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:05:11.355439 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-23 21:05:11.396577 (MainThread): 
2020-10-23 21:05:11.399067 (MainThread): Completed with 3 errors and 0 warnings:
2020-10-23 21:05:11.401558 (MainThread): 
2020-10-23 21:05:11.405263 (MainThread): Database Error in model stg_command_actives (models/staging/stg_command_actives.sql)
2020-10-23 21:05:11.407946 (MainThread):   Unrecognized name: item_data; Did you mean ItemData? at [46:27]
2020-10-23 21:05:11.410154 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_command_actives.sql
2020-10-23 21:05:11.412683 (MainThread): 
2020-10-23 21:05:11.415610 (MainThread): Database Error in model stg_command_results (models/staging/stg_command_results.sql)
2020-10-23 21:05:11.419750 (MainThread):   Unrecognized name: item_data; Did you mean ItemData? at [46:27]
2020-10-23 21:05:11.422279 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_command_results.sql
2020-10-23 21:05:11.425007 (MainThread): 
2020-10-23 21:05:11.427580 (MainThread): Database Error in model stg_commands (models/staging/stg_commands.sql)
2020-10-23 21:05:11.429753 (MainThread):   Unrecognized name: item_data; Did you mean ItemData? at [46:27]
2020-10-23 21:05:11.431690 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:05:11.433909 (MainThread): 
Done. PASS=4 WARN=0 ERROR=3 SKIP=0 TOTAL=7
2020-10-23 21:05:11.438189 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a07958b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a0731dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a0909d30>]}
2020-10-23 21:05:11.440675 (MainThread): Flushing usage events
2020-10-23 21:08:24.251683 (MainThread): Running with dbt=0.18.0
2020-10-23 21:08:24.548851 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:08:24.555639 (MainThread): Tracking: tracking
2020-10-23 21:08:24.559127 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac202f820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac132cfa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac132c730>]}
2020-10-23 21:08:24.594886 (MainThread): Partial parsing not enabled
2020-10-23 21:08:24.598123 (MainThread): Parsing macros/etc.sql
2020-10-23 21:08:24.601698 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:08:24.616500 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:08:24.651464 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:08:24.659432 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:08:24.677022 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:08:24.705515 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:08:24.710608 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:08:24.719966 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:08:24.727922 (MainThread): Parsing macros/core.sql
2020-10-23 21:08:24.737650 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:08:24.757303 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:08:24.768223 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:08:24.781852 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:08:24.810512 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:08:24.840272 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:08:24.845782 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:08:24.900156 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:08:24.912318 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:08:24.917610 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:08:24.930382 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:08:24.968852 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:08:25.056680 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:08:25.060213 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:08:25.064252 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:08:25.068241 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:08:25.084432 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:08:25.089386 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:08:25.092372 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:08:25.097861 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:08:25.102260 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:08:25.107971 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:08:25.121913 (MainThread): Partial parsing not enabled
2020-10-23 21:08:25.221070 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:08:25.253413 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:08:25.271641 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:08:25.289487 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:08:25.314250 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:08:25.338030 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:08:25.361384 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:08:25.393283 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:08:25.415376 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:08:25.437190 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:08:25.458468 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:08:25.479169 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:08:26.587447 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:08:26.591857 (MainThread): 
2020-10-23 21:08:26.594165 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:08:26.597865 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:08:26.599690 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:08:26.602413 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:08:27.870327 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:08:27.872804 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:08:27.874697 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:08:28.482504 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:08:29.018281 (MainThread): 21:08:29 | Concurrency: 4 threads (target='dev')
2020-10-23 21:08:29.021282 (MainThread): 21:08:29 | 
2020-10-23 21:08:29.030656 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 21:08:29.034424 (Thread-1): 21:08:29 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:08:29.040476 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:08:29.042946 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 21:08:29.096036 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:08:29.105404 (Thread-1): finished collecting timing info
2020-10-23 21:08:29.118795 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57276), raddr=('172.217.14.74', 443)>
2020-10-23 21:08:29.121396 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44094), raddr=('142.250.72.234', 443)>
2020-10-23 21:08:29.123757 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57280), raddr=('172.217.14.74', 443)>
2020-10-23 21:08:29.126102 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44098), raddr=('142.250.72.234', 443)>
2020-10-23 21:08:29.244955 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:08:29.253893 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:08:29.256107 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:08:29.859246 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select

    JSON_EXTRACT_SCALAR(item_data '$.uuid') as event_uuid

    ,JSON_EXTRACT_SCALAR(item_data '$.desired_state[0]') as command

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      JSON_EXTRACT(item_data '$.desired_state')
      else null
    end as _raw_command_desired_state


    ,case
     when JSON_EXTRACT_SCALAR(item_data '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data '$.timestamp'),0,26) as timestamp)
    end as event_timestamp


    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data '$.client')
      else null
    end as command_client
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data '$.user')
      else null
    end as command_user
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data '$.origin')
      else null
     end as command_origin
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data '$.origin_id')
      else null
     end as command_origin_id

    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data '$.result')
      else null
    end as command_result
    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data '$.failure_string')
      else null
    end as command_failure_string

    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data '$.node_id')
      else null
    end as command_node_id

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:08:30.252230 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Syntax error: Expected ")" but got string literal \'$.uuid\' at [25:35]')
2020-10-23 21:08:31.487656 (Thread-1): finished collecting timing info
2020-10-23 21:08:31.491875 (Thread-1): Database Error in model stg_commands (models/staging/stg_commands.sql)
  Syntax error: Expected ")" but got string literal '$.uuid' at [25:35]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Syntax error: Expected ")" but got string literal '$.uuid' at [25:35]

(job ID: cf0cd99e-cb82-49e5-ac2a-d64a6f2d8b0b)

                                                      -----Query Job SQL Follows-----                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with column_renames as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  19:  from
  20:    `analytics-interview`.`interview_source`.`raw_sync_events`
  21:)
  22:,extract_event_values as (
  23:  select
  24:
  25:    JSON_EXTRACT_SCALAR(item_data '$.uuid') as event_uuid
  26:
  27:    ,JSON_EXTRACT_SCALAR(item_data '$.desired_state[0]') as command
  28:
  29:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  30:      JSON_EXTRACT(item_data '$.desired_state')
  31:      else null
  32:    end as _raw_command_desired_state
  33:
  34:
  35:    ,case
  36:     when JSON_EXTRACT_SCALAR(item_data '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data '$.timestamp')) < 26
  37:      then safe_cast(JSON_EXTRACT_SCALAR(item_data '$.timestamp') as timestamp)
  38:      when JSON_EXTRACT_SCALAR(item_data '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data '$.timestamp')) > 26
  39:      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data '$.timestamp'),0,26) as timestamp)
  40:    end as event_timestamp
  41:
  42:
  43:    ,case when ItemKey IN ('Command') then
  44:      JSON_EXTRACT_SCALAR(item_data '$.client')
  45:      else null
  46:    end as command_client
  47:    ,case when ItemKey IN ('Command') then
  48:      JSON_EXTRACT_SCALAR(item_data '$.user')
  49:      else null
  50:    end as command_user
  51:    ,case when ItemKey IN ('Command') then
  52:      JSON_EXTRACT_SCALAR(item_data '$.origin')
  53:      else null
  54:     end as command_origin
  55:    ,case when ItemKey IN ('Command') then
  56:      JSON_EXTRACT_SCALAR(item_data '$.origin_id')
  57:      else null
  58:     end as command_origin_id
  59:
  60:    ,case when ItemKey IN ('CommandResult') then
  61:      JSON_EXTRACT_SCALAR(item_data '$.result')
  62:      else null
  63:    end as command_result
  64:    ,case when ItemKey IN ('CommandResult') then
  65:      JSON_EXTRACT_SCALAR(item_data '$.failure_string')
  66:      else null
  67:    end as command_failure_string
  68:
  69:    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
  70:      JSON_EXTRACT_SCALAR(item_data '$.node_id')
  71:      else null
  72:    end as command_node_id
  73:
  74:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  75:      case
  76:        when JSON_EXTRACT_SCALAR(item_data '$.command_id') is not null
  77:        then JSON_EXTRACT_SCALAR(item_data '$.command_id')
  78:        else JSON_EXTRACT_SCALAR(item_data '$.uuid')
  79:      end
  80:      else null
  81:    end as command_uuid
  82:
  83:    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --
  84:
  85:  from
  86:    column_renames
  87:)
  88:,final as (
  89:  select
  90:    *
  91:  from
  92:    extract_event_values
  93:  where
  94:    item_key = 'Command'
  95:    and command_uuid is not null
  96:)
  97:
  98:select *
  99:from final;
 100:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/stg_commands.sql)
  Syntax error: Expected ")" but got string literal '$.uuid' at [25:35]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:08:31.497221 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '069ce884-936b-4175-a499-f6fabef5f655', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac11bd4c0>]}
2020-10-23 21:08:31.501059 (Thread-1): 21:08:31 | 1 of 1 ERROR creating view model dev_sam.stg_commands................ [ERROR in 2.46s]
2020-10-23 21:08:31.503056 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 21:08:31.508059 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:08:31.510622 (MainThread): 21:08:31 | 
2020-10-23 21:08:31.512371 (MainThread): 21:08:31 | Finished running 1 view model in 4.92s.
2020-10-23 21:08:31.514528 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:08:31.516806 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:08:31.530709 (MainThread): 
2020-10-23 21:08:31.533245 (MainThread): Completed with 1 error and 0 warnings:
2020-10-23 21:08:31.535536 (MainThread): 
2020-10-23 21:08:31.538091 (MainThread): Database Error in model stg_commands (models/staging/stg_commands.sql)
2020-10-23 21:08:31.540621 (MainThread):   Syntax error: Expected ")" but got string literal '$.uuid' at [25:35]
2020-10-23 21:08:31.542966 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:08:31.545228 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2020-10-23 21:08:31.548048 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac0e51fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac0e51f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffac0e51ee0>]}
2020-10-23 21:08:31.550421 (MainThread): Flushing usage events
2020-10-23 21:09:16.275117 (MainThread): Running with dbt=0.18.0
2020-10-23 21:09:16.524451 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:09:16.530745 (MainThread): Tracking: tracking
2020-10-23 21:09:16.534254 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc18cf760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc0bccf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc0bccee0>]}
2020-10-23 21:09:16.570044 (MainThread): Partial parsing not enabled
2020-10-23 21:09:16.574753 (MainThread): Parsing macros/etc.sql
2020-10-23 21:09:16.578583 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:09:16.592175 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:09:16.628808 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:09:16.635063 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:09:16.652726 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:09:16.676682 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:09:16.681519 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:09:16.690461 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:09:16.696857 (MainThread): Parsing macros/core.sql
2020-10-23 21:09:16.704144 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:09:16.721140 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:09:16.730558 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:09:16.742979 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:09:16.769212 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:09:16.796907 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:09:16.802993 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:09:16.855889 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:09:16.868640 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:09:16.873385 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:09:16.885039 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:09:16.944256 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:09:17.027176 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:09:17.031049 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:09:17.035241 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:09:17.038892 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:09:17.055011 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:09:17.060592 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:09:17.063931 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:09:17.068079 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:09:17.072238 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:09:17.077893 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:09:17.092095 (MainThread): Partial parsing not enabled
2020-10-23 21:09:17.197657 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:09:17.231316 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:09:17.249701 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:09:17.269106 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:09:17.292865 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:09:17.317331 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:09:17.339704 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:09:17.372221 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:09:17.393437 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:09:17.433514 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:09:17.457439 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:09:17.478280 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:09:18.678133 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:09:18.682869 (MainThread): 
2020-10-23 21:09:18.685294 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:09:18.689362 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:09:18.690925 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:09:18.693426 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:09:19.746248 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:09:19.748164 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:09:19.750121 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:09:20.366396 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:09:20.892328 (MainThread): 21:09:20 | Concurrency: 4 threads (target='dev')
2020-10-23 21:09:20.895113 (MainThread): 21:09:20 | 
2020-10-23 21:09:20.905007 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 21:09:20.908595 (Thread-1): 21:09:20 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:09:20.911283 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:09:20.913264 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 21:09:20.952547 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:09:20.958316 (Thread-1): finished collecting timing info
2020-10-23 21:09:20.966426 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57290), raddr=('172.217.14.74', 443)>
2020-10-23 21:09:20.969164 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 41380), raddr=('172.217.14.106', 443)>
2020-10-23 21:09:20.971346 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57294), raddr=('172.217.14.74', 443)>
2020-10-23 21:09:20.973157 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 41384), raddr=('172.217.14.106', 443)>
2020-10-23 21:09:21.068887 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:09:21.075291 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:09:21.077398 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:09:21.668622 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select

    JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid

    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state


    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp


    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when ItemKey IN ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when ItemKey IN ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:09:22.479753 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/b02dd46b-29cd-4b78-af38-a90d65307496?maxResults=0&location=US: Unrecognized name: ItemKey; Did you mean item_key? at [29:16]')
2020-10-23 21:09:24.135493 (Thread-1): finished collecting timing info
2020-10-23 21:09:24.140062 (Thread-1): Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: ItemKey; Did you mean item_key? at [29:16]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/6af30f9b-3b00-4ef4-8bc5-5c684b58f0a5?maxResults=0&location=US: Unrecognized name: ItemKey; Did you mean item_key? at [29:16]

(job ID: 6af30f9b-3b00-4ef4-8bc5-5c684b58f0a5)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with column_renames as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  19:  from
  20:    `analytics-interview`.`interview_source`.`raw_sync_events`
  21:)
  22:,extract_event_values as (
  23:  select
  24:
  25:    JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
  26:
  27:    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command
  28:
  29:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  30:      JSON_EXTRACT(item_data, '$.desired_state')
  31:      else null
  32:    end as _raw_command_desired_state
  33:
  34:
  35:    ,case
  36:     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
  37:      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
  38:      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
  39:      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
  40:    end as event_timestamp
  41:
  42:
  43:    ,case when ItemKey IN ('Command') then
  44:      JSON_EXTRACT_SCALAR(item_data, '$.client')
  45:      else null
  46:    end as command_client
  47:    ,case when ItemKey IN ('Command') then
  48:      JSON_EXTRACT_SCALAR(item_data, '$.user')
  49:      else null
  50:    end as command_user
  51:    ,case when ItemKey IN ('Command') then
  52:      JSON_EXTRACT_SCALAR(item_data, '$.origin')
  53:      else null
  54:     end as command_origin
  55:    ,case when ItemKey IN ('Command') then
  56:      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
  57:      else null
  58:     end as command_origin_id
  59:
  60:    ,case when ItemKey IN ('CommandResult') then
  61:      JSON_EXTRACT_SCALAR(item_data, '$.result')
  62:      else null
  63:    end as command_result
  64:    ,case when ItemKey IN ('CommandResult') then
  65:      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
  66:      else null
  67:    end as command_failure_string
  68:
  69:    ,case when ItemKey IN ('CommandActive', 'CommandResult') then
  70:      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
  71:      else null
  72:    end as command_node_id
  73:
  74:    ,case when ItemKey IN ('Command', 'CommandActive', 'CommandResult') then
  75:      case
  76:        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
  77:        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
  78:        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
  79:      end
  80:      else null
  81:    end as command_uuid
  82:
  83:    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --
  84:
  85:  from
  86:    column_renames
  87:)
  88:,final as (
  89:  select
  90:    *
  91:  from
  92:    extract_event_values
  93:  where
  94:    item_key = 'Command'
  95:    and command_uuid is not null
  96:)
  97:
  98:select *
  99:from final;
 100:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: ItemKey; Did you mean item_key? at [29:16]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:09:24.146737 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c107e905-b2be-49f1-af10-98e5d1949d18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc0a4dfa0>]}
2020-10-23 21:09:24.150990 (Thread-1): 21:09:24 | 1 of 1 ERROR creating view model dev_sam.stg_commands................ [ERROR in 3.24s]
2020-10-23 21:09:24.153404 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 21:09:24.159187 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:09:24.161645 (MainThread): 21:09:24 | 
2020-10-23 21:09:24.163229 (MainThread): 21:09:24 | Finished running 1 view model in 5.48s.
2020-10-23 21:09:24.165043 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:09:24.167027 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:09:24.179297 (MainThread): 
2020-10-23 21:09:24.181400 (MainThread): Completed with 1 error and 0 warnings:
2020-10-23 21:09:24.183904 (MainThread): 
2020-10-23 21:09:24.185949 (MainThread): Database Error in model stg_commands (models/staging/stg_commands.sql)
2020-10-23 21:09:24.188257 (MainThread):   Unrecognized name: ItemKey; Did you mean item_key? at [29:16]
2020-10-23 21:09:24.190322 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:09:24.192394 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2020-10-23 21:09:24.194739 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc06f2df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc06f2e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9cc06f2b50>]}
2020-10-23 21:09:24.196466 (MainThread): Flushing usage events
2020-10-23 21:10:44.026506 (MainThread): Running with dbt=0.18.0
2020-10-23 21:10:44.271158 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:10:44.281731 (MainThread): Tracking: tracking
2020-10-23 21:10:44.285644 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca79128d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca7b6fdee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca791360a0>]}
2020-10-23 21:10:44.322308 (MainThread): Partial parsing not enabled
2020-10-23 21:10:44.326332 (MainThread): Parsing macros/etc.sql
2020-10-23 21:10:44.333051 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:10:44.347372 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:10:44.381939 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:10:44.388650 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:10:44.406737 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:10:44.428491 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:10:44.433623 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:10:44.441704 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:10:44.449446 (MainThread): Parsing macros/core.sql
2020-10-23 21:10:44.457193 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:10:44.474153 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:10:44.484586 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:10:44.496705 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:10:44.523169 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:10:44.551605 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:10:44.556675 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:10:44.610323 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:10:44.622768 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:10:44.627706 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:10:44.640026 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:10:44.680402 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:10:44.783167 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:10:44.786749 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:10:44.790552 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:10:44.795285 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:10:44.821431 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:10:44.830258 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:10:44.835643 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:10:44.844424 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:10:44.849195 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:10:44.858492 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:10:44.880052 (MainThread): Partial parsing not enabled
2020-10-23 21:10:45.014864 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:10:45.048590 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:10:45.067473 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:10:45.085432 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:10:45.108529 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:10:45.142449 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:10:45.177175 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:10:45.209480 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:10:45.229442 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:10:45.251646 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:10:45.273261 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:10:45.293141 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:10:46.443437 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:10:46.448974 (MainThread): 
2020-10-23 21:10:46.451624 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:10:46.455719 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:10:46.457637 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:10:46.460262 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:10:47.550743 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:10:47.553533 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:10:47.556222 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:10:48.202540 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:10:48.710183 (MainThread): 21:10:48 | Concurrency: 4 threads (target='dev')
2020-10-23 21:10:48.713096 (MainThread): 21:10:48 | 
2020-10-23 21:10:48.722645 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 21:10:48.726351 (Thread-1): 21:10:48 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:10:48.728511 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:10:48.730622 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 21:10:48.767374 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:10:48.775314 (Thread-1): finished collecting timing info
2020-10-23 21:10:48.785068 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57304), raddr=('172.217.14.74', 443)>
2020-10-23 21:10:48.787209 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44122), raddr=('142.250.72.234', 443)>
2020-10-23 21:10:48.788648 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57308), raddr=('172.217.14.74', 443)>
2020-10-23 21:10:48.790219 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44126), raddr=('142.250.72.234', 443)>
2020-10-23 21:10:48.887844 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:10:48.894199 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:10:48.896365 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:10:49.473622 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select

    JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:10:50.377539 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/c46b99f8-3c62-4fda-adf5-197348eba341?maxResults=0&location=US: Unrecognized name: item_key at [90:5]')
2020-10-23 21:10:51.938535 (Thread-1): finished collecting timing info
2020-10-23 21:10:51.944181 (Thread-1): Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: item_key at [90:5]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 122, in result
    self._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3103, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 101, in _blocking_poll
    retry_(self._done_or_raise)()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 80, in _done_or_raise
    if not self.done():
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3083, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1288, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 558, in _call_api
    return call()
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/google/cloud/_http.py", line 423, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/analytics-interview/queries/601e9b3b-86d9-4fcb-8140-c8441a23a82e?maxResults=0&location=US: Unrecognized name: item_key at [90:5]

(job ID: 601e9b3b-86d9-4fcb-8140-c8441a23a82e)

                                                       -----Query Job SQL Follows-----                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */
   2:
   3:
   4:  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
   5:  OPTIONS()
   6:  as with column_renames as (
   7:  select
   8:    EventType as event_type
   9:    ,DateCreated as update_timestamp
  10:    ,MapRevision as map_revision
  11:    ,ItemKey as item_key
  12:    ,ItemRevision as item_revision
  13:    ,EndpointId as twilio_sync_endpoint_id
  14:    ,ItemData as item_data
  15:    ,MapUniqueName as  device_id
  16:
  17:    ,_source_file
  18:    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  19:  from
  20:    `analytics-interview`.`interview_source`.`raw_sync_events`
  21:)
  22:,extract_event_values as (
  23:  select
  24:
  25:    JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
  26:    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command
  27:
  28:    ,case
  29:     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
  30:      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
  31:      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
  32:      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
  33:    end as event_timestamp
  34:
  35:    ,case when item_key in ('Command') then
  36:      JSON_EXTRACT(item_data, '$.desired_state')
  37:      else null
  38:    end as _raw_command_desired_state
  39:    ,case when item_key in ('Command') then
  40:      JSON_EXTRACT_SCALAR(item_data, '$.client')
  41:      else null
  42:    end as command_client
  43:    ,case when item_key in ('Command') then
  44:      JSON_EXTRACT_SCALAR(item_data, '$.user')
  45:      else null
  46:    end as command_user
  47:    ,case when item_key in ('Command') then
  48:      JSON_EXTRACT_SCALAR(item_data, '$.origin')
  49:      else null
  50:     end as command_origin
  51:    ,case when item_key in ('Command') then
  52:      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
  53:      else null
  54:     end as command_origin_id
  55:
  56:    ,case when item_key in ('CommandResult') then
  57:      JSON_EXTRACT_SCALAR(item_data, '$.result')
  58:      else null
  59:    end as command_result
  60:    ,case when item_key in ('CommandResult') then
  61:      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
  62:      else null
  63:    end as command_failure_string
  64:
  65:    ,case when item_key in ('CommandActive', 'CommandResult') then
  66:      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
  67:      else null
  68:    end as command_node_id
  69:
  70:    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
  71:      case
  72:        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
  73:        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
  74:        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
  75:      end
  76:      else null
  77:    end as command_uuid
  78:
  79:    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --
  80:
  81:  from
  82:    column_renames
  83:)
  84:,final as (
  85:  select
  86:    *
  87:  from
  88:    extract_event_values
  89:  where
  90:    item_key = 'Command'
  91:    and command_uuid is not null
  92:)
  93:
  94:select *
  95:from final;
  96:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/run.py", line 233, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_commands (models/staging/stg_commands.sql)
  Unrecognized name: item_key at [90:5]
  compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:10:51.951768 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e749b01-09f6-4051-af01-7f151f310ef7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca78fafca0>]}
2020-10-23 21:10:51.956258 (Thread-1): 21:10:51 | 1 of 1 ERROR creating view model dev_sam.stg_commands................ [ERROR in 3.22s]
2020-10-23 21:10:51.958214 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 21:10:51.963314 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:10:51.965554 (MainThread): 21:10:51 | 
2020-10-23 21:10:51.967187 (MainThread): 21:10:51 | Finished running 1 view model in 5.51s.
2020-10-23 21:10:51.968989 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:10:51.970923 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:10:51.983286 (MainThread): 
2020-10-23 21:10:51.985776 (MainThread): Completed with 1 error and 0 warnings:
2020-10-23 21:10:51.987905 (MainThread): 
2020-10-23 21:10:51.990220 (MainThread): Database Error in model stg_commands (models/staging/stg_commands.sql)
2020-10-23 21:10:51.992466 (MainThread):   Unrecognized name: item_key at [90:5]
2020-10-23 21:10:51.994480 (MainThread):   compiled SQL at target/run/dwelo/models/staging/stg_commands.sql
2020-10-23 21:10:51.996219 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2020-10-23 21:10:51.998301 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca78fafe80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca78c53f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca78c53e20>]}
2020-10-23 21:10:52.000442 (MainThread): Flushing usage events
2020-10-23 21:11:33.146142 (MainThread): Running with dbt=0.18.0
2020-10-23 21:11:33.390654 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:11:33.398492 (MainThread): Tracking: tracking
2020-10-23 21:11:33.403386 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e180cdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e3de0f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e181b0d0>]}
2020-10-23 21:11:33.442387 (MainThread): Partial parsing not enabled
2020-10-23 21:11:33.446813 (MainThread): Parsing macros/etc.sql
2020-10-23 21:11:33.452687 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:11:33.476352 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:11:33.522645 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:11:33.528785 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:11:33.552222 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:11:33.578369 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:11:33.587097 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:11:33.596799 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:11:33.603789 (MainThread): Parsing macros/core.sql
2020-10-23 21:11:33.612103 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:11:33.631511 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:11:33.644053 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:11:33.657728 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:11:33.685147 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:11:33.712285 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:11:33.717526 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:11:33.778942 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:11:33.793178 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:11:33.799205 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:11:33.812165 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:11:33.849883 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:11:33.932442 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:11:33.935945 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:11:33.940240 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:11:33.944229 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:11:33.960274 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:11:33.967746 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:11:33.972150 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:11:33.977262 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:11:33.981893 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:11:33.988990 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:11:34.004127 (MainThread): Partial parsing not enabled
2020-10-23 21:11:34.100660 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:11:34.133387 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:11:34.151817 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:11:34.170048 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:11:34.191981 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:11:34.215640 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:11:34.237039 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:11:34.268047 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:11:34.288072 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:11:34.308099 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:11:34.329463 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:11:34.350107 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:11:35.558654 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:11:35.563756 (MainThread): 
2020-10-23 21:11:35.566157 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:11:35.569966 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:11:35.571689 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:11:35.573932 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:11:36.775994 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:11:36.778638 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:11:36.780766 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:11:37.395481 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:11:37.937441 (MainThread): 21:11:37 | Concurrency: 4 threads (target='dev')
2020-10-23 21:11:37.940297 (MainThread): 21:11:37 | 
2020-10-23 21:11:37.971734 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 21:11:37.979775 (Thread-1): 21:11:37 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:11:37.983236 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:11:37.985727 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 21:11:38.028698 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:11:38.034747 (Thread-1): finished collecting timing info
2020-10-23 21:11:38.043022 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57318), raddr=('172.217.14.74', 443)>
2020-10-23 21:11:38.046178 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44136), raddr=('142.250.72.234', 443)>
2020-10-23 21:11:38.056892 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57322), raddr=('172.217.14.74', 443)>
2020-10-23 21:11:38.065366 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44140), raddr=('142.250.72.234', 443)>
2020-10-23 21:11:38.182392 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:11:38.189777 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:11:38.192171 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:11:38.846286 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select
    *

    ,JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:11:40.116108 (Thread-1): finished collecting timing info
2020-10-23 21:11:40.121015 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f762416f-d554-4cce-83b7-c358e54a806c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e1692400>]}
2020-10-23 21:11:40.125279 (Thread-1): 21:11:40 | 1 of 1 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 2.14s]
2020-10-23 21:11:40.127725 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 21:11:40.134718 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:11:40.138280 (MainThread): 21:11:40 | 
2020-10-23 21:11:40.140378 (MainThread): 21:11:40 | Finished running 1 view model in 4.57s.
2020-10-23 21:11:40.142960 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:11:40.145996 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:11:40.163139 (MainThread): 
2020-10-23 21:11:40.165716 (MainThread): Completed successfully
2020-10-23 21:11:40.168091 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-23 21:11:40.175923 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e0a87910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e0a87850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2e0a87820>]}
2020-10-23 21:11:40.180769 (MainThread): Flushing usage events
2020-10-23 21:12:43.073322 (MainThread): Running with dbt=0.18.0
2020-10-23 21:12:43.315175 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['stg_commands'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:12:43.322628 (MainThread): Tracking: tracking
2020-10-23 21:12:43.328097 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c4a2e8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c3d25fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c3d342e0>]}
2020-10-23 21:12:43.365023 (MainThread): Partial parsing not enabled
2020-10-23 21:12:43.368792 (MainThread): Parsing macros/etc.sql
2020-10-23 21:12:43.372291 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:12:43.385594 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:12:43.420077 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:12:43.427192 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:12:43.445740 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:12:43.467705 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:12:43.472873 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:12:43.481343 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:12:43.488138 (MainThread): Parsing macros/core.sql
2020-10-23 21:12:43.495605 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:12:43.511760 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:12:43.521575 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:12:43.534371 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:12:43.562116 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:12:43.589518 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:12:43.594826 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:12:43.647379 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:12:43.659347 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:12:43.664557 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:12:43.677035 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:12:43.713790 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:12:43.795799 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:12:43.800288 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:12:43.805025 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:12:43.809057 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:12:43.825433 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:12:43.830754 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:12:43.833402 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:12:43.837310 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:12:43.841026 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:12:43.846479 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:12:43.860058 (MainThread): Partial parsing not enabled
2020-10-23 21:12:43.960084 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:12:43.991998 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:12:44.010162 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:12:44.030451 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:12:44.054886 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:12:44.078273 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:12:44.101505 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:12:44.135692 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:12:44.156289 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:12:44.176889 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:12:44.198105 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:12:44.218359 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:12:45.325433 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:12:45.330653 (MainThread): 
2020-10-23 21:12:45.333799 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:12:45.337901 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:12:45.339469 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:12:45.341831 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:12:46.534614 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:12:46.536809 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:12:46.538604 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:12:47.112777 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:12:47.667983 (MainThread): 21:12:47 | Concurrency: 4 threads (target='dev')
2020-10-23 21:12:47.670834 (MainThread): 21:12:47 | 
2020-10-23 21:12:47.680301 (Thread-1): Began running node model.dwelo.stg_commands
2020-10-23 21:12:47.684173 (Thread-1): 21:12:47 | 1 of 1 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:12:47.688774 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:12:47.693991 (Thread-1): Compiling model.dwelo.stg_commands
2020-10-23 21:12:47.730454 (Thread-1): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:12:47.738734 (Thread-1): finished collecting timing info
2020-10-23 21:12:47.746447 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57332), raddr=('172.217.14.74', 443)>
2020-10-23 21:12:47.748849 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44150), raddr=('142.250.72.234', 443)>
2020-10-23 21:12:47.751348 (Thread-1): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57336), raddr=('172.217.14.74', 443)>
2020-10-23 21:12:47.755079 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44154), raddr=('142.250.72.234', 443)>
2020-10-23 21:12:47.853406 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:12:47.859170 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:12:47.861119 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:12:48.450206 (Thread-1): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select
    *

    ,JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:12:49.327092 (Thread-1): finished collecting timing info
2020-10-23 21:12:49.330447 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3a06bdd-ef0a-48f2-94ec-3d4292c72234', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c3c09d30>]}
2020-10-23 21:12:49.334081 (Thread-1): 21:12:49 | 1 of 1 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.64s]
2020-10-23 21:12:49.336070 (Thread-1): Finished running node model.dwelo.stg_commands
2020-10-23 21:12:49.341055 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:12:49.343228 (MainThread): 21:12:49 | 
2020-10-23 21:12:49.345198 (MainThread): 21:12:49 | Finished running 1 view model in 4.01s.
2020-10-23 21:12:49.347019 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:12:49.348793 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:12:49.361320 (MainThread): 
2020-10-23 21:12:49.363644 (MainThread): Completed successfully
2020-10-23 21:12:49.365796 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2020-10-23 21:12:49.367966 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c0784af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c3852cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f62c3852be0>]}
2020-10-23 21:12:49.370248 (MainThread): Flushing usage events
2020-10-23 21:12:55.609109 (MainThread): Running with dbt=0.18.0
2020-10-23 21:12:55.874358 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['staging'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-10-23 21:12:55.880706 (MainThread): Tracking: tracking
2020-10-23 21:12:55.884356 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3bbe7760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3aee3f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3aee3ee0>]}
2020-10-23 21:12:55.922467 (MainThread): Partial parsing not enabled
2020-10-23 21:12:55.926483 (MainThread): Parsing macros/etc.sql
2020-10-23 21:12:55.929905 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:12:55.943266 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:12:55.978326 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:12:55.984249 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:12:56.002369 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:12:56.024038 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:12:56.028580 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:12:56.036796 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:12:56.043557 (MainThread): Parsing macros/core.sql
2020-10-23 21:12:56.051248 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:12:56.068130 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:12:56.078046 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:12:56.090636 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:12:56.118320 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:12:56.147109 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:12:56.153020 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:12:56.206000 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:12:56.220178 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:12:56.225757 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:12:56.237944 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:12:56.301095 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:12:56.399982 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:12:56.406191 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:12:56.410947 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:12:56.415740 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:12:56.433446 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:12:56.439896 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:12:56.443373 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:12:56.448588 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:12:56.453013 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:12:56.459392 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:12:56.473890 (MainThread): Partial parsing not enabled
2020-10-23 21:12:56.568567 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:12:56.615133 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:12:56.646759 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:12:56.671679 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:12:56.701071 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:12:56.723887 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:12:56.748390 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:12:56.784912 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:12:56.804851 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:12:56.824335 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:12:56.844243 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:12:56.864003 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:12:58.083761 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:12:58.088599 (MainThread): 
2020-10-23 21:12:58.092045 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:12:58.100625 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_analytics-interview".
2020-10-23 21:12:58.102593 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2020-10-23 21:12:58.105152 (ThreadPoolExecutor-0_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:12:59.323069 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:12:59.325999 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2020-10-23 21:12:59.328348 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:12:59.912654 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:13:00.476349 (MainThread): 21:13:00 | Concurrency: 4 threads (target='dev')
2020-10-23 21:13:00.480160 (MainThread): 21:13:00 | 
2020-10-23 21:13:00.490038 (Thread-1): Began running node model.dwelo.stg_command_actives
2020-10-23 21:13:00.490413 (Thread-2): Began running node model.dwelo.stg_command_results
2020-10-23 21:13:00.491165 (Thread-3): Began running node model.dwelo.stg_commands
2020-10-23 21:13:00.491583 (Thread-4): Began running node model.dwelo.stg_users
2020-10-23 21:13:00.494073 (Thread-1): 21:13:00 | 1 of 4 START view model dev_sam.stg_command_actives.................. [RUN]
2020-10-23 21:13:00.497292 (Thread-2): 21:13:00 | 2 of 4 START view model dev_sam.stg_command_results.................. [RUN]
2020-10-23 21:13:00.502099 (Thread-3): 21:13:00 | 3 of 4 START view model dev_sam.stg_commands......................... [RUN]
2020-10-23 21:13:00.506150 (Thread-4): 21:13:00 | 4 of 4 START view model dev_sam.stg_users............................ [RUN]
2020-10-23 21:13:00.509315 (Thread-1): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:13:00.511330 (Thread-2): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:13:00.514191 (Thread-3): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:13:00.515901 (Thread-4): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:13:00.518040 (Thread-1): Compiling model.dwelo.stg_command_actives
2020-10-23 21:13:00.519923 (Thread-2): Compiling model.dwelo.stg_command_results
2020-10-23 21:13:00.522023 (Thread-3): Compiling model.dwelo.stg_commands
2020-10-23 21:13:00.525087 (Thread-4): Compiling model.dwelo.stg_users
2020-10-23 21:13:00.617474 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44164), raddr=('142.250.72.234', 443)>
2020-10-23 21:13:00.623664 (Thread-2): Writing injected SQL for node "model.dwelo.stg_command_results"
2020-10-23 21:13:00.638775 (Thread-4): Writing injected SQL for node "model.dwelo.stg_users"
2020-10-23 21:13:00.639851 (Thread-1): Writing injected SQL for node "model.dwelo.stg_command_actives"
2020-10-23 21:13:00.640290 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57346), raddr=('172.217.14.74', 443)>
2020-10-23 21:13:00.646849 (Thread-2): finished collecting timing info
2020-10-23 21:13:00.652276 (Thread-3): unclosed <socket.socket fd=8, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57350), raddr=('172.217.14.74', 443)>
2020-10-23 21:13:00.653278 (Thread-4): finished collecting timing info
2020-10-23 21:13:00.655374 (Thread-1): finished collecting timing info
2020-10-23 21:13:00.681650 (Thread-3): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44168), raddr=('142.250.72.234', 443)>
2020-10-23 21:13:00.710217 (Thread-4): Writing runtime SQL for node "model.dwelo.stg_users"
2020-10-23 21:13:00.714054 (Thread-2): Writing runtime SQL for node "model.dwelo.stg_command_results"
2020-10-23 21:13:00.719910 (Thread-1): Writing runtime SQL for node "model.dwelo.stg_command_actives"
2020-10-23 21:13:00.783127 (Thread-4): Opening a new connection, currently in state init
2020-10-23 21:13:00.800211 (Thread-2): Opening a new connection, currently in state init
2020-10-23 21:13:00.802939 (Thread-3): Writing injected SQL for node "model.dwelo.stg_commands"
2020-10-23 21:13:00.804119 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:13:00.804784 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:13:00.806008 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:13:00.814181 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:13:00.818581 (Thread-3): finished collecting timing info
2020-10-23 21:13:00.835863 (Thread-3): Writing runtime SQL for node "model.dwelo.stg_commands"
2020-10-23 21:13:00.841480 (Thread-3): Opening a new connection, currently in state init
2020-10-23 21:13:00.843540 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:13:01.445366 (Thread-2): On model.dwelo.stg_command_results: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_results"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_results`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select
    *

    ,JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
    select
      command_uuid

      ,command_result IN ('success', 'true') as is_hub_success
      ,command_failure_string
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,event_uuid
      ,device_id

      ,_uid
      ,_source_file
    from
      extract_event_values
    where
      item_key = 'CommandResult'
      and command_uuid is not null
)

select *
from final;


2020-10-23 21:13:01.449102 (Thread-4): On model.dwelo.stg_users: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_users"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_users`
  OPTIONS()
  as with final as (
  select
    *
  from
    `analytics-interview`.`interview_source`.`raw_users`
)

select
  *
from
  final;


2020-10-23 21:13:01.493202 (Thread-1): On model.dwelo.stg_command_actives: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_command_actives"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_command_actives`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select
    *

    ,JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
    select
      command_uuid
      ,command_node_id

      ,update_timestamp
      ,event_timestamp
      ,device_id

      ,_uid
      ,_source_file
    from
      extract_event_values
    where
      item_key = 'CommandActive'
      and command_uuid is not null
)

select *
from final;


2020-10-23 21:13:01.517747 (Thread-3): On model.dwelo.stg_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "model.dwelo.stg_commands"} */


  create or replace view `analytics-interview`.`dev_sam`.`stg_commands`
  OPTIONS()
  as with column_renames as (
  select
    EventType as event_type
    ,DateCreated as update_timestamp
    ,MapRevision as map_revision
    ,ItemKey as item_key
    ,ItemRevision as item_revision
    ,EndpointId as twilio_sync_endpoint_id
    ,ItemData as item_data
    ,MapUniqueName as  device_id

    ,_source_file
    ,concat(MapUniqueName, '_', MapRevision, '_', STRING(DateCreated)) as _uid
  from
    `analytics-interview`.`interview_source`.`raw_sync_events`
)
,extract_event_values as (
  select
    *

    ,JSON_EXTRACT_SCALAR(item_data, '$.uuid') as event_uuid
    ,JSON_EXTRACT_SCALAR(item_data, '$.desired_state[0]') as command

    ,case
     when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) < 26
      then safe_cast(JSON_EXTRACT_SCALAR(item_data, '$.timestamp') as timestamp)
      when JSON_EXTRACT_SCALAR(item_data, '$.timestamp') is not null and CHAR_LENGTH(JSON_EXTRACT_SCALAR(item_data, '$.timestamp')) > 26
      then safe_cast(substr(JSON_EXTRACT_SCALAR(item_data, '$.timestamp'),0,26) as timestamp)
    end as event_timestamp

    ,case when item_key in ('Command') then
      JSON_EXTRACT(item_data, '$.desired_state')
      else null
    end as _raw_command_desired_state
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.client')
      else null
    end as command_client
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.user')
      else null
    end as command_user
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin')
      else null
     end as command_origin
    ,case when item_key in ('Command') then
      JSON_EXTRACT_SCALAR(item_data, '$.origin_id')
      else null
     end as command_origin_id

    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.result')
      else null
    end as command_result
    ,case when item_key in ('CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.failure_string')
      else null
    end as command_failure_string

    ,case when item_key in ('CommandActive', 'CommandResult') then
      JSON_EXTRACT_SCALAR(item_data, '$.node_id')
      else null
    end as command_node_id

    ,case when item_key in ('Command', 'CommandActive', 'CommandResult') then
      case
        when JSON_EXTRACT_SCALAR(item_data, '$.command_id') is not null
        then JSON_EXTRACT_SCALAR(item_data, '$.command_id')
        else JSON_EXTRACT_SCALAR(item_data, '$.uuid')
      end
      else null
    end as command_uuid

    -- NEW COLUMNS PARSING `$.desired_state'` CAN BE ADDED HERE --

  from
    column_renames
)
,final as (
  select
    *
  from
    extract_event_values
  where
    item_key = 'Command'
    and command_uuid is not null
)

select *
from final;


2020-10-23 21:13:02.429270 (Thread-3): finished collecting timing info
2020-10-23 21:13:02.432600 (Thread-3): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5cb7646-8c41-4f1a-8b8b-530d841d3050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3a161760>]}
2020-10-23 21:13:02.436108 (Thread-3): 21:13:02 | 3 of 4 OK created view model dev_sam.stg_commands.................... [CREATE VIEW in 1.92s]
2020-10-23 21:13:02.438379 (Thread-3): Finished running node model.dwelo.stg_commands
2020-10-23 21:13:02.446415 (Thread-1): finished collecting timing info
2020-10-23 21:13:02.450097 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5cb7646-8c41-4f1a-8b8b-530d841d3050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3aab0760>]}
2020-10-23 21:13:02.453179 (Thread-1): 21:13:02 | 1 of 4 OK created view model dev_sam.stg_command_actives............. [CREATE VIEW in 1.94s]
2020-10-23 21:13:02.454959 (Thread-1): Finished running node model.dwelo.stg_command_actives
2020-10-23 21:13:02.469316 (Thread-2): finished collecting timing info
2020-10-23 21:13:02.482580 (Thread-4): finished collecting timing info
2020-10-23 21:13:02.483785 (Thread-2): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5cb7646-8c41-4f1a-8b8b-530d841d3050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3aab0af0>]}
2020-10-23 21:13:02.486549 (Thread-4): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5cb7646-8c41-4f1a-8b8b-530d841d3050', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3a172dc0>]}
2020-10-23 21:13:02.490156 (Thread-2): 21:13:02 | 2 of 4 OK created view model dev_sam.stg_command_results............. [CREATE VIEW in 1.97s]
2020-10-23 21:13:02.493080 (Thread-4): 21:13:02 | 4 of 4 OK created view model dev_sam.stg_users....................... [CREATE VIEW in 1.97s]
2020-10-23 21:13:02.494632 (Thread-2): Finished running node model.dwelo.stg_command_results
2020-10-23 21:13:02.496834 (Thread-4): Finished running node model.dwelo.stg_users
2020-10-23 21:13:02.502680 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:13:02.504930 (MainThread): 21:13:02 | 
2020-10-23 21:13:02.507032 (MainThread): 21:13:02 | Finished running 4 view models in 4.41s.
2020-10-23 21:13:02.512956 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:13:02.517990 (MainThread): Connection 'model.dwelo.stg_command_actives' was properly closed.
2020-10-23 21:13:02.520362 (MainThread): Connection 'model.dwelo.stg_command_results' was properly closed.
2020-10-23 21:13:02.523301 (MainThread): Connection 'model.dwelo.stg_commands' was properly closed.
2020-10-23 21:13:02.527160 (MainThread): Connection 'model.dwelo.stg_users' was properly closed.
2020-10-23 21:13:02.571390 (MainThread): 
2020-10-23 21:13:02.582352 (MainThread): Completed successfully
2020-10-23 21:13:02.587730 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-10-23 21:13:02.597511 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3a178280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3a161d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f3adb9130>]}
2020-10-23 21:13:02.603789 (MainThread): Flushing usage events
2020-10-23 21:14:01.060062 (MainThread): Running with dbt=0.18.0
2020-10-23 21:14:01.324224 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['staging'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-23 21:14:01.330530 (MainThread): Tracking: tracking
2020-10-23 21:14:01.333821 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6be97f2dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bebdc6f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6be98000d0>]}
2020-10-23 21:14:01.366680 (MainThread): Partial parsing not enabled
2020-10-23 21:14:01.370984 (MainThread): Parsing macros/etc.sql
2020-10-23 21:14:01.374521 (MainThread): Parsing macros/catalog.sql
2020-10-23 21:14:01.389036 (MainThread): Parsing macros/adapters.sql
2020-10-23 21:14:01.423405 (MainThread): Parsing macros/materializations/view.sql
2020-10-23 21:14:01.430055 (MainThread): Parsing macros/materializations/table.sql
2020-10-23 21:14:01.447563 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-23 21:14:01.468854 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-23 21:14:01.474367 (MainThread): Parsing macros/materializations/copy.sql
2020-10-23 21:14:01.482837 (MainThread): Parsing macros/materializations/seed.sql
2020-10-23 21:14:01.492123 (MainThread): Parsing macros/core.sql
2020-10-23 21:14:01.503028 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-23 21:14:01.525151 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-23 21:14:01.539449 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-23 21:14:01.555500 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-23 21:14:01.591194 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-23 21:14:01.631028 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-23 21:14:01.637718 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-23 21:14:01.692156 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-23 21:14:01.704672 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-23 21:14:01.710910 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-23 21:14:01.723005 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-23 21:14:01.761274 (MainThread): Parsing macros/adapters/common.sql
2020-10-23 21:14:01.843123 (MainThread): Parsing macros/etc/query.sql
2020-10-23 21:14:01.847907 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-23 21:14:01.852483 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-23 21:14:01.856409 (MainThread): Parsing macros/etc/datetime.sql
2020-10-23 21:14:01.872382 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-23 21:14:01.877152 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-23 21:14:01.880256 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-23 21:14:01.885500 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-23 21:14:01.889648 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-23 21:14:01.895584 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-23 21:14:01.909417 (MainThread): Partial parsing not enabled
2020-10-23 21:14:02.011194 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-23 21:14:02.043120 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-23 21:14:02.062983 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-23 21:14:02.082305 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-23 21:14:02.104901 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-23 21:14:02.132706 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-23 21:14:02.155021 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-23 21:14:02.187202 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:14:02.207582 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:14:02.227652 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:14:02.247588 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:14:02.268056 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:14:03.370408 (MainThread): Found 7 models, 36 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-23 21:14:03.375219 (MainThread): 
2020-10-23 21:14:03.378263 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:14:03.463411 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-23 21:14:03.466045 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-23 21:14:03.469378 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:04.068301 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-23 21:14:04.486478 (MainThread): 21:14:04 | Concurrency: 4 threads (target='dev')
2020-10-23 21:14:04.489470 (MainThread): 21:14:04 | 
2020-10-23 21:14:04.500663 (Thread-1): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-23 21:14:04.501104 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-23 21:14:04.501424 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-23 21:14:04.507666 (Thread-3): 21:14:04 | 3 of 23 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-23 21:14:04.503679 (Thread-1): 21:14:04 | 1 of 23 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-23 21:14:04.505925 (Thread-2): 21:14:04 | 2 of 23 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-23 21:14:04.501848 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-23 21:14:04.518074 (Thread-4): 21:14:04 | 4 of 23 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-23 21:14:04.512995 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-23 21:14:04.515810 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-23 21:14:04.510722 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-23 21:14:04.527268 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-23 21:14:04.523000 (Thread-1): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-23 21:14:04.525497 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-23 21:14:04.520905 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-23 21:14:04.573193 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57372), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:04.585453 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-23 21:14:04.587138 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-23 21:14:04.586974 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-23 21:14:04.589638 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44190), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:04.613943 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-23 21:14:04.614219 (Thread-1): finished collecting timing info
2020-10-23 21:14:04.667418 (Thread-3): finished collecting timing info
2020-10-23 21:14:04.670074 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:04.686079 (Thread-3): Opening a new connection, currently in state init
2020-10-23 21:14:04.686310 (Thread-4): finished collecting timing info
2020-10-23 21:14:04.692759 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-23 21:14:04.695466 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:04.697177 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:04.698592 (Thread-4): Opening a new connection, currently in state init
2020-10-23 21:14:04.710886 (Thread-2): finished collecting timing info
2020-10-23 21:14:04.714161 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:04.715711 (Thread-2): Opening a new connection, currently in state init
2020-10-23 21:14:04.724009 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:05.322088 (Thread-1): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-23 21:14:05.330644 (Thread-2): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-23 21:14:05.346329 (Thread-3): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-23 21:14:05.370089 (Thread-4): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-23 21:14:06.446493 (Thread-2): finished collecting timing info
2020-10-23 21:14:06.452334 (Thread-2): 21:14:06 | 2 of 23 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 1.94s]
2020-10-23 21:14:06.455682 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-23 21:14:06.459563 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-23 21:14:06.462997 (Thread-2): 21:14:06 | 5 of 23 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-23 21:14:06.465733 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-23 21:14:06.468328 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-23 21:14:06.488561 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-23 21:14:06.503991 (Thread-2): finished collecting timing info
2020-10-23 21:14:06.507442 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:14:06.510517 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:06.856461 (Thread-1): finished collecting timing info
2020-10-23 21:14:06.859926 (Thread-1): 21:14:06 | 1 of 23 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.35s]
2020-10-23 21:14:06.861675 (Thread-1): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-23 21:14:06.865204 (Thread-1): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 21:14:06.866397 (Thread-4): finished collecting timing info
2020-10-23 21:14:06.867637 (Thread-1): 21:14:06 | 6 of 23 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-23 21:14:06.869535 (Thread-4): 21:14:06 | 4 of 23 PASS not_null_stg_command_results_is_hub_success............. [PASS in 2.35s]
2020-10-23 21:14:06.872447 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-23 21:14:06.873708 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-23 21:14:06.876137 (Thread-1): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 21:14:06.877932 (Thread-4): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 21:14:06.896296 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-23 21:14:06.897841 (Thread-4): 21:14:06 | 7 of 23 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-23 21:14:06.904697 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-23 21:14:06.906597 (Thread-1): finished collecting timing info
2020-10-23 21:14:06.907614 (Thread-4): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 21:14:06.909773 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:06.925731 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-23 21:14:06.926759 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:06.940217 (Thread-4): finished collecting timing info
2020-10-23 21:14:06.945178 (Thread-4): Opening a new connection, currently in state closed
2020-10-23 21:14:06.951327 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:06.991593 (Thread-3): finished collecting timing info
2020-10-23 21:14:06.996616 (Thread-3): 21:14:06 | 3 of 23 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.49s]
2020-10-23 21:14:06.999936 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-23 21:14:07.002583 (Thread-3): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 21:14:07.005564 (Thread-3): 21:14:07 | 8 of 23 START test not_null_stg_commands_update_timestamp............ [RUN]
2020-10-23 21:14:07.009511 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-23 21:14:07.012794 (Thread-3): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 21:14:07.042423 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44194), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:07.047320 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44196), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:07.052181 (Thread-3): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57382), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:07.055377 (Thread-3): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57384), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:07.058356 (Thread-3): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57386), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:07.061513 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57388), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:07.064826 (Thread-3): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44198), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:07.068129 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44200), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:07.083527 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-23 21:14:07.099568 (Thread-3): finished collecting timing info
2020-10-23 21:14:07.103485 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:14:07.107633 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:07.312430 (Thread-2): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-23 21:14:07.690661 (Thread-4): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-23 21:14:07.700344 (Thread-1): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-23 21:14:07.807724 (Thread-3): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-23 21:14:08.357185 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: _raw_desired_state at [10:7]')
2020-10-23 21:14:08.775575 (Thread-2): finished collecting timing info
2020-10-23 21:14:08.780132 (Thread-2): 21:14:08 | 5 of 23 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.31s]
2020-10-23 21:14:08.782804 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-23 21:14:08.785532 (Thread-2): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-23 21:14:08.787785 (Thread-2): 21:14:08 | 9 of 23 START test not_null_stg_commands_user_id..................... [RUN]
2020-10-23 21:14:08.792059 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-23 21:14:08.794519 (Thread-2): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-23 21:14:08.812225 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-23 21:14:08.818500 (Thread-2): finished collecting timing info
2020-10-23 21:14:08.820812 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:14:08.823085 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:09.261966 (Thread-3): finished collecting timing info
2020-10-23 21:14:09.267513 (Thread-3): 21:14:09 | 8 of 23 PASS not_null_stg_commands_update_timestamp.................. [PASS in 2.26s]
2020-10-23 21:14:09.270441 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-23 21:14:09.273007 (Thread-3): Began running node test.dwelo.not_null_stg_users_date_registered
2020-10-23 21:14:09.275714 (Thread-3): 21:14:09 | 10 of 23 START test not_null_stg_users_date_registered............... [RUN]
2020-10-23 21:14:09.278754 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_date_registered".
2020-10-23 21:14:09.281249 (Thread-3): Compiling test.dwelo.not_null_stg_users_date_registered
2020-10-23 21:14:09.303501 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_date_registered"
2020-10-23 21:14:09.314502 (Thread-3): finished collecting timing info
2020-10-23 21:14:09.318004 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:14:09.321618 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:09.398979 (Thread-4): finished collecting timing info
2020-10-23 21:14:09.402109 (Thread-4): 21:14:09 | 7 of 23 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.50s]
2020-10-23 21:14:09.404453 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-23 21:14:09.406437 (Thread-4): Began running node test.dwelo.not_null_stg_users_last_modified
2020-10-23 21:14:09.408274 (Thread-4): 21:14:09 | 11 of 23 START test not_null_stg_users_last_modified................. [RUN]
2020-10-23 21:14:09.410660 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_last_modified".
2020-10-23 21:14:09.412500 (Thread-4): Compiling test.dwelo.not_null_stg_users_last_modified
2020-10-23 21:14:09.437876 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_users_last_modified"
2020-10-23 21:14:09.445276 (Thread-4): finished collecting timing info
2020-10-23 21:14:09.447486 (Thread-4): Opening a new connection, currently in state closed
2020-10-23 21:14:09.449627 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:09.494821 (Thread-2): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-23 21:14:09.629526 (Thread-1): finished collecting timing info
2020-10-23 21:14:09.632760 (Thread-1): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: _raw_desired_state at [10:7]

(job ID: 05aa20ba-bf81-4b63-91fa-42636c975cfb)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-23 21:14:09.636595 (Thread-1): 21:14:09 | 6 of 23 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 2.77s]
2020-10-23 21:14:09.642431 (Thread-1): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-23 21:14:09.645536 (Thread-1): Began running node test.dwelo.not_null_stg_users_user_id
2020-10-23 21:14:09.647907 (Thread-1): 21:14:09 | 12 of 23 START test not_null_stg_users_user_id....................... [RUN]
2020-10-23 21:14:09.651332 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_user_id".
2020-10-23 21:14:09.653214 (Thread-1): Compiling test.dwelo.not_null_stg_users_user_id
2020-10-23 21:14:09.669982 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_user_id"
2020-10-23 21:14:09.677816 (Thread-1): finished collecting timing info
2020-10-23 21:14:09.680910 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:09.683276 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:10.015058 (Thread-3): On test.dwelo.not_null_stg_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where date_registered is null



2020-10-23 21:14:10.079380 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-23 21:14:10.105889 (Thread-4): On test.dwelo.not_null_stg_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where last_modified is null



2020-10-23 21:14:10.276820 (Thread-1): On test.dwelo.not_null_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where user_id is null



2020-10-23 21:14:10.605025 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]')
2020-10-23 21:14:10.893811 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-23 21:14:11.345479 (Thread-3): finished collecting timing info
2020-10-23 21:14:11.349647 (Thread-3): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]

(job ID: 44d92148-34dc-4c7b-8d75-76ec6baa3582)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-23 21:14:11.352864 (Thread-3): 21:14:11 | 10 of 23 ERROR not_null_stg_users_date_registered.................... [ERROR in 2.07s]
2020-10-23 21:14:11.359664 (Thread-2): finished collecting timing info
2020-10-23 21:14:11.364239 (Thread-3): Finished running node test.dwelo.not_null_stg_users_date_registered
2020-10-23 21:14:11.366883 (Thread-2): Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 950a7bb6-c826-4fa7-a421-9ea737af14f8)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-23 21:14:11.369017 (Thread-3): Began running node test.dwelo.not_null_stg_users_username
2020-10-23 21:14:11.370973 (Thread-2): 21:14:11 | 9 of 23 ERROR not_null_stg_commands_user_id.......................... [ERROR in 2.58s]
2020-10-23 21:14:11.372583 (Thread-3): 21:14:11 | 13 of 23 START test not_null_stg_users_username...................... [RUN]
2020-10-23 21:14:11.374483 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-23 21:14:11.377383 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_username".
2020-10-23 21:14:11.378863 (Thread-2): Began running node test.dwelo.stg_commands_locked_state
2020-10-23 21:14:11.381254 (Thread-3): Compiling test.dwelo.not_null_stg_users_username
2020-10-23 21:14:11.383412 (Thread-2): 21:14:11 | 14 of 23 START test stg_commands_locked_state........................ [RUN]
2020-10-23 21:14:11.400507 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_username"
2020-10-23 21:14:11.401376 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-23 21:14:11.405542 (Thread-2): Compiling test.dwelo.stg_commands_locked_state
2020-10-23 21:14:11.421673 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57392), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:11.424866 (Thread-3): finished collecting timing info
2020-10-23 21:14:11.426022 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44210), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:11.428501 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:14:11.432751 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44218), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:11.435663 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:11.438696 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57400), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:11.454972 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44214), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:11.460499 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57404), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:11.463812 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57408), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:11.466145 (Thread-2): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44226), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:11.468453 (Thread-2): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57414), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:11.470959 (Thread-2): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44230), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:11.495928 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-23 21:14:11.503838 (Thread-2): finished collecting timing info
2020-10-23 21:14:11.507069 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:14:11.509764 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:11.736987 (Thread-4): finished collecting timing info
2020-10-23 21:14:11.740007 (Thread-4): 21:14:11 | 11 of 23 PASS not_null_stg_users_last_modified....................... [PASS in 2.33s]
2020-10-23 21:14:11.741586 (Thread-4): Finished running node test.dwelo.not_null_stg_users_last_modified
2020-10-23 21:14:11.744076 (Thread-4): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-23 21:14:11.745783 (Thread-4): 21:14:11 | 15 of 23 START test stg_commands_pin_assignment...................... [RUN]
2020-10-23 21:14:11.747898 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-23 21:14:11.749688 (Thread-4): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-23 21:14:11.765359 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-23 21:14:11.772664 (Thread-4): finished collecting timing info
2020-10-23 21:14:11.775393 (Thread-4): Opening a new connection, currently in state closed
2020-10-23 21:14:11.778129 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:11.969247 (Thread-1): finished collecting timing info
2020-10-23 21:14:11.972493 (Thread-1): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 46d196d8-e49b-4ec3-9e27-b8b2766b1a45)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-23 21:14:11.975233 (Thread-1): 21:14:11 | 12 of 23 ERROR not_null_stg_users_user_id............................ [ERROR in 2.32s]
2020-10-23 21:14:11.977502 (Thread-1): Finished running node test.dwelo.not_null_stg_users_user_id
2020-10-23 21:14:11.980575 (Thread-1): Began running node test.dwelo.stg_commands_switch_state
2020-10-23 21:14:11.982791 (Thread-1): 21:14:11 | 16 of 23 START test stg_commands_switch_state........................ [RUN]
2020-10-23 21:14:11.985560 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-23 21:14:11.988743 (Thread-1): Compiling test.dwelo.stg_commands_switch_state
2020-10-23 21:14:12.004678 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-23 21:14:12.011718 (Thread-1): finished collecting timing info
2020-10-23 21:14:12.014855 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:12.017167 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:12.192551 (Thread-3): On test.dwelo.not_null_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where username is null



2020-10-23 21:14:12.239547 (Thread-2): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:14:12.479354 (Thread-4): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:14:12.647981 (Thread-1): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:14:12.827652 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-23 21:14:13.075576 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:6]')
2020-10-23 21:14:13.116891 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-23 21:14:13.678777 (Thread-3): finished collecting timing info
2020-10-23 21:14:13.685926 (Thread-3): 21:14:13 | 13 of 23 PASS not_null_stg_users_username............................ [PASS in 2.31s]
2020-10-23 21:14:13.688626 (Thread-3): Finished running node test.dwelo.not_null_stg_users_username
2020-10-23 21:14:13.691651 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:14:13.694335 (Thread-3): 21:14:13 | 17 of 23 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-23 21:14:13.696792 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-23 21:14:13.698936 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:14:13.715597 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-23 21:14:13.721498 (Thread-3): finished collecting timing info
2020-10-23 21:14:13.723776 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:14:13.725808 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:13.884096 (Thread-2): finished collecting timing info
2020-10-23 21:14:13.888442 (Thread-2): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 73fc8a6c-c3b9-4080-8b8f-ac94d5d83f9c)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 21:14:13.890754 (Thread-2): 21:14:13 | 14 of 23 ERROR stg_commands_locked_state............................. [ERROR in 2.49s]
2020-10-23 21:14:13.892845 (Thread-2): Finished running node test.dwelo.stg_commands_locked_state
2020-10-23 21:14:13.894523 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:14:13.896147 (Thread-2): 21:14:13 | 18 of 23 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-23 21:14:13.898685 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-23 21:14:13.900483 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:14:13.915732 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-23 21:14:13.920961 (Thread-2): finished collecting timing info
2020-10-23 21:14:13.923158 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:14:13.925844 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:14.347560 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:14:14.350661 (Thread-4): finished collecting timing info
2020-10-23 21:14:14.359396 (Thread-4): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:6]

(job ID: fe754dee-23c7-40c5-b976-169f3a0d2b11)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 21:14:14.362322 (Thread-4): 21:14:14 | 15 of 23 ERROR stg_commands_pin_assignment........................... [ERROR in 2.61s]
2020-10-23 21:14:14.364275 (Thread-4): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-23 21:14:14.366355 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-23 21:14:14.367876 (Thread-4): 21:14:14 | 19 of 23 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-23 21:14:14.369637 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-23 21:14:14.371272 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-23 21:14:14.386424 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-23 21:14:14.393281 (Thread-1): finished collecting timing info
2020-10-23 21:14:14.395893 (Thread-1): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 0df18c14-b9f8-406f-8117-76e9ec96aa45)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 21:14:14.398381 (Thread-1): 21:14:14 | 16 of 23 ERROR stg_commands_switch_state............................. [ERROR in 2.41s]
2020-10-23 21:14:14.399363 (Thread-4): finished collecting timing info
2020-10-23 21:14:14.401363 (Thread-1): Finished running node test.dwelo.stg_commands_switch_state
2020-10-23 21:14:14.403700 (Thread-4): Opening a new connection, currently in state closed
2020-10-23 21:14:14.406008 (Thread-1): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-23 21:14:14.408673 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:14.410313 (Thread-1): 21:14:14 | 20 of 23 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-23 21:14:14.423622 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-23 21:14:14.425916 (Thread-1): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-23 21:14:14.443557 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-23 21:14:14.451876 (Thread-1): finished collecting timing info
2020-10-23 21:14:14.461385 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:14.466987 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:14.562788 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-23 21:14:14.764802 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44250), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:14.767513 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57426), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:14.769968 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57428), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:14.772321 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44242), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:14.774240 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44244), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:14.776194 (Thread-2): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57432), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:14.778377 (Thread-2): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57436), raddr=('172.217.14.74', 443)>
2020-10-23 21:14:14.780841 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44254), raddr=('142.250.72.234', 443)>
2020-10-23 21:14:15.000224 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-23 21:14:15.028599 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-23 21:14:15.092524 (Thread-1): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-23 21:14:15.171686 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-23 21:14:15.518691 (Thread-3): finished collecting timing info
2020-10-23 21:14:15.523934 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: e86617a7-57c0-4453-8b1b-3bbdd4449b8e)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 21:14:15.528813 (Thread-3): 21:14:15 | 17 of 23 ERROR stg_commands_thermostat_mode.......................... [ERROR in 1.83s]
2020-10-23 21:14:15.531313 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-23 21:14:15.534608 (Thread-3): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-23 21:14:15.537399 (Thread-3): 21:14:15 | 21 of 23 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-23 21:14:15.539749 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-23 21:14:15.541869 (Thread-3): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-23 21:14:15.559747 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-23 21:14:15.566684 (Thread-3): finished collecting timing info
2020-10-23 21:14:15.569080 (Thread-3): Opening a new connection, currently in state closed
2020-10-23 21:14:15.571983 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:16.164853 (Thread-3): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-23 21:14:16.428921 (Thread-2): finished collecting timing info
2020-10-23 21:14:16.434497 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: 16ec2e88-24bf-441f-a4e2-84344484e849)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 21:14:16.437612 (Thread-2): 21:14:16 | 18 of 23 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 2.54s]
2020-10-23 21:14:16.439787 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-23 21:14:16.442340 (Thread-2): Began running node test.dwelo.unique_stg_users_user_id
2020-10-23 21:14:16.444338 (Thread-2): 21:14:16 | 22 of 23 START test unique_stg_users_user_id......................... [RUN]
2020-10-23 21:14:16.446516 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_users_user_id".
2020-10-23 21:14:16.448560 (Thread-2): Compiling test.dwelo.unique_stg_users_user_id
2020-10-23 21:14:16.464355 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_users_user_id"
2020-10-23 21:14:16.477353 (Thread-2): finished collecting timing info
2020-10-23 21:14:16.479279 (Thread-2): Opening a new connection, currently in state closed
2020-10-23 21:14:16.481526 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:16.695457 (Thread-1): finished collecting timing info
2020-10-23 21:14:16.701775 (Thread-1): 21:14:16 | 20 of 23 FAIL 144 unique_stg_command_results_command_uuid............ [FAIL 144 in 2.28s]
2020-10-23 21:14:16.703151 (Thread-4): finished collecting timing info
2020-10-23 21:14:16.706883 (Thread-1): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-23 21:14:16.708991 (Thread-4): 21:14:16 | 19 of 23 FAIL 145 unique_stg_command_actives_command_uuid............ [FAIL 145 in 2.34s]
2020-10-23 21:14:16.711438 (Thread-1): Began running node test.dwelo.unique_stg_users_username
2020-10-23 21:14:16.715313 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-23 21:14:16.716522 (Thread-1): 21:14:16 | 23 of 23 START test unique_stg_users_username........................ [RUN]
2020-10-23 21:14:16.726132 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_users_username".
2020-10-23 21:14:16.732925 (Thread-1): Compiling test.dwelo.unique_stg_users_username
2020-10-23 21:14:16.756844 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_users_username"
2020-10-23 21:14:16.765131 (Thread-1): finished collecting timing info
2020-10-23 21:14:16.767549 (Thread-1): Opening a new connection, currently in state closed
2020-10-23 21:14:16.770293 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-23 21:14:17.090172 (Thread-2): On test.dwelo.unique_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`stg_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-23 21:14:17.354455 (Thread-1): On test.dwelo.unique_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`stg_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-23 21:14:17.704702 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-23 21:14:17.746157 (Thread-3): finished collecting timing info
2020-10-23 21:14:17.753365 (Thread-3): 21:14:17 | 21 of 23 FAIL 112 unique_stg_commands_command_uuid................... [FAIL 112 in 2.21s]
2020-10-23 21:14:17.756798 (Thread-3): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-23 21:14:18.846863 (Thread-1): finished collecting timing info
2020-10-23 21:14:18.851534 (Thread-1): 21:14:18 | 23 of 23 PASS unique_stg_users_username.............................. [PASS in 2.13s]
2020-10-23 21:14:18.854448 (Thread-1): Finished running node test.dwelo.unique_stg_users_username
2020-10-23 21:14:18.983549 (Thread-2): finished collecting timing info
2020-10-23 21:14:18.987996 (Thread-2): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: f53d8213-6067-45a0-9c12-3c602a1c0e56)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-23 21:14:18.991561 (Thread-2): 21:14:18 | 22 of 23 ERROR unique_stg_users_user_id.............................. [ERROR in 2.55s]
2020-10-23 21:14:18.993533 (Thread-2): Finished running node test.dwelo.unique_stg_users_user_id
2020-10-23 21:14:18.998804 (MainThread): Acquiring new bigquery connection "master".
2020-10-23 21:14:19.001281 (MainThread): 21:14:19 | 
2020-10-23 21:14:19.003308 (MainThread): 21:14:19 | Finished running 23 tests in 15.62s.
2020-10-23 21:14:19.005710 (MainThread): Connection 'master' was properly closed.
2020-10-23 21:14:19.008373 (MainThread): Connection 'test.dwelo.unique_stg_users_username' was properly closed.
2020-10-23 21:14:19.010149 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-23 21:14:19.012253 (MainThread): Connection 'test.dwelo.unique_stg_users_user_id' was properly closed.
2020-10-23 21:14:19.014093 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-23 21:14:19.115347 (MainThread): 
2020-10-23 21:14:19.117463 (MainThread): Completed with 13 errors and 0 warnings:
2020-10-23 21:14:19.119753 (MainThread): 
2020-10-23 21:14:19.122123 (MainThread): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
2020-10-23 21:14:19.124601 (MainThread):   Unrecognized name: _raw_desired_state at [10:7]
2020-10-23 21:14:19.126579 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-23 21:14:19.128288 (MainThread): 
2020-10-23 21:14:19.130103 (MainThread): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
2020-10-23 21:14:19.131971 (MainThread):   Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
2020-10-23 21:14:19.133654 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-23 21:14:19.136107 (MainThread): 
2020-10-23 21:14:19.139935 (MainThread): Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-23 21:14:19.142723 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-23 21:14:19.144832 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-23 21:14:19.146908 (MainThread): 
2020-10-23 21:14:19.148689 (MainThread): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
2020-10-23 21:14:19.150806 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-23 21:14:19.153280 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-23 21:14:19.155662 (MainThread): 
2020-10-23 21:14:19.157533 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-23 21:14:19.159287 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-23 21:14:19.160758 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-23 21:14:19.162409 (MainThread): 
2020-10-23 21:14:19.164412 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-23 21:14:19.168278 (MainThread):   Unrecognized name: slot at [11:6]
2020-10-23 21:14:19.171420 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-23 21:14:19.174031 (MainThread): 
2020-10-23 21:14:19.176858 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-23 21:14:19.180212 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-23 21:14:19.184191 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-23 21:14:19.187780 (MainThread): 
2020-10-23 21:14:19.190646 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-23 21:14:19.192855 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-23 21:14:19.195154 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-23 21:14:19.197761 (MainThread): 
2020-10-23 21:14:19.199781 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-23 21:14:19.201658 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-23 21:14:19.203399 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-23 21:14:19.205100 (MainThread): 
2020-10-23 21:14:19.207134 (MainThread): Failure in test unique_stg_command_results_command_uuid (models/staging/schema.yml)
2020-10-23 21:14:19.209001 (MainThread):   Got 144 results, expected 0.
2020-10-23 21:14:19.210780 (MainThread): 
2020-10-23 21:14:19.212610 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_command_results_command_uuid.sql
2020-10-23 21:14:19.214648 (MainThread): 
2020-10-23 21:14:19.216837 (MainThread): Failure in test unique_stg_command_actives_command_uuid (models/staging/schema.yml)
2020-10-23 21:14:19.219743 (MainThread):   Got 145 results, expected 0.
2020-10-23 21:14:19.222220 (MainThread): 
2020-10-23 21:14:19.224770 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_command_actives_command_uuid.sql
2020-10-23 21:14:19.226696 (MainThread): 
2020-10-23 21:14:19.229497 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-23 21:14:19.232468 (MainThread):   Got 112 results, expected 0.
2020-10-23 21:14:19.235144 (MainThread): 
2020-10-23 21:14:19.236960 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-23 21:14:19.238986 (MainThread): 
2020-10-23 21:14:19.241156 (MainThread): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
2020-10-23 21:14:19.242995 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-23 21:14:19.244776 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-23 21:14:19.246771 (MainThread): 
Done. PASS=10 WARN=0 ERROR=13 SKIP=0 TOTAL=23
2020-10-23 21:14:19.249343 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6be93c3430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6be9496f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6be943ab50>]}
2020-10-23 21:14:19.251483 (MainThread): Flushing usage events
2020-10-26 17:43:12.368649 (MainThread): Running with dbt=0.18.0
2020-10-26 17:43:12.626314 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_two'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-26 17:43:12.635225 (MainThread): Tracking: tracking
2020-10-26 17:43:12.639137 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85aa14b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff859d10e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff859d10e50>]}
2020-10-26 17:43:12.676126 (MainThread): Partial parsing not enabled
2020-10-26 17:43:12.679946 (MainThread): Parsing macros/etc.sql
2020-10-26 17:43:12.684367 (MainThread): Parsing macros/catalog.sql
2020-10-26 17:43:12.697579 (MainThread): Parsing macros/adapters.sql
2020-10-26 17:43:12.731569 (MainThread): Parsing macros/materializations/view.sql
2020-10-26 17:43:12.737916 (MainThread): Parsing macros/materializations/table.sql
2020-10-26 17:43:12.757734 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-26 17:43:12.778379 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-26 17:43:12.783548 (MainThread): Parsing macros/materializations/copy.sql
2020-10-26 17:43:12.791458 (MainThread): Parsing macros/materializations/seed.sql
2020-10-26 17:43:12.798219 (MainThread): Parsing macros/core.sql
2020-10-26 17:43:12.805266 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-26 17:43:12.821570 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-26 17:43:12.832206 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-26 17:43:12.844064 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-26 17:43:12.870206 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-26 17:43:12.898070 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-26 17:43:12.903077 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-26 17:43:12.954162 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-26 17:43:12.965595 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-26 17:43:12.970246 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-26 17:43:12.982113 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-26 17:43:13.018774 (MainThread): Parsing macros/adapters/common.sql
2020-10-26 17:43:13.100800 (MainThread): Parsing macros/etc/query.sql
2020-10-26 17:43:13.105003 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-26 17:43:13.109092 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-26 17:43:13.112823 (MainThread): Parsing macros/etc/datetime.sql
2020-10-26 17:43:13.129124 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-26 17:43:13.134379 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-26 17:43:13.137555 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-26 17:43:13.142113 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-26 17:43:13.146061 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-26 17:43:13.152767 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-26 17:43:13.167532 (MainThread): Partial parsing not enabled
2020-10-26 17:43:13.267834 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-26 17:43:13.301267 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-26 17:43:13.323483 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-26 17:43:13.345506 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-26 17:43:13.369652 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-26 17:43:13.393537 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-26 17:43:13.417254 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-26 17:43:13.452390 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-26 17:43:13.473032 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-26 17:43:13.495392 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-26 17:43:13.516384 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-26 17:43:13.536504 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-26 17:43:14.682896 (MainThread): Found 7 models, 37 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-26 17:43:14.687187 (MainThread): 
2020-10-26 17:43:14.689950 (MainThread): Acquiring new bigquery connection "master".
2020-10-26 17:43:14.762360 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-26 17:43:14.764651 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-26 17:43:14.766838 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:15.416464 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-26 17:43:15.878754 (MainThread): 17:43:15 | Concurrency: 4 threads (target='dev')
2020-10-26 17:43:15.881207 (MainThread): 17:43:15 | 
2020-10-26 17:43:15.890176 (Thread-1): Began running node test.dwelo.not_met_daily_command_count_by_username_num_of_successful_commands
2020-10-26 17:43:15.890875 (Thread-2): Began running node test.dwelo.not_null_dim_users_date_registered
2020-10-26 17:43:15.892045 (Thread-3): Began running node test.dwelo.not_null_dim_users_last_modified
2020-10-26 17:43:15.892672 (Thread-4): Began running node test.dwelo.not_null_dim_users_user_id
2020-10-26 17:43:15.893124 (Thread-1): 17:43:15 | 1 of 17 START test not_met_daily_command_count_by_username_num_of_successful_commands [RUN]
2020-10-26 17:43:15.895157 (Thread-2): 17:43:15 | 2 of 17 START test not_null_dim_users_date_registered................ [RUN]
2020-10-26 17:43:15.896931 (Thread-3): 17:43:15 | 3 of 17 START test not_null_dim_users_last_modified.................. [RUN]
2020-10-26 17:43:15.899189 (Thread-4): 17:43:15 | 4 of 17 START test not_null_dim_users_user_id........................ [RUN]
2020-10-26 17:43:15.902796 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_met_daily_command_count_by_username_num_of_successful_commands".
2020-10-26 17:43:15.907410 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_date_registered".
2020-10-26 17:43:15.910309 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_last_modified".
2020-10-26 17:43:15.922621 (Thread-3): Compiling test.dwelo.not_null_dim_users_last_modified
2020-10-26 17:43:15.917346 (Thread-1): Compiling test.dwelo.not_met_daily_command_count_by_username_num_of_successful_commands
2020-10-26 17:43:15.920027 (Thread-2): Compiling test.dwelo.not_null_dim_users_date_registered
2020-10-26 17:43:15.914362 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_user_id".
2020-10-26 17:43:15.945725 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57470), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:15.973541 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_dim_users_last_modified"
2020-10-26 17:43:15.981223 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_dim_users_date_registered"
2020-10-26 17:43:15.982253 (Thread-4): Compiling test.dwelo.not_null_dim_users_user_id
2020-10-26 17:43:15.985006 (Thread-1): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53532), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:16.016476 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_dim_users_user_id"
2020-10-26 17:43:16.065324 (Thread-3): finished collecting timing info
2020-10-26 17:43:16.066545 (Thread-2): finished collecting timing info
2020-10-26 17:43:16.079591 (Thread-3): Opening a new connection, currently in state init
2020-10-26 17:43:16.089765 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:16.087279 (Thread-2): Opening a new connection, currently in state init
2020-10-26 17:43:16.088570 (Thread-1): finished collecting timing info
2020-10-26 17:43:16.086000 (Thread-4): finished collecting timing info
2020-10-26 17:43:16.097224 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:16.103168 (Thread-4): Opening a new connection, currently in state init
2020-10-26 17:43:16.100330 (Thread-1): Compilation Error in test not_met_daily_command_count_by_username_num_of_successful_commands (models/marts/schema.yml)
  'test_not' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 1, in top-level template code
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/site-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'test_not' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/site-packages/dbt/compilation.py", line 475, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/site-packages/dbt/compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in test not_met_daily_command_count_by_username_num_of_successful_commands (models/marts/schema.yml)
  'test_not' is undefined
2020-10-26 17:43:16.112195 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:16.114627 (Thread-1): 17:43:16 | 1 of 17 ERROR not_met_daily_command_count_by_username_num_of_successful_commands [ERROR in 0.21s]
2020-10-26 17:43:16.123173 (Thread-1): Finished running node test.dwelo.not_met_daily_command_count_by_username_num_of_successful_commands
2020-10-26 17:43:16.126021 (Thread-1): Began running node test.dwelo.not_null_dim_users_username
2020-10-26 17:43:16.129688 (Thread-1): 17:43:16 | 5 of 17 START test not_null_dim_users_username....................... [RUN]
2020-10-26 17:43:16.134112 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_dim_users_username".
2020-10-26 17:43:16.137916 (Thread-1): Compiling test.dwelo.not_null_dim_users_username
2020-10-26 17:43:16.166034 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_dim_users_username"
2020-10-26 17:43:16.180958 (Thread-1): finished collecting timing info
2020-10-26 17:43:16.185268 (Thread-1): Opening a new connection, currently in state closed
2020-10-26 17:43:16.188895 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:16.926411 (Thread-3): On test.dwelo.not_null_dim_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where last_modified is null



2020-10-26 17:43:16.961400 (Thread-2): On test.dwelo.not_null_dim_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where date_registered is null



2020-10-26 17:43:16.963178 (Thread-4): On test.dwelo.not_null_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where user_id is null



2020-10-26 17:43:17.012181 (Thread-1): On test.dwelo.not_null_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`dim_users`
where username is null



2020-10-26 17:43:17.455989 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered at [10:7]')
2020-10-26 17:43:17.464258 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: last_modified at [10:7]')
2020-10-26 17:43:17.476759 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-26 17:43:17.512585 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: username at [10:7]')
2020-10-26 17:43:18.724419 (Thread-2): finished collecting timing info
2020-10-26 17:43:18.733964 (Thread-4): finished collecting timing info
2020-10-26 17:43:18.736975 (Thread-4): Database Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: b022df73-fdf7-44ba-b532-b4f0d8dd0e86)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_dim_users_user_id (models/marts/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_user_id.sql
2020-10-26 17:43:18.742332 (Thread-3): finished collecting timing info
2020-10-26 17:43:18.730636 (Thread-2): Database Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  Unrecognized name: date_registered at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered at [10:7]

(job ID: 06b367c5-0d2c-4eaf-961e-ef26c5bd7a57)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
  Unrecognized name: date_registered at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_date_registered.sql
2020-10-26 17:43:18.744175 (Thread-4): 17:43:18 | 4 of 17 ERROR not_null_dim_users_user_id............................. [ERROR in 2.83s]
2020-10-26 17:43:18.746797 (Thread-3): Database Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  Unrecognized name: last_modified at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_last_modified.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: last_modified at [10:7]

(job ID: d3c35e15-6ffe-4617-abef-2c3552acb407)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_last_modified"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where last_modified is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
  Unrecognized name: last_modified at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_last_modified.sql
2020-10-26 17:43:18.748787 (Thread-2): 17:43:18 | 2 of 17 ERROR not_null_dim_users_date_registered..................... [ERROR in 2.84s]
2020-10-26 17:43:18.751198 (Thread-4): Finished running node test.dwelo.not_null_dim_users_user_id
2020-10-26 17:43:18.753894 (Thread-3): 17:43:18 | 3 of 17 ERROR not_null_dim_users_last_modified....................... [ERROR in 2.84s]
2020-10-26 17:43:18.762192 (Thread-3): Finished running node test.dwelo.not_null_dim_users_last_modified
2020-10-26 17:43:18.759873 (Thread-1): finished collecting timing info
2020-10-26 17:43:18.760360 (Thread-4): Began running node test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands
2020-10-26 17:43:18.758539 (Thread-2): Finished running node test.dwelo.not_null_dim_users_date_registered
2020-10-26 17:43:18.763878 (Thread-3): Began running node test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date
2020-10-26 17:43:18.765762 (Thread-1): Database Error in test not_null_dim_users_username (models/marts/schema.yml)
  Unrecognized name: username at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_username.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: username at [10:7]

(job ID: 9d018566-d7d8-41e6-acff-95a3ed7be5ea)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`dim_users`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_dim_users_username (models/marts/schema.yml)
  Unrecognized name: username at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_username.sql
2020-10-26 17:43:18.767582 (Thread-4): 17:43:18 | 6 of 17 START test not_null_met_daily_command_count_by_username_num_of_commands [RUN]
2020-10-26 17:43:18.768998 (Thread-2): Began running node test.dwelo.not_null_met_daily_command_count_by_username_username
2020-10-26 17:43:18.770539 (Thread-3): 17:43:18 | 7 of 17 START test not_null_met_daily_command_count_by_username_timestamp_date [RUN]
2020-10-26 17:43:18.773123 (Thread-1): 17:43:18 | 5 of 17 ERROR not_null_dim_users_username............................ [ERROR in 2.64s]
2020-10-26 17:43:18.775837 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands".
2020-10-26 17:43:18.783823 (Thread-4): Compiling test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands
2020-10-26 17:43:18.780026 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date".
2020-10-26 17:43:18.803226 (Thread-3): Compiling test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date
2020-10-26 17:43:18.777998 (Thread-2): 17:43:18 | 8 of 17 START test not_null_met_daily_command_count_by_username_username [RUN]
2020-10-26 17:43:18.781659 (Thread-1): Finished running node test.dwelo.not_null_dim_users_username
2020-10-26 17:43:18.820202 (Thread-1): Began running node test.dwelo.not_null_stg_users_date_registered
2020-10-26 17:43:18.822188 (Thread-1): 17:43:18 | 9 of 17 START test not_null_stg_users_date_registered................ [RUN]
2020-10-26 17:43:18.817909 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_met_daily_command_count_by_username_username".
2020-10-26 17:43:18.802885 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands"
2020-10-26 17:43:18.816671 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date"
2020-10-26 17:43:18.824345 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_date_registered".
2020-10-26 17:43:18.826152 (Thread-2): Compiling test.dwelo.not_null_met_daily_command_count_by_username_username
2020-10-26 17:43:18.831608 (Thread-1): Compiling test.dwelo.not_null_stg_users_date_registered
2020-10-26 17:43:18.832142 (Thread-4): finished collecting timing info
2020-10-26 17:43:18.842437 (Thread-2): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53536), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:18.857576 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_users_date_registered"
2020-10-26 17:43:18.857854 (Thread-3): finished collecting timing info
2020-10-26 17:43:18.863770 (Thread-3): Opening a new connection, currently in state closed
2020-10-26 17:43:18.865727 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:18.858333 (Thread-4): Opening a new connection, currently in state closed
2020-10-26 17:43:18.860434 (Thread-2): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53538), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:18.873269 (Thread-1): finished collecting timing info
2020-10-26 17:43:18.874588 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:18.875535 (Thread-2): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53540), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:18.877730 (Thread-1): Opening a new connection, currently in state closed
2020-10-26 17:43:18.887858 (Thread-2): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53542), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:18.890707 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:18.892373 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57480), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:18.899748 (Thread-2): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57482), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:18.902112 (Thread-2): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57484), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:18.904932 (Thread-2): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57486), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:18.916999 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_met_daily_command_count_by_username_username"
2020-10-26 17:43:18.923795 (Thread-2): finished collecting timing info
2020-10-26 17:43:18.926648 (Thread-2): Opening a new connection, currently in state closed
2020-10-26 17:43:18.929016 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:19.511083 (Thread-3): On test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
where timestamp_date is null



2020-10-26 17:43:19.523778 (Thread-4): On test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
where num_of_commands is null



2020-10-26 17:43:19.534317 (Thread-1): On test.dwelo.not_null_stg_users_date_registered: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where date_registered is null



2020-10-26 17:43:19.557027 (Thread-2): On test.dwelo.not_null_met_daily_command_count_by_username_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
where username is null



2020-10-26 17:43:19.982772 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: timestamp_date at [10:7]')
2020-10-26 17:43:20.010847 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]')
2020-10-26 17:43:20.025736 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: username at [10:7]')
2020-10-26 17:43:20.052230 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: num_of_commands at [10:7]')
2020-10-26 17:43:20.741288 (Thread-4): finished collecting timing info
2020-10-26 17:43:20.746049 (Thread-4): Database Error in test not_null_met_daily_command_count_by_username_num_of_commands (models/marts/schema.yml)
  Unrecognized name: num_of_commands at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_num_of_commands.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: num_of_commands at [10:7]

(job ID: 3035da08-6984-4ebd-904e-e6f9860a977e)

                                                                             -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
  10:where num_of_commands is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_met_daily_command_count_by_username_num_of_commands (models/marts/schema.yml)
  Unrecognized name: num_of_commands at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_num_of_commands.sql
2020-10-26 17:43:20.749571 (Thread-4): 17:43:20 | 6 of 17 ERROR not_null_met_daily_command_count_by_username_num_of_commands [ERROR in 1.97s]
2020-10-26 17:43:20.751686 (Thread-4): Finished running node test.dwelo.not_null_met_daily_command_count_by_username_num_of_commands
2020-10-26 17:43:20.754233 (Thread-4): Began running node test.dwelo.not_null_stg_users_last_modified
2020-10-26 17:43:20.756635 (Thread-4): 17:43:20 | 10 of 17 START test not_null_stg_users_last_modified................. [RUN]
2020-10-26 17:43:20.759179 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_last_modified".
2020-10-26 17:43:20.761164 (Thread-4): Compiling test.dwelo.not_null_stg_users_last_modified
2020-10-26 17:43:20.778817 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_users_last_modified"
2020-10-26 17:43:20.784846 (Thread-4): finished collecting timing info
2020-10-26 17:43:20.787005 (Thread-4): Opening a new connection, currently in state closed
2020-10-26 17:43:20.788967 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:20.905414 (Thread-3): finished collecting timing info
2020-10-26 17:43:20.908766 (Thread-3): Database Error in test not_null_met_daily_command_count_by_username_timestamp_date (models/marts/schema.yml)
  Unrecognized name: timestamp_date at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_timestamp_date.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: timestamp_date at [10:7]

(job ID: 67fef3de-f5d5-4410-b8a4-d891cfb1eaec)

                                                                            -----Query Job SQL Follows-----                                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
  10:where timestamp_date is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_met_daily_command_count_by_username_timestamp_date (models/marts/schema.yml)
  Unrecognized name: timestamp_date at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_timestamp_date.sql
2020-10-26 17:43:20.910836 (Thread-3): 17:43:20 | 7 of 17 ERROR not_null_met_daily_command_count_by_username_timestamp_date [ERROR in 2.13s]
2020-10-26 17:43:20.912876 (Thread-3): Finished running node test.dwelo.not_null_met_daily_command_count_by_username_timestamp_date
2020-10-26 17:43:20.914663 (Thread-3): Began running node test.dwelo.not_null_stg_users_user_id
2020-10-26 17:43:20.916029 (Thread-3): 17:43:20 | 11 of 17 START test not_null_stg_users_user_id....................... [RUN]
2020-10-26 17:43:20.918269 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_user_id".
2020-10-26 17:43:20.919771 (Thread-3): Compiling test.dwelo.not_null_stg_users_user_id
2020-10-26 17:43:20.936962 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_users_user_id"
2020-10-26 17:43:20.944203 (Thread-3): finished collecting timing info
2020-10-26 17:43:20.946504 (Thread-3): Opening a new connection, currently in state closed
2020-10-26 17:43:20.948079 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:21.368587 (Thread-4): On test.dwelo.not_null_stg_users_last_modified: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_last_modified"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where last_modified is null



2020-10-26 17:43:21.382617 (Thread-2): finished collecting timing info
2020-10-26 17:43:21.384045 (Thread-1): finished collecting timing info
2020-10-26 17:43:21.386339 (Thread-2): Database Error in test not_null_met_daily_command_count_by_username_username (models/marts/schema.yml)
  Unrecognized name: username at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_username.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: username at [10:7]

(job ID: 4b931bb6-7ce4-49df-bf5f-0dc4dfff9dd6)

                                                                         -----Query Job SQL Follows-----                                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_met_daily_command_count_by_username_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
  10:where username is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_met_daily_command_count_by_username_username (models/marts/schema.yml)
  Unrecognized name: username at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_username.sql
2020-10-26 17:43:21.388846 (Thread-1): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]

(job ID: 43ac6a70-0347-44d2-ad74-61815b4867f7)

                                                                -----Query Job SQL Follows-----                                                                

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_date_registered"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where date_registered is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
  Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-26 17:43:21.391564 (Thread-2): 17:43:21 | 8 of 17 ERROR not_null_met_daily_command_count_by_username_username.. [ERROR in 2.57s]
2020-10-26 17:43:21.393367 (Thread-1): 17:43:21 | 9 of 17 ERROR not_null_stg_users_date_registered..................... [ERROR in 2.57s]
2020-10-26 17:43:21.396246 (Thread-2): Finished running node test.dwelo.not_null_met_daily_command_count_by_username_username
2020-10-26 17:43:21.397978 (Thread-1): Finished running node test.dwelo.not_null_stg_users_date_registered
2020-10-26 17:43:21.399519 (Thread-2): Began running node test.dwelo.not_null_stg_users_username
2020-10-26 17:43:21.405024 (Thread-1): Began running node test.dwelo.unique_dim_users_user_id
2020-10-26 17:43:21.406724 (Thread-2): 17:43:21 | 12 of 17 START test not_null_stg_users_username...................... [RUN]
2020-10-26 17:43:21.408170 (Thread-1): 17:43:21 | 13 of 17 START test unique_dim_users_user_id......................... [RUN]
2020-10-26 17:43:21.410676 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_users_username".
2020-10-26 17:43:21.412934 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_dim_users_user_id".
2020-10-26 17:43:21.414579 (Thread-2): Compiling test.dwelo.not_null_stg_users_username
2020-10-26 17:43:21.416960 (Thread-1): Compiling test.dwelo.unique_dim_users_user_id
2020-10-26 17:43:21.443107 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_users_username"
2020-10-26 17:43:21.457311 (Thread-1): Writing injected SQL for node "test.dwelo.unique_dim_users_user_id"
2020-10-26 17:43:21.458675 (Thread-2): finished collecting timing info
2020-10-26 17:43:21.461808 (Thread-2): Opening a new connection, currently in state closed
2020-10-26 17:43:21.464488 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:21.465020 (Thread-1): finished collecting timing info
2020-10-26 17:43:21.471367 (Thread-1): Opening a new connection, currently in state closed
2020-10-26 17:43:21.473494 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:21.576187 (Thread-3): On test.dwelo.not_null_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where user_id is null



2020-10-26 17:43:22.004867 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-26 17:43:22.053776 (Thread-2): On test.dwelo.not_null_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_username"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_users`
where username is null



2020-10-26 17:43:22.086675 (Thread-1): On test.dwelo.unique_dim_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`dim_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-26 17:43:22.492388 (Thread-3): finished collecting timing info
2020-10-26 17:43:22.497252 (Thread-3): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 062fe832-840f-4746-83b8-6be21d2a07f8)

                                                            -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_users`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-26 17:43:22.500408 (Thread-3): 17:43:22 | 11 of 17 ERROR not_null_stg_users_user_id............................ [ERROR in 1.58s]
2020-10-26 17:43:22.503129 (Thread-3): Finished running node test.dwelo.not_null_stg_users_user_id
2020-10-26 17:43:22.505875 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-26 17:43:22.506572 (Thread-3): Began running node test.dwelo.unique_dim_users_username
2020-10-26 17:43:22.511995 (Thread-3): 17:43:22 | 14 of 17 START test unique_dim_users_username........................ [RUN]
2020-10-26 17:43:22.514605 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_dim_users_username".
2020-10-26 17:43:22.516757 (Thread-3): Compiling test.dwelo.unique_dim_users_username
2020-10-26 17:43:22.524536 (Thread-3): unclosed <socket.socket fd=5, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53552), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:22.526425 (Thread-3): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57496), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:22.528670 (Thread-3): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57498), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:22.531031 (Thread-3): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57500), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:22.532830 (Thread-3): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57502), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:22.534612 (Thread-3): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53554), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:22.536349 (Thread-3): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53556), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:22.537951 (Thread-3): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53558), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:22.539690 (Thread-3): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 53572), raddr=('172.217.11.170', 443)>
2020-10-26 17:43:22.542651 (Thread-3): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 57510), raddr=('172.217.14.74', 443)>
2020-10-26 17:43:22.556214 (Thread-3): Writing injected SQL for node "test.dwelo.unique_dim_users_username"
2020-10-26 17:43:22.562548 (Thread-3): finished collecting timing info
2020-10-26 17:43:22.564642 (Thread-3): Opening a new connection, currently in state closed
2020-10-26 17:43:22.566954 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:23.100814 (Thread-4): finished collecting timing info
2020-10-26 17:43:23.104627 (Thread-4): 17:43:23 | 10 of 17 PASS not_null_stg_users_last_modified....................... [PASS in 2.35s]
2020-10-26 17:43:23.108105 (Thread-4): Finished running node test.dwelo.not_null_stg_users_last_modified
2020-10-26 17:43:23.111574 (Thread-4): Began running node test.dwelo.unique_met_daily_command_count_by_username_username
2020-10-26 17:43:23.114701 (Thread-4): 17:43:23 | 15 of 17 START test unique_met_daily_command_count_by_username_username [RUN]
2020-10-26 17:43:23.118329 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_met_daily_command_count_by_username_username".
2020-10-26 17:43:23.120197 (Thread-4): Compiling test.dwelo.unique_met_daily_command_count_by_username_username
2020-10-26 17:43:23.136640 (Thread-3): On test.dwelo.unique_dim_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`dim_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-26 17:43:23.140306 (Thread-4): Writing injected SQL for node "test.dwelo.unique_met_daily_command_count_by_username_username"
2020-10-26 17:43:23.151830 (Thread-4): finished collecting timing info
2020-10-26 17:43:23.153850 (Thread-4): Opening a new connection, currently in state closed
2020-10-26 17:43:23.155621 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:23.544545 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: username at [15:11]')
2020-10-26 17:43:23.572110 (Thread-2): finished collecting timing info
2020-10-26 17:43:23.574812 (Thread-2): 17:43:23 | 12 of 17 PASS not_null_stg_users_username............................ [PASS in 2.16s]
2020-10-26 17:43:23.576911 (Thread-2): Finished running node test.dwelo.not_null_stg_users_username
2020-10-26 17:43:23.579058 (Thread-2): Began running node test.dwelo.unique_stg_users_user_id
2020-10-26 17:43:23.581377 (Thread-2): 17:43:23 | 16 of 17 START test unique_stg_users_user_id......................... [RUN]
2020-10-26 17:43:23.584001 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_stg_users_user_id".
2020-10-26 17:43:23.586550 (Thread-2): Compiling test.dwelo.unique_stg_users_user_id
2020-10-26 17:43:23.603452 (Thread-2): Writing injected SQL for node "test.dwelo.unique_stg_users_user_id"
2020-10-26 17:43:23.611135 (Thread-2): finished collecting timing info
2020-10-26 17:43:23.613886 (Thread-2): Opening a new connection, currently in state closed
2020-10-26 17:43:23.616220 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:23.693601 (Thread-1): finished collecting timing info
2020-10-26 17:43:23.697331 (Thread-1): Database Error in test unique_dim_users_user_id (models/marts/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: 4af58dfd-6193-410f-9c50-4eb774082135)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_dim_users_user_id (models/marts/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_user_id.sql
2020-10-26 17:43:23.699736 (Thread-1): 17:43:23 | 13 of 17 ERROR unique_dim_users_user_id.............................. [ERROR in 2.29s]
2020-10-26 17:43:23.701629 (Thread-1): Finished running node test.dwelo.unique_dim_users_user_id
2020-10-26 17:43:23.703814 (Thread-1): Began running node test.dwelo.unique_stg_users_username
2020-10-26 17:43:23.706307 (Thread-1): 17:43:23 | 17 of 17 START test unique_stg_users_username........................ [RUN]
2020-10-26 17:43:23.708882 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_users_username".
2020-10-26 17:43:23.710621 (Thread-1): Compiling test.dwelo.unique_stg_users_username
2020-10-26 17:43:23.730917 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_users_username"
2020-10-26 17:43:23.738920 (Thread-1): finished collecting timing info
2020-10-26 17:43:23.741561 (Thread-1): Opening a new connection, currently in state closed
2020-10-26 17:43:23.743713 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-26 17:43:23.772792 (Thread-4): On test.dwelo.unique_met_daily_command_count_by_username_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_username_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-26 17:43:24.225412 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: username at [15:11]')
2020-10-26 17:43:24.241966 (Thread-2): On test.dwelo.unique_stg_users_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        user_id

    from `analytics-interview`.`dev_sam`.`stg_users`
    where user_id is not null
    group by user_id
    having count(*) > 1

) validation_errors



2020-10-26 17:43:24.325791 (Thread-1): On test.dwelo.unique_stg_users_username: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_username"} */

    
    



select count(*) as validation_errors
from (

    select
        username

    from `analytics-interview`.`dev_sam`.`stg_users`
    where username is not null
    group by username
    having count(*) > 1

) validation_errors



2020-10-26 17:43:24.730940 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [15:11]')
2020-10-26 17:43:24.789880 (Thread-4): finished collecting timing info
2020-10-26 17:43:24.795349 (Thread-4): Database Error in test unique_met_daily_command_count_by_username_username (models/marts/schema.yml)
  Unrecognized name: username at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_met_daily_command_count_by_username_username.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: username at [15:11]

(job ID: 2de4979b-9f75-405a-880d-0af7086f3523)

                                                                        -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_met_daily_command_count_by_username_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`met_daily_command_count_by_username`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_met_daily_command_count_by_username_username (models/marts/schema.yml)
  Unrecognized name: username at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_met_daily_command_count_by_username_username.sql
2020-10-26 17:43:24.799236 (Thread-4): 17:43:24 | 15 of 17 ERROR unique_met_daily_command_count_by_username_username... [ERROR in 1.68s]
2020-10-26 17:43:24.801981 (Thread-4): Finished running node test.dwelo.unique_met_daily_command_count_by_username_username
2020-10-26 17:43:24.837078 (Thread-3): finished collecting timing info
2020-10-26 17:43:24.840558 (Thread-3): Database Error in test unique_dim_users_username (models/marts/schema.yml)
  Unrecognized name: username at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_username.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: username at [15:11]

(job ID: 135316ad-a7c4-4b70-a749-51d19abae5ab)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_dim_users_username"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        username
  13:
  14:    from `analytics-interview`.`dev_sam`.`dim_users`
  15:    where username is not null
  16:    group by username
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_dim_users_username (models/marts/schema.yml)
  Unrecognized name: username at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_username.sql
2020-10-26 17:43:24.843697 (Thread-3): 17:43:24 | 14 of 17 ERROR unique_dim_users_username............................. [ERROR in 2.33s]
2020-10-26 17:43:24.845307 (Thread-3): Finished running node test.dwelo.unique_dim_users_username
2020-10-26 17:43:25.753823 (Thread-1): finished collecting timing info
2020-10-26 17:43:25.758175 (Thread-1): 17:43:25 | 17 of 17 PASS unique_stg_users_username.............................. [PASS in 2.05s]
2020-10-26 17:43:25.760610 (Thread-1): Finished running node test.dwelo.unique_stg_users_username
2020-10-26 17:43:25.982239 (Thread-2): finished collecting timing info
2020-10-26 17:43:25.987728 (Thread-2): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [15:11]

(job ID: 13b037e2-ce21-4abe-8c4b-3e8c8c3534f7)

                                                           -----Query Job SQL Follows-----                                                           

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_users_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        user_id
  13:
  14:    from `analytics-interview`.`dev_sam`.`stg_users`
  15:    where user_id is not null
  16:    group by user_id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [15:11]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-26 17:43:25.991030 (Thread-2): 17:43:25 | 16 of 17 ERROR unique_stg_users_user_id.............................. [ERROR in 2.41s]
2020-10-26 17:43:25.993628 (Thread-2): Finished running node test.dwelo.unique_stg_users_user_id
2020-10-26 17:43:25.999390 (MainThread): Acquiring new bigquery connection "master".
2020-10-26 17:43:26.001920 (MainThread): 17:43:26 | 
2020-10-26 17:43:26.003889 (MainThread): 17:43:26 | Finished running 17 tests in 11.31s.
2020-10-26 17:43:26.005783 (MainThread): Connection 'master' was properly closed.
2020-10-26 17:43:26.007929 (MainThread): Connection 'test.dwelo.unique_stg_users_username' was properly closed.
2020-10-26 17:43:26.009560 (MainThread): Connection 'test.dwelo.unique_stg_users_user_id' was properly closed.
2020-10-26 17:43:26.011199 (MainThread): Connection 'test.dwelo.unique_dim_users_username' was properly closed.
2020-10-26 17:43:26.013184 (MainThread): Connection 'test.dwelo.unique_met_daily_command_count_by_username_username' was properly closed.
2020-10-26 17:43:26.085145 (MainThread): 
2020-10-26 17:43:26.086831 (MainThread): Completed with 14 errors and 0 warnings:
2020-10-26 17:43:26.089022 (MainThread): 
2020-10-26 17:43:26.091119 (MainThread): Compilation Error in test not_met_daily_command_count_by_username_num_of_successful_commands (models/marts/schema.yml)
2020-10-26 17:43:26.093257 (MainThread):   'test_not' is undefined
2020-10-26 17:43:26.095235 (MainThread): 
2020-10-26 17:43:26.098051 (MainThread): Database Error in test not_null_dim_users_user_id (models/marts/schema.yml)
2020-10-26 17:43:26.100075 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-26 17:43:26.103284 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_user_id.sql
2020-10-26 17:43:26.105774 (MainThread): 
2020-10-26 17:43:26.107697 (MainThread): Database Error in test not_null_dim_users_last_modified (models/marts/schema.yml)
2020-10-26 17:43:26.109682 (MainThread):   Unrecognized name: last_modified at [10:7]
2020-10-26 17:43:26.111776 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_last_modified.sql
2020-10-26 17:43:26.116293 (MainThread): 
2020-10-26 17:43:26.118964 (MainThread): Database Error in test not_null_dim_users_date_registered (models/marts/schema.yml)
2020-10-26 17:43:26.122262 (MainThread):   Unrecognized name: date_registered at [10:7]
2020-10-26 17:43:26.124853 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_date_registered.sql
2020-10-26 17:43:26.126738 (MainThread): 
2020-10-26 17:43:26.129027 (MainThread): Database Error in test not_null_dim_users_username (models/marts/schema.yml)
2020-10-26 17:43:26.132872 (MainThread):   Unrecognized name: username at [10:7]
2020-10-26 17:43:26.135506 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_dim_users_username.sql
2020-10-26 17:43:26.138075 (MainThread): 
2020-10-26 17:43:26.140395 (MainThread): Database Error in test not_null_met_daily_command_count_by_username_num_of_commands (models/marts/schema.yml)
2020-10-26 17:43:26.142137 (MainThread):   Unrecognized name: num_of_commands at [10:7]
2020-10-26 17:43:26.144273 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_num_of_commands.sql
2020-10-26 17:43:26.146887 (MainThread): 
2020-10-26 17:43:26.149110 (MainThread): Database Error in test not_null_met_daily_command_count_by_username_timestamp_date (models/marts/schema.yml)
2020-10-26 17:43:26.151365 (MainThread):   Unrecognized name: timestamp_date at [10:7]
2020-10-26 17:43:26.153403 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_timestamp_date.sql
2020-10-26 17:43:26.155320 (MainThread): 
2020-10-26 17:43:26.157251 (MainThread): Database Error in test not_null_met_daily_command_count_by_username_username (models/marts/schema.yml)
2020-10-26 17:43:26.159331 (MainThread):   Unrecognized name: username at [10:7]
2020-10-26 17:43:26.161101 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_met_daily_command_count_by_username_username.sql
2020-10-26 17:43:26.162789 (MainThread): 
2020-10-26 17:43:26.165074 (MainThread): Database Error in test not_null_stg_users_date_registered (models/staging/schema.yml)
2020-10-26 17:43:26.167334 (MainThread):   Unrecognized name: date_registered; Did you mean dateRegistered? at [10:7]
2020-10-26 17:43:26.169963 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_date_registered.sql
2020-10-26 17:43:26.172071 (MainThread): 
2020-10-26 17:43:26.173853 (MainThread): Database Error in test not_null_stg_users_user_id (models/staging/schema.yml)
2020-10-26 17:43:26.175704 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-26 17:43:26.177806 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_users_user_id.sql
2020-10-26 17:43:26.179637 (MainThread): 
2020-10-26 17:43:26.181975 (MainThread): Database Error in test unique_dim_users_user_id (models/marts/schema.yml)
2020-10-26 17:43:26.183709 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-26 17:43:26.185805 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_user_id.sql
2020-10-26 17:43:26.187681 (MainThread): 
2020-10-26 17:43:26.189406 (MainThread): Database Error in test unique_met_daily_command_count_by_username_username (models/marts/schema.yml)
2020-10-26 17:43:26.192350 (MainThread):   Unrecognized name: username at [15:11]
2020-10-26 17:43:26.194173 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_met_daily_command_count_by_username_username.sql
2020-10-26 17:43:26.196167 (MainThread): 
2020-10-26 17:43:26.198609 (MainThread): Database Error in test unique_dim_users_username (models/marts/schema.yml)
2020-10-26 17:43:26.200755 (MainThread):   Unrecognized name: username at [15:11]
2020-10-26 17:43:26.203001 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_dim_users_username.sql
2020-10-26 17:43:26.204882 (MainThread): 
2020-10-26 17:43:26.206678 (MainThread): Database Error in test unique_stg_users_user_id (models/staging/schema.yml)
2020-10-26 17:43:26.208382 (MainThread):   Unrecognized name: user_id at [15:11]
2020-10-26 17:43:26.211086 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_users_user_id.sql
2020-10-26 17:43:26.212895 (MainThread): 
Done. PASS=3 WARN=0 ERROR=14 SKIP=0 TOTAL=17
2020-10-26 17:43:26.215319 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff85994a910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8598dd310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8598dd7f0>]}
2020-10-26 17:43:26.217154 (MainThread): Flushing usage events
2020-10-27 19:00:20.300301 (MainThread): Running with dbt=0.18.0
2020-10-27 19:00:20.578153 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=True, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_two'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 19:00:20.588189 (MainThread): Tracking: tracking
2020-10-27 19:00:20.591819 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8580552b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff857350e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff857350e50>]}
2020-10-27 19:00:20.631200 (MainThread): Partial parsing not enabled
2020-10-27 19:00:20.637538 (MainThread): Parsing macros/etc.sql
2020-10-27 19:00:20.640944 (MainThread): Parsing macros/catalog.sql
2020-10-27 19:00:20.654802 (MainThread): Parsing macros/adapters.sql
2020-10-27 19:00:20.691018 (MainThread): Parsing macros/materializations/view.sql
2020-10-27 19:00:20.696835 (MainThread): Parsing macros/materializations/table.sql
2020-10-27 19:00:20.715366 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-27 19:00:20.738136 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-27 19:00:20.744717 (MainThread): Parsing macros/materializations/copy.sql
2020-10-27 19:00:20.753622 (MainThread): Parsing macros/materializations/seed.sql
2020-10-27 19:00:20.761137 (MainThread): Parsing macros/core.sql
2020-10-27 19:00:20.769998 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 19:00:20.787039 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 19:00:20.797883 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 19:00:20.810841 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 19:00:20.839733 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 19:00:20.871200 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 19:00:20.877582 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 19:00:20.933726 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 19:00:20.944967 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 19:00:20.950275 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 19:00:20.962402 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 19:00:21.001185 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 19:00:21.084218 (MainThread): Parsing macros/etc/query.sql
2020-10-27 19:00:21.087725 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 19:00:21.091589 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-27 19:00:21.095453 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 19:00:21.111826 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 19:00:21.117323 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 19:00:21.120728 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 19:00:21.124913 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 19:00:21.128807 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 19:00:21.135307 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 19:00:21.151237 (MainThread): Partial parsing not enabled
2020-10-27 19:00:21.267748 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-27 19:00:21.304249 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-27 19:00:21.325783 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-27 19:00:21.347521 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-27 19:00:21.373055 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-27 19:00:21.396885 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-27 19:00:21.424528 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-27 19:00:21.463486 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-27 19:00:21.486584 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-27 19:00:21.508538 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-27 19:00:21.532041 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-27 19:00:21.554311 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-27 19:00:22.847925 (MainThread): Found 7 models, 37 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-27 19:00:22.851643 (MainThread): The selector 'None' does not match any nodes and will be ignored
2020-10-27 19:00:22.856693 (MainThread): WARNING: Nothing to do. Try checking your model configs and model specification args
2020-10-27 19:00:22.859163 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff857102d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8570af2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8570af9a0>]}
2020-10-27 19:00:22.860955 (MainThread): Flushing usage events
2020-10-27 19:00:23.283804 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-27 19:00:30.637163 (MainThread): Running with dbt=0.18.0
2020-10-27 19:00:30.894959 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=True, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 19:00:30.900084 (MainThread): Tracking: tracking
2020-10-27 19:00:30.903653 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f047e91ad60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0480eeeeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f047e927070>]}
2020-10-27 19:00:30.941666 (MainThread): Partial parsing not enabled
2020-10-27 19:00:30.945615 (MainThread): Parsing macros/etc.sql
2020-10-27 19:00:30.949044 (MainThread): Parsing macros/catalog.sql
2020-10-27 19:00:30.963017 (MainThread): Parsing macros/adapters.sql
2020-10-27 19:00:30.999169 (MainThread): Parsing macros/materializations/view.sql
2020-10-27 19:00:31.005886 (MainThread): Parsing macros/materializations/table.sql
2020-10-27 19:00:31.023565 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-27 19:00:31.047255 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-27 19:00:31.052513 (MainThread): Parsing macros/materializations/copy.sql
2020-10-27 19:00:31.061817 (MainThread): Parsing macros/materializations/seed.sql
2020-10-27 19:00:31.068283 (MainThread): Parsing macros/core.sql
2020-10-27 19:00:31.076176 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 19:00:31.093434 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 19:00:31.103275 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 19:00:31.115814 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 19:00:31.144441 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 19:00:31.172880 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 19:00:31.178685 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 19:00:31.233889 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 19:00:31.245365 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 19:00:31.249795 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 19:00:31.263284 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 19:00:31.302075 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 19:00:31.385208 (MainThread): Parsing macros/etc/query.sql
2020-10-27 19:00:31.388255 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 19:00:31.392720 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-27 19:00:31.397167 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 19:00:31.414318 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 19:00:31.419183 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 19:00:31.421952 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 19:00:31.426705 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 19:00:31.431146 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 19:00:31.436832 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 19:00:31.450982 (MainThread): Partial parsing not enabled
2020-10-27 19:00:31.553409 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-27 19:00:31.586503 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-27 19:00:31.606262 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-27 19:00:31.627809 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-27 19:00:31.650135 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-27 19:00:31.673644 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-27 19:00:31.697083 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-27 19:00:31.732476 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-27 19:00:31.754218 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-27 19:00:31.773941 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-27 19:00:31.795328 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-27 19:00:31.815675 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-27 19:00:33.064512 (MainThread): Found 7 models, 37 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-27 19:00:33.069479 (MainThread): 
2020-10-27 19:00:33.072188 (MainThread): Acquiring new bigquery connection "master".
2020-10-27 19:00:33.147168 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-27 19:00:33.152017 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-27 19:00:33.155221 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:33.853096 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-27 19:00:34.338005 (MainThread): 19:00:34 | Concurrency: 4 threads (target='dev')
2020-10-27 19:00:34.340087 (MainThread): 19:00:34 | 
2020-10-27 19:00:34.400918 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-27 19:00:34.401227 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-27 19:00:34.401823 (Thread-3): Began running node test.dwelo.stg_commands_switch_state
2020-10-27 19:00:34.402369 (Thread-4): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:00:34.403158 (Thread-1): 19:00:34 | 1 of 5 START test stg_commands_locked_state.......................... [RUN]
2020-10-27 19:00:34.405238 (Thread-2): 19:00:34 | 2 of 5 START test stg_commands_pin_assignment........................ [RUN]
2020-10-27 19:00:34.406887 (Thread-3): 19:00:34 | 3 of 5 START test stg_commands_switch_state.......................... [RUN]
2020-10-27 19:00:34.408855 (Thread-4): 19:00:34 | 4 of 5 START test stg_commands_thermostat_mode....................... [RUN]
2020-10-27 19:00:34.411085 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-27 19:00:34.415656 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-27 19:00:34.418214 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-27 19:00:34.419714 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-27 19:00:34.421495 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-27 19:00:34.423796 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-27 19:00:34.425620 (Thread-3): Compiling test.dwelo.stg_commands_switch_state
2020-10-27 19:00:34.427880 (Thread-4): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:00:34.470163 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-27 19:00:34.474914 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-27 19:00:34.486499 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-27 19:00:34.499268 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-27 19:00:34.515676 (Thread-1): finished collecting timing info
2020-10-27 19:00:34.516786 (Thread-3): finished collecting timing info
2020-10-27 19:00:34.517138 (Thread-2): finished collecting timing info
2020-10-27 19:00:34.522756 (Thread-2): Opening a new connection, currently in state init
2020-10-27 19:00:34.519489 (Thread-4): finished collecting timing info
2020-10-27 19:00:34.525919 (Thread-4): Opening a new connection, currently in state init
2020-10-27 19:00:34.519260 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:00:34.530653 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:34.521074 (Thread-3): Opening a new connection, currently in state init
2020-10-27 19:00:34.528224 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:34.524776 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:34.541281 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:35.227398 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:00:35.242634 (Thread-4): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:00:35.262845 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:00:35.286438 (Thread-3): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:00:35.786627 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-27 19:00:35.811291 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-27 19:00:35.831993 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-27 19:00:35.872190 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:6]')
2020-10-27 19:00:36.856008 (Thread-2): finished collecting timing info
2020-10-27 19:00:36.860288 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:6]

(job ID: 05d0816b-f778-4627-b7ff-1e242bb6c529)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-27 19:00:36.866445 (Thread-2): 19:00:36 | 2 of 5 ERROR stg_commands_pin_assignment............................. [ERROR in 2.45s]
2020-10-27 19:00:36.868904 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-27 19:00:36.871922 (Thread-2): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:00:36.875037 (Thread-2): 19:00:36 | 5 of 5 START test stg_commands_thermostat_setpoint................... [RUN]
2020-10-27 19:00:36.877607 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-27 19:00:36.879804 (Thread-2): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:00:36.885648 (Thread-2): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 50316), raddr=('172.217.4.170', 443)>
2020-10-27 19:00:36.887758 (Thread-2): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55312), raddr=('142.250.68.10', 443)>
2020-10-27 19:00:36.901505 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-27 19:00:36.914210 (Thread-2): finished collecting timing info
2020-10-27 19:00:36.918001 (Thread-2): Opening a new connection, currently in state closed
2020-10-27 19:00:36.920250 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:00:37.069291 (Thread-1): finished collecting timing info
2020-10-27 19:00:37.072106 (Thread-1): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: 9ef7fe5c-9869-4395-a742-15e3cd76f81f)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-27 19:00:37.074175 (Thread-1): 19:00:37 | 1 of 5 ERROR stg_commands_locked_state............................... [ERROR in 2.66s]
2020-10-27 19:00:37.075668 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-27 19:00:37.089835 (Thread-3): finished collecting timing info
2020-10-27 19:00:37.092347 (Thread-3): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: ad016fa7-8be5-4b9c-a3ad-f7c8d7f5cab9)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-27 19:00:37.094062 (Thread-3): 19:00:37 | 3 of 5 ERROR stg_commands_switch_state............................... [ERROR in 2.68s]
2020-10-27 19:00:37.095476 (Thread-3): Finished running node test.dwelo.stg_commands_switch_state
2020-10-27 19:00:37.102244 (Thread-4): finished collecting timing info
2020-10-27 19:00:37.104424 (Thread-4): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 5cf261b6-f4c8-4dd2-96df-92694ce78517)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-27 19:00:37.106643 (Thread-4): 19:00:37 | 4 of 5 ERROR stg_commands_thermostat_mode............................ [ERROR in 2.69s]
2020-10-27 19:00:37.108130 (Thread-4): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:00:37.544739 (Thread-2): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:00:38.007612 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-27 19:00:39.103127 (Thread-2): finished collecting timing info
2020-10-27 19:00:39.108708 (Thread-2): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: d96f8e9e-74b2-4aab-93f3-4c4059411661)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-27 19:00:39.111178 (Thread-2): 19:00:39 | 5 of 5 ERROR stg_commands_thermostat_setpoint........................ [ERROR in 2.23s]
2020-10-27 19:00:39.113413 (Thread-2): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:00:39.119488 (MainThread): Acquiring new bigquery connection "master".
2020-10-27 19:00:39.122331 (MainThread): 19:00:39 | 
2020-10-27 19:00:39.123968 (MainThread): 19:00:39 | Finished running 5 tests in 6.05s.
2020-10-27 19:00:39.126097 (MainThread): Connection 'master' was properly closed.
2020-10-27 19:00:39.127696 (MainThread): Connection 'test.dwelo.stg_commands_locked_state' was properly closed.
2020-10-27 19:00:39.129237 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_setpoint' was properly closed.
2020-10-27 19:00:39.130398 (MainThread): Connection 'test.dwelo.stg_commands_switch_state' was properly closed.
2020-10-27 19:00:39.131674 (MainThread): Connection 'test.dwelo.stg_commands_thermostat_mode' was properly closed.
2020-10-27 19:00:39.160604 (MainThread): 
2020-10-27 19:00:39.162012 (MainThread): Completed with 5 errors and 0 warnings:
2020-10-27 19:00:39.163774 (MainThread): 
2020-10-27 19:00:39.165839 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-27 19:00:39.169433 (MainThread):   Unrecognized name: slot at [11:6]
2020-10-27 19:00:39.172335 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-27 19:00:39.175017 (MainThread): 
2020-10-27 19:00:39.177371 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-27 19:00:39.180467 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-27 19:00:39.185809 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-27 19:00:39.189825 (MainThread): 
2020-10-27 19:00:39.193326 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-27 19:00:39.197735 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-27 19:00:39.200353 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-27 19:00:39.203907 (MainThread): 
2020-10-27 19:00:39.207284 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-27 19:00:39.210814 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-27 19:00:39.214381 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-27 19:00:39.217414 (MainThread): 
2020-10-27 19:00:39.220900 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-27 19:00:39.223173 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-27 19:00:39.225169 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-27 19:00:39.226911 (MainThread): 
Done. PASS=0 WARN=0 ERROR=5 SKIP=0 TOTAL=5
2020-10-27 19:00:39.229368 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f047e66b4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f047e7f5b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f047e6a3130>]}
2020-10-27 19:00:39.232006 (MainThread): Flushing usage events
2020-10-27 19:02:26.684278 (MainThread): Running with dbt=0.18.0
2020-10-27 19:02:26.942712 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.test.TestTask'>, data=False, debug=False, defer=None, exclude=None, fail_fast=False, log_cache_events=False, log_format='default', models=['tag:part_one'], partial_parse=None, profile=None, profiles_dir='/usr/app/dbt', project_dir=None, record_timing_info=None, rpc_method='test', schema=False, selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='test', write_json=True)
2020-10-27 19:02:26.950384 (MainThread): Tracking: tracking
2020-10-27 19:02:26.955021 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868336ce20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f868593ff70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683378130>]}
2020-10-27 19:02:26.990801 (MainThread): Partial parsing not enabled
2020-10-27 19:02:26.994766 (MainThread): Parsing macros/etc.sql
2020-10-27 19:02:26.998598 (MainThread): Parsing macros/catalog.sql
2020-10-27 19:02:27.012573 (MainThread): Parsing macros/adapters.sql
2020-10-27 19:02:27.048269 (MainThread): Parsing macros/materializations/view.sql
2020-10-27 19:02:27.054640 (MainThread): Parsing macros/materializations/table.sql
2020-10-27 19:02:27.073219 (MainThread): Parsing macros/materializations/incremental.sql
2020-10-27 19:02:27.095714 (MainThread): Parsing macros/materializations/snapshot.sql
2020-10-27 19:02:27.100710 (MainThread): Parsing macros/materializations/copy.sql
2020-10-27 19:02:27.109223 (MainThread): Parsing macros/materializations/seed.sql
2020-10-27 19:02:27.116307 (MainThread): Parsing macros/core.sql
2020-10-27 19:02:27.124514 (MainThread): Parsing macros/materializations/helpers.sql
2020-10-27 19:02:27.141380 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-10-27 19:02:27.151223 (MainThread): Parsing macros/materializations/view/view.sql
2020-10-27 19:02:27.164276 (MainThread): Parsing macros/materializations/common/merge.sql
2020-10-27 19:02:27.191498 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-10-27 19:02:27.221959 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-10-27 19:02:27.226446 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-10-27 19:02:27.280939 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-10-27 19:02:27.293009 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-10-27 19:02:27.298517 (MainThread): Parsing macros/materializations/table/table.sql
2020-10-27 19:02:27.310555 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-10-27 19:02:27.350250 (MainThread): Parsing macros/adapters/common.sql
2020-10-27 19:02:27.440757 (MainThread): Parsing macros/etc/query.sql
2020-10-27 19:02:27.443762 (MainThread): Parsing macros/etc/is_incremental.sql
2020-10-27 19:02:27.448106 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-10-27 19:02:27.452218 (MainThread): Parsing macros/etc/datetime.sql
2020-10-27 19:02:27.468792 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-10-27 19:02:27.473687 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-10-27 19:02:27.476533 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-10-27 19:02:27.481462 (MainThread): Parsing macros/schema_tests/unique.sql
2020-10-27 19:02:27.485533 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-10-27 19:02:27.491039 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-10-27 19:02:27.505201 (MainThread): Partial parsing not enabled
2020-10-27 19:02:27.606113 (MainThread): Acquiring new bigquery connection "model.dwelo.dim_users".
2020-10-27 19:02:27.641325 (MainThread): Acquiring new bigquery connection "model.dwelo.fct_command_statuses".
2020-10-27 19:02:27.662395 (MainThread): Acquiring new bigquery connection "model.dwelo.met_daily_command_count_by_username".
2020-10-27 19:02:27.683166 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_actives".
2020-10-27 19:02:27.706048 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_command_results".
2020-10-27 19:02:27.730577 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_commands".
2020-10-27 19:02:27.754223 (MainThread): Acquiring new bigquery connection "model.dwelo.stg_users".
2020-10-27 19:02:27.790231 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-27 19:02:27.812298 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-27 19:02:27.833031 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-27 19:02:27.853529 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-27 19:02:27.874539 (MainThread): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-27 19:02:29.132354 (MainThread): Found 7 models, 37 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 2 sources
2020-10-27 19:02:29.138098 (MainThread): 
2020-10-27 19:02:29.140425 (MainThread): Acquiring new bigquery connection "master".
2020-10-27 19:02:29.247402 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_analytics-interview_dev_sam".
2020-10-27 19:02:29.250443 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-10-27 19:02:29.256175 (ThreadPoolExecutor-1_0): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:30.085516 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-10-27 19:02:30.712294 (MainThread): 19:02:30 | Concurrency: 4 threads (target='dev')
2020-10-27 19:02:30.716339 (MainThread): 19:02:30 | 
2020-10-27 19:02:30.782989 (Thread-1): Began running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-27 19:02:30.783370 (Thread-2): Began running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-27 19:02:30.784058 (Thread-3): Began running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-27 19:02:30.784811 (Thread-4): Began running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-27 19:02:30.786034 (Thread-1): 19:02:30 | 1 of 20 START test not_null_fct_command_statuses_command_uuid........ [RUN]
2020-10-27 19:02:30.788895 (Thread-2): 19:02:30 | 2 of 20 START test not_null_stg_command_actives_command_uuid......... [RUN]
2020-10-27 19:02:30.791341 (Thread-3): 19:02:30 | 3 of 20 START test not_null_stg_command_actives_update_timestamp..... [RUN]
2020-10-27 19:02:30.793713 (Thread-4): 19:02:30 | 4 of 20 START test not_null_stg_command_results_command_uuid......... [RUN]
2020-10-27 19:02:30.797755 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_fct_command_statuses_command_uuid".
2020-10-27 19:02:30.800910 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_command_uuid".
2020-10-27 19:02:30.802760 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_actives_update_timestamp".
2020-10-27 19:02:30.806316 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_command_uuid".
2020-10-27 19:02:30.816366 (Thread-4): Compiling test.dwelo.not_null_stg_command_results_command_uuid
2020-10-27 19:02:30.811599 (Thread-2): Compiling test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-27 19:02:30.813756 (Thread-3): Compiling test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-27 19:02:30.809555 (Thread-1): Compiling test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-27 19:02:30.875263 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_command_uuid"
2020-10-27 19:02:30.880394 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_command_uuid"
2020-10-27 19:02:30.882912 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_actives_update_timestamp"
2020-10-27 19:02:30.897408 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_fct_command_statuses_command_uuid"
2020-10-27 19:02:30.909706 (Thread-2): finished collecting timing info
2020-10-27 19:02:30.914409 (Thread-2): Opening a new connection, currently in state init
2020-10-27 19:02:30.910571 (Thread-4): finished collecting timing info
2020-10-27 19:02:30.916983 (Thread-3): finished collecting timing info
2020-10-27 19:02:30.920397 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:30.923338 (Thread-4): Opening a new connection, currently in state init
2020-10-27 19:02:30.927568 (Thread-3): Opening a new connection, currently in state init
2020-10-27 19:02:30.928268 (Thread-1): finished collecting timing info
2020-10-27 19:02:30.938531 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:30.941617 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:30.944477 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:02:30.958153 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:31.735664 (Thread-2): On test.dwelo.not_null_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where command_uuid is null



2020-10-27 19:02:31.890373 (Thread-4): On test.dwelo.not_null_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where command_uuid is null



2020-10-27 19:02:31.938810 (Thread-3): On test.dwelo.not_null_stg_command_actives_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_actives_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_actives`
where update_timestamp is null



2020-10-27 19:02:31.959966 (Thread-1): On test.dwelo.not_null_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`fct_command_statuses`
where command_uuid is null



2020-10-27 19:02:32.575242 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [10:7]')
2020-10-27 19:02:33.402397 (Thread-2): finished collecting timing info
2020-10-27 19:02:33.406387 (Thread-2): 19:02:33 | 2 of 20 PASS not_null_stg_command_actives_command_uuid............... [PASS in 2.61s]
2020-10-27 19:02:33.410107 (Thread-2): Finished running node test.dwelo.not_null_stg_command_actives_command_uuid
2020-10-27 19:02:33.421474 (Thread-2): Began running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-27 19:02:33.424827 (Thread-2): 19:02:33 | 5 of 20 START test not_null_stg_command_results_is_hub_success....... [RUN]
2020-10-27 19:02:33.427589 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_is_hub_success".
2020-10-27 19:02:33.430881 (Thread-2): Compiling test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-27 19:02:33.460973 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_is_hub_success"
2020-10-27 19:02:33.468314 (Thread-2): finished collecting timing info
2020-10-27 19:02:33.471309 (Thread-2): Opening a new connection, currently in state closed
2020-10-27 19:02:33.472952 (Thread-3): finished collecting timing info
2020-10-27 19:02:33.475018 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:33.480438 (Thread-3): 19:02:33 | 3 of 20 PASS not_null_stg_command_actives_update_timestamp........... [PASS in 2.68s]
2020-10-27 19:02:33.489743 (Thread-3): Finished running node test.dwelo.not_null_stg_command_actives_update_timestamp
2020-10-27 19:02:33.491755 (Thread-3): Began running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-27 19:02:33.493967 (Thread-3): 19:02:33 | 6 of 20 START test not_null_stg_command_results_update_timestamp..... [RUN]
2020-10-27 19:02:33.496795 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_command_results_update_timestamp".
2020-10-27 19:02:33.498796 (Thread-3): Compiling test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-27 19:02:33.519106 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_command_results_update_timestamp"
2020-10-27 19:02:33.526880 (Thread-3): finished collecting timing info
2020-10-27 19:02:33.529003 (Thread-3): Opening a new connection, currently in state closed
2020-10-27 19:02:33.530730 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:33.672169 (Thread-4): finished collecting timing info
2020-10-27 19:02:33.675208 (Thread-4): 19:02:33 | 4 of 20 PASS not_null_stg_command_results_command_uuid............... [PASS in 2.87s]
2020-10-27 19:02:33.677053 (Thread-4): Finished running node test.dwelo.not_null_stg_command_results_command_uuid
2020-10-27 19:02:33.679414 (Thread-4): Began running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-27 19:02:33.681729 (Thread-4): 19:02:33 | 7 of 20 START test not_null_stg_commands__raw_desired_state.......... [RUN]
2020-10-27 19:02:33.684524 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands__raw_desired_state".
2020-10-27 19:02:33.687087 (Thread-4): Compiling test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-27 19:02:33.706219 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands__raw_desired_state"
2020-10-27 19:02:33.724208 (Thread-4): finished collecting timing info
2020-10-27 19:02:33.727457 (Thread-4): Opening a new connection, currently in state closed
2020-10-27 19:02:33.730769 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:33.836949 (Thread-1): finished collecting timing info
2020-10-27 19:02:33.840105 (Thread-1): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [10:7]

(job ID: a108071b-de6f-4bf6-889b-fa31e2187d12)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  10:where command_uuid is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [10:7]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-27 19:02:33.846903 (Thread-1): 19:02:33 | 1 of 20 ERROR not_null_fct_command_statuses_command_uuid............. [ERROR in 3.05s]
2020-10-27 19:02:33.849370 (Thread-1): Finished running node test.dwelo.not_null_fct_command_statuses_command_uuid
2020-10-27 19:02:33.851984 (Thread-1): Began running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-27 19:02:33.855577 (Thread-1): 19:02:33 | 8 of 20 START test not_null_stg_commands_command_uuid................ [RUN]
2020-10-27 19:02:33.858934 (Thread-1): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_command_uuid".
2020-10-27 19:02:33.861327 (Thread-1): Compiling test.dwelo.not_null_stg_commands_command_uuid
2020-10-27 19:02:33.889407 (Thread-1): Writing injected SQL for node "test.dwelo.not_null_stg_commands_command_uuid"
2020-10-27 19:02:33.896470 (Thread-1): finished collecting timing info
2020-10-27 19:02:33.899304 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:02:33.902295 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:34.246721 (Thread-2): On test.dwelo.not_null_stg_command_results_is_hub_success: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_is_hub_success"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where is_hub_success is null



2020-10-27 19:02:34.280002 (Thread-3): On test.dwelo.not_null_stg_command_results_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_command_results_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_command_results`
where update_timestamp is null



2020-10-27 19:02:34.471837 (Thread-4): On test.dwelo.not_null_stg_commands__raw_desired_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where _raw_desired_state is null



2020-10-27 19:02:34.634920 (Thread-1): On test.dwelo.not_null_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where command_uuid is null



2020-10-27 19:02:35.073735 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: _raw_desired_state at [10:7]')
2020-10-27 19:02:35.742863 (Thread-2): finished collecting timing info
2020-10-27 19:02:35.749764 (Thread-2): 19:02:35 | 5 of 20 PASS not_null_stg_command_results_is_hub_success............. [PASS in 2.32s]
2020-10-27 19:02:35.751841 (Thread-2): Finished running node test.dwelo.not_null_stg_command_results_is_hub_success
2020-10-27 19:02:35.755198 (Thread-2): Began running node test.dwelo.not_null_stg_commands_device_id
2020-10-27 19:02:35.757848 (Thread-2): 19:02:35 | 9 of 20 START test not_null_stg_commands_device_id................... [RUN]
2020-10-27 19:02:35.759906 (Thread-2): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_device_id".
2020-10-27 19:02:35.762137 (Thread-2): Compiling test.dwelo.not_null_stg_commands_device_id
2020-10-27 19:02:35.781266 (Thread-2): Writing injected SQL for node "test.dwelo.not_null_stg_commands_device_id"
2020-10-27 19:02:35.788692 (Thread-2): finished collecting timing info
2020-10-27 19:02:35.791654 (Thread-2): Opening a new connection, currently in state closed
2020-10-27 19:02:35.793415 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:35.858031 (Thread-4): finished collecting timing info
2020-10-27 19:02:35.862004 (Thread-4): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: _raw_desired_state at [10:7]

(job ID: e7334b9d-c225-4c68-b4c6-3444af617a29)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands__raw_desired_state"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where _raw_desired_state is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
  Unrecognized name: _raw_desired_state at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-27 19:02:35.865691 (Thread-4): 19:02:35 | 7 of 20 ERROR not_null_stg_commands__raw_desired_state............... [ERROR in 2.18s]
2020-10-27 19:02:35.868056 (Thread-4): Finished running node test.dwelo.not_null_stg_commands__raw_desired_state
2020-10-27 19:02:35.871234 (Thread-4): Began running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-27 19:02:35.874542 (Thread-4): 19:02:35 | 10 of 20 START test not_null_stg_commands_update_timestamp........... [RUN]
2020-10-27 19:02:35.878273 (Thread-4): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_update_timestamp".
2020-10-27 19:02:35.881675 (Thread-4): Compiling test.dwelo.not_null_stg_commands_update_timestamp
2020-10-27 19:02:35.906381 (Thread-4): Writing injected SQL for node "test.dwelo.not_null_stg_commands_update_timestamp"
2020-10-27 19:02:35.914041 (Thread-4): finished collecting timing info
2020-10-27 19:02:35.916669 (Thread-4): Opening a new connection, currently in state closed
2020-10-27 19:02:35.919047 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:35.973763 (Thread-3): finished collecting timing info
2020-10-27 19:02:35.977867 (Thread-3): 19:02:35 | 6 of 20 PASS not_null_stg_command_results_update_timestamp........... [PASS in 2.48s]
2020-10-27 19:02:35.980361 (Thread-3): Finished running node test.dwelo.not_null_stg_command_results_update_timestamp
2020-10-27 19:02:35.982652 (Thread-3): Began running node test.dwelo.not_null_stg_commands_user_id
2020-10-27 19:02:35.984973 (Thread-3): 19:02:35 | 11 of 20 START test not_null_stg_commands_user_id.................... [RUN]
2020-10-27 19:02:35.988537 (Thread-3): Acquiring new bigquery connection "test.dwelo.not_null_stg_commands_user_id".
2020-10-27 19:02:35.991917 (Thread-3): Compiling test.dwelo.not_null_stg_commands_user_id
2020-10-27 19:02:36.006716 (Thread-3): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44406), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:36.009436 (Thread-3): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44408), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:36.011951 (Thread-3): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55352), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:36.015052 (Thread-3): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55346), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:36.017363 (Thread-3): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55348), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:36.019523 (Thread-3): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44414), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:36.032519 (Thread-3): Writing injected SQL for node "test.dwelo.not_null_stg_commands_user_id"
2020-10-27 19:02:36.040988 (Thread-3): finished collecting timing info
2020-10-27 19:02:36.043785 (Thread-3): Opening a new connection, currently in state closed
2020-10-27 19:02:36.046033 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:36.087911 (Thread-1): finished collecting timing info
2020-10-27 19:02:36.091998 (Thread-1): 19:02:36 | 8 of 20 PASS not_null_stg_commands_command_uuid...................... [PASS in 2.23s]
2020-10-27 19:02:36.094254 (Thread-1): Finished running node test.dwelo.not_null_stg_commands_command_uuid
2020-10-27 19:02:36.096315 (Thread-1): Began running node test.dwelo.stg_commands_locked_state
2020-10-27 19:02:36.098366 (Thread-1): 19:02:36 | 12 of 20 START test stg_commands_locked_state........................ [RUN]
2020-10-27 19:02:36.100878 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_locked_state".
2020-10-27 19:02:36.102960 (Thread-1): Compiling test.dwelo.stg_commands_locked_state
2020-10-27 19:02:36.133765 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_locked_state"
2020-10-27 19:02:36.141219 (Thread-1): finished collecting timing info
2020-10-27 19:02:36.143745 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:02:36.146342 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:36.571048 (Thread-2): On test.dwelo.not_null_stg_commands_device_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_device_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where device_id is null



2020-10-27 19:02:36.749916 (Thread-4): On test.dwelo.not_null_stg_commands_update_timestamp: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_update_timestamp"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where update_timestamp is null



2020-10-27 19:02:36.932954 (Thread-3): On test.dwelo.not_null_stg_commands_user_id: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */

    
    



select count(*) as validation_errors
from `analytics-interview`.`dev_sam`.`stg_commands`
where user_id is null



2020-10-27 19:02:37.003960 (Thread-1): On test.dwelo.stg_commands_locked_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('LockedState')
  and (
    lock_state is null
    or lock_state NOT IN ('locked', 'unlocked')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:02:37.487250 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: lock_state at [11:5]')
2020-10-27 19:02:37.558416 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: user_id at [10:7]')
2020-10-27 19:02:38.135382 (Thread-2): finished collecting timing info
2020-10-27 19:02:38.140769 (Thread-2): 19:02:38 | 9 of 20 PASS not_null_stg_commands_device_id......................... [PASS in 2.38s]
2020-10-27 19:02:38.143497 (Thread-2): Finished running node test.dwelo.not_null_stg_commands_device_id
2020-10-27 19:02:38.146176 (Thread-2): Began running node test.dwelo.stg_commands_pin_assignment
2020-10-27 19:02:38.148452 (Thread-2): 19:02:38 | 13 of 20 START test stg_commands_pin_assignment...................... [RUN]
2020-10-27 19:02:38.151130 (Thread-2): Acquiring new bigquery connection "test.dwelo.stg_commands_pin_assignment".
2020-10-27 19:02:38.153525 (Thread-2): Compiling test.dwelo.stg_commands_pin_assignment
2020-10-27 19:02:38.171857 (Thread-2): Writing injected SQL for node "test.dwelo.stg_commands_pin_assignment"
2020-10-27 19:02:38.178999 (Thread-2): finished collecting timing info
2020-10-27 19:02:38.181380 (Thread-2): Opening a new connection, currently in state closed
2020-10-27 19:02:38.183381 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:38.517689 (Thread-4): finished collecting timing info
2020-10-27 19:02:38.530268 (Thread-4): 19:02:38 | 10 of 20 PASS not_null_stg_commands_update_timestamp................. [PASS in 2.65s]
2020-10-27 19:02:38.537066 (Thread-3): finished collecting timing info
2020-10-27 19:02:38.540268 (Thread-4): Finished running node test.dwelo.not_null_stg_commands_update_timestamp
2020-10-27 19:02:38.543081 (Thread-3): Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: user_id at [10:7]

(job ID: 8793a417-c18f-4e99-9d3c-f78d92d3a186)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.not_null_stg_commands_user_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `analytics-interview`.`dev_sam`.`stg_commands`
  10:where user_id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
  Unrecognized name: user_id at [10:7]
  compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-27 19:02:38.547566 (Thread-4): Began running node test.dwelo.stg_commands_switch_state
2020-10-27 19:02:38.551335 (Thread-3): 19:02:38 | 11 of 20 ERROR not_null_stg_commands_user_id......................... [ERROR in 2.56s]
2020-10-27 19:02:38.553809 (Thread-4): 19:02:38 | 14 of 20 START test stg_commands_switch_state........................ [RUN]
2020-10-27 19:02:38.556629 (Thread-3): Finished running node test.dwelo.not_null_stg_commands_user_id
2020-10-27 19:02:38.563584 (Thread-4): Acquiring new bigquery connection "test.dwelo.stg_commands_switch_state".
2020-10-27 19:02:38.566696 (Thread-3): Began running node test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:02:38.570922 (Thread-4): Compiling test.dwelo.stg_commands_switch_state
2020-10-27 19:02:38.574312 (Thread-3): 19:02:38 | 15 of 20 START test stg_commands_thermostat_mode..................... [RUN]
2020-10-27 19:02:38.604971 (Thread-3): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_mode".
2020-10-27 19:02:38.629606 (Thread-4): Writing injected SQL for node "test.dwelo.stg_commands_switch_state"
2020-10-27 19:02:38.631110 (Thread-3): Compiling test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:02:38.652593 (Thread-3): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_mode"
2020-10-27 19:02:38.652914 (Thread-4): finished collecting timing info
2020-10-27 19:02:38.656935 (Thread-4): Opening a new connection, currently in state closed
2020-10-27 19:02:38.658982 (Thread-3): finished collecting timing info
2020-10-27 19:02:38.660124 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:38.662027 (Thread-3): Opening a new connection, currently in state closed
2020-10-27 19:02:38.671653 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:38.751053 (Thread-1): finished collecting timing info
2020-10-27 19:02:38.756020 (Thread-1): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: lock_state at [11:5]

(job ID: d3a69e14-4e58-494d-b674-e99f150680e1)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_locked_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('LockedState')
  10:  and (
  11:    lock_state is null
  12:    or lock_state NOT IN ('locked', 'unlocked')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
  Unrecognized name: lock_state at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-27 19:02:38.761535 (Thread-1): 19:02:38 | 12 of 20 ERROR stg_commands_locked_state............................. [ERROR in 2.66s]
2020-10-27 19:02:38.764342 (Thread-1): Finished running node test.dwelo.stg_commands_locked_state
2020-10-27 19:02:38.772023 (Thread-1): Began running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:02:38.775596 (Thread-1): 19:02:38 | 16 of 20 START test stg_commands_thermostat_setpoint................. [RUN]
2020-10-27 19:02:38.778982 (Thread-1): Acquiring new bigquery connection "test.dwelo.stg_commands_thermostat_setpoint".
2020-10-27 19:02:38.781301 (Thread-1): Compiling test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:02:38.803737 (Thread-1): Writing injected SQL for node "test.dwelo.stg_commands_thermostat_setpoint"
2020-10-27 19:02:38.811053 (Thread-1): finished collecting timing info
2020-10-27 19:02:38.814466 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:02:38.816822 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:38.965060 (Thread-2): On test.dwelo.stg_commands_pin_assignment: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('PinAssignment')
  and (
    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:02:39.458298 (Thread-4): On test.dwelo.stg_commands_switch_state: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('SwitchState')
  and (
      switch_state is null
      or switch_state not in ('on', 'off')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:02:39.483211 (Thread-3): On test.dwelo.stg_commands_thermostat_mode: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatMode')
  and (
    thermostat_mode is null
    or thermostat_set_point NOT IN (
      'cool'
      ,'settocool'
      ,'heat'
      ,'off'
      ,'operatingstate'
      ,'settoheat'
      ,'auto'
    )
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:02:39.526548 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: slot at [11:6]')
2020-10-27 19:02:39.632216 (Thread-1): On test.dwelo.stg_commands_thermostat_setpoint: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */

with dbt__CTE__INTERNAL_test as (
select
  command_uuid
from
  `analytics-interview`.`dev_sam`.`stg_commands`
where
  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  and thermostat_set_point is null
  and (
    thermostat_set_point IS NULL
    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  )
limit 1
)select count(*) from dbt__CTE__INTERNAL_test
2020-10-27 19:02:40.052034 (Thread-4): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: switch_state at [11:7]')
2020-10-27 19:02:40.083494 (Thread-3): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_mode at [11:5]')
2020-10-27 19:02:40.087961 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: thermostat_set_point at [10:7]')
2020-10-27 19:02:40.840154 (Thread-2): finished collecting timing info
2020-10-27 19:02:40.847073 (Thread-2): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: slot at [11:6]

(job ID: 296e91f6-3aa1-4f1a-a8d1-e9b22f8c8068)

                                                            -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_pin_assignment"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('PinAssignment')
  10:  and (
  11:    (slot IS NULL or NOT REGEXP_CONTAINS(slot, '^([0-9]{1,3}|None)$'))
  12:    or NOT REGEXP_CONTAINS(pin, '^([0-9]{4,5}|None)$')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
  Unrecognized name: slot at [11:6]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-27 19:02:40.850071 (Thread-2): 19:02:40 | 13 of 20 ERROR stg_commands_pin_assignment........................... [ERROR in 2.70s]
2020-10-27 19:02:40.852978 (Thread-2): Finished running node test.dwelo.stg_commands_pin_assignment
2020-10-27 19:02:40.856229 (Thread-2): Began running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-27 19:02:40.858932 (Thread-2): 19:02:40 | 17 of 20 START test unique_fct_command_statuses_command_uuid......... [RUN]
2020-10-27 19:02:40.862467 (Thread-2): Acquiring new bigquery connection "test.dwelo.unique_fct_command_statuses_command_uuid".
2020-10-27 19:02:40.864946 (Thread-2): Compiling test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-27 19:02:40.875331 (Thread-2): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55360), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:40.880108 (Thread-2): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44422), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:40.882915 (Thread-2): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44430), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:40.886460 (Thread-2): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44432), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:40.889115 (Thread-2): unclosed <socket.socket fd=25, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55370), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:40.891978 (Thread-2): unclosed <socket.socket fd=26, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55372), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:40.894935 (Thread-2): unclosed <socket.socket fd=31, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 55376), raddr=('142.250.68.10', 443)>
2020-10-27 19:02:40.897473 (Thread-2): unclosed <socket.socket fd=27, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.20.0.2', 44438), raddr=('142.250.72.234', 443)>
2020-10-27 19:02:40.910205 (Thread-2): Writing injected SQL for node "test.dwelo.unique_fct_command_statuses_command_uuid"
2020-10-27 19:02:40.917604 (Thread-2): finished collecting timing info
2020-10-27 19:02:40.920007 (Thread-2): Opening a new connection, currently in state closed
2020-10-27 19:02:40.922060 (Thread-2): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:41.326155 (Thread-4): finished collecting timing info
2020-10-27 19:02:41.330030 (Thread-4): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: switch_state at [11:7]

(job ID: 19652bff-9701-4d95-87ae-9ffe2a9cfabc)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_switch_state"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('SwitchState')
  10:  and (
  11:      switch_state is null
  12:      or switch_state not in ('on', 'off')
  13:  )
  14:limit 1
  15:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
  Unrecognized name: switch_state at [11:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-27 19:02:41.332488 (Thread-4): 19:02:41 | 14 of 20 ERROR stg_commands_switch_state............................. [ERROR in 2.77s]
2020-10-27 19:02:41.334421 (Thread-4): Finished running node test.dwelo.stg_commands_switch_state
2020-10-27 19:02:41.336460 (Thread-4): Began running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-27 19:02:41.337989 (Thread-4): 19:02:41 | 18 of 20 START test unique_stg_command_actives_command_uuid.......... [RUN]
2020-10-27 19:02:41.340226 (Thread-4): Acquiring new bigquery connection "test.dwelo.unique_stg_command_actives_command_uuid".
2020-10-27 19:02:41.342375 (Thread-4): Compiling test.dwelo.unique_stg_command_actives_command_uuid
2020-10-27 19:02:41.368537 (Thread-4): Writing injected SQL for node "test.dwelo.unique_stg_command_actives_command_uuid"
2020-10-27 19:02:41.369749 (Thread-3): finished collecting timing info
2020-10-27 19:02:41.374839 (Thread-3): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_mode at [11:5]

(job ID: 2442ce46-7932-470a-b3c9-c694150dd27f)

                                                             -----Query Job SQL Follows-----                                                             

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_mode"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatMode')
  10:  and (
  11:    thermostat_mode is null
  12:    or thermostat_set_point NOT IN (
  13:      'cool'
  14:      ,'settocool'
  15:      ,'heat'
  16:      ,'off'
  17:      ,'operatingstate'
  18:      ,'settoheat'
  19:      ,'auto'
  20:    )
  21:  )
  22:limit 1
  23:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
  Unrecognized name: thermostat_mode at [11:5]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-27 19:02:41.379980 (Thread-3): 19:02:41 | 15 of 20 ERROR stg_commands_thermostat_mode.......................... [ERROR in 2.78s]
2020-10-27 19:02:41.380556 (Thread-4): finished collecting timing info
2020-10-27 19:02:41.383919 (Thread-3): Finished running node test.dwelo.stg_commands_thermostat_mode
2020-10-27 19:02:41.385695 (Thread-4): Opening a new connection, currently in state closed
2020-10-27 19:02:41.389214 (Thread-3): Began running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-27 19:02:41.393111 (Thread-4): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:41.395232 (Thread-3): 19:02:41 | 19 of 20 START test unique_stg_command_results_command_uuid.......... [RUN]
2020-10-27 19:02:41.406812 (Thread-3): Acquiring new bigquery connection "test.dwelo.unique_stg_command_results_command_uuid".
2020-10-27 19:02:41.409367 (Thread-3): Compiling test.dwelo.unique_stg_command_results_command_uuid
2020-10-27 19:02:41.439595 (Thread-3): Writing injected SQL for node "test.dwelo.unique_stg_command_results_command_uuid"
2020-10-27 19:02:41.452957 (Thread-3): finished collecting timing info
2020-10-27 19:02:41.456734 (Thread-3): Opening a new connection, currently in state closed
2020-10-27 19:02:41.465384 (Thread-3): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:41.503053 (Thread-1): finished collecting timing info
2020-10-27 19:02:41.511507 (Thread-1): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: thermostat_set_point at [10:7]

(job ID: f90d7ee2-0ec5-4173-b54c-badbe0ea11a2)

                                                               -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.stg_commands_thermostat_setpoint"} */
   2:
   3:with dbt__CTE__INTERNAL_test as (
   4:select
   5:  command_uuid
   6:from
   7:  `analytics-interview`.`dev_sam`.`stg_commands`
   8:where
   9:  command IN ('ThermostatHeatSetPoint', 'ThermostatCoolSetPoint')
  10:  and thermostat_set_point is null
  11:  and (
  12:    thermostat_set_point IS NULL
  13:    or NOT REGEXP_CONTAINS(thermostat_set_point, '^([0-9]{1,3}\\.?[0-9]{1,3})$')
  14:  )
  15:limit 1
  16:)select count(*) from dbt__CTE__INTERNAL_test
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 82, in execute
    failed_rows = self.execute_data_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 44, in execute_data_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
  Unrecognized name: thermostat_set_point at [10:7]
  compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-27 19:02:41.518108 (Thread-1): 19:02:41 | 16 of 20 ERROR stg_commands_thermostat_setpoint...................... [ERROR in 2.74s]
2020-10-27 19:02:41.522903 (Thread-1): Finished running node test.dwelo.stg_commands_thermostat_setpoint
2020-10-27 19:02:41.527202 (Thread-1): Began running node test.dwelo.unique_stg_commands_command_uuid
2020-10-27 19:02:41.530383 (Thread-1): 19:02:41 | 20 of 20 START test unique_stg_commands_command_uuid................. [RUN]
2020-10-27 19:02:41.534259 (Thread-1): Acquiring new bigquery connection "test.dwelo.unique_stg_commands_command_uuid".
2020-10-27 19:02:41.537651 (Thread-1): Compiling test.dwelo.unique_stg_commands_command_uuid
2020-10-27 19:02:41.577288 (Thread-1): Writing injected SQL for node "test.dwelo.unique_stg_commands_command_uuid"
2020-10-27 19:02:41.588499 (Thread-1): finished collecting timing info
2020-10-27 19:02:41.592804 (Thread-1): Opening a new connection, currently in state closed
2020-10-27 19:02:41.600772 (Thread-1): Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a "quota exceeded" or "API not enabled" error. We recommend you rerun `gcloud auth application-default login` and make sure a quota project is added. Or you can use service accounts instead. For more information about service accounts, see https://cloud.google.com/docs/authentication/
2020-10-27 19:02:41.699229 (Thread-2): On test.dwelo.unique_fct_command_statuses_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-27 19:02:42.124010 (Thread-2): Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: command_uuid at [15:11]')
2020-10-27 19:02:42.233120 (Thread-4): On test.dwelo.unique_stg_command_actives_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_actives_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_actives`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-27 19:02:42.294569 (Thread-3): On test.dwelo.unique_stg_command_results_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_command_results_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_command_results`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-27 19:02:42.369601 (Thread-1): On test.dwelo.unique_stg_commands_command_uuid: /* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_stg_commands_command_uuid"} */

    
    



select count(*) as validation_errors
from (

    select
        command_uuid

    from `analytics-interview`.`dev_sam`.`stg_commands`
    where command_uuid is not null
    group by command_uuid
    having count(*) > 1

) validation_errors



2020-10-27 19:02:43.402383 (Thread-2): finished collecting timing info
2020-10-27 19:02:43.406838 (Thread-2): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 3207, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job.py", line 812, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.8/site-packages/google/api_core/future/polling.py", line 127, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Unrecognized name: command_uuid at [15:11]

(job ID: f0d962eb-7901-4722-b7a0-45158e56adef)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.0", "profile_name": "default", "target_name": "dev", "node_id": "test.dwelo.unique_fct_command_statuses_command_uuid"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        command_uuid
  13:
  14:    from `analytics-interview`.`dev_sam`.`fct_command_statuses`
  15:    where command_uuid is not null
  16:    group by command_uuid
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.8/site-packages/dbt/task/test.py", line 61, in execute_schema_test
    res, table = self.adapter.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 224, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 442, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 107, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 95, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
  Unrecognized name: command_uuid at [15:11]
  compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-27 19:02:43.410261 (Thread-2): 19:02:43 | 17 of 20 ERROR unique_fct_command_statuses_command_uuid.............. [ERROR in 2.55s]
2020-10-27 19:02:43.413347 (Thread-2): Finished running node test.dwelo.unique_fct_command_statuses_command_uuid
2020-10-27 19:02:43.752789 (Thread-3): finished collecting timing info
2020-10-27 19:02:43.755814 (Thread-3): 19:02:43 | 19 of 20 FAIL 144 unique_stg_command_results_command_uuid............ [FAIL 144 in 2.35s]
2020-10-27 19:02:43.758511 (Thread-3): Finished running node test.dwelo.unique_stg_command_results_command_uuid
2020-10-27 19:02:43.872089 (Thread-1): finished collecting timing info
2020-10-27 19:02:43.875942 (Thread-1): 19:02:43 | 20 of 20 FAIL 112 unique_stg_commands_command_uuid................... [FAIL 112 in 2.34s]
2020-10-27 19:02:43.878375 (Thread-1): Finished running node test.dwelo.unique_stg_commands_command_uuid
2020-10-27 19:02:43.977330 (Thread-4): finished collecting timing info
2020-10-27 19:02:43.982547 (Thread-4): 19:02:43 | 18 of 20 FAIL 145 unique_stg_command_actives_command_uuid............ [FAIL 145 in 2.64s]
2020-10-27 19:02:43.984796 (Thread-4): Finished running node test.dwelo.unique_stg_command_actives_command_uuid
2020-10-27 19:02:43.989543 (MainThread): Acquiring new bigquery connection "master".
2020-10-27 19:02:43.991471 (MainThread): 19:02:43 | 
2020-10-27 19:02:43.992991 (MainThread): 19:02:43 | Finished running 20 tests in 14.85s.
2020-10-27 19:02:43.994698 (MainThread): Connection 'master' was properly closed.
2020-10-27 19:02:43.997760 (MainThread): Connection 'test.dwelo.unique_stg_commands_command_uuid' was properly closed.
2020-10-27 19:02:43.999677 (MainThread): Connection 'test.dwelo.unique_fct_command_statuses_command_uuid' was properly closed.
2020-10-27 19:02:44.001433 (MainThread): Connection 'test.dwelo.unique_stg_command_results_command_uuid' was properly closed.
2020-10-27 19:02:44.003286 (MainThread): Connection 'test.dwelo.unique_stg_command_actives_command_uuid' was properly closed.
2020-10-27 19:02:44.089695 (MainThread): 
2020-10-27 19:02:44.091756 (MainThread): Completed with 12 errors and 0 warnings:
2020-10-27 19:02:44.093834 (MainThread): 
2020-10-27 19:02:44.097104 (MainThread): Database Error in test not_null_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-27 19:02:44.099507 (MainThread):   Unrecognized name: command_uuid at [10:7]
2020-10-27 19:02:44.102193 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/not_null_fct_command_statuses_command_uuid.sql
2020-10-27 19:02:44.104980 (MainThread): 
2020-10-27 19:02:44.106731 (MainThread): Database Error in test not_null_stg_commands__raw_desired_state (models/staging/schema.yml)
2020-10-27 19:02:44.109169 (MainThread):   Unrecognized name: _raw_desired_state at [10:7]
2020-10-27 19:02:44.112271 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands__raw_desired_state.sql
2020-10-27 19:02:44.116009 (MainThread): 
2020-10-27 19:02:44.118911 (MainThread): Database Error in test not_null_stg_commands_user_id (models/staging/schema.yml)
2020-10-27 19:02:44.121588 (MainThread):   Unrecognized name: user_id at [10:7]
2020-10-27 19:02:44.123822 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/not_null_stg_commands_user_id.sql
2020-10-27 19:02:44.126061 (MainThread): 
2020-10-27 19:02:44.128086 (MainThread): Database Error in test stg_commands_locked_state (tests/staging/commands/stg_commands_locked_state.sql)
2020-10-27 19:02:44.130968 (MainThread):   Unrecognized name: lock_state at [11:5]
2020-10-27 19:02:44.133912 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_locked_state.sql
2020-10-27 19:02:44.136167 (MainThread): 
2020-10-27 19:02:44.138345 (MainThread): Database Error in test stg_commands_pin_assignment (tests/staging/commands/stg_commands_pin_assignment.sql)
2020-10-27 19:02:44.140660 (MainThread):   Unrecognized name: slot at [11:6]
2020-10-27 19:02:44.142958 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_pin_assignment.sql
2020-10-27 19:02:44.145149 (MainThread): 
2020-10-27 19:02:44.147516 (MainThread): Database Error in test stg_commands_switch_state (tests/staging/commands/stg_commands_switch_state.sql)
2020-10-27 19:02:44.150404 (MainThread):   Unrecognized name: switch_state at [11:7]
2020-10-27 19:02:44.152241 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_switch_state.sql
2020-10-27 19:02:44.154222 (MainThread): 
2020-10-27 19:02:44.156246 (MainThread): Database Error in test stg_commands_thermostat_mode (tests/staging/commands/stg_commands_thermostat_mode.sql)
2020-10-27 19:02:44.158218 (MainThread):   Unrecognized name: thermostat_mode at [11:5]
2020-10-27 19:02:44.160090 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_mode.sql
2020-10-27 19:02:44.162048 (MainThread): 
2020-10-27 19:02:44.165561 (MainThread): Database Error in test stg_commands_thermostat_setpoint (tests/staging/commands/stg_commands_thermostat_setpoint.sql)
2020-10-27 19:02:44.167775 (MainThread):   Unrecognized name: thermostat_set_point at [10:7]
2020-10-27 19:02:44.170667 (MainThread):   compiled SQL at target/compiled/dwelo/tests/staging/commands/stg_commands_thermostat_setpoint.sql
2020-10-27 19:02:44.172574 (MainThread): 
2020-10-27 19:02:44.174582 (MainThread): Database Error in test unique_fct_command_statuses_command_uuid (models/marts/schema.yml)
2020-10-27 19:02:44.176318 (MainThread):   Unrecognized name: command_uuid at [15:11]
2020-10-27 19:02:44.178358 (MainThread):   compiled SQL at target/compiled/dwelo/models/marts/schema.yml/schema_test/unique_fct_command_statuses_command_uuid.sql
2020-10-27 19:02:44.181170 (MainThread): 
2020-10-27 19:02:44.183493 (MainThread): Failure in test unique_stg_command_results_command_uuid (models/staging/schema.yml)
2020-10-27 19:02:44.185253 (MainThread):   Got 144 results, expected 0.
2020-10-27 19:02:44.186997 (MainThread): 
2020-10-27 19:02:44.188583 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_command_results_command_uuid.sql
2020-10-27 19:02:44.191128 (MainThread): 
2020-10-27 19:02:44.192962 (MainThread): Failure in test unique_stg_commands_command_uuid (models/staging/schema.yml)
2020-10-27 19:02:44.194894 (MainThread):   Got 112 results, expected 0.
2020-10-27 19:02:44.197996 (MainThread): 
2020-10-27 19:02:44.200461 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_commands_command_uuid.sql
2020-10-27 19:02:44.203873 (MainThread): 
2020-10-27 19:02:44.207411 (MainThread): Failure in test unique_stg_command_actives_command_uuid (models/staging/schema.yml)
2020-10-27 19:02:44.210148 (MainThread):   Got 145 results, expected 0.
2020-10-27 19:02:44.213351 (MainThread): 
2020-10-27 19:02:44.216302 (MainThread):   compiled SQL at target/compiled/dwelo/models/staging/schema.yml/schema_test/unique_stg_command_actives_command_uuid.sql
2020-10-27 19:02:44.218842 (MainThread): 
Done. PASS=8 WARN=0 ERROR=12 SKIP=0 TOTAL=20
2020-10-27 19:02:44.224447 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8682fc6130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8683288d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f86831c7f10>]}
2020-10-27 19:02:44.227156 (MainThread): Flushing usage events
